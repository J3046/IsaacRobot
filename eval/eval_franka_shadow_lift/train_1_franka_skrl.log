################################################################################
                        [1m Learning iteration 1/1 [0m                        

                       Computation: 478964 steps/s (collection: 0.021s, learning 0.185s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 0.21s
                      Time elapsed: 00:00:01
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 2/1 [0m                        

                       Computation: 1163254 steps/s (collection: 0.021s, learning 0.064s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 0.08s
                      Time elapsed: 00:00:02
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 3/1 [0m                        

                       Computation: 1068136 steps/s (collection: 0.021s, learning 0.071s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 0.09s
                      Time elapsed: 00:00:02
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 4/1 [0m                        

                       Computation: 1149622 steps/s (collection: 0.021s, learning 0.065s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 0.09s
                      Time elapsed: 00:00:03
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 5/1 [0m                        

                       Computation: 1008011 steps/s (collection: 0.022s, learning 0.076s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 0.10s
                      Time elapsed: 00:00:03
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 6/1 [0m                        

                       Computation: 1116984 steps/s (collection: 0.022s, learning 0.067s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 0.09s
                      Time elapsed: 00:00:04
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 7/1 [0m                        

                       Computation: 1097801 steps/s (collection: 0.021s, learning 0.069s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 0.09s
                      Time elapsed: 00:00:05
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 8/1 [0m                        

                       Computation: 1102516 steps/s (collection: 0.022s, learning 0.067s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 0.09s
                      Time elapsed: 00:00:05
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 9/1 [0m                        

                       Computation: 1020177 steps/s (collection: 0.025s, learning 0.071s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 0.10s
                      Time elapsed: 00:00:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 10/1 [0m                        

                       Computation: 1029253 steps/s (collection: 0.023s, learning 0.073s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 0.10s
                      Time elapsed: 00:00:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 11/1 [0m                        

                       Computation: 1116711 steps/s (collection: 0.020s, learning 0.069s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object -0.0002
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.0227
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2560.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 0.09s
                      Time elapsed: 00:00:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 12/1 [0m                        

                       Computation: 1032661 steps/s (collection: 0.027s, learning 0.068s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object -0.0004
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0363
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 0.10s
                      Time elapsed: 00:00:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 13/1 [0m                        

                       Computation: 1129827 steps/s (collection: 0.022s, learning 0.065s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object -0.0004
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0363
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 0.09s
                      Time elapsed: 00:00:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 14/1 [0m                        

                       Computation: 1029202 steps/s (collection: 0.023s, learning 0.073s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object -0.0004
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0363
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 0.10s
                      Time elapsed: 00:00:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 15/1 [0m                        

                       Computation: 1152395 steps/s (collection: 0.023s, learning 0.062s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object -0.0004
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0363
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 0.09s
                      Time elapsed: 00:00:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 16/1 [0m                        

                       Computation: 1110480 steps/s (collection: 0.026s, learning 0.062s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object -0.0004
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0363
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 0.09s
                      Time elapsed: 00:00:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 17/1 [0m                        

                       Computation: 1123506 steps/s (collection: 0.023s, learning 0.064s)
                       Mean reward: 0.26
               Mean episode length: 148.50
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object -0.0001
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.0467
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 1536.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 0.09s
                      Time elapsed: 00:00:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 18/1 [0m                        

                       Computation: 1062579 steps/s (collection: 0.025s, learning 0.068s)
                       Mean reward: 0.26
               Mean episode length: 148.50
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.0578
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 0.09s
                      Time elapsed: 00:00:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 19/1 [0m                        

                       Computation: 1116920 steps/s (collection: 0.025s, learning 0.063s)
                       Mean reward: 0.40
               Mean episode length: 190.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.0767
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 0.09s
                      Time elapsed: 00:00:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 20/1 [0m                        

                       Computation: 993510 steps/s (collection: 0.024s, learning 0.074s)
                       Mean reward: 8.60
               Mean episode length: 217.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 0.9333
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.0921
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 0.10s
                      Time elapsed: 00:00:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 21/1 [0m                        

                       Computation: 1058267 steps/s (collection: 0.026s, learning 0.067s)
                       Mean reward: 1.63
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 0.5033
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.1477
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 851.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 0.09s
                      Time elapsed: 00:00:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 22/1 [0m                        

                       Computation: 892020 steps/s (collection: 0.024s, learning 0.087s)
                       Mean reward: 1.63
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.1758
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.1510
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4086.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 0.11s
                      Time elapsed: 00:00:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 23/1 [0m                        

                       Computation: 931275 steps/s (collection: 0.027s, learning 0.079s)
                       Mean reward: 1.63
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.1758
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.1510
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4086.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 0.11s
                      Time elapsed: 00:00:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 24/1 [0m                        

                       Computation: 915017 steps/s (collection: 0.028s, learning 0.079s)
                       Mean reward: 4.19
               Mean episode length: 69.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 0.3839
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1136
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 2724.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 0.11s
                      Time elapsed: 00:00:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 25/1 [0m                        

                       Computation: 889198 steps/s (collection: 0.029s, learning 0.082s)
                       Mean reward: 0.39
               Mean episode length: 88.77
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0008
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0007
     Episode_Reward/reaching_object 0.0768
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 0.11s
                      Time elapsed: 00:00:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 26/1 [0m                        

                       Computation: 833003 steps/s (collection: 0.031s, learning 0.087s)
                       Mean reward: 3.68
               Mean episode length: 112.64
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0011
      Episode_Reward/lifting_object 0.6222
       Episode_Reward/object_height 0.0009
     Episode_Reward/reaching_object 0.1111
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 0.12s
                      Time elapsed: 00:00:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 27/1 [0m                        

                       Computation: 821201 steps/s (collection: 0.034s, learning 0.086s)
                       Mean reward: 2.10
               Mean episode length: 146.71
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 0.1667
       Episode_Reward/object_height 0.0012
     Episode_Reward/reaching_object 0.1213
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 0.12s
                      Time elapsed: 00:00:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 28/1 [0m                        

                       Computation: 1056136 steps/s (collection: 0.030s, learning 0.064s)
                       Mean reward: 8.71
               Mean episode length: 162.38
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 1.8833
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1612
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 0.09s
                      Time elapsed: 00:00:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 29/1 [0m                        

                       Computation: 789437 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 2.97
               Mean episode length: 192.62
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 0.3833
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1994
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 0.12s
                      Time elapsed: 00:00:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 30/1 [0m                        

                       Computation: 1012175 steps/s (collection: 0.028s, learning 0.069s)
                       Mean reward: 3.50
               Mean episode length: 211.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 0.9667
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2217
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 0.10s
                      Time elapsed: 00:00:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 31/1 [0m                        

                       Computation: 1052478 steps/s (collection: 0.031s, learning 0.062s)
                       Mean reward: 3.06
               Mean episode length: 234.05
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 0.3167
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2561
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 0.09s
                      Time elapsed: 00:00:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 32/1 [0m                        

                       Computation: 1004218 steps/s (collection: 0.024s, learning 0.074s)
                       Mean reward: 4.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.6205
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2460
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 3146.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 0.10s
                      Time elapsed: 00:00:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 33/1 [0m                        

                       Computation: 989065 steps/s (collection: 0.026s, learning 0.074s)
                       Mean reward: 4.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.6259
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2365
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3974.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 0.10s
                      Time elapsed: 00:00:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 34/1 [0m                        

                       Computation: 1015048 steps/s (collection: 0.026s, learning 0.071s)
                       Mean reward: 0.20
               Mean episode length: 55.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0011
      Episode_Reward/lifting_object 0.1825
       Episode_Reward/object_height 0.0009
     Episode_Reward/reaching_object 0.0967
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 1159.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 0.10s
                      Time elapsed: 00:00:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 35/1 [0m                        

                       Computation: 861868 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 10.03
               Mean episode length: 190.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0013
      Episode_Reward/lifting_object 1.0833
       Episode_Reward/object_height 0.0012
     Episode_Reward/reaching_object 0.1366
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 0.11s
                      Time elapsed: 00:00:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 36/1 [0m                        

                       Computation: 846139 steps/s (collection: 0.043s, learning 0.074s)
                       Mean reward: 3.84
               Mean episode length: 200.96
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 0.2750
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.1962
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 0.12s
                      Time elapsed: 00:00:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 37/1 [0m                        

                       Computation: 844198 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 5.32
               Mean episode length: 208.94
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 0.6556
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2267
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 0.12s
                      Time elapsed: 00:00:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 38/1 [0m                        

                       Computation: 744611 steps/s (collection: 0.030s, learning 0.102s)
                       Mean reward: 5.53
               Mean episode length: 237.58
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 0.4417
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2493
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 0.13s
                      Time elapsed: 00:00:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 39/1 [0m                        

                       Computation: 846964 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 5.29
               Mean episode length: 226.04
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 0.7889
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2212
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 0.12s
                      Time elapsed: 00:00:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 40/1 [0m                        

                       Computation: 885543 steps/s (collection: 0.035s, learning 0.077s)
                       Mean reward: 8.87
               Mean episode length: 214.03
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 1.1222
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2326
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 0.11s
                      Time elapsed: 00:00:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 41/1 [0m                        

                       Computation: 931993 steps/s (collection: 0.033s, learning 0.073s)
                       Mean reward: 5.66
               Mean episode length: 237.85
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 1.0056
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2543
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 0.11s
                      Time elapsed: 00:00:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 42/1 [0m                        

                       Computation: 869316 steps/s (collection: 0.026s, learning 0.088s)
                       Mean reward: 6.07
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 0.4991
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2311
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 1463.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 0.11s
                      Time elapsed: 00:00:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 43/1 [0m                        

                       Computation: 887720 steps/s (collection: 0.029s, learning 0.081s)
                       Mean reward: 6.07
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.9575
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2626
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3900.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 0.11s
                      Time elapsed: 00:00:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 44/1 [0m                        

                       Computation: 861405 steps/s (collection: 0.029s, learning 0.085s)
                       Mean reward: 4.82
               Mean episode length: 170.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 0.6530
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1514
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 488.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 0.11s
                      Time elapsed: 00:00:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 45/1 [0m                        

                       Computation: 813297 steps/s (collection: 0.034s, learning 0.087s)
                       Mean reward: 11.51
               Mean episode length: 192.25
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 2.5444
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1949
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 0.12s
                      Time elapsed: 00:00:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 46/1 [0m                        

                       Computation: 867962 steps/s (collection: 0.028s, learning 0.085s)
                       Mean reward: 5.75
               Mean episode length: 196.95
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 1.3667
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.2015
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 0.11s
                      Time elapsed: 00:00:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 47/1 [0m                        

                       Computation: 925938 steps/s (collection: 0.029s, learning 0.077s)
                       Mean reward: 11.51
               Mean episode length: 213.55
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 2.1583
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2379
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 0.11s
                      Time elapsed: 00:00:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 48/1 [0m                        

                       Computation: 806966 steps/s (collection: 0.032s, learning 0.090s)
                       Mean reward: 11.85
               Mean episode length: 203.23
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 2.4028
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.2050
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 0.12s
                      Time elapsed: 00:00:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 49/1 [0m                        

                       Computation: 863161 steps/s (collection: 0.033s, learning 0.081s)
                       Mean reward: 8.34
               Mean episode length: 227.56
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 1.5144
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2513
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 0.11s
                      Time elapsed: 00:00:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 50/1 [0m                        

                       Computation: 791661 steps/s (collection: 0.034s, learning 0.090s)
                       Mean reward: 9.22
               Mean episode length: 234.53
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 1.9667
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2601
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 0.12s
                      Time elapsed: 00:00:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 51/1 [0m                        

                       Computation: 897615 steps/s (collection: 0.033s, learning 0.077s)
                       Mean reward: 11.17
               Mean episode length: 236.69
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 1.7667
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2582
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 0.11s
                      Time elapsed: 00:00:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 52/1 [0m                        

                       Computation: 905965 steps/s (collection: 0.033s, learning 0.075s)
                       Mean reward: 11.87
               Mean episode length: 243.43
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 1.9250
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2582
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 0.11s
                      Time elapsed: 00:00:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 53/1 [0m                        

                       Computation: 761701 steps/s (collection: 0.028s, learning 0.101s)
                       Mean reward: 13.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 2.5136
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2847
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 3659.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 0.13s
                      Time elapsed: 00:00:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 54/1 [0m                        

                       Computation: 861004 steps/s (collection: 0.027s, learning 0.087s)
                       Mean reward: 1.37
               Mean episode length: 209.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 1.3454
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2869
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 2069.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 0.11s
                      Time elapsed: 00:00:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 55/1 [0m                        

                       Computation: 854388 steps/s (collection: 0.034s, learning 0.081s)
                       Mean reward: 8.86
               Mean episode length: 162.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 1.8067
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1621
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 0.12s
                      Time elapsed: 00:00:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 56/1 [0m                        

                       Computation: 833972 steps/s (collection: 0.034s, learning 0.084s)
                       Mean reward: 8.17
               Mean episode length: 154.57
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 1.7167
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1740
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 0.12s
                      Time elapsed: 00:00:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 57/1 [0m                        

                       Computation: 954236 steps/s (collection: 0.034s, learning 0.069s)
                       Mean reward: 8.46
               Mean episode length: 180.88
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 1.3909
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2365
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 0.10s
                      Time elapsed: 00:00:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 58/1 [0m                        

                       Computation: 819112 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 18.38
               Mean episode length: 212.38
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 4.0928
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2715
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 0.12s
                      Time elapsed: 00:00:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 59/1 [0m                        

                       Computation: 930447 steps/s (collection: 0.026s, learning 0.079s)
                       Mean reward: 22.95
               Mean episode length: 220.12
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 4.1432
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2787
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 0.11s
                      Time elapsed: 00:00:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 60/1 [0m                        

                       Computation: 910358 steps/s (collection: 0.033s, learning 0.075s)
                       Mean reward: 18.25
               Mean episode length: 225.67
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 3.3833
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2728
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 0.11s
                      Time elapsed: 00:00:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 61/1 [0m                        

                       Computation: 949710 steps/s (collection: 0.033s, learning 0.071s)
                       Mean reward: 18.53
               Mean episode length: 223.62
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 3.5467
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2708
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 0.10s
                      Time elapsed: 00:00:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 62/1 [0m                        

                       Computation: 836763 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 18.18
               Mean episode length: 240.73
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 3.1633
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2953
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 0.12s
                      Time elapsed: 00:00:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 63/1 [0m                        

                       Computation: 895163 steps/s (collection: 0.030s, learning 0.080s)
                       Mean reward: 19.70
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 2.6964
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2828
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 1975.9167
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 0.11s
                      Time elapsed: 00:00:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 64/1 [0m                        

                       Computation: 845379 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 17.51
               Mean episode length: 134.67
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0009
      Episode_Reward/lifting_object 0.8333
       Episode_Reward/object_height 0.0007
     Episode_Reward/reaching_object 0.1062
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 0.12s
                      Time elapsed: 00:00:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 65/1 [0m                        

                       Computation: 800108 steps/s (collection: 0.034s, learning 0.089s)
                       Mean reward: 11.46
               Mean episode length: 168.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 1.6222
       Episode_Reward/object_height 0.0015
     Episode_Reward/reaching_object 0.1713
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 0.12s
                      Time elapsed: 00:00:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 66/1 [0m                        

                       Computation: 777536 steps/s (collection: 0.033s, learning 0.093s)
                       Mean reward: 15.06
               Mean episode length: 178.40
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 2.4306
       Episode_Reward/object_height 0.0015
     Episode_Reward/reaching_object 0.1776
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 0.13s
                      Time elapsed: 00:00:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 67/1 [0m                        

                       Computation: 857567 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 20.14
               Mean episode length: 193.21
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 3.5578
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.2198
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 0.11s
                      Time elapsed: 00:00:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 68/1 [0m                        

                       Computation: 712276 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 21.11
               Mean episode length: 206.09
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 3.4913
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2364
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 0.14s
                      Time elapsed: 00:00:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 69/1 [0m                        

                       Computation: 808451 steps/s (collection: 0.033s, learning 0.088s)
                       Mean reward: 23.81
               Mean episode length: 208.90
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 4.1850
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2354
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 0.12s
                      Time elapsed: 00:00:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 70/1 [0m                        

                       Computation: 742121 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 25.93
               Mean episode length: 221.05
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 5.0539
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2526
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 0.13s
                      Time elapsed: 00:00:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 71/1 [0m                        

                       Computation: 934763 steps/s (collection: 0.033s, learning 0.072s)
                       Mean reward: 26.71
               Mean episode length: 227.86
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 4.6331
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2732
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 0.11s
                      Time elapsed: 00:00:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 72/1 [0m                        

                       Computation: 894895 steps/s (collection: 0.037s, learning 0.072s)
                       Mean reward: 31.11
               Mean episode length: 240.77
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 6.0592
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2973
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 0.11s
                      Time elapsed: 00:00:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 73/1 [0m                        

                       Computation: 997112 steps/s (collection: 0.024s, learning 0.075s)
                       Mean reward: 30.81
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 5.2520
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2910
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 431.6250
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 0.10s
                      Time elapsed: 00:01:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 74/1 [0m                        

                       Computation: 628003 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 23.68
               Mean episode length: 166.50
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 4.8785
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.2179
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 572.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 0.16s
                      Time elapsed: 00:01:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 75/1 [0m                        

                       Computation: 655220 steps/s (collection: 0.051s, learning 0.100s)
                       Mean reward: 21.66
               Mean episode length: 183.79
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 4.0944
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2411
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 0.15s
                      Time elapsed: 00:01:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 76/1 [0m                        

                       Computation: 756677 steps/s (collection: 0.035s, learning 0.095s)
                       Mean reward: 23.81
               Mean episode length: 193.37
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 4.5706
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.2242
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 0.13s
                      Time elapsed: 00:01:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 77/1 [0m                        

                       Computation: 730809 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 35.74
               Mean episode length: 225.97
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 6.3901
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2655
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 0.13s
                      Time elapsed: 00:01:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 78/1 [0m                        

                       Computation: 788032 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 33.33
               Mean episode length: 220.63
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 5.9489
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2581
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 0.12s
                      Time elapsed: 00:01:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 79/1 [0m                        

                       Computation: 701223 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 37.45
               Mean episode length: 225.77
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 7.3987
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2734
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 0.14s
                      Time elapsed: 00:01:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 80/1 [0m                        

                       Computation: 677850 steps/s (collection: 0.048s, learning 0.097s)
                       Mean reward: 33.74
               Mean episode length: 223.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 6.6483
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2618
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 0.15s
                      Time elapsed: 00:01:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 81/1 [0m                        

                       Computation: 764766 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 36.23
               Mean episode length: 222.56
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 6.8715
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2660
Episode_Termination/object_dropping 2.1667
       Episode_Termination/time_out 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 0.13s
                      Time elapsed: 00:01:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 82/1 [0m                        

                       Computation: 712558 steps/s (collection: 0.035s, learning 0.102s)
                       Mean reward: 34.85
               Mean episode length: 233.63
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 6.6780
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2782
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 0.14s
                      Time elapsed: 00:01:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 83/1 [0m                        

                       Computation: 825978 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 38.45
               Mean episode length: 242.61
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 7.3655
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2908
Episode_Termination/object_dropping 1.9167
       Episode_Termination/time_out 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 0.12s
                      Time elapsed: 00:01:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 84/1 [0m                        

                       Computation: 884249 steps/s (collection: 0.028s, learning 0.084s)
                       Mean reward: 40.39
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 7.2910
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2158
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 663.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 0.11s
                      Time elapsed: 00:01:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 85/1 [0m                        

                       Computation: 851027 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 39.31
               Mean episode length: 207.43
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 6.9333
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2634
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 0.12s
                      Time elapsed: 00:01:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 86/1 [0m                        

                       Computation: 407876 steps/s (collection: 0.055s, learning 0.186s)
                       Mean reward: 33.23
               Mean episode length: 196.16
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 6.2533
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2207
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 0.24s
                      Time elapsed: 00:01:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 87/1 [0m                        

                       Computation: 747455 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 35.06
               Mean episode length: 198.27
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 6.5548
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2321
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 0.13s
                      Time elapsed: 00:01:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 88/1 [0m                        

                       Computation: 798563 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 38.74
               Mean episode length: 198.92
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 7.6218
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2351
Episode_Termination/object_dropping 2.2917
       Episode_Termination/time_out 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 0.12s
                      Time elapsed: 00:01:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 89/1 [0m                        

                       Computation: 826572 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 40.06
               Mean episode length: 195.11
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 7.4656
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2259
Episode_Termination/object_dropping 2.6667
       Episode_Termination/time_out 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 0.12s
                      Time elapsed: 00:01:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 90/1 [0m                        

                       Computation: 829449 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 42.59
               Mean episode length: 210.68
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 8.2360
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2565
Episode_Termination/object_dropping 3.3333
       Episode_Termination/time_out 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 0.12s
                      Time elapsed: 00:01:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 91/1 [0m                        

                       Computation: 675726 steps/s (collection: 0.036s, learning 0.110s)
                       Mean reward: 41.87
               Mean episode length: 214.28
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 8.2063
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2586
Episode_Termination/object_dropping 3.2500
       Episode_Termination/time_out 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 0.15s
                      Time elapsed: 00:01:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 92/1 [0m                        

                       Computation: 918785 steps/s (collection: 0.035s, learning 0.072s)
                       Mean reward: 44.33
               Mean episode length: 230.55
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 8.4783
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2772
Episode_Termination/object_dropping 2.4167
       Episode_Termination/time_out 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 0.11s
                      Time elapsed: 00:01:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 93/1 [0m                        

                       Computation: 833000 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 44.00
               Mean episode length: 234.85
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 8.4020
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2841
Episode_Termination/object_dropping 3.2500
       Episode_Termination/time_out 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 0.12s
                      Time elapsed: 00:01:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 94/1 [0m                        

                       Computation: 568169 steps/s (collection: 0.051s, learning 0.122s)
                       Mean reward: 47.79
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 7.6813
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2654
Episode_Termination/object_dropping 3.0833
       Episode_Termination/time_out 118.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 0.17s
                      Time elapsed: 00:01:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 95/1 [0m                        

                       Computation: 583334 steps/s (collection: 0.046s, learning 0.123s)
                       Mean reward: 41.15
               Mean episode length: 193.12
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 8.7944
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2334
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 0.17s
                      Time elapsed: 00:01:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 96/1 [0m                        

                       Computation: 728113 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 42.42
               Mean episode length: 217.41
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 8.9625
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2511
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 0.14s
                      Time elapsed: 00:01:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 97/1 [0m                        

                       Computation: 620130 steps/s (collection: 0.042s, learning 0.117s)
                       Mean reward: 44.61
               Mean episode length: 206.28
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 8.3304
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2431
Episode_Termination/object_dropping 1.9583
       Episode_Termination/time_out 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 0.16s
                      Time elapsed: 00:01:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 98/1 [0m                        

                       Computation: 624106 steps/s (collection: 0.043s, learning 0.115s)
                       Mean reward: 40.22
               Mean episode length: 204.93
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 8.0113
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2441
Episode_Termination/object_dropping 2.4583
       Episode_Termination/time_out 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 0.16s
                      Time elapsed: 00:01:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 99/1 [0m                        

                       Computation: 546004 steps/s (collection: 0.055s, learning 0.126s)
                       Mean reward: 44.59
               Mean episode length: 205.36
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 8.7403
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2474
Episode_Termination/object_dropping 2.9167
       Episode_Termination/time_out 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 0.18s
                      Time elapsed: 00:01:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 100/1 [0m                       

                       Computation: 783241 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 50.64
               Mean episode length: 210.57
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 9.8566
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2527
Episode_Termination/object_dropping 3.6667
       Episode_Termination/time_out 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 0.13s
                      Time elapsed: 00:01:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 101/1 [0m                       

                       Computation: 775677 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 49.61
               Mean episode length: 215.41
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 9.6423
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2611
Episode_Termination/object_dropping 4.4167
       Episode_Termination/time_out 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 0.13s
                      Time elapsed: 00:01:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 102/1 [0m                       

                       Computation: 666977 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 52.49
               Mean episode length: 222.53
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 10.3194
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2707
Episode_Termination/object_dropping 4.8333
       Episode_Termination/time_out 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 0.15s
                      Time elapsed: 00:01:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 103/1 [0m                       

                       Computation: 789845 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 58.50
               Mean episode length: 225.07
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 11.3832
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2743
Episode_Termination/object_dropping 5.0417
       Episode_Termination/time_out 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 0.12s
                      Time elapsed: 00:01:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 104/1 [0m                       

                       Computation: 696291 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 57.53
               Mean episode length: 231.55
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 11.4584
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2858
Episode_Termination/object_dropping 4.8750
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 0.14s
                      Time elapsed: 00:01:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 105/1 [0m                       

                       Computation: 584076 steps/s (collection: 0.045s, learning 0.124s)
                       Mean reward: 59.76
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 10.4113
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2565
Episode_Termination/object_dropping 2.2083
       Episode_Termination/time_out 94.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 0.17s
                      Time elapsed: 00:01:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 106/1 [0m                       

                       Computation: 883437 steps/s (collection: 0.035s, learning 0.076s)
                       Mean reward: 47.52
               Mean episode length: 189.21
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 9.2609
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2343
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 0.11s
                      Time elapsed: 00:01:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 107/1 [0m                       

                       Computation: 313073 steps/s (collection: 0.102s, learning 0.212s)
                       Mean reward: 53.77
               Mean episode length: 201.87
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 10.3766
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2494
Episode_Termination/object_dropping 2.7917
       Episode_Termination/time_out 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 0.31s
                      Time elapsed: 00:01:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 108/1 [0m                       

                       Computation: 722696 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 54.57
               Mean episode length: 194.92
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 10.4302
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2513
Episode_Termination/object_dropping 3.7500
       Episode_Termination/time_out 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 0.14s
                      Time elapsed: 00:01:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 109/1 [0m                       

                       Computation: 630058 steps/s (collection: 0.051s, learning 0.106s)
                       Mean reward: 54.98
               Mean episode length: 195.01
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 10.7360
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2417
Episode_Termination/object_dropping 5.5000
       Episode_Termination/time_out 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 0.16s
                      Time elapsed: 00:01:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 110/1 [0m                       

                       Computation: 692929 steps/s (collection: 0.037s, learning 0.105s)
                       Mean reward: 55.06
               Mean episode length: 202.23
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 10.9226
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2518
Episode_Termination/object_dropping 5.1667
       Episode_Termination/time_out 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 0.14s
                      Time elapsed: 00:01:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 111/1 [0m                       

                       Computation: 692637 steps/s (collection: 0.052s, learning 0.090s)
                       Mean reward: 59.45
               Mean episode length: 211.01
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 11.6468
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2681
Episode_Termination/object_dropping 6.1667
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 0.14s
                      Time elapsed: 00:01:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 112/1 [0m                       

                       Computation: 653209 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 64.68
               Mean episode length: 220.88
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 12.6248
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2816
Episode_Termination/object_dropping 5.3750
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 0.15s
                      Time elapsed: 00:01:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 113/1 [0m                       

                       Computation: 759264 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 64.45
               Mean episode length: 228.20
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 12.6240
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2839
Episode_Termination/object_dropping 4.8750
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 0.13s
                      Time elapsed: 00:01:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 114/1 [0m                       

                       Computation: 472033 steps/s (collection: 0.048s, learning 0.160s)
                       Mean reward: 64.22
               Mean episode length: 228.34
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 12.4133
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2872
Episode_Termination/object_dropping 5.0833
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 0.21s
                      Time elapsed: 00:01:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 115/1 [0m                       

                       Computation: 538504 steps/s (collection: 0.063s, learning 0.120s)
                       Mean reward: 67.32
               Mean episode length: 246.53
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 11.9834
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2684
Episode_Termination/object_dropping 4.0000
       Episode_Termination/time_out 76.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 0.18s
                      Time elapsed: 00:01:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 116/1 [0m                       

                       Computation: 462466 steps/s (collection: 0.037s, learning 0.176s)
                       Mean reward: 59.81
               Mean episode length: 197.93
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 11.7630
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2418
Episode_Termination/object_dropping 2.6250
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 0.21s
                      Time elapsed: 00:01:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 117/1 [0m                       

                       Computation: 423676 steps/s (collection: 0.047s, learning 0.185s)
                       Mean reward: 62.47
               Mean episode length: 201.99
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 12.5368
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2451
Episode_Termination/object_dropping 2.7500
       Episode_Termination/time_out 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 0.23s
                      Time elapsed: 00:01:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 118/1 [0m                       

                       Computation: 618168 steps/s (collection: 0.055s, learning 0.105s)
                       Mean reward: 62.47
               Mean episode length: 206.03
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 12.0462
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2491
Episode_Termination/object_dropping 3.4583
       Episode_Termination/time_out 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 0.16s
                      Time elapsed: 00:01:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 119/1 [0m                       

                       Computation: 524230 steps/s (collection: 0.048s, learning 0.140s)
                       Mean reward: 63.68
               Mean episode length: 204.93
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 12.5536
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2502
Episode_Termination/object_dropping 5.0833
       Episode_Termination/time_out 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 0.19s
                      Time elapsed: 00:01:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 120/1 [0m                       

                       Computation: 697076 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 68.35
               Mean episode length: 212.02
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 13.3376
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2615
Episode_Termination/object_dropping 5.2083
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 0.14s
                      Time elapsed: 00:01:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 121/1 [0m                       

                       Computation: 607876 steps/s (collection: 0.078s, learning 0.084s)
                       Mean reward: 70.35
               Mean episode length: 219.14
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 13.8067
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2731
Episode_Termination/object_dropping 5.9583
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 0.16s
                      Time elapsed: 00:01:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 122/1 [0m                       

                       Computation: 535716 steps/s (collection: 0.043s, learning 0.140s)
                       Mean reward: 72.88
               Mean episode length: 220.97
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 14.3180
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2756
Episode_Termination/object_dropping 5.5000
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 0.18s
                      Time elapsed: 00:01:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 123/1 [0m                       

                       Computation: 424800 steps/s (collection: 0.065s, learning 0.166s)
                       Mean reward: 76.74
               Mean episode length: 226.94
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 15.2424
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2828
Episode_Termination/object_dropping 4.8750
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 0.23s
                      Time elapsed: 00:01:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 124/1 [0m                       

                       Computation: 555769 steps/s (collection: 0.049s, learning 0.128s)
                       Mean reward: 73.94
               Mean episode length: 226.32
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 14.3934
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2792
Episode_Termination/object_dropping 4.6667
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 0.18s
                      Time elapsed: 00:01:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 125/1 [0m                       

                       Computation: 373154 steps/s (collection: 0.057s, learning 0.206s)
                       Mean reward: 78.11
               Mean episode length: 245.83
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 14.9746
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2884
Episode_Termination/object_dropping 4.4167
       Episode_Termination/time_out 62.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 0.26s
                      Time elapsed: 00:02:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 126/1 [0m                       

                       Computation: 851036 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 75.02
               Mean episode length: 205.50
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 14.7671
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2535
Episode_Termination/object_dropping 2.7083
       Episode_Termination/time_out 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 0.12s
                      Time elapsed: 00:02:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 127/1 [0m                       

                       Computation: 391660 steps/s (collection: 0.045s, learning 0.206s)
                       Mean reward: 68.92
               Mean episode length: 201.71
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 13.8775
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2471
Episode_Termination/object_dropping 3.2500
       Episode_Termination/time_out 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 0.25s
                      Time elapsed: 00:02:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 128/1 [0m                       

                       Computation: 619337 steps/s (collection: 0.041s, learning 0.118s)
                       Mean reward: 75.09
               Mean episode length: 208.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 14.8028
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2549
Episode_Termination/object_dropping 4.3750
       Episode_Termination/time_out 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 0.16s
                      Time elapsed: 00:02:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 129/1 [0m                       

                       Computation: 637236 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 77.64
               Mean episode length: 206.52
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 15.4404
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2600
Episode_Termination/object_dropping 5.7917
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 0.15s
                      Time elapsed: 00:02:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 130/1 [0m                       

                       Computation: 529825 steps/s (collection: 0.052s, learning 0.134s)
                       Mean reward: 74.38
               Mean episode length: 211.97
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 14.6414
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2619
Episode_Termination/object_dropping 6.4167
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 0.19s
                      Time elapsed: 00:02:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 131/1 [0m                       

                       Computation: 785925 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 77.94
               Mean episode length: 217.78
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 15.3637
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2685
Episode_Termination/object_dropping 5.6250
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 0.13s
                      Time elapsed: 00:02:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 132/1 [0m                       

                       Computation: 431741 steps/s (collection: 0.053s, learning 0.175s)
                       Mean reward: 76.74
               Mean episode length: 219.30
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 15.4670
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2733
Episode_Termination/object_dropping 6.0833
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 0.23s
                      Time elapsed: 00:02:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 133/1 [0m                       

                       Computation: 761982 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 82.44
               Mean episode length: 222.57
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 16.2661
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2734
Episode_Termination/object_dropping 5.7917
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 0.13s
                      Time elapsed: 00:02:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 134/1 [0m                       

                       Computation: 552203 steps/s (collection: 0.051s, learning 0.128s)
                       Mean reward: 82.16
               Mean episode length: 218.30
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 16.0502
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2721
Episode_Termination/object_dropping 6.6667
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 0.18s
                      Time elapsed: 00:02:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 135/1 [0m                       

                       Computation: 597724 steps/s (collection: 0.048s, learning 0.116s)
                       Mean reward: 82.23
               Mean episode length: 217.02
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 16.1037
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2662
Episode_Termination/object_dropping 6.5417
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 0.16s
                      Time elapsed: 00:02:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 136/1 [0m                       

                       Computation: 628099 steps/s (collection: 0.041s, learning 0.116s)
                       Mean reward: 84.35
               Mean episode length: 238.15
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 15.6233
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2500
Episode_Termination/object_dropping 6.2500
       Episode_Termination/time_out 43.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 0.16s
                      Time elapsed: 00:02:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 137/1 [0m                       

                       Computation: 847739 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 76.63
               Mean episode length: 188.13
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 14.9917
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2318
Episode_Termination/object_dropping 5.5417
       Episode_Termination/time_out 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 0.12s
                      Time elapsed: 00:02:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 138/1 [0m                       

                       Computation: 677051 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 76.67
               Mean episode length: 196.56
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 15.3247
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2397
Episode_Termination/object_dropping 6.3333
       Episode_Termination/time_out 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 0.15s
                      Time elapsed: 00:02:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 139/1 [0m                       

                       Computation: 893594 steps/s (collection: 0.036s, learning 0.074s)
                       Mean reward: 78.57
               Mean episode length: 199.63
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 15.5149
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2401
Episode_Termination/object_dropping 7.9583
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 0.11s
                      Time elapsed: 00:02:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 140/1 [0m                       

                       Computation: 806654 steps/s (collection: 0.035s, learning 0.087s)
                       Mean reward: 80.45
               Mean episode length: 203.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 15.8214
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2426
Episode_Termination/object_dropping 8.6250
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 0.12s
                      Time elapsed: 00:02:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 141/1 [0m                       

                       Computation: 722754 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 80.76
               Mean episode length: 204.98
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 15.8847
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2452
Episode_Termination/object_dropping 8.1667
       Episode_Termination/time_out 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 0.14s
                      Time elapsed: 00:02:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 142/1 [0m                       

                       Computation: 707117 steps/s (collection: 0.046s, learning 0.094s)
                       Mean reward: 80.56
               Mean episode length: 208.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 15.6679
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2469
Episode_Termination/object_dropping 9.0417
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 0.14s
                      Time elapsed: 00:02:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 143/1 [0m                       

                       Computation: 789444 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 81.36
               Mean episode length: 213.66
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 16.0500
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2548
Episode_Termination/object_dropping 7.5000
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 0.12s
                      Time elapsed: 00:02:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 144/1 [0m                       

                       Computation: 796804 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 80.84
               Mean episode length: 209.78
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 15.8655
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2515
Episode_Termination/object_dropping 8.2917
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 0.12s
                      Time elapsed: 00:02:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 145/1 [0m                       

                       Computation: 776996 steps/s (collection: 0.033s, learning 0.094s)
                       Mean reward: 79.65
               Mean episode length: 212.59
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 15.6996
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2520
Episode_Termination/object_dropping 7.7917
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 0.13s
                      Time elapsed: 00:02:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 146/1 [0m                       

                       Computation: 822204 steps/s (collection: 0.035s, learning 0.085s)
                       Mean reward: 83.20
               Mean episode length: 229.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 15.9877
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2458
Episode_Termination/object_dropping 9.1250
       Episode_Termination/time_out 30.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 0.12s
                      Time elapsed: 00:02:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 147/1 [0m                       

                       Computation: 852369 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 82.63
               Mean episode length: 194.41
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 16.1637
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2301
Episode_Termination/object_dropping 7.1667
       Episode_Termination/time_out 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 0.12s
                      Time elapsed: 00:02:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 148/1 [0m                       

                       Computation: 851799 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 86.82
               Mean episode length: 203.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 17.1003
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2465
Episode_Termination/object_dropping 6.6250
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 0.12s
                      Time elapsed: 00:02:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 149/1 [0m                       

                       Computation: 803143 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 84.95
               Mean episode length: 205.76
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 16.7275
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2437
Episode_Termination/object_dropping 7.3750
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 0.12s
                      Time elapsed: 00:02:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 150/1 [0m                       

                       Computation: 750504 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 88.70
               Mean episode length: 208.72
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 17.4629
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2507
Episode_Termination/object_dropping 7.6667
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 0.13s
                      Time elapsed: 00:02:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 151/1 [0m                       

                       Computation: 823734 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 93.04
               Mean episode length: 212.87
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 18.3304
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2574
Episode_Termination/object_dropping 8.1667
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 0.12s
                      Time elapsed: 00:02:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 152/1 [0m                       

                       Computation: 756124 steps/s (collection: 0.034s, learning 0.096s)
                       Mean reward: 92.23
               Mean episode length: 209.41
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 18.1793
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2581
Episode_Termination/object_dropping 8.2917
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 0.13s
                      Time elapsed: 00:02:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 153/1 [0m                       

                       Computation: 712225 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 98.85
               Mean episode length: 217.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 19.4732
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2686
Episode_Termination/object_dropping 7.0833
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 0.14s
                      Time elapsed: 00:02:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 154/1 [0m                       

                       Computation: 794245 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 93.76
               Mean episode length: 215.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 18.3679
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2641
Episode_Termination/object_dropping 7.9167
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 0.12s
                      Time elapsed: 00:02:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 155/1 [0m                       

                       Computation: 873341 steps/s (collection: 0.034s, learning 0.079s)
                       Mean reward: 99.21
               Mean episode length: 221.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 19.6064
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2778
Episode_Termination/object_dropping 5.8750
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 0.11s
                      Time elapsed: 00:02:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 156/1 [0m                       

                       Computation: 887812 steps/s (collection: 0.034s, learning 0.076s)
                       Mean reward: 105.54
               Mean episode length: 217.92
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 20.8479
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2783
Episode_Termination/object_dropping 6.5417
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 0.11s
                      Time elapsed: 00:02:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 157/1 [0m                       

                       Computation: 865993 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 106.79
               Mean episode length: 232.98
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 20.5376
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2732
Episode_Termination/object_dropping 5.5000
       Episode_Termination/time_out 21.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 0.11s
                      Time elapsed: 00:02:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 158/1 [0m                       

                       Computation: 786094 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 109.94
               Mean episode length: 217.57
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 21.5323
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2798
Episode_Termination/object_dropping 4.5417
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 0.13s
                      Time elapsed: 00:02:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 159/1 [0m                       

                       Computation: 830654 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 106.17
               Mean episode length: 213.18
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 20.9553
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2723
Episode_Termination/object_dropping 6.5833
       Episode_Termination/time_out 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 0.12s
                      Time elapsed: 00:02:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 160/1 [0m                       

                       Computation: 765329 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 111.90
               Mean episode length: 224.19
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 22.1219
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2866
Episode_Termination/object_dropping 6.2083
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 0.13s
                      Time elapsed: 00:02:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 161/1 [0m                       

                       Computation: 767323 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 112.80
               Mean episode length: 225.38
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 22.2942
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2903
Episode_Termination/object_dropping 6.1250
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 0.13s
                      Time elapsed: 00:02:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 162/1 [0m                       

                       Computation: 857195 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 116.10
               Mean episode length: 222.80
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 22.9728
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2915
Episode_Termination/object_dropping 6.5417
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 0.11s
                      Time elapsed: 00:02:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 163/1 [0m                       

                       Computation: 769796 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 120.13
               Mean episode length: 225.33
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 23.6304
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2886
Episode_Termination/object_dropping 5.2500
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 0.13s
                      Time elapsed: 00:02:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 164/1 [0m                       

                       Computation: 891524 steps/s (collection: 0.034s, learning 0.076s)
                       Mean reward: 116.80
               Mean episode length: 226.82
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 23.0662
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2958
Episode_Termination/object_dropping 6.0417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 0.11s
                      Time elapsed: 00:02:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 165/1 [0m                       

                       Computation: 746435 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 116.38
               Mean episode length: 229.58
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 22.8372
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3006
Episode_Termination/object_dropping 4.8750
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 0.13s
                      Time elapsed: 00:02:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 166/1 [0m                       

                       Computation: 733095 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 120.28
               Mean episode length: 228.04
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 23.5079
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2981
Episode_Termination/object_dropping 5.4583
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 0.13s
                      Time elapsed: 00:02:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 167/1 [0m                       

                       Computation: 727140 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 122.98
               Mean episode length: 234.76
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 24.1979
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3020
Episode_Termination/object_dropping 5.3750
       Episode_Termination/time_out 20.8750
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 0.14s
                      Time elapsed: 00:02:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 168/1 [0m                       

                       Computation: 753624 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 121.26
               Mean episode length: 223.09
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 23.9236
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2946
Episode_Termination/object_dropping 4.1250
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 0.13s
                      Time elapsed: 00:02:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 169/1 [0m                       

                       Computation: 687318 steps/s (collection: 0.037s, learning 0.106s)
                       Mean reward: 123.33
               Mean episode length: 226.82
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 24.1210
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3016
Episode_Termination/object_dropping 4.8333
       Episode_Termination/time_out 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 0.14s
                      Time elapsed: 00:02:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 170/1 [0m                       

                       Computation: 714676 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 126.22
               Mean episode length: 229.99
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 25.0473
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3095
Episode_Termination/object_dropping 5.0417
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 0.14s
                      Time elapsed: 00:02:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 171/1 [0m                       

                       Computation: 753220 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 128.54
               Mean episode length: 229.56
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 25.6404
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3173
Episode_Termination/object_dropping 5.0000
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 0.13s
                      Time elapsed: 00:02:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 172/1 [0m                       

                       Computation: 702065 steps/s (collection: 0.045s, learning 0.095s)
                       Mean reward: 134.59
               Mean episode length: 225.99
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 26.5873
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3101
Episode_Termination/object_dropping 6.4167
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 0.14s
                      Time elapsed: 00:02:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 173/1 [0m                       

                       Computation: 796755 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 136.97
               Mean episode length: 227.72
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 27.0732
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3177
Episode_Termination/object_dropping 5.7083
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 0.12s
                      Time elapsed: 00:02:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 174/1 [0m                       

                       Computation: 863602 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 136.23
               Mean episode length: 227.33
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 26.7584
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3150
Episode_Termination/object_dropping 6.3333
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 0.11s
                      Time elapsed: 00:02:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 175/1 [0m                       

                       Computation: 675523 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 133.15
               Mean episode length: 223.06
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 26.2246
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3096
Episode_Termination/object_dropping 5.7917
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 0.15s
                      Time elapsed: 00:02:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 176/1 [0m                       

                       Computation: 777226 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 135.49
               Mean episode length: 222.18
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 26.8841
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3121
Episode_Termination/object_dropping 5.7083
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 0.13s
                      Time elapsed: 00:02:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 177/1 [0m                       

                       Computation: 873380 steps/s (collection: 0.036s, learning 0.077s)
                       Mean reward: 138.77
               Mean episode length: 225.56
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 27.3672
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3143
Episode_Termination/object_dropping 6.1667
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 0.11s
                      Time elapsed: 00:02:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 178/1 [0m                       

                       Computation: 723764 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 137.68
               Mean episode length: 225.62
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 26.4146
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3021
Episode_Termination/object_dropping 6.6667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 0.14s
                      Time elapsed: 00:02:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 179/1 [0m                       

                       Computation: 789147 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 136.96
               Mean episode length: 221.44
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 27.0105
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3075
Episode_Termination/object_dropping 5.4167
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 0.12s
                      Time elapsed: 00:02:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 180/1 [0m                       

                       Computation: 725383 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 140.01
               Mean episode length: 225.79
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 27.5897
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3187
Episode_Termination/object_dropping 5.1667
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 0.14s
                      Time elapsed: 00:03:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 181/1 [0m                       

                       Computation: 869896 steps/s (collection: 0.035s, learning 0.078s)
                       Mean reward: 136.50
               Mean episode length: 224.07
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 26.7742
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3140
Episode_Termination/object_dropping 6.1667
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 0.11s
                      Time elapsed: 00:03:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 182/1 [0m                       

                       Computation: 776917 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 144.19
               Mean episode length: 227.49
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 28.5380
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3221
Episode_Termination/object_dropping 6.1250
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 0.13s
                      Time elapsed: 00:03:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 183/1 [0m                       

                       Computation: 839961 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 147.21
               Mean episode length: 225.91
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 29.2450
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3249
Episode_Termination/object_dropping 5.6667
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 0.12s
                      Time elapsed: 00:03:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 184/1 [0m                       

                       Computation: 861837 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 144.85
               Mean episode length: 232.07
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 28.6660
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3309
Episode_Termination/object_dropping 4.3750
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 0.11s
                      Time elapsed: 00:03:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 185/1 [0m                       

                       Computation: 873088 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 147.65
               Mean episode length: 235.33
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 28.8648
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3372
Episode_Termination/object_dropping 3.6667
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 0.11s
                      Time elapsed: 00:03:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 186/1 [0m                       

                       Computation: 788625 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 141.00
               Mean episode length: 230.20
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 27.8943
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3250
Episode_Termination/object_dropping 4.4583
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 0.12s
                      Time elapsed: 00:03:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 187/1 [0m                       

                       Computation: 574785 steps/s (collection: 0.068s, learning 0.103s)
                       Mean reward: 148.49
               Mean episode length: 236.89
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.3991
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3409
Episode_Termination/object_dropping 2.7917
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 0.17s
                      Time elapsed: 00:03:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 188/1 [0m                       

                       Computation: 730683 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 156.97
               Mean episode length: 239.38
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 30.6871
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3390
Episode_Termination/object_dropping 2.8333
       Episode_Termination/time_out 18.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 0.13s
                      Time elapsed: 00:03:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 189/1 [0m                       

                       Computation: 624109 steps/s (collection: 0.050s, learning 0.108s)
                       Mean reward: 152.38
               Mean episode length: 233.40
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 30.0664
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3354
Episode_Termination/object_dropping 3.3750
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 0.16s
                      Time elapsed: 00:03:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 190/1 [0m                       

                       Computation: 747464 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 154.31
               Mean episode length: 235.05
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 30.4795
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3390
Episode_Termination/object_dropping 3.1667
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 0.13s
                      Time elapsed: 00:03:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 191/1 [0m                       

                       Computation: 866033 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 159.89
               Mean episode length: 239.90
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 31.6598
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3481
Episode_Termination/object_dropping 2.4167
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 0.11s
                      Time elapsed: 00:03:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 192/1 [0m                       

                       Computation: 764885 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 157.67
               Mean episode length: 241.53
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 31.2473
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3528
Episode_Termination/object_dropping 2.2917
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 0.13s
                      Time elapsed: 00:03:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 193/1 [0m                       

                       Computation: 795272 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 172.43
               Mean episode length: 244.44
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 34.2246
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3657
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 0.12s
                      Time elapsed: 00:03:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 194/1 [0m                       

                       Computation: 797734 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 169.61
               Mean episode length: 245.24
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 33.3129
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3626
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 0.12s
                      Time elapsed: 00:03:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 195/1 [0m                       

                       Computation: 745743 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 169.41
               Mean episode length: 243.86
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 33.4141
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3608
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 0.13s
                      Time elapsed: 00:03:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 196/1 [0m                       

                       Computation: 821204 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 166.93
               Mean episode length: 243.70
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 33.0420
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3651
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 0.12s
                      Time elapsed: 00:03:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 197/1 [0m                       

                       Computation: 831958 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 165.09
               Mean episode length: 243.71
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 32.5453
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3606
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 0.12s
                      Time elapsed: 00:03:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 198/1 [0m                       

                       Computation: 785772 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 177.06
               Mean episode length: 246.06
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 34.6768
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3677
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 19.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 0.13s
                      Time elapsed: 00:03:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 199/1 [0m                       

                       Computation: 859810 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 173.67
               Mean episode length: 243.53
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 34.2600
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3684
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 0.11s
                      Time elapsed: 00:03:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 200/1 [0m                       

                       Computation: 761935 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 174.09
               Mean episode length: 244.82
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 34.7721
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3731
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 0.13s
                      Time elapsed: 00:03:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 201/1 [0m                       

                       Computation: 750151 steps/s (collection: 0.050s, learning 0.081s)
                       Mean reward: 178.83
               Mean episode length: 247.16
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 35.3520
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3752
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 0.13s
                      Time elapsed: 00:03:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 202/1 [0m                       

                       Computation: 770399 steps/s (collection: 0.035s, learning 0.093s)
                       Mean reward: 177.37
               Mean episode length: 245.19
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 35.1366
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3743
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 0.13s
                      Time elapsed: 00:03:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 203/1 [0m                       

                       Computation: 774651 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 181.64
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 35.8678
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3809
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 0.13s
                      Time elapsed: 00:03:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 204/1 [0m                       

                       Computation: 850234 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 181.53
               Mean episode length: 245.73
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 35.7963
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3763
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 0.12s
                      Time elapsed: 00:03:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 205/1 [0m                       

                       Computation: 750012 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 188.58
               Mean episode length: 247.51
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 37.5181
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3847
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 0.13s
                      Time elapsed: 00:03:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 206/1 [0m                       

                       Computation: 758286 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 186.73
               Mean episode length: 247.12
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 36.9712
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3851
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 0.13s
                      Time elapsed: 00:03:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 207/1 [0m                       

                       Computation: 819125 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 191.61
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 37.7036
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3855
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 0.12s
                      Time elapsed: 00:03:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 208/1 [0m                       

                       Computation: 765484 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 192.50
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 37.8430
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3920
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 0.13s
                      Time elapsed: 00:03:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 209/1 [0m                       

                       Computation: 778276 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 194.75
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 38.0920
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3919
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 19.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 0.13s
                      Time elapsed: 00:03:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 210/1 [0m                       

                       Computation: 730731 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 193.93
               Mean episode length: 246.60
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 38.2677
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3902
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 0.13s
                      Time elapsed: 00:03:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 211/1 [0m                       

                       Computation: 771504 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 198.77
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 39.4437
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3944
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 0.13s
                      Time elapsed: 00:03:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 212/1 [0m                       

                       Computation: 737295 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 200.11
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 39.5666
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3945
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 0.13s
                      Time elapsed: 00:03:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 213/1 [0m                       

                       Computation: 842947 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 194.43
               Mean episode length: 245.92
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 38.5683
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3881
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 0.12s
                      Time elapsed: 00:03:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 214/1 [0m                       

                       Computation: 718041 steps/s (collection: 0.036s, learning 0.101s)
                       Mean reward: 203.51
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 40.2948
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3945
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 0.14s
                      Time elapsed: 00:03:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 215/1 [0m                       

                       Computation: 874577 steps/s (collection: 0.036s, learning 0.076s)
                       Mean reward: 201.67
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 40.1423
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3981
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 0.11s
                      Time elapsed: 00:03:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 216/1 [0m                       

                       Computation: 726685 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 204.16
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 40.3893
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3934
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 0.14s
                      Time elapsed: 00:03:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 217/1 [0m                       

                       Computation: 812299 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 208.23
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 41.3510
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3977
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 0.12s
                      Time elapsed: 00:03:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 218/1 [0m                       

                       Computation: 789387 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 209.73
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 41.5569
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3954
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 0.12s
                      Time elapsed: 00:03:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 219/1 [0m                       

                       Computation: 776876 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 209.83
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 41.2000
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3947
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 19.3333
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 0.13s
                      Time elapsed: 00:03:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 220/1 [0m                       

                       Computation: 760694 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 206.82
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 41.2220
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3977
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 0.13s
                      Time elapsed: 00:03:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 221/1 [0m                       

                       Computation: 880909 steps/s (collection: 0.036s, learning 0.076s)
                       Mean reward: 203.57
               Mean episode length: 247.10
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 40.1284
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3947
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 0.11s
                      Time elapsed: 00:03:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 222/1 [0m                       

                       Computation: 679984 steps/s (collection: 0.048s, learning 0.097s)
                       Mean reward: 212.20
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.2005
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3970
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 0.14s
                      Time elapsed: 00:03:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 223/1 [0m                       

                       Computation: 735896 steps/s (collection: 0.051s, learning 0.083s)
                       Mean reward: 209.45
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 41.6321
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3963
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 0.13s
                      Time elapsed: 00:03:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 224/1 [0m                       

                       Computation: 815682 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 212.81
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.1555
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3997
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 0.12s
                      Time elapsed: 00:03:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 225/1 [0m                       

                       Computation: 613530 steps/s (collection: 0.044s, learning 0.117s)
                       Mean reward: 210.43
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 41.4226
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3950
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 0.16s
                      Time elapsed: 00:03:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 226/1 [0m                       

                       Computation: 634539 steps/s (collection: 0.055s, learning 0.100s)
                       Mean reward: 218.41
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.1519
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3959
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 0.15s
                      Time elapsed: 00:03:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 227/1 [0m                       

                       Computation: 858476 steps/s (collection: 0.041s, learning 0.074s)
                       Mean reward: 219.53
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.5294
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4026
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 0.11s
                      Time elapsed: 00:03:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 228/1 [0m                       

                       Computation: 512005 steps/s (collection: 0.053s, learning 0.139s)
                       Mean reward: 211.90
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.0363
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3957
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 0.19s
                      Time elapsed: 00:03:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 229/1 [0m                       

                       Computation: 795834 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 217.79
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.3463
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4003
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 0.12s
                      Time elapsed: 00:03:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 230/1 [0m                       

                       Computation: 738019 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 221.45
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.9167
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4030
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 19.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 0.13s
                      Time elapsed: 00:03:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 231/1 [0m                       

                       Computation: 827684 steps/s (collection: 0.043s, learning 0.076s)
                       Mean reward: 218.94
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.2817
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3993
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 0.12s
                      Time elapsed: 00:03:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 232/1 [0m                       

                       Computation: 730755 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 221.26
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.0878
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4030
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 0.13s
                      Time elapsed: 00:03:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 233/1 [0m                       

                       Computation: 841866 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 224.93
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.3557
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4003
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 0.12s
                      Time elapsed: 00:03:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 234/1 [0m                       

                       Computation: 867239 steps/s (collection: 0.035s, learning 0.078s)
                       Mean reward: 220.78
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.9451
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4024
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 0.11s
                      Time elapsed: 00:03:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 235/1 [0m                       

                       Computation: 826960 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 218.21
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.0564
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3998
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 0.12s
                      Time elapsed: 00:03:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 236/1 [0m                       

                       Computation: 843739 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 222.17
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.8819
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4001
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 0.12s
                      Time elapsed: 00:03:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 237/1 [0m                       

                       Computation: 836196 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 221.83
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.8737
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3996
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 0.12s
                      Time elapsed: 00:04:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 238/1 [0m                       

                       Computation: 667256 steps/s (collection: 0.039s, learning 0.109s)
                       Mean reward: 220.00
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.7242
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3946
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 0.15s
                      Time elapsed: 00:04:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 239/1 [0m                       

                       Computation: 689692 steps/s (collection: 0.036s, learning 0.107s)
                       Mean reward: 221.62
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.9215
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3958
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 0.14s
                      Time elapsed: 00:04:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 240/1 [0m                       

                       Computation: 629498 steps/s (collection: 0.038s, learning 0.118s)
                       Mean reward: 222.91
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.0672
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3931
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 19.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 0.16s
                      Time elapsed: 00:04:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 241/1 [0m                       

                       Computation: 666657 steps/s (collection: 0.052s, learning 0.095s)
                       Mean reward: 220.97
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.9064
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3965
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 0.15s
                      Time elapsed: 00:04:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 242/1 [0m                       

                       Computation: 622107 steps/s (collection: 0.044s, learning 0.114s)
                       Mean reward: 226.00
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.1701
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3934
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 0.16s
                      Time elapsed: 00:04:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 243/1 [0m                       

                       Computation: 722766 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 225.22
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.7979
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3948
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 0.14s
                      Time elapsed: 00:04:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 244/1 [0m                       

                       Computation: 689758 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 224.79
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.7688
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3938
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 0.14s
                      Time elapsed: 00:04:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 245/1 [0m                       

                       Computation: 835822 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 216.76
               Mean episode length: 246.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.2227
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3910
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 0.12s
                      Time elapsed: 00:04:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 246/1 [0m                       

                       Computation: 697595 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 226.50
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.8968
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3937
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 0.14s
                      Time elapsed: 00:04:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 247/1 [0m                       

                       Computation: 776959 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 226.09
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.4798
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3947
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 0.13s
                      Time elapsed: 00:04:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 248/1 [0m                       

                       Computation: 819086 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 226.22
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.9124
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3921
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 0.12s
                      Time elapsed: 00:04:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 249/1 [0m                       

                       Computation: 555365 steps/s (collection: 0.054s, learning 0.123s)
                       Mean reward: 227.24
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.0420
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3926
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 0.18s
                      Time elapsed: 00:04:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 250/1 [0m                       

                       Computation: 687426 steps/s (collection: 0.050s, learning 0.093s)
                       Mean reward: 223.57
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.1897
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3888
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 19.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 0.14s
                      Time elapsed: 00:04:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 251/1 [0m                       

                       Computation: 825303 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 225.22
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.5337
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3903
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 0.12s
                      Time elapsed: 00:04:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 252/1 [0m                       

                       Computation: 850332 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 229.23
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.6786
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3921
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 0.12s
                      Time elapsed: 00:04:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 253/1 [0m                       

                       Computation: 866046 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 228.91
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.6748
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3917
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 0.11s
                      Time elapsed: 00:04:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 254/1 [0m                       

                       Computation: 802085 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 233.11
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.2962
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3937
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 0.12s
                      Time elapsed: 00:04:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 255/1 [0m                       

                       Computation: 485662 steps/s (collection: 0.047s, learning 0.156s)
                       Mean reward: 232.74
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.1310
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3953
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 0.20s
                      Time elapsed: 00:04:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 256/1 [0m                       

                       Computation: 836512 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 231.18
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.6511
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3928
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 0.12s
                      Time elapsed: 00:04:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 257/1 [0m                       

                       Computation: 842172 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 229.41
               Mean episode length: 245.91
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 45.6875
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3902
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 0.12s
                      Time elapsed: 00:04:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 258/1 [0m                       

                       Computation: 791981 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 231.85
               Mean episode length: 246.92
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.8843
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3915
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 0.12s
                      Time elapsed: 00:04:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 259/1 [0m                       

                       Computation: 766490 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 229.37
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.4944
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3915
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 0.13s
                      Time elapsed: 00:04:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 260/1 [0m                       

                       Computation: 769434 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 236.81
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.9463
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3909
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 0.13s
                      Time elapsed: 00:04:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 261/1 [0m                       

                       Computation: 748571 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 234.87
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.6162
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3929
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 0.13s
                      Time elapsed: 00:04:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 262/1 [0m                       

                       Computation: 808946 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 230.15
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.3791
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3920
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 0.12s
                      Time elapsed: 00:04:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 263/1 [0m                       

                       Computation: 614297 steps/s (collection: 0.044s, learning 0.117s)
                       Mean reward: 231.75
               Mean episode length: 247.42
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 45.7702
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3866
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 0.16s
                      Time elapsed: 00:04:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 264/1 [0m                       

                       Computation: 699635 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 235.41
               Mean episode length: 247.11
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.6644
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3888
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 0.14s
                      Time elapsed: 00:04:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 265/1 [0m                       

                       Computation: 877398 steps/s (collection: 0.039s, learning 0.073s)
                       Mean reward: 238.99
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.3911
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3929
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 0.11s
                      Time elapsed: 00:04:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 266/1 [0m                       

                       Computation: 750159 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 240.45
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.6272
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3936
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 0.13s
                      Time elapsed: 00:04:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 267/1 [0m                       

                       Computation: 797346 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 238.63
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.2420
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3922
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 0.12s
                      Time elapsed: 00:04:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 268/1 [0m                       

                       Computation: 847337 steps/s (collection: 0.041s, learning 0.075s)
                       Mean reward: 240.64
               Mean episode length: 247.74
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.6679
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3907
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 0.12s
                      Time elapsed: 00:04:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 269/1 [0m                       

                       Computation: 675888 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 238.17
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.2167
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3914
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 0.15s
                      Time elapsed: 00:04:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 270/1 [0m                       

                       Computation: 513263 steps/s (collection: 0.054s, learning 0.137s)
                       Mean reward: 245.93
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.9548
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3937
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 0.19s
                      Time elapsed: 00:04:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 271/1 [0m                       

                       Computation: 536394 steps/s (collection: 0.051s, learning 0.132s)
                       Mean reward: 238.87
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.1754
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3912
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 19.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 0.18s
                      Time elapsed: 00:04:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 272/1 [0m                       

                       Computation: 734202 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 242.36
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.1945
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3947
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 0.13s
                      Time elapsed: 00:04:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 273/1 [0m                       

                       Computation: 583096 steps/s (collection: 0.049s, learning 0.120s)
                       Mean reward: 239.99
               Mean episode length: 247.24
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 46.9658
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3886
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 0.17s
                      Time elapsed: 00:04:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 274/1 [0m                       

                       Computation: 659711 steps/s (collection: 0.043s, learning 0.107s)
                       Mean reward: 242.69
               Mean episode length: 247.12
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.2296
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3888
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 0.15s
                      Time elapsed: 00:04:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 275/1 [0m                       

                       Computation: 617904 steps/s (collection: 0.041s, learning 0.118s)
                       Mean reward: 239.65
               Mean episode length: 246.26
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 47.5776
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3886
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 0.16s
                      Time elapsed: 00:04:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 276/1 [0m                       

                       Computation: 789640 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 241.01
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.8516
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3898
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 0.12s
                      Time elapsed: 00:04:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 277/1 [0m                       

                       Computation: 634438 steps/s (collection: 0.048s, learning 0.107s)
                       Mean reward: 246.28
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.7158
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3938
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 0.15s
                      Time elapsed: 00:04:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 278/1 [0m                       

                       Computation: 765616 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 239.11
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.4497
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3912
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 0.13s
                      Time elapsed: 00:04:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 279/1 [0m                       

                       Computation: 701225 steps/s (collection: 0.052s, learning 0.089s)
                       Mean reward: 238.17
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.3577
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3895
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 0.14s
                      Time elapsed: 00:04:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 280/1 [0m                       

                       Computation: 717534 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 244.52
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.3558
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3895
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 0.14s
                      Time elapsed: 00:04:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 281/1 [0m                       

                       Computation: 532450 steps/s (collection: 0.045s, learning 0.140s)
                       Mean reward: 239.74
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.3198
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3872
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 0.18s
                      Time elapsed: 00:04:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 282/1 [0m                       

                       Computation: 692052 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 243.87
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.9754
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3954
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 0.14s
                      Time elapsed: 00:04:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 283/1 [0m                       

                       Computation: 675350 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 244.87
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.6899
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3923
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 0.15s
                      Time elapsed: 00:04:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 284/1 [0m                       

                       Computation: 684764 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 247.32
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 49.2612
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3930
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 0.14s
                      Time elapsed: 00:04:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 285/1 [0m                       

                       Computation: 635981 steps/s (collection: 0.044s, learning 0.111s)
                       Mean reward: 245.22
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.5197
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3933
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 0.15s
                      Time elapsed: 00:04:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 286/1 [0m                       

                       Computation: 675457 steps/s (collection: 0.050s, learning 0.096s)
                       Mean reward: 244.73
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.5256
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3920
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 0.15s
                      Time elapsed: 00:04:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 287/1 [0m                       

                       Computation: 744324 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 247.66
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 49.1083
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3954
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 0.13s
                      Time elapsed: 00:04:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 288/1 [0m                       

                       Computation: 696886 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 248.94
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 49.3845
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3944
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 0.14s
                      Time elapsed: 00:04:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 289/1 [0m                       

                       Computation: 714753 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 249.26
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 49.5541
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3959
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 0.14s
                      Time elapsed: 00:04:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 290/1 [0m                       

                       Computation: 638292 steps/s (collection: 0.039s, learning 0.115s)
                       Mean reward: 246.37
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.6280
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3944
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 0.15s
                      Time elapsed: 00:04:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 291/1 [0m                       

                       Computation: 550519 steps/s (collection: 0.042s, learning 0.137s)
                       Mean reward: 245.63
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.5457
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3915
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 0.18s
                      Time elapsed: 00:04:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 292/1 [0m                       

                       Computation: 677858 steps/s (collection: 0.043s, learning 0.103s)
                       Mean reward: 249.34
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.1785
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3962
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 0.15s
                      Time elapsed: 00:05:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 293/1 [0m                       

                       Computation: 637984 steps/s (collection: 0.060s, learning 0.095s)
                       Mean reward: 252.68
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.0123
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3989
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 0.15s
                      Time elapsed: 00:05:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 294/1 [0m                       

                       Computation: 653014 steps/s (collection: 0.050s, learning 0.101s)
                       Mean reward: 251.08
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.3086
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3981
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 0.15s
                      Time elapsed: 00:05:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 295/1 [0m                       

                       Computation: 652850 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 255.25
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.7907
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3993
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 0.15s
                      Time elapsed: 00:05:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 296/1 [0m                       

                       Computation: 618142 steps/s (collection: 0.048s, learning 0.111s)
                       Mean reward: 253.34
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.2306
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3985
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 0.16s
                      Time elapsed: 00:05:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 297/1 [0m                       

                       Computation: 836371 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 259.57
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 51.4797
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4021
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 0.12s
                      Time elapsed: 00:05:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 298/1 [0m                       

                       Computation: 739009 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 253.91
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.4129
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4040
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 0.13s
                      Time elapsed: 00:05:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 299/1 [0m                       

                       Computation: 659608 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 254.02
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.4270
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4022
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 0.15s
                      Time elapsed: 00:05:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 300/1 [0m                       

                       Computation: 725267 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 256.52
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 51.0506
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4051
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 0.14s
                      Time elapsed: 00:05:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 301/1 [0m                       

                       Computation: 727783 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 259.59
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.5172
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4032
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 0.14s
                      Time elapsed: 00:05:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 302/1 [0m                       

                       Computation: 733371 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 258.81
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 51.3179
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4040
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 0.13s
                      Time elapsed: 00:05:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 303/1 [0m                       

                       Computation: 684861 steps/s (collection: 0.040s, learning 0.104s)
                       Mean reward: 259.12
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.0782
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4030
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 18.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 0.14s
                      Time elapsed: 00:05:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 304/1 [0m                       

                       Computation: 699302 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 258.39
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.2586
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4021
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 0.14s
                      Time elapsed: 00:05:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 305/1 [0m                       

                       Computation: 640214 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 256.16
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 50.8793
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4038
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 0.15s
                      Time elapsed: 00:05:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 306/1 [0m                       

                       Computation: 692134 steps/s (collection: 0.046s, learning 0.096s)
                       Mean reward: 263.17
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 52.1402
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4077
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 0.14s
                      Time elapsed: 00:05:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 307/1 [0m                       

                       Computation: 628995 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 258.49
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.2210
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4088
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 0.16s
                      Time elapsed: 00:05:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 308/1 [0m                       

                       Computation: 750227 steps/s (collection: 0.046s, learning 0.085s)
                       Mean reward: 259.79
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.3839
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4049
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 0.13s
                      Time elapsed: 00:05:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 309/1 [0m                       

                       Computation: 644611 steps/s (collection: 0.044s, learning 0.109s)
                       Mean reward: 254.55
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 50.3577
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4050
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 0.15s
                      Time elapsed: 00:05:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 310/1 [0m                       

                       Computation: 778138 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 265.78
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.8116
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4098
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 0.13s
                      Time elapsed: 00:05:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 311/1 [0m                       

                       Computation: 741859 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 262.10
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.9559
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4068
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 0.13s
                      Time elapsed: 00:05:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 312/1 [0m                       

                       Computation: 677865 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 261.33
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.8531
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4089
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 0.15s
                      Time elapsed: 00:05:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 313/1 [0m                       

                       Computation: 735976 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 265.13
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 52.5639
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4116
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 0.13s
                      Time elapsed: 00:05:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 314/1 [0m                       

                       Computation: 660818 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 261.13
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 51.9331
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4112
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 0.15s
                      Time elapsed: 00:05:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 315/1 [0m                       

                       Computation: 822567 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 264.82
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.5064
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4099
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 0.12s
                      Time elapsed: 00:05:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 316/1 [0m                       

                       Computation: 847490 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 264.59
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.3952
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4102
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 0.12s
                      Time elapsed: 00:05:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 317/1 [0m                       

                       Computation: 704546 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 263.27
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 52.2384
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4132
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 0.14s
                      Time elapsed: 00:05:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 318/1 [0m                       

                       Computation: 720212 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 268.02
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.2302
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4091
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 0.14s
                      Time elapsed: 00:05:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 319/1 [0m                       

                       Computation: 565508 steps/s (collection: 0.048s, learning 0.126s)
                       Mean reward: 268.05
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.4558
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4138
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 0.17s
                      Time elapsed: 00:05:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 320/1 [0m                       

                       Computation: 811688 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 267.03
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.0724
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4116
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 0.12s
                      Time elapsed: 00:05:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 321/1 [0m                       

                       Computation: 667334 steps/s (collection: 0.046s, learning 0.101s)
                       Mean reward: 264.38
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.4751
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4126
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 0.15s
                      Time elapsed: 00:05:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 322/1 [0m                       

                       Computation: 648769 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 258.08
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.3813
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4096
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 0.15s
                      Time elapsed: 00:05:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 323/1 [0m                       

                       Computation: 707693 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 263.50
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.0812
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4083
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 0.14s
                      Time elapsed: 00:05:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 324/1 [0m                       

                       Computation: 670917 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 263.98
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.5059
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4099
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 0.15s
                      Time elapsed: 00:05:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 325/1 [0m                       

                       Computation: 595713 steps/s (collection: 0.045s, learning 0.121s)
                       Mean reward: 262.95
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.7784
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4085
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 0.17s
                      Time elapsed: 00:05:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 326/1 [0m                       

                       Computation: 629975 steps/s (collection: 0.043s, learning 0.114s)
                       Mean reward: 264.28
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.1914
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4060
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 0.16s
                      Time elapsed: 00:05:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 327/1 [0m                       

                       Computation: 606482 steps/s (collection: 0.045s, learning 0.117s)
                       Mean reward: 264.39
               Mean episode length: 247.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.3508
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4062
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 0.16s
                      Time elapsed: 00:05:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 328/1 [0m                       

                       Computation: 883882 steps/s (collection: 0.039s, learning 0.072s)
                       Mean reward: 267.58
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.3473
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4088
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 0.11s
                      Time elapsed: 00:05:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 329/1 [0m                       

                       Computation: 704532 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 264.99
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.4825
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4068
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 0.14s
                      Time elapsed: 00:05:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 330/1 [0m                       

                       Computation: 647231 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 266.41
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.6474
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4063
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 0.15s
                      Time elapsed: 00:05:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 331/1 [0m                       

                       Computation: 732811 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 275.68
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.7406
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4091
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 0.13s
                      Time elapsed: 00:05:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 332/1 [0m                       

                       Computation: 735231 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 268.17
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.2962
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4068
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 0.13s
                      Time elapsed: 00:05:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 333/1 [0m                       

                       Computation: 730817 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 270.21
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.6206
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4073
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 0.13s
                      Time elapsed: 00:05:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 334/1 [0m                       

                       Computation: 607473 steps/s (collection: 0.044s, learning 0.118s)
                       Mean reward: 269.26
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.9774
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4035
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 0.16s
                      Time elapsed: 00:05:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 335/1 [0m                       

                       Computation: 519823 steps/s (collection: 0.047s, learning 0.143s)
                       Mean reward: 265.87
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.8063
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4081
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 0.19s
                      Time elapsed: 00:05:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 336/1 [0m                       

                       Computation: 893365 steps/s (collection: 0.039s, learning 0.072s)
                       Mean reward: 268.16
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.4256
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4080
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 0.11s
                      Time elapsed: 00:05:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 337/1 [0m                       

                       Computation: 751070 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 269.25
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.5991
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4074
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 0.13s
                      Time elapsed: 00:05:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 338/1 [0m                       

                       Computation: 829357 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 267.86
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.2077
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4097
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 0.12s
                      Time elapsed: 00:05:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 339/1 [0m                       

                       Computation: 756035 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 270.42
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.7088
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4108
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 0.13s
                      Time elapsed: 00:05:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 340/1 [0m                       

                       Computation: 842334 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 273.10
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.0364
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4113
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 0.12s
                      Time elapsed: 00:05:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 341/1 [0m                       

                       Computation: 798429 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 270.49
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.5768
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4136
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 0.12s
                      Time elapsed: 00:05:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 342/1 [0m                       

                       Computation: 847222 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 271.20
               Mean episode length: 247.58
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.7838
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4088
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 0.12s
                      Time elapsed: 00:05:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 343/1 [0m                       

                       Computation: 772736 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 271.47
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.9276
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4102
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 0.13s
                      Time elapsed: 00:05:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 344/1 [0m                       

                       Computation: 794172 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 271.53
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.4942
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4107
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 0.12s
                      Time elapsed: 00:05:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 345/1 [0m                       

                       Computation: 730942 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 267.02
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.1178
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4102
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 0.13s
                      Time elapsed: 00:05:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 346/1 [0m                       

                       Computation: 555261 steps/s (collection: 0.043s, learning 0.135s)
                       Mean reward: 270.36
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.5097
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4066
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 0.18s
                      Time elapsed: 00:05:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 347/1 [0m                       

                       Computation: 692373 steps/s (collection: 0.042s, learning 0.100s)
                       Mean reward: 269.56
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.6325
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4097
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 0.14s
                      Time elapsed: 00:05:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 348/1 [0m                       

                       Computation: 799975 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 275.44
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.6815
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4115
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 0.12s
                      Time elapsed: 00:06:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 349/1 [0m                       

                       Computation: 825985 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 273.22
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.1370
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4107
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 0.12s
                      Time elapsed: 00:06:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 350/1 [0m                       

                       Computation: 646607 steps/s (collection: 0.039s, learning 0.114s)
                       Mean reward: 268.64
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.3396
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4099
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 0.15s
                      Time elapsed: 00:06:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 351/1 [0m                       

                       Computation: 638465 steps/s (collection: 0.047s, learning 0.107s)
                       Mean reward: 271.57
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.8529
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4148
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 0.15s
                      Time elapsed: 00:06:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 352/1 [0m                       

                       Computation: 625468 steps/s (collection: 0.045s, learning 0.112s)
                       Mean reward: 270.64
               Mean episode length: 247.74
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.5093
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4089
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 0.16s
                      Time elapsed: 00:06:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 353/1 [0m                       

                       Computation: 683890 steps/s (collection: 0.055s, learning 0.089s)
                       Mean reward: 275.55
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.5582
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4148
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 0.14s
                      Time elapsed: 00:06:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 354/1 [0m                       

                       Computation: 728024 steps/s (collection: 0.036s, learning 0.099s)
                       Mean reward: 271.52
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.1739
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4117
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 0.14s
                      Time elapsed: 00:06:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 355/1 [0m                       

                       Computation: 770482 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 269.37
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.5045
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4096
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 18.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 0.13s
                      Time elapsed: 00:06:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 356/1 [0m                       

                       Computation: 700146 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 272.09
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.0694
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4133
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 0.14s
                      Time elapsed: 00:06:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 357/1 [0m                       

                       Computation: 749510 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 276.22
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.0058
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4136
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 0.13s
                      Time elapsed: 00:06:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 358/1 [0m                       

                       Computation: 606706 steps/s (collection: 0.051s, learning 0.111s)
                       Mean reward: 282.12
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.9587
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4195
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 0.16s
                      Time elapsed: 00:06:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 359/1 [0m                       

                       Computation: 610488 steps/s (collection: 0.052s, learning 0.109s)
                       Mean reward: 274.98
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.8259
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4172
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 0.16s
                      Time elapsed: 00:06:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 360/1 [0m                       

                       Computation: 504174 steps/s (collection: 0.066s, learning 0.129s)
                       Mean reward: 270.99
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.7453
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4157
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 0.19s
                      Time elapsed: 00:06:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 361/1 [0m                       

                       Computation: 750349 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 282.34
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.9829
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4207
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 0.13s
                      Time elapsed: 00:06:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 362/1 [0m                       

                       Computation: 561830 steps/s (collection: 0.042s, learning 0.133s)
                       Mean reward: 276.69
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.8451
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4141
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 0.17s
                      Time elapsed: 00:06:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 363/1 [0m                       

                       Computation: 832050 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 272.12
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.0547
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4197
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 0.12s
                      Time elapsed: 00:06:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 364/1 [0m                       

                       Computation: 816887 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 278.04
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.1524
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4163
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 0.12s
                      Time elapsed: 00:06:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 365/1 [0m                       

                       Computation: 804863 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 271.77
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.9174
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4121
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 0.12s
                      Time elapsed: 00:06:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 366/1 [0m                       

                       Computation: 848420 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 274.24
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.2948
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4161
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 0.12s
                      Time elapsed: 00:06:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 367/1 [0m                       

                       Computation: 808399 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 274.95
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.2582
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 0.12s
                      Time elapsed: 00:06:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 368/1 [0m                       

                       Computation: 859269 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 272.29
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.0939
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4163
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 0.11s
                      Time elapsed: 00:06:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 369/1 [0m                       

                       Computation: 820069 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 274.63
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.6354
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4141
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 0.12s
                      Time elapsed: 00:06:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 370/1 [0m                       

                       Computation: 862181 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 277.42
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.0742
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4155
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 0.11s
                      Time elapsed: 00:06:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 371/1 [0m                       

                       Computation: 804721 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 275.53
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.8602
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 0.12s
                      Time elapsed: 00:06:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 372/1 [0m                       

                       Computation: 702249 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 281.66
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.8293
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4142
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 0.14s
                      Time elapsed: 00:06:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 373/1 [0m                       

                       Computation: 822511 steps/s (collection: 0.043s, learning 0.077s)
                       Mean reward: 279.49
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.4105
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4140
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 0.12s
                      Time elapsed: 00:06:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 374/1 [0m                       

                       Computation: 836123 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 273.21
               Mean episode length: 247.50
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.0597
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4099
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 0.12s
                      Time elapsed: 00:06:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 375/1 [0m                       

                       Computation: 780489 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 280.73
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.2992
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4140
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 19.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 0.13s
                      Time elapsed: 00:06:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 376/1 [0m                       

                       Computation: 771012 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 273.30
               Mean episode length: 246.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.8095
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4094
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 0.13s
                      Time elapsed: 00:06:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 377/1 [0m                       

                       Computation: 568946 steps/s (collection: 0.049s, learning 0.124s)
                       Mean reward: 276.34
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.7708
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4109
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 0.17s
                      Time elapsed: 00:06:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 378/1 [0m                       

                       Computation: 739823 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 275.41
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.8308
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4109
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 0.13s
                      Time elapsed: 00:06:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 379/1 [0m                       

                       Computation: 699532 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 281.44
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.9369
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4100
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 0.14s
                      Time elapsed: 00:06:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 380/1 [0m                       

                       Computation: 696188 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 275.53
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.6345
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4096
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 0.14s
                      Time elapsed: 00:06:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 381/1 [0m                       

                       Computation: 736698 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 275.02
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.4337
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4089
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 0.13s
                      Time elapsed: 00:06:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 382/1 [0m                       

                       Computation: 663330 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 283.09
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.0648
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4132
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 0.15s
                      Time elapsed: 00:06:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 383/1 [0m                       

                       Computation: 705549 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 275.34
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.6434
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 0.14s
                      Time elapsed: 00:06:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 384/1 [0m                       

                       Computation: 808141 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 275.90
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.7198
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4094
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 0.12s
                      Time elapsed: 00:06:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 385/1 [0m                       

                       Computation: 722404 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 271.05
               Mean episode length: 246.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.9102
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4060
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 0.14s
                      Time elapsed: 00:06:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 386/1 [0m                       

                       Computation: 820749 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 281.97
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.9596
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4091
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 0.12s
                      Time elapsed: 00:06:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 387/1 [0m                       

                       Computation: 736727 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 275.13
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.6791
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4087
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 0.13s
                      Time elapsed: 00:06:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 388/1 [0m                       

                       Computation: 823415 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 281.18
               Mean episode length: 246.97
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.6139
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4044
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 0.12s
                      Time elapsed: 00:06:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 389/1 [0m                       

                       Computation: 638257 steps/s (collection: 0.058s, learning 0.097s)
                       Mean reward: 276.66
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.6562
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4048
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 0.15s
                      Time elapsed: 00:06:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 390/1 [0m                       

                       Computation: 756106 steps/s (collection: 0.046s, learning 0.085s)
                       Mean reward: 276.10
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.9536
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4058
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 0.13s
                      Time elapsed: 00:06:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 391/1 [0m                       

                       Computation: 620161 steps/s (collection: 0.051s, learning 0.108s)
                       Mean reward: 279.04
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.6013
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4066
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 0.16s
                      Time elapsed: 00:06:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 392/1 [0m                       

                       Computation: 815740 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 280.51
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.8348
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4103
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 0.12s
                      Time elapsed: 00:06:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 393/1 [0m                       

                       Computation: 657698 steps/s (collection: 0.046s, learning 0.104s)
                       Mean reward: 281.34
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.9353
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4055
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 0.15s
                      Time elapsed: 00:06:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 394/1 [0m                       

                       Computation: 653110 steps/s (collection: 0.047s, learning 0.104s)
                       Mean reward: 280.41
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.4940
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4077
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 0.15s
                      Time elapsed: 00:06:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 395/1 [0m                       

                       Computation: 843376 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 281.15
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.7113
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4089
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 0.12s
                      Time elapsed: 00:06:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 396/1 [0m                       

                       Computation: 764246 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 276.31
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.7293
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4091
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 0.13s
                      Time elapsed: 00:06:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 397/1 [0m                       

                       Computation: 821482 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 282.93
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.3571
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4081
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 0.12s
                      Time elapsed: 00:06:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 398/1 [0m                       

                       Computation: 661303 steps/s (collection: 0.043s, learning 0.106s)
                       Mean reward: 281.68
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.7882
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4048
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 0.15s
                      Time elapsed: 00:06:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 399/1 [0m                       

                       Computation: 581588 steps/s (collection: 0.052s, learning 0.117s)
                       Mean reward: 280.42
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.6898
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 0.17s
                      Time elapsed: 00:06:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 400/1 [0m                       

                       Computation: 603674 steps/s (collection: 0.043s, learning 0.119s)
                       Mean reward: 280.60
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.0015
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4077
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 0.16s
                      Time elapsed: 00:06:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 401/1 [0m                       

                       Computation: 721461 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 278.39
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.1658
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4072
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 0.14s
                      Time elapsed: 00:07:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 402/1 [0m                       

                       Computation: 805394 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 289.43
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.6079
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4093
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 0.12s
                      Time elapsed: 00:07:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 403/1 [0m                       

                       Computation: 649204 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 284.91
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.6801
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4096
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 0.15s
                      Time elapsed: 00:07:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 404/1 [0m                       

                       Computation: 559133 steps/s (collection: 0.061s, learning 0.115s)
                       Mean reward: 284.97
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.6091
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4105
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 0.18s
                      Time elapsed: 00:07:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 405/1 [0m                       

                       Computation: 847215 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 286.19
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.8050
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4091
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 0.12s
                      Time elapsed: 00:07:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 406/1 [0m                       

                       Computation: 892267 steps/s (collection: 0.037s, learning 0.073s)
                       Mean reward: 284.20
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.2585
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4081
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 0.11s
                      Time elapsed: 00:07:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 407/1 [0m                       

                       Computation: 862759 steps/s (collection: 0.039s, learning 0.075s)
                       Mean reward: 283.33
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.6973
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4088
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 0.11s
                      Time elapsed: 00:07:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 408/1 [0m                       

                       Computation: 717484 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 286.48
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.7439
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4091
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 0.14s
                      Time elapsed: 00:07:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 409/1 [0m                       

                       Computation: 835361 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 284.57
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.3890
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4080
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 0.12s
                      Time elapsed: 00:07:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 410/1 [0m                       

                       Computation: 704551 steps/s (collection: 0.046s, learning 0.094s)
                       Mean reward: 283.03
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.1341
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4106
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 0.14s
                      Time elapsed: 00:07:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 411/1 [0m                       

                       Computation: 520211 steps/s (collection: 0.051s, learning 0.138s)
                       Mean reward: 284.89
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.3193
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4077
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 0.19s
                      Time elapsed: 00:07:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 412/1 [0m                       

                       Computation: 744611 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 288.01
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.1110
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4086
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 0.13s
                      Time elapsed: 00:07:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 413/1 [0m                       

                       Computation: 661410 steps/s (collection: 0.055s, learning 0.094s)
                       Mean reward: 284.04
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.6623
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4076
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 0.15s
                      Time elapsed: 00:07:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 414/1 [0m                       

                       Computation: 756203 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 285.89
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.7255
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4093
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 0.13s
                      Time elapsed: 00:07:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 415/1 [0m                       

                       Computation: 661003 steps/s (collection: 0.038s, learning 0.111s)
                       Mean reward: 287.91
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.2957
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4075
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 0.15s
                      Time elapsed: 00:07:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 416/1 [0m                       

                       Computation: 844615 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 283.53
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.2925
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4059
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 0.12s
                      Time elapsed: 00:07:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 417/1 [0m                       

                       Computation: 853850 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 287.03
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.5467
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4049
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 18.5833
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 0.12s
                      Time elapsed: 00:07:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 418/1 [0m                       

                       Computation: 888596 steps/s (collection: 0.036s, learning 0.075s)
                       Mean reward: 286.15
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.5356
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4029
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 0.11s
                      Time elapsed: 00:07:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 419/1 [0m                       

                       Computation: 855326 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 293.57
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.3955
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4116
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 0.11s
                      Time elapsed: 00:07:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 420/1 [0m                       

                       Computation: 787092 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 285.27
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.7347
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4083
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 0.12s
                      Time elapsed: 00:07:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 421/1 [0m                       

                       Computation: 850739 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 289.22
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.4099
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4107
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 0.12s
                      Time elapsed: 00:07:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 422/1 [0m                       

                       Computation: 729160 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 289.77
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.4367
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4103
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 0.13s
                      Time elapsed: 00:07:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 423/1 [0m                       

                       Computation: 784559 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 287.83
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.0799
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4086
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 0.13s
                      Time elapsed: 00:07:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 424/1 [0m                       

                       Computation: 828068 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 292.15
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.3422
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4090
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 0.12s
                      Time elapsed: 00:07:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 425/1 [0m                       

                       Computation: 760785 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 288.74
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.2716
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4079
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 0.13s
                      Time elapsed: 00:07:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 426/1 [0m                       

                       Computation: 806872 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 292.76
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.9437
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4088
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 0.12s
                      Time elapsed: 00:07:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 427/1 [0m                       

                       Computation: 802147 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 294.14
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.3184
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 0.12s
                      Time elapsed: 00:07:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 428/1 [0m                       

                       Computation: 820565 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 288.88
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.5048
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4081
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 0.12s
                      Time elapsed: 00:07:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 429/1 [0m                       

                       Computation: 493911 steps/s (collection: 0.048s, learning 0.152s)
                       Mean reward: 289.16
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.3423
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4078
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 0.20s
                      Time elapsed: 00:07:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 430/1 [0m                       

                       Computation: 640602 steps/s (collection: 0.053s, learning 0.100s)
                       Mean reward: 287.10
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.9102
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4059
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 0.15s
                      Time elapsed: 00:07:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 431/1 [0m                       

                       Computation: 786760 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 290.10
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.5369
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4050
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 0.12s
                      Time elapsed: 00:07:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 432/1 [0m                       

                       Computation: 757769 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 287.29
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.8726
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4050
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 0.13s
                      Time elapsed: 00:07:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 433/1 [0m                       

                       Computation: 799167 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 292.60
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.0619
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4073
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 0.12s
                      Time elapsed: 00:07:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 434/1 [0m                       

                       Computation: 657479 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 291.72
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.6991
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4029
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 0.15s
                      Time elapsed: 00:07:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 435/1 [0m                       

                       Computation: 778264 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 287.87
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.3281
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4024
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 0.13s
                      Time elapsed: 00:07:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 436/1 [0m                       

                       Computation: 767866 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 287.62
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.0522
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4049
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 0.13s
                      Time elapsed: 00:07:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 437/1 [0m                       

                       Computation: 771815 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 291.75
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.0759
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4036
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 0.13s
                      Time elapsed: 00:07:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 438/1 [0m                       

                       Computation: 741723 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 295.11
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.8246
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4057
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 0.13s
                      Time elapsed: 00:07:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 439/1 [0m                       

                       Computation: 564812 steps/s (collection: 0.051s, learning 0.124s)
                       Mean reward: 296.83
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.8635
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4042
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 0.17s
                      Time elapsed: 00:07:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 440/1 [0m                       

                       Computation: 612026 steps/s (collection: 0.050s, learning 0.111s)
                       Mean reward: 294.25
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.7061
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4023
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 0.16s
                      Time elapsed: 00:07:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 441/1 [0m                       

                       Computation: 782640 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 293.20
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.0922
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4018
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 0.13s
                      Time elapsed: 00:07:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 442/1 [0m                       

                       Computation: 666006 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 292.80
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.1901
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4023
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 0.15s
                      Time elapsed: 00:07:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 443/1 [0m                       

                       Computation: 619994 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 287.43
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.2041
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4028
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 0.16s
                      Time elapsed: 00:07:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 444/1 [0m                       

                       Computation: 659611 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 293.68
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.2391
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4035
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 0.15s
                      Time elapsed: 00:07:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 445/1 [0m                       

                       Computation: 658806 steps/s (collection: 0.038s, learning 0.111s)
                       Mean reward: 286.31
               Mean episode length: 247.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.7479
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.3976
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 0.15s
                      Time elapsed: 00:07:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 446/1 [0m                       

                       Computation: 767972 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 290.87
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.3565
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4015
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 0.13s
                      Time elapsed: 00:07:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 447/1 [0m                       

                       Computation: 707136 steps/s (collection: 0.048s, learning 0.092s)
                       Mean reward: 297.57
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.1282
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4019
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 0.14s
                      Time elapsed: 00:07:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 448/1 [0m                       

                       Computation: 622504 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 296.22
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.8802
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4006
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 18.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 0.16s
                      Time elapsed: 00:07:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 449/1 [0m                       

                       Computation: 773552 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 290.90
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.9320
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4001
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 0.13s
                      Time elapsed: 00:07:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 450/1 [0m                       

                       Computation: 695776 steps/s (collection: 0.050s, learning 0.091s)
                       Mean reward: 294.04
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.7132
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4003
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 0.14s
                      Time elapsed: 00:07:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 451/1 [0m                       

                       Computation: 552565 steps/s (collection: 0.062s, learning 0.116s)
                       Mean reward: 289.81
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.6891
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4026
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 0.18s
                      Time elapsed: 00:07:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 452/1 [0m                       

                       Computation: 697082 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 291.99
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.3747
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4024
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 0.14s
                      Time elapsed: 00:07:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 453/1 [0m                       

                       Computation: 640257 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 295.31
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.6195
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4025
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 0.15s
                      Time elapsed: 00:07:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 454/1 [0m                       

                       Computation: 780092 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 293.45
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.2962
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4027
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 0.13s
                      Time elapsed: 00:07:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 455/1 [0m                       

                       Computation: 625060 steps/s (collection: 0.046s, learning 0.112s)
                       Mean reward: 301.70
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.9767
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4054
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 0.16s
                      Time elapsed: 00:08:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 456/1 [0m                       

                       Computation: 742803 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 297.50
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.0916
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4073
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 0.13s
                      Time elapsed: 00:08:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 457/1 [0m                       

                       Computation: 857068 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 291.25
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.8189
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4023
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 0.11s
                      Time elapsed: 00:08:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 458/1 [0m                       

                       Computation: 720492 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 296.12
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.5627
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4047
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 0.14s
                      Time elapsed: 00:08:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 459/1 [0m                       

                       Computation: 655310 steps/s (collection: 0.046s, learning 0.104s)
                       Mean reward: 305.05
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.4208
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4065
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 19.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 0.15s
                      Time elapsed: 00:08:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 460/1 [0m                       

                       Computation: 636369 steps/s (collection: 0.049s, learning 0.106s)
                       Mean reward: 296.57
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.8219
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4046
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 0.15s
                      Time elapsed: 00:08:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 461/1 [0m                       

                       Computation: 784951 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 295.61
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.7522
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4066
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 0.13s
                      Time elapsed: 00:08:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 462/1 [0m                       

                       Computation: 587982 steps/s (collection: 0.049s, learning 0.119s)
                       Mean reward: 299.67
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.4465
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4053
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 0.17s
                      Time elapsed: 00:08:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 463/1 [0m                       

                       Computation: 642409 steps/s (collection: 0.047s, learning 0.106s)
                       Mean reward: 298.41
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.4150
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4098
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 0.15s
                      Time elapsed: 00:08:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 464/1 [0m                       

                       Computation: 638115 steps/s (collection: 0.042s, learning 0.112s)
                       Mean reward: 296.79
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.1245
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4041
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 0.15s
                      Time elapsed: 00:08:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 465/1 [0m                       

                       Computation: 829481 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 301.33
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.9467
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4062
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 0.12s
                      Time elapsed: 00:08:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 466/1 [0m                       

                       Computation: 667251 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 298.46
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.5362
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4050
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 0.15s
                      Time elapsed: 00:08:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 467/1 [0m                       

                       Computation: 822104 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 293.20
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.2018
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4028
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 0.12s
                      Time elapsed: 00:08:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 468/1 [0m                       

                       Computation: 696530 steps/s (collection: 0.037s, learning 0.105s)
                       Mean reward: 304.21
               Mean episode length: 247.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.7634
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4069
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 0.14s
                      Time elapsed: 00:08:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 469/1 [0m                       

                       Computation: 715901 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 296.85
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.9737
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4066
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 0.14s
                      Time elapsed: 00:08:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 470/1 [0m                       

                       Computation: 649788 steps/s (collection: 0.038s, learning 0.113s)
                       Mean reward: 296.79
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.2623
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4061
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 0.15s
                      Time elapsed: 00:08:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 471/1 [0m                       

                       Computation: 655087 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 296.02
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.6481
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4045
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 0.15s
                      Time elapsed: 00:08:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 472/1 [0m                       

                       Computation: 852646 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 300.73
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.5631
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4062
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 0.12s
                      Time elapsed: 00:08:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 473/1 [0m                       

                       Computation: 895593 steps/s (collection: 0.037s, learning 0.073s)
                       Mean reward: 297.93
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.9864
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4057
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 0.11s
                      Time elapsed: 00:08:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 474/1 [0m                       

                       Computation: 893563 steps/s (collection: 0.036s, learning 0.074s)
                       Mean reward: 303.97
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.4032
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4099
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 0.11s
                      Time elapsed: 00:08:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 475/1 [0m                       

                       Computation: 874746 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 302.13
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.3079
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4106
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 0.11s
                      Time elapsed: 00:08:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 476/1 [0m                       

                       Computation: 816060 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 302.60
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.8230
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 0.12s
                      Time elapsed: 00:08:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 477/1 [0m                       

                       Computation: 811257 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 306.24
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.7130
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4095
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 0.12s
                      Time elapsed: 00:08:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 478/1 [0m                       

                       Computation: 722564 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 297.83
               Mean episode length: 246.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.9082
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4056
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 0.14s
                      Time elapsed: 00:08:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 479/1 [0m                       

                       Computation: 714978 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 302.05
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.1358
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4067
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 0.14s
                      Time elapsed: 00:08:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 480/1 [0m                       

                       Computation: 783159 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 300.09
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.2734
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4079
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 0.13s
                      Time elapsed: 00:08:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 481/1 [0m                       

                       Computation: 795576 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 298.95
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.0669
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4072
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 0.12s
                      Time elapsed: 00:08:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 482/1 [0m                       

                       Computation: 696151 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 299.40
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.5736
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4070
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 0.14s
                      Time elapsed: 00:08:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 483/1 [0m                       

                       Computation: 678900 steps/s (collection: 0.046s, learning 0.099s)
                       Mean reward: 302.27
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.1671
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4064
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 0.14s
                      Time elapsed: 00:08:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 484/1 [0m                       

                       Computation: 725383 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 302.78
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.0377
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4085
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 0.14s
                      Time elapsed: 00:08:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 485/1 [0m                       

                       Computation: 857828 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 301.23
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.8309
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4083
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 0.11s
                      Time elapsed: 00:08:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 486/1 [0m                       

                       Computation: 767075 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 304.15
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.4887
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4086
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 0.13s
                      Time elapsed: 00:08:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 487/1 [0m                       

                       Computation: 887109 steps/s (collection: 0.037s, learning 0.074s)
                       Mean reward: 307.77
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.9585
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4107
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 0.11s
                      Time elapsed: 00:08:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 488/1 [0m                       

                       Computation: 829502 steps/s (collection: 0.043s, learning 0.076s)
                       Mean reward: 305.17
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.6348
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4100
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 0.12s
                      Time elapsed: 00:08:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 489/1 [0m                       

                       Computation: 897679 steps/s (collection: 0.037s, learning 0.073s)
                       Mean reward: 295.77
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.9316
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4052
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 0.11s
                      Time elapsed: 00:08:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 490/1 [0m                       

                       Computation: 786775 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 304.87
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.6945
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4084
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 19.0000
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 0.12s
                      Time elapsed: 00:08:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 491/1 [0m                       

                       Computation: 749094 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 302.80
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.1442
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4110
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 0.13s
                      Time elapsed: 00:08:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 492/1 [0m                       

                       Computation: 670297 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 301.46
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.5516
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4063
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 0.15s
                      Time elapsed: 00:08:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 493/1 [0m                       

                       Computation: 659641 steps/s (collection: 0.047s, learning 0.102s)
                       Mean reward: 301.29
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.0614
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4083
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 0.15s
                      Time elapsed: 00:08:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 494/1 [0m                       

                       Computation: 728995 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 304.04
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.2912
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4087
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 0.13s
                      Time elapsed: 00:08:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 495/1 [0m                       

                       Computation: 703670 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 303.93
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.2737
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4074
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 0.14s
                      Time elapsed: 00:08:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 496/1 [0m                       

                       Computation: 617422 steps/s (collection: 0.043s, learning 0.116s)
                       Mean reward: 301.95
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.1227
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 0.16s
                      Time elapsed: 00:08:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 497/1 [0m                       

                       Computation: 710129 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 303.70
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.2571
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4085
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 0.14s
                      Time elapsed: 00:08:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 498/1 [0m                       

                       Computation: 764940 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 306.28
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.6001
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4115
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 0.13s
                      Time elapsed: 00:08:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 499/1 [0m                       

                       Computation: 807870 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 303.02
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.6587
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4108
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 0.12s
                      Time elapsed: 00:08:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 500/1 [0m                       

                       Computation: 685926 steps/s (collection: 0.039s, learning 0.104s)
                       Mean reward: 305.94
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.5895
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4108
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 19.0833
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 0.14s
                      Time elapsed: 00:08:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 501/1 [0m                       

                       Computation: 858421 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 304.29
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.4731
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4091
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 0.11s
                      Time elapsed: 00:08:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 502/1 [0m                       

                       Computation: 863371 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 305.94
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.8296
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4094
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 0.11s
                      Time elapsed: 00:08:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 503/1 [0m                       

                       Computation: 827932 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 306.33
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.9611
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4113
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 0.12s
                      Time elapsed: 00:08:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 504/1 [0m                       

                       Computation: 851004 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 304.11
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.5629
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4107
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 0.12s
                      Time elapsed: 00:08:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 505/1 [0m                       

                       Computation: 854712 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 308.63
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.4059
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 0.12s
                      Time elapsed: 00:08:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 506/1 [0m                       

                       Computation: 884392 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 304.29
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.7786
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4088
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 0.11s
                      Time elapsed: 00:08:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 507/1 [0m                       

                       Computation: 824996 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 307.14
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.3167
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4097
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 0.12s
                      Time elapsed: 00:08:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 508/1 [0m                       

                       Computation: 502759 steps/s (collection: 0.060s, learning 0.136s)
                       Mean reward: 309.99
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.5768
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 0.20s
                      Time elapsed: 00:08:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 509/1 [0m                       

                       Computation: 741811 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 308.36
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.4310
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4085
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 0.13s
                      Time elapsed: 00:08:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 510/1 [0m                       

                       Computation: 773226 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 312.00
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.9552
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4117
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 0.13s
                      Time elapsed: 00:09:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 511/1 [0m                       

                       Computation: 817287 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 310.20
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.7037
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4115
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 0.12s
                      Time elapsed: 00:09:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 512/1 [0m                       

                       Computation: 805684 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 308.58
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.0320
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4105
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 0.12s
                      Time elapsed: 00:09:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 513/1 [0m                       

                       Computation: 770703 steps/s (collection: 0.045s, learning 0.083s)
                       Mean reward: 305.64
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.7526
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4082
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 0.13s
                      Time elapsed: 00:09:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 514/1 [0m                       

                       Computation: 745596 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 308.81
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.2532
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4103
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 0.13s
                      Time elapsed: 00:09:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 515/1 [0m                       

                       Computation: 762055 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 311.06
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.6131
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4100
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 0.13s
                      Time elapsed: 00:09:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 516/1 [0m                       

                       Computation: 718208 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 309.91
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.4862
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4123
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 0.14s
                      Time elapsed: 00:09:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 517/1 [0m                       

                       Computation: 827997 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 303.91
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.4613
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4079
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 0.12s
                      Time elapsed: 00:09:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 518/1 [0m                       

                       Computation: 729025 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 315.25
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.5806
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 0.13s
                      Time elapsed: 00:09:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 519/1 [0m                       

                       Computation: 889683 steps/s (collection: 0.037s, learning 0.073s)
                       Mean reward: 312.48
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.0096
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4143
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 0.11s
                      Time elapsed: 00:09:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 520/1 [0m                       

                       Computation: 840480 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 311.90
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.8867
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4118
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 0.12s
                      Time elapsed: 00:09:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 521/1 [0m                       

                       Computation: 819418 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 306.93
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.7335
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4082
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 19.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 0.12s
                      Time elapsed: 00:09:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 522/1 [0m                       

                       Computation: 770010 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 311.74
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.1279
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4156
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 0.13s
                      Time elapsed: 00:09:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 523/1 [0m                       

                       Computation: 725987 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 313.59
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.3446
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4126
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 0.14s
                      Time elapsed: 00:09:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 524/1 [0m                       

                       Computation: 758342 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 313.93
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.3268
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4147
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 0.13s
                      Time elapsed: 00:09:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 525/1 [0m                       

                       Computation: 839326 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 314.90
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.5202
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4116
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 0.12s
                      Time elapsed: 00:09:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 526/1 [0m                       

                       Computation: 747457 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 304.94
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.6202
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4102
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 0.13s
                      Time elapsed: 00:09:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 527/1 [0m                       

                       Computation: 779649 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 312.76
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.0408
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4128
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 0.13s
                      Time elapsed: 00:09:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 528/1 [0m                       

                       Computation: 802243 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 312.00
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.0651
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4152
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 0.12s
                      Time elapsed: 00:09:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 529/1 [0m                       

                       Computation: 855336 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 308.39
               Mean episode length: 247.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.2017
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4080
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 0.11s
                      Time elapsed: 00:09:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 530/1 [0m                       

                       Computation: 817845 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 310.11
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.8857
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4089
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 0.12s
                      Time elapsed: 00:09:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 531/1 [0m                       

                       Computation: 801404 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 310.36
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.5998
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4083
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 0.12s
                      Time elapsed: 00:09:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 532/1 [0m                       

                       Computation: 815545 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 314.18
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.9688
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4119
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.5417
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 0.12s
                      Time elapsed: 00:09:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 533/1 [0m                       

                       Computation: 824294 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 309.83
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.7010
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 0.12s
                      Time elapsed: 00:09:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 534/1 [0m                       

                       Computation: 833005 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 312.18
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.2109
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 0.12s
                      Time elapsed: 00:09:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 535/1 [0m                       

                       Computation: 889551 steps/s (collection: 0.039s, learning 0.072s)
                       Mean reward: 314.22
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.5961
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4099
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 0.11s
                      Time elapsed: 00:09:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 536/1 [0m                       

                       Computation: 759975 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 312.02
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.8858
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4113
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 0.13s
                      Time elapsed: 00:09:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 537/1 [0m                       

                       Computation: 836517 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 313.54
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.3673
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4097
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 0.12s
                      Time elapsed: 00:09:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 538/1 [0m                       

                       Computation: 836542 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 307.04
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.1023
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4085
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 0.12s
                      Time elapsed: 00:09:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 539/1 [0m                       

                       Computation: 773854 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 310.85
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.7135
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4052
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 0.13s
                      Time elapsed: 00:09:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 540/1 [0m                       

                       Computation: 828922 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 314.19
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.2802
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4078
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 0.12s
                      Time elapsed: 00:09:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 541/1 [0m                       

                       Computation: 859091 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 310.10
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.4424
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4061
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 0.11s
                      Time elapsed: 00:09:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 542/1 [0m                       

                       Computation: 834869 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 315.64
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.0096
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4079
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 19.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 0.12s
                      Time elapsed: 00:09:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 543/1 [0m                       

                       Computation: 889227 steps/s (collection: 0.037s, learning 0.074s)
                       Mean reward: 316.01
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.7035
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4065
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 0.11s
                      Time elapsed: 00:09:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 544/1 [0m                       

                       Computation: 861056 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 310.79
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.0842
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4061
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 0.11s
                      Time elapsed: 00:09:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 545/1 [0m                       

                       Computation: 828452 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 313.44
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.2958
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4058
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 0.12s
                      Time elapsed: 00:09:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 546/1 [0m                       

                       Computation: 891985 steps/s (collection: 0.037s, learning 0.073s)
                       Mean reward: 314.80
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.5803
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4065
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 0.11s
                      Time elapsed: 00:09:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 547/1 [0m                       

                       Computation: 892028 steps/s (collection: 0.037s, learning 0.073s)
                       Mean reward: 313.52
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.3681
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4058
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 0.11s
                      Time elapsed: 00:09:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 548/1 [0m                       

                       Computation: 890462 steps/s (collection: 0.037s, learning 0.074s)
                       Mean reward: 312.53
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.0013
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4064
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 0.11s
                      Time elapsed: 00:09:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 549/1 [0m                       

                       Computation: 785423 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 313.63
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.0516
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4073
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 0.13s
                      Time elapsed: 00:09:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 550/1 [0m                       

                       Computation: 824707 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 310.08
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.6037
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4067
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 0.12s
                      Time elapsed: 00:09:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 551/1 [0m                       

                       Computation: 770072 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 311.38
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.1536
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4019
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 0.13s
                      Time elapsed: 00:09:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 552/1 [0m                       

                       Computation: 802792 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 314.35
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.4730
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4058
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 0.12s
                      Time elapsed: 00:09:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 553/1 [0m                       

                       Computation: 744656 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 317.69
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.7739
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4042
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 0.13s
                      Time elapsed: 00:09:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 554/1 [0m                       

                       Computation: 865072 steps/s (collection: 0.036s, learning 0.077s)
                       Mean reward: 316.55
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.6366
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.3995
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 0.11s
                      Time elapsed: 00:09:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 555/1 [0m                       

                       Computation: 853836 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 316.82
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.8970
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4018
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 0.12s
                      Time elapsed: 00:09:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 556/1 [0m                       

                       Computation: 849969 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 322.26
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.1633
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4056
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 0.12s
                      Time elapsed: 00:09:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 557/1 [0m                       

                       Computation: 848512 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 310.89
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.6438
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4004
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 0.12s
                      Time elapsed: 00:09:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 558/1 [0m                       

                       Computation: 829307 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 316.72
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.8819
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4028
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 0.12s
                      Time elapsed: 00:09:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 559/1 [0m                       

                       Computation: 868176 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 314.54
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.5941
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4031
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 0.11s
                      Time elapsed: 00:09:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 560/1 [0m                       

                       Computation: 753950 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 317.21
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.1292
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4037
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 0.13s
                      Time elapsed: 00:09:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 561/1 [0m                       

                       Computation: 846035 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 317.04
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.8331
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4028
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 0.12s
                      Time elapsed: 00:09:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 562/1 [0m                       

                       Computation: 842117 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 318.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.2317
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4036
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 0.12s
                      Time elapsed: 00:09:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 563/1 [0m                       

                       Computation: 751325 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 315.83
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.4245
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.3999
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 0.13s
                      Time elapsed: 00:09:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 564/1 [0m                       

                       Computation: 820312 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 321.41
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.7536
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4034
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 0.12s
                      Time elapsed: 00:09:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 565/1 [0m                       

                       Computation: 809569 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 323.05
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.1320
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4044
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 0.12s
                      Time elapsed: 00:09:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 566/1 [0m                       

                       Computation: 823811 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 320.35
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.6429
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4029
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 0.12s
                      Time elapsed: 00:09:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 567/1 [0m                       

                       Computation: 774979 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 319.79
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.6569
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4006
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 0.13s
                      Time elapsed: 00:09:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 568/1 [0m                       

                       Computation: 841516 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 322.09
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9575
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4039
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 0.12s
                      Time elapsed: 00:09:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 569/1 [0m                       

                       Computation: 789171 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 316.18
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.4965
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4026
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 0.12s
                      Time elapsed: 00:10:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 570/1 [0m                       

                       Computation: 571308 steps/s (collection: 0.045s, learning 0.127s)
                       Mean reward: 318.36
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.2559
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4018
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 0.17s
                      Time elapsed: 00:10:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 571/1 [0m                       

                       Computation: 734389 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 317.83
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.0530
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4048
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 0.13s
                      Time elapsed: 00:10:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 572/1 [0m                       

                       Computation: 773990 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 322.49
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9309
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4043
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 0.13s
                      Time elapsed: 00:10:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 573/1 [0m                       

                       Computation: 877626 steps/s (collection: 0.041s, learning 0.071s)
                       Mean reward: 317.17
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.3217
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4036
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 0.11s
                      Time elapsed: 00:10:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 574/1 [0m                       

                       Computation: 775898 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 318.07
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.0374
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4052
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 0.13s
                      Time elapsed: 00:10:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 575/1 [0m                       

                       Computation: 916787 steps/s (collection: 0.038s, learning 0.070s)
                       Mean reward: 318.12
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.0716
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4031
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 0.11s
                      Time elapsed: 00:10:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 576/1 [0m                       

                       Computation: 789195 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 320.26
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.5989
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4070
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 0.12s
                      Time elapsed: 00:10:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 577/1 [0m                       

                       Computation: 839964 steps/s (collection: 0.041s, learning 0.076s)
                       Mean reward: 323.64
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.2478
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4071
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 0.12s
                      Time elapsed: 00:10:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 578/1 [0m                       

                       Computation: 794717 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 315.91
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.7470
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4062
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 0.12s
                      Time elapsed: 00:10:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 579/1 [0m                       

                       Computation: 801169 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 322.72
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.0465
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4091
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 0.12s
                      Time elapsed: 00:10:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 580/1 [0m                       

                       Computation: 838475 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 319.09
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.4472
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4077
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 0.12s
                      Time elapsed: 00:10:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 581/1 [0m                       

                       Computation: 890831 steps/s (collection: 0.036s, learning 0.075s)
                       Mean reward: 315.92
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.7187
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4096
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 0.11s
                      Time elapsed: 00:10:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 582/1 [0m                       

                       Computation: 854408 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 315.70
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.7163
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4090
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 0.12s
                      Time elapsed: 00:10:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 583/1 [0m                       

                       Computation: 877355 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 321.50
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9811
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4107
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 0.11s
                      Time elapsed: 00:10:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 584/1 [0m                       

                       Computation: 873487 steps/s (collection: 0.038s, learning 0.074s)
                       Mean reward: 318.91
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.3523
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4110
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 18.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 0.11s
                      Time elapsed: 00:10:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 585/1 [0m                       

                       Computation: 660121 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 321.69
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9762
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4120
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 0.15s
                      Time elapsed: 00:10:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 586/1 [0m                       

                       Computation: 649391 steps/s (collection: 0.050s, learning 0.102s)
                       Mean reward: 319.78
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.6331
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4128
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 0.15s
                      Time elapsed: 00:10:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 587/1 [0m                       

                       Computation: 569757 steps/s (collection: 0.050s, learning 0.123s)
                       Mean reward: 313.40
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.2747
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 0.17s
                      Time elapsed: 00:10:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 588/1 [0m                       

                       Computation: 593697 steps/s (collection: 0.046s, learning 0.120s)
                       Mean reward: 320.35
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.6047
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4137
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 0.17s
                      Time elapsed: 00:10:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 589/1 [0m                       

                       Computation: 473676 steps/s (collection: 0.052s, learning 0.156s)
                       Mean reward: 320.96
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9074
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4120
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 0.21s
                      Time elapsed: 00:10:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 590/1 [0m                       

                       Computation: 809769 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 318.45
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.4317
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 0.12s
                      Time elapsed: 00:10:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 591/1 [0m                       

                       Computation: 767866 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 321.52
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.0539
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4109
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 0.13s
                      Time elapsed: 00:10:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 592/1 [0m                       

                       Computation: 719771 steps/s (collection: 0.051s, learning 0.086s)
                       Mean reward: 320.18
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.7610
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4116
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 0.14s
                      Time elapsed: 00:10:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 593/1 [0m                       

                       Computation: 685117 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 319.23
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.4832
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4122
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 0.14s
                      Time elapsed: 00:10:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 594/1 [0m                       

                       Computation: 747854 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 322.29
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.8803
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4086
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 18.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 0.13s
                      Time elapsed: 00:10:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 595/1 [0m                       

                       Computation: 668494 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 322.81
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.1978
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4120
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 0.15s
                      Time elapsed: 00:10:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 596/1 [0m                       

                       Computation: 756120 steps/s (collection: 0.045s, learning 0.086s)
                       Mean reward: 323.07
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.0300
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4131
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 0.13s
                      Time elapsed: 00:10:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 597/1 [0m                       

                       Computation: 716584 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 320.91
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.5519
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4100
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 0.14s
                      Time elapsed: 00:10:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 598/1 [0m                       

                       Computation: 741869 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 323.47
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.2217
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4086
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 0.13s
                      Time elapsed: 00:10:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 599/1 [0m                       

                       Computation: 788224 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 321.90
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.8479
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4087
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 0.12s
                      Time elapsed: 00:10:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 600/1 [0m                       

                       Computation: 715260 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 322.09
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.0472
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4095
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 0.14s
                      Time elapsed: 00:10:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 601/1 [0m                       

                       Computation: 709611 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 324.28
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.4110
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4100
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 0.14s
                      Time elapsed: 00:10:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 602/1 [0m                       

                       Computation: 734378 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 324.23
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.4674
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4092
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 0.13s
                      Time elapsed: 00:10:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 603/1 [0m                       

                       Computation: 683889 steps/s (collection: 0.042s, learning 0.102s)
                       Mean reward: 321.80
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.7959
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4082
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 0.14s
                      Time elapsed: 00:10:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 604/1 [0m                       

                       Computation: 785799 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 320.99
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.0951
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4070
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 0.13s
                      Time elapsed: 00:10:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 605/1 [0m                       

                       Computation: 718921 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 321.83
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.7291
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4067
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 18.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 0.14s
                      Time elapsed: 00:10:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 606/1 [0m                       

                       Computation: 728100 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 322.02
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9119
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4043
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 0.14s
                      Time elapsed: 00:10:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 607/1 [0m                       

                       Computation: 609732 steps/s (collection: 0.046s, learning 0.116s)
                       Mean reward: 330.12
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.7895
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4084
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 0.16s
                      Time elapsed: 00:10:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 608/1 [0m                       

                       Computation: 661927 steps/s (collection: 0.050s, learning 0.099s)
                       Mean reward: 324.98
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.6994
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4063
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 0.15s
                      Time elapsed: 00:10:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 609/1 [0m                       

                       Computation: 675144 steps/s (collection: 0.039s, learning 0.107s)
                       Mean reward: 324.56
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.4556
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4098
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 0.15s
                      Time elapsed: 00:10:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 610/1 [0m                       

                       Computation: 640380 steps/s (collection: 0.038s, learning 0.116s)
                       Mean reward: 323.11
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.0833
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4055
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 0.15s
                      Time elapsed: 00:10:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 611/1 [0m                       

                       Computation: 705087 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 328.80
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.2922
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4122
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 0.14s
                      Time elapsed: 00:10:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 612/1 [0m                       

                       Computation: 657416 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 324.59
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.4703
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4093
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 0.15s
                      Time elapsed: 00:10:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 613/1 [0m                       

                       Computation: 627756 steps/s (collection: 0.050s, learning 0.107s)
                       Mean reward: 325.08
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.4699
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4092
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 0.16s
                      Time elapsed: 00:10:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 614/1 [0m                       

                       Computation: 650938 steps/s (collection: 0.038s, learning 0.113s)
                       Mean reward: 322.19
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9590
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4100
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 0.15s
                      Time elapsed: 00:10:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 615/1 [0m                       

                       Computation: 686255 steps/s (collection: 0.048s, learning 0.095s)
                       Mean reward: 328.28
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.9966
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4123
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 19.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 0.14s
                      Time elapsed: 00:10:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 616/1 [0m                       

                       Computation: 699412 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 329.01
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.5373
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4105
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 0.14s
                      Time elapsed: 00:10:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 617/1 [0m                       

                       Computation: 627911 steps/s (collection: 0.045s, learning 0.112s)
                       Mean reward: 323.27
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.0701
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4086
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 0.16s
                      Time elapsed: 00:10:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 618/1 [0m                       

                       Computation: 694539 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 327.43
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.8586
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4085
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 0.14s
                      Time elapsed: 00:10:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 619/1 [0m                       

                       Computation: 696857 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 328.24
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.1945
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4102
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 0.14s
                      Time elapsed: 00:10:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 620/1 [0m                       

                       Computation: 517067 steps/s (collection: 0.049s, learning 0.141s)
                       Mean reward: 327.00
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.0854
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4090
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 0.19s
                      Time elapsed: 00:10:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 621/1 [0m                       

                       Computation: 517091 steps/s (collection: 0.054s, learning 0.136s)
                       Mean reward: 329.11
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.4581
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4096
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 0.19s
                      Time elapsed: 00:10:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 622/1 [0m                       

                       Computation: 541289 steps/s (collection: 0.053s, learning 0.129s)
                       Mean reward: 328.01
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.2424
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4111
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 0.18s
                      Time elapsed: 00:10:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 623/1 [0m                       

                       Computation: 572897 steps/s (collection: 0.046s, learning 0.126s)
                       Mean reward: 327.88
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.0808
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4108
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 0.17s
                      Time elapsed: 00:11:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 624/1 [0m                       

                       Computation: 679999 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 327.08
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.0812
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4111
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 0.14s
                      Time elapsed: 00:11:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 625/1 [0m                       

                       Computation: 618158 steps/s (collection: 0.046s, learning 0.113s)
                       Mean reward: 324.14
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.4477
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4115
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 0.16s
                      Time elapsed: 00:11:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 626/1 [0m                       

                       Computation: 679942 steps/s (collection: 0.038s, learning 0.107s)
                       Mean reward: 330.60
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.6846
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4115
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 0.14s
                      Time elapsed: 00:11:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 627/1 [0m                       

                       Computation: 574575 steps/s (collection: 0.052s, learning 0.120s)
                       Mean reward: 328.02
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.9358
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4099
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 0.17s
                      Time elapsed: 00:11:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 628/1 [0m                       

                       Computation: 479112 steps/s (collection: 0.047s, learning 0.159s)
                       Mean reward: 323.78
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.2468
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4097
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 0.21s
                      Time elapsed: 00:11:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 629/1 [0m                       

                       Computation: 393053 steps/s (collection: 0.079s, learning 0.171s)
                       Mean reward: 329.47
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.4578
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4093
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 0.25s
                      Time elapsed: 00:11:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 630/1 [0m                       

                       Computation: 408551 steps/s (collection: 0.061s, learning 0.180s)
                       Mean reward: 327.13
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.7922
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4117
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 0.24s
                      Time elapsed: 00:11:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 631/1 [0m                       

                       Computation: 518558 steps/s (collection: 0.074s, learning 0.116s)
                       Mean reward: 323.82
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.2453
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4071
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 0.19s
                      Time elapsed: 00:11:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 632/1 [0m                       

                       Computation: 347765 steps/s (collection: 0.069s, learning 0.214s)
                       Mean reward: 333.15
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.5490
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4103
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 0.28s
                      Time elapsed: 00:11:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 633/1 [0m                       

                       Computation: 633470 steps/s (collection: 0.053s, learning 0.103s)
                       Mean reward: 330.32
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.6215
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4123
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 0.16s
                      Time elapsed: 00:11:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 634/1 [0m                       

                       Computation: 679810 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 331.91
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.8340
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 0.14s
                      Time elapsed: 00:11:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 635/1 [0m                       

                       Computation: 679948 steps/s (collection: 0.048s, learning 0.097s)
                       Mean reward: 329.53
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.2297
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4072
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 0.14s
                      Time elapsed: 00:11:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 636/1 [0m                       

                       Computation: 750302 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 327.84
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.1758
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4101
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 0.13s
                      Time elapsed: 00:11:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 637/1 [0m                       

                       Computation: 599342 steps/s (collection: 0.043s, learning 0.122s)
                       Mean reward: 327.11
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.9033
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4080
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 0.16s
                      Time elapsed: 00:11:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 638/1 [0m                       

                       Computation: 544565 steps/s (collection: 0.046s, learning 0.135s)
                       Mean reward: 327.56
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.4774
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4095
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 0.18s
                      Time elapsed: 00:11:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 639/1 [0m                       

                       Computation: 710932 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 334.70
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.4505
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4113
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 0.14s
                      Time elapsed: 00:11:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 640/1 [0m                       

                       Computation: 582556 steps/s (collection: 0.044s, learning 0.125s)
                       Mean reward: 328.97
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.4132
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4083
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 0.17s
                      Time elapsed: 00:11:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 641/1 [0m                       

                       Computation: 717015 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 332.90
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.2501
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4089
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 0.14s
                      Time elapsed: 00:11:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 642/1 [0m                       

                       Computation: 620098 steps/s (collection: 0.045s, learning 0.114s)
                       Mean reward: 332.87
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.2691
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4090
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 0.16s
                      Time elapsed: 00:11:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 643/1 [0m                       

                       Computation: 733556 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 327.42
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.8607
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4070
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 0.13s
                      Time elapsed: 00:11:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 644/1 [0m                       

                       Computation: 470282 steps/s (collection: 0.059s, learning 0.150s)
                       Mean reward: 335.87
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.7767
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4108
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 0.21s
                      Time elapsed: 00:11:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 645/1 [0m                       

                       Computation: 686772 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 336.56
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6531
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4079
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 0.14s
                      Time elapsed: 00:11:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 646/1 [0m                       

                       Computation: 579544 steps/s (collection: 0.048s, learning 0.121s)
                       Mean reward: 331.75
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.7992
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4080
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 19.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 0.17s
                      Time elapsed: 00:11:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 647/1 [0m                       

                       Computation: 753234 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 331.16
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.0290
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4073
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 0.13s
                      Time elapsed: 00:11:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 648/1 [0m                       

                       Computation: 605810 steps/s (collection: 0.048s, learning 0.114s)
                       Mean reward: 333.33
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.0559
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4072
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 0.16s
                      Time elapsed: 00:11:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 649/1 [0m                       

                       Computation: 722739 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 324.95
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.6650
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4073
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 0.14s
                      Time elapsed: 00:11:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 650/1 [0m                       

                       Computation: 660859 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 339.44
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.5327
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4077
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 0.15s
                      Time elapsed: 00:11:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 651/1 [0m                       

                       Computation: 706792 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 331.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.2068
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4081
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 0.14s
                      Time elapsed: 00:11:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 652/1 [0m                       

                       Computation: 600590 steps/s (collection: 0.053s, learning 0.111s)
                       Mean reward: 333.62
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.4504
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4072
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 0.16s
                      Time elapsed: 00:11:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 653/1 [0m                       

                       Computation: 740744 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 329.98
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.6325
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4079
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 0.13s
                      Time elapsed: 00:11:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 654/1 [0m                       

                       Computation: 815703 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 334.20
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6539
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4081
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 0.12s
                      Time elapsed: 00:11:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 655/1 [0m                       

                       Computation: 712294 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 335.58
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.7896
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4083
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 0.14s
                      Time elapsed: 00:11:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 656/1 [0m                       

                       Computation: 686385 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 334.68
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6212
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4087
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 0.14s
                      Time elapsed: 00:11:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 657/1 [0m                       

                       Computation: 773702 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 337.43
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.9572
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4087
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 0.13s
                      Time elapsed: 00:11:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 658/1 [0m                       

                       Computation: 620539 steps/s (collection: 0.047s, learning 0.111s)
                       Mean reward: 336.90
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.0434
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4084
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 0.16s
                      Time elapsed: 00:11:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 659/1 [0m                       

                       Computation: 779587 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 331.87
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.9227
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4102
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 0.13s
                      Time elapsed: 00:11:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 660/1 [0m                       

                       Computation: 747361 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 336.76
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.7621
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4095
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 0.13s
                      Time elapsed: 00:11:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 661/1 [0m                       

                       Computation: 612316 steps/s (collection: 0.047s, learning 0.114s)
                       Mean reward: 329.14
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.2203
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4102
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 0.16s
                      Time elapsed: 00:11:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 662/1 [0m                       

                       Computation: 795342 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 336.14
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.8395
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4123
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 0.12s
                      Time elapsed: 00:11:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 663/1 [0m                       

                       Computation: 749706 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 333.96
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.5053
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 0.13s
                      Time elapsed: 00:11:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 664/1 [0m                       

                       Computation: 847380 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 332.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.1042
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4117
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 0.12s
                      Time elapsed: 00:11:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 665/1 [0m                       

                       Computation: 601265 steps/s (collection: 0.040s, learning 0.123s)
                       Mean reward: 338.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.2716
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 0.16s
                      Time elapsed: 00:11:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 666/1 [0m                       

                       Computation: 675526 steps/s (collection: 0.039s, learning 0.107s)
                       Mean reward: 336.18
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8992
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4105
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 0.15s
                      Time elapsed: 00:11:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 667/1 [0m                       

                       Computation: 676305 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 333.77
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.5003
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4132
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 19.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 0.15s
                      Time elapsed: 00:11:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 668/1 [0m                       

                       Computation: 749398 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 338.63
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.4897
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4142
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 0.13s
                      Time elapsed: 00:11:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 669/1 [0m                       

                       Computation: 675118 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 337.15
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7920
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4137
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 0.15s
                      Time elapsed: 00:11:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 670/1 [0m                       

                       Computation: 603422 steps/s (collection: 0.048s, learning 0.115s)
                       Mean reward: 337.24
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.9924
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4119
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 0.16s
                      Time elapsed: 00:11:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 671/1 [0m                       

                       Computation: 665998 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 332.64
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.9968
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4168
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 0.15s
                      Time elapsed: 00:11:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 672/1 [0m                       

                       Computation: 705597 steps/s (collection: 0.047s, learning 0.092s)
                       Mean reward: 336.91
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8296
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4138
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 0.14s
                      Time elapsed: 00:11:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 673/1 [0m                       

                       Computation: 630056 steps/s (collection: 0.050s, learning 0.107s)
                       Mean reward: 338.83
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.4724
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4154
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 0.16s
                      Time elapsed: 00:12:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 674/1 [0m                       

                       Computation: 730801 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 336.66
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2078
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4148
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 0.13s
                      Time elapsed: 00:12:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 675/1 [0m                       

                       Computation: 747560 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 339.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.4670
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4164
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 0.13s
                      Time elapsed: 00:12:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 676/1 [0m                       

                       Computation: 507950 steps/s (collection: 0.053s, learning 0.141s)
                       Mean reward: 339.56
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.3928
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4150
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 0.19s
                      Time elapsed: 00:12:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 677/1 [0m                       

                       Computation: 606633 steps/s (collection: 0.051s, learning 0.112s)
                       Mean reward: 337.73
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.9176
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4151
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 0.16s
                      Time elapsed: 00:12:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 678/1 [0m                       

                       Computation: 798518 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 336.64
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.0644
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4155
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.7917
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 0.12s
                      Time elapsed: 00:12:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 679/1 [0m                       

                       Computation: 682504 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 338.20
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.3030
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4143
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 0.14s
                      Time elapsed: 00:12:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 680/1 [0m                       

                       Computation: 789366 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 340.06
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.4503
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4164
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 0.12s
                      Time elapsed: 00:12:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 681/1 [0m                       

                       Computation: 772787 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 332.87
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.1769
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4110
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 0.13s
                      Time elapsed: 00:12:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 682/1 [0m                       

                       Computation: 778435 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 332.03
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.9826
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4144
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 0.13s
                      Time elapsed: 00:12:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 683/1 [0m                       

                       Computation: 519983 steps/s (collection: 0.048s, learning 0.142s)
                       Mean reward: 334.73
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.5334
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4152
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 0.19s
                      Time elapsed: 00:12:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 684/1 [0m                       

                       Computation: 691248 steps/s (collection: 0.048s, learning 0.094s)
                       Mean reward: 334.88
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.4710
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4145
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 0.14s
                      Time elapsed: 00:12:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 685/1 [0m                       

                       Computation: 708324 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 329.42
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.7937
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4122
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 0.14s
                      Time elapsed: 00:12:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 686/1 [0m                       

                       Computation: 610393 steps/s (collection: 0.045s, learning 0.117s)
                       Mean reward: 333.63
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.0914
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4141
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 0.16s
                      Time elapsed: 00:12:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 687/1 [0m                       

                       Computation: 804962 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 333.96
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.4793
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4168
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 0.12s
                      Time elapsed: 00:12:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 688/1 [0m                       

                       Computation: 859342 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 333.52
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7856
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4148
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 0.11s
                      Time elapsed: 00:12:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 689/1 [0m                       

                       Computation: 807895 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 331.94
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.1091
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4153
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 0.12s
                      Time elapsed: 00:12:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 690/1 [0m                       

                       Computation: 852265 steps/s (collection: 0.041s, learning 0.074s)
                       Mean reward: 331.21
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.4855
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4164
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 0.12s
                      Time elapsed: 00:12:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 691/1 [0m                       

                       Computation: 761389 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 339.61
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.7562
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4148
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 0.13s
                      Time elapsed: 00:12:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 692/1 [0m                       

                       Computation: 828779 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 332.94
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.2327
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4162
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 0.12s
                      Time elapsed: 00:12:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 693/1 [0m                       

                       Computation: 729210 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 338.16
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3341
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4167
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 0.13s
                      Time elapsed: 00:12:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 694/1 [0m                       

                       Computation: 638169 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 335.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5591
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4177
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 0.15s
                      Time elapsed: 00:12:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 695/1 [0m                       

                       Computation: 624041 steps/s (collection: 0.039s, learning 0.118s)
                       Mean reward: 334.14
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.4843
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4130
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 0.16s
                      Time elapsed: 00:12:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 696/1 [0m                       

                       Computation: 666352 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 339.97
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6439
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4149
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 0.15s
                      Time elapsed: 00:12:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 697/1 [0m                       

                       Computation: 665646 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 335.87
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6786
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4151
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 0.15s
                      Time elapsed: 00:12:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 698/1 [0m                       

                       Computation: 673938 steps/s (collection: 0.039s, learning 0.107s)
                       Mean reward: 329.81
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.7566
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4122
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.9167
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 0.15s
                      Time elapsed: 00:12:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 699/1 [0m                       

                       Computation: 640371 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 335.63
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5603
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4163
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 0.15s
                      Time elapsed: 00:12:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 700/1 [0m                       

                       Computation: 662541 steps/s (collection: 0.046s, learning 0.102s)
                       Mean reward: 337.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.7604
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4157
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 0.15s
                      Time elapsed: 00:12:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 701/1 [0m                       

                       Computation: 541477 steps/s (collection: 0.056s, learning 0.126s)
                       Mean reward: 333.34
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.1175
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4138
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 0.18s
                      Time elapsed: 00:12:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 702/1 [0m                       

                       Computation: 701349 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 334.14
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.4498
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4145
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 0.14s
                      Time elapsed: 00:12:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 703/1 [0m                       

                       Computation: 818703 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 333.21
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.0089
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4138
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 0.12s
                      Time elapsed: 00:12:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 704/1 [0m                       

                       Computation: 661000 steps/s (collection: 0.048s, learning 0.101s)
                       Mean reward: 338.74
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4939
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4157
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 0.15s
                      Time elapsed: 00:12:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 705/1 [0m                       

                       Computation: 771553 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 334.57
               Mean episode length: 247.42
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.4889
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4113
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 0.13s
                      Time elapsed: 00:12:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 706/1 [0m                       

                       Computation: 745226 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 336.67
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8507
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4116
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 0.13s
                      Time elapsed: 00:12:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 707/1 [0m                       

                       Computation: 822449 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 339.95
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3943
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4122
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 0.12s
                      Time elapsed: 00:12:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 708/1 [0m                       

                       Computation: 824406 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 334.25
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.1187
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4116
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 0.12s
                      Time elapsed: 00:12:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 709/1 [0m                       

                       Computation: 691221 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 333.44
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5771
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4131
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 18.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 0.14s
                      Time elapsed: 00:12:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 710/1 [0m                       

                       Computation: 807376 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 342.29
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9600
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4119
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 0.12s
                      Time elapsed: 00:12:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 711/1 [0m                       

                       Computation: 668544 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 334.23
               Mean episode length: 246.85
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.0992
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4082
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 0.15s
                      Time elapsed: 00:12:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 712/1 [0m                       

                       Computation: 630056 steps/s (collection: 0.049s, learning 0.107s)
                       Mean reward: 335.22
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6699
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4124
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 0.16s
                      Time elapsed: 00:12:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 713/1 [0m                       

                       Computation: 799142 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 342.31
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.1388
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4129
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 0.12s
                      Time elapsed: 00:12:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 714/1 [0m                       

                       Computation: 649405 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 339.83
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.7416
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4112
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 0.15s
                      Time elapsed: 00:12:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 715/1 [0m                       

                       Computation: 762217 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 339.72
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4826
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4137
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 0.13s
                      Time elapsed: 00:12:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 716/1 [0m                       

                       Computation: 601133 steps/s (collection: 0.037s, learning 0.127s)
                       Mean reward: 341.30
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.7075
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4099
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 0.16s
                      Time elapsed: 00:12:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 717/1 [0m                       

                       Computation: 697719 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 338.38
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3663
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4089
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 0.14s
                      Time elapsed: 00:12:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 718/1 [0m                       

                       Computation: 669949 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 340.85
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4254
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4129
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 0.15s
                      Time elapsed: 00:12:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 719/1 [0m                       

                       Computation: 736226 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 342.48
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.1086
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4139
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.9583
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 0.13s
                      Time elapsed: 00:12:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 720/1 [0m                       

                       Computation: 608618 steps/s (collection: 0.045s, learning 0.117s)
                       Mean reward: 339.01
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4112
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 0.16s
                      Time elapsed: 00:12:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 721/1 [0m                       

                       Computation: 668677 steps/s (collection: 0.046s, learning 0.101s)
                       Mean reward: 340.01
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4998
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4128
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 0.15s
                      Time elapsed: 00:12:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 722/1 [0m                       

                       Computation: 599334 steps/s (collection: 0.046s, learning 0.118s)
                       Mean reward: 336.50
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8635
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4086
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 0.16s
                      Time elapsed: 00:12:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 723/1 [0m                       

                       Computation: 645963 steps/s (collection: 0.044s, learning 0.108s)
                       Mean reward: 333.56
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5257
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4107
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 0.15s
                      Time elapsed: 00:12:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 724/1 [0m                       

                       Computation: 643996 steps/s (collection: 0.048s, learning 0.105s)
                       Mean reward: 340.52
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4966
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4133
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 0.15s
                      Time elapsed: 00:12:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 725/1 [0m                       

                       Computation: 704452 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 337.45
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.0591
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4122
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 0.14s
                      Time elapsed: 00:13:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 726/1 [0m                       

                       Computation: 799108 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 336.67
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6822
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4080
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 0.12s
                      Time elapsed: 00:13:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 727/1 [0m                       

                       Computation: 767019 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 339.27
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3858
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4099
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 0.13s
                      Time elapsed: 00:13:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 728/1 [0m                       

                       Computation: 799879 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 340.50
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.5311
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4140
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 0.12s
                      Time elapsed: 00:13:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 729/1 [0m                       

                       Computation: 753963 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 346.54
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9929
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4149
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 0.13s
                      Time elapsed: 00:13:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 730/1 [0m                       

                       Computation: 595102 steps/s (collection: 0.048s, learning 0.118s)
                       Mean reward: 338.31
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7422
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4118
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 0.17s
                      Time elapsed: 00:13:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 731/1 [0m                       

                       Computation: 750953 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 340.59
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6451
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4111
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 0.13s
                      Time elapsed: 00:13:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 732/1 [0m                       

                       Computation: 628023 steps/s (collection: 0.050s, learning 0.107s)
                       Mean reward: 332.12
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.0471
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4118
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 0.16s
                      Time elapsed: 00:13:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 733/1 [0m                       

                       Computation: 739055 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 338.30
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.1723
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4114
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 0.13s
                      Time elapsed: 00:13:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 734/1 [0m                       

                       Computation: 721275 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 336.68
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8062
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4116
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 0.14s
                      Time elapsed: 00:13:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 735/1 [0m                       

                       Computation: 509275 steps/s (collection: 0.055s, learning 0.139s)
                       Mean reward: 335.79
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6857
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4122
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 0.19s
                      Time elapsed: 00:13:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 736/1 [0m                       

                       Computation: 638789 steps/s (collection: 0.049s, learning 0.105s)
                       Mean reward: 335.43
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.4889
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4119
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 0.15s
                      Time elapsed: 00:13:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 737/1 [0m                       

                       Computation: 734438 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 336.67
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7208
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4144
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 0.13s
                      Time elapsed: 00:13:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 738/1 [0m                       

                       Computation: 688462 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 334.17
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.1422
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4110
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 0.14s
                      Time elapsed: 00:13:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 739/1 [0m                       

                       Computation: 584859 steps/s (collection: 0.051s, learning 0.118s)
                       Mean reward: 336.67
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.9814
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4147
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 0.17s
                      Time elapsed: 00:13:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 740/1 [0m                       

                       Computation: 471861 steps/s (collection: 0.078s, learning 0.130s)
                       Mean reward: 337.66
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.1447
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4161
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 0.21s
                      Time elapsed: 00:13:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 741/1 [0m                       

                       Computation: 675540 steps/s (collection: 0.043s, learning 0.103s)
                       Mean reward: 334.85
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6884
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4123
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 0.15s
                      Time elapsed: 00:13:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 742/1 [0m                       

                       Computation: 756264 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 334.02
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.4807
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4153
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 0.13s
                      Time elapsed: 00:13:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 743/1 [0m                       

                       Computation: 659843 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 331.20
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.8842
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4133
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 0.15s
                      Time elapsed: 00:13:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 744/1 [0m                       

                       Computation: 592069 steps/s (collection: 0.046s, learning 0.120s)
                       Mean reward: 333.47
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.3163
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4141
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 0.17s
                      Time elapsed: 00:13:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 745/1 [0m                       

                       Computation: 789623 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 333.90
               Mean episode length: 247.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.4820
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4111
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 0.12s
                      Time elapsed: 00:13:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 746/1 [0m                       

                       Computation: 750903 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 335.64
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8547
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4121
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 0.13s
                      Time elapsed: 00:13:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 747/1 [0m                       

                       Computation: 697329 steps/s (collection: 0.049s, learning 0.092s)
                       Mean reward: 335.22
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8114
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4117
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 0.14s
                      Time elapsed: 00:13:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 748/1 [0m                       

                       Computation: 522814 steps/s (collection: 0.060s, learning 0.128s)
                       Mean reward: 336.71
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6461
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4126
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 0.19s
                      Time elapsed: 00:13:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 749/1 [0m                       

                       Computation: 714001 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 335.89
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.9143
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4109
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 0.14s
                      Time elapsed: 00:13:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 750/1 [0m                       

                       Computation: 738687 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 335.73
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7529
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4103
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 0.13s
                      Time elapsed: 00:13:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 751/1 [0m                       

                       Computation: 652157 steps/s (collection: 0.042s, learning 0.109s)
                       Mean reward: 335.13
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5769
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4130
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 0.15s
                      Time elapsed: 00:13:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 752/1 [0m                       

                       Computation: 610497 steps/s (collection: 0.043s, learning 0.119s)
                       Mean reward: 335.18
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5975
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4149
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 0.16s
                      Time elapsed: 00:13:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 753/1 [0m                       

                       Computation: 829494 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 337.30
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7996
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4130
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 0.12s
                      Time elapsed: 00:13:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 754/1 [0m                       

                       Computation: 798300 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 335.28
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6029
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4131
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 0.12s
                      Time elapsed: 00:13:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 755/1 [0m                       

                       Computation: 704635 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 335.29
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5553
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4150
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 0.14s
                      Time elapsed: 00:13:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 756/1 [0m                       

                       Computation: 671792 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 338.07
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2432
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4161
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 0.15s
                      Time elapsed: 00:13:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 757/1 [0m                       

                       Computation: 606754 steps/s (collection: 0.044s, learning 0.119s)
                       Mean reward: 336.70
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.9447
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4157
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 0.16s
                      Time elapsed: 00:13:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 758/1 [0m                       

                       Computation: 564113 steps/s (collection: 0.053s, learning 0.122s)
                       Mean reward: 333.09
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.9112
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4145
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 0.17s
                      Time elapsed: 00:13:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 759/1 [0m                       

                       Computation: 764404 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 337.90
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.5291
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4165
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 0.13s
                      Time elapsed: 00:13:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 760/1 [0m                       

                       Computation: 745207 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 331.80
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.8784
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4134
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 0.13s
                      Time elapsed: 00:13:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 761/1 [0m                       

                       Computation: 608594 steps/s (collection: 0.048s, learning 0.114s)
                       Mean reward: 332.69
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.2064
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4133
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 0.16s
                      Time elapsed: 00:13:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 762/1 [0m                       

                       Computation: 646536 steps/s (collection: 0.055s, learning 0.097s)
                       Mean reward: 332.59
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.0753
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4168
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 0.15s
                      Time elapsed: 00:13:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 763/1 [0m                       

                       Computation: 689726 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 333.48
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.9961
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4145
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 0.14s
                      Time elapsed: 00:13:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 764/1 [0m                       

                       Computation: 602872 steps/s (collection: 0.052s, learning 0.112s)
                       Mean reward: 335.47
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7651
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4160
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 0.16s
                      Time elapsed: 00:13:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 765/1 [0m                       

                       Computation: 787268 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 333.44
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.3031
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4157
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 0.12s
                      Time elapsed: 00:13:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 766/1 [0m                       

                       Computation: 833471 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 338.68
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.4258
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4196
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 0.12s
                      Time elapsed: 00:13:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 767/1 [0m                       

                       Computation: 822551 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 333.83
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.3564
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4130
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 0.12s
                      Time elapsed: 00:13:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 768/1 [0m                       

                       Computation: 800071 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 328.79
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.5134
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4151
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 0.12s
                      Time elapsed: 00:13:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 769/1 [0m                       

                       Computation: 756661 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 333.05
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.1866
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4180
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 0.13s
                      Time elapsed: 00:13:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 770/1 [0m                       

                       Computation: 628083 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 338.46
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.3673
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4192
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 0.16s
                      Time elapsed: 00:13:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 771/1 [0m                       

                       Computation: 785886 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 338.09
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2366
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4168
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 0.13s
                      Time elapsed: 00:13:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 772/1 [0m                       

                       Computation: 780015 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 330.61
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.7982
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4170
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 0.13s
                      Time elapsed: 00:13:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 773/1 [0m                       

                       Computation: 772736 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 339.10
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3609
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4143
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 0.13s
                      Time elapsed: 00:13:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 774/1 [0m                       

                       Computation: 577278 steps/s (collection: 0.047s, learning 0.124s)
                       Mean reward: 335.74
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6531
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4176
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 0.17s
                      Time elapsed: 00:13:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 775/1 [0m                       

                       Computation: 655356 steps/s (collection: 0.045s, learning 0.105s)
                       Mean reward: 336.35
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8428
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4168
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 0.15s
                      Time elapsed: 00:13:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 776/1 [0m                       

                       Computation: 589402 steps/s (collection: 0.043s, learning 0.124s)
                       Mean reward: 335.02
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7545
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4136
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 0.17s
                      Time elapsed: 00:13:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 777/1 [0m                       

                       Computation: 712066 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 330.84
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.6914
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4131
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 0.14s
                      Time elapsed: 00:14:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 778/1 [0m                       

                       Computation: 758932 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 333.16
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.3236
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4187
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 0.13s
                      Time elapsed: 00:14:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 779/1 [0m                       

                       Computation: 688251 steps/s (collection: 0.048s, learning 0.095s)
                       Mean reward: 338.87
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2760
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4183
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 0.14s
                      Time elapsed: 00:14:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 780/1 [0m                       

                       Computation: 634652 steps/s (collection: 0.044s, learning 0.111s)
                       Mean reward: 337.93
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.1902
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4177
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 0.15s
                      Time elapsed: 00:14:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 781/1 [0m                       

                       Computation: 699557 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 341.06
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6687
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4178
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 0.14s
                      Time elapsed: 00:14:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 782/1 [0m                       

                       Computation: 752191 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 338.48
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3651
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4180
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 0.13s
                      Time elapsed: 00:14:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 783/1 [0m                       

                       Computation: 685148 steps/s (collection: 0.039s, learning 0.104s)
                       Mean reward: 331.20
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.5797
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4180
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 0.14s
                      Time elapsed: 00:14:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 784/1 [0m                       

                       Computation: 717716 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 336.46
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8963
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4168
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 0.14s
                      Time elapsed: 00:14:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 785/1 [0m                       

                       Computation: 636212 steps/s (collection: 0.056s, learning 0.099s)
                       Mean reward: 341.36
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.0036
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4183
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 0.15s
                      Time elapsed: 00:14:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 786/1 [0m                       

                       Computation: 777230 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 337.37
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2150
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4195
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 0.13s
                      Time elapsed: 00:14:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 787/1 [0m                       

                       Computation: 784409 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 330.74
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.8174
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4173
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 0.13s
                      Time elapsed: 00:14:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 788/1 [0m                       

                       Computation: 757729 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 334.60
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.3365
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4166
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 0.13s
                      Time elapsed: 00:14:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 789/1 [0m                       

                       Computation: 699827 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 334.28
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.1156
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4184
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 0.14s
                      Time elapsed: 00:14:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 790/1 [0m                       

                       Computation: 778454 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 337.12
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2442
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4202
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 0.13s
                      Time elapsed: 00:14:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 791/1 [0m                       

                       Computation: 706788 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 339.07
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3597
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4209
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 0.14s
                      Time elapsed: 00:14:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 792/1 [0m                       

                       Computation: 726482 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 340.11
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6658
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4203
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 19.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 0.14s
                      Time elapsed: 00:14:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 793/1 [0m                       

                       Computation: 764926 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 337.60
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.1736
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4182
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 0.13s
                      Time elapsed: 00:14:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 794/1 [0m                       

                       Computation: 770497 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 335.92
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6871
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4205
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 0.13s
                      Time elapsed: 00:14:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 795/1 [0m                       

                       Computation: 767876 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 336.49
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.0637
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4194
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 0.13s
                      Time elapsed: 00:14:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 796/1 [0m                       

                       Computation: 847339 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 337.90
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.1695
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4190
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 0.12s
                      Time elapsed: 00:14:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 797/1 [0m                       

                       Computation: 846097 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 330.33
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.7296
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4186
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 0.12s
                      Time elapsed: 00:14:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 798/1 [0m                       

                       Computation: 791960 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 337.43
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.1245
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4173
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 0.12s
                      Time elapsed: 00:14:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 799/1 [0m                       

                       Computation: 806642 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 339.74
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.5556
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4195
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 0.12s
                      Time elapsed: 00:14:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 800/1 [0m                       

                       Computation: 643672 steps/s (collection: 0.039s, learning 0.113s)
                       Mean reward: 338.58
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3116
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4219
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 0.15s
                      Time elapsed: 00:14:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 801/1 [0m                       

                       Computation: 712098 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 333.71
               Mean episode length: 246.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.1092
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4181
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 0.14s
                      Time elapsed: 00:14:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 802/1 [0m                       

                       Computation: 704089 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 332.87
               Mean episode length: 246.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.8990
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4172
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 0.14s
                      Time elapsed: 00:14:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 803/1 [0m                       

                       Computation: 616302 steps/s (collection: 0.037s, learning 0.123s)
                       Mean reward: 339.52
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2506
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4180
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 0.16s
                      Time elapsed: 00:14:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 804/1 [0m                       

                       Computation: 652437 steps/s (collection: 0.038s, learning 0.113s)
                       Mean reward: 335.89
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8162
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4190
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 0.15s
                      Time elapsed: 00:14:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 805/1 [0m                       

                       Computation: 658426 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 337.01
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3346
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4193
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 0.15s
                      Time elapsed: 00:14:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 806/1 [0m                       

                       Computation: 563267 steps/s (collection: 0.047s, learning 0.128s)
                       Mean reward: 334.26
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5395
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4203
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 0.17s
                      Time elapsed: 00:14:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 807/1 [0m                       

                       Computation: 664235 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 336.65
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7149
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4179
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 0.15s
                      Time elapsed: 00:14:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 808/1 [0m                       

                       Computation: 669092 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 336.99
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.0717
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4198
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 0.15s
                      Time elapsed: 00:14:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 809/1 [0m                       

                       Computation: 735020 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 336.84
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.1879
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4195
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 0.13s
                      Time elapsed: 00:14:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 810/1 [0m                       

                       Computation: 795915 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 326.69
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.1787
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4184
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 0.12s
                      Time elapsed: 00:14:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 811/1 [0m                       

                       Computation: 846068 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 340.71
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.7431
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4206
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 0.12s
                      Time elapsed: 00:14:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 812/1 [0m                       

                       Computation: 768334 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 330.03
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.4956
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4193
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 0.13s
                      Time elapsed: 00:14:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 813/1 [0m                       

                       Computation: 805668 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 335.76
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5474
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4164
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 0.12s
                      Time elapsed: 00:14:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 814/1 [0m                       

                       Computation: 833015 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 333.59
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.0376
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4195
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 0.12s
                      Time elapsed: 00:14:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 815/1 [0m                       

                       Computation: 854744 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 336.78
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.0713
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4216
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 0.12s
                      Time elapsed: 00:14:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 816/1 [0m                       

                       Computation: 765362 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 335.37
               Mean episode length: 247.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6542
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4178
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 0.13s
                      Time elapsed: 00:14:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 817/1 [0m                       

                       Computation: 834865 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 340.06
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3510
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4215
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 0.12s
                      Time elapsed: 00:14:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 818/1 [0m                       

                       Computation: 694661 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 336.33
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.0255
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4187
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 0.14s
                      Time elapsed: 00:14:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 819/1 [0m                       

                       Computation: 723327 steps/s (collection: 0.048s, learning 0.088s)
                       Mean reward: 336.20
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6096
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4206
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 0.14s
                      Time elapsed: 00:14:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 820/1 [0m                       

                       Computation: 509168 steps/s (collection: 0.061s, learning 0.132s)
                       Mean reward: 336.94
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8753
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4182
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 0.19s
                      Time elapsed: 00:14:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 821/1 [0m                       

                       Computation: 875353 steps/s (collection: 0.036s, learning 0.076s)
                       Mean reward: 332.77
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.3629
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4185
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 0.11s
                      Time elapsed: 00:14:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 822/1 [0m                       

                       Computation: 741826 steps/s (collection: 0.051s, learning 0.082s)
                       Mean reward: 332.28
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.0845
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4179
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 0.13s
                      Time elapsed: 00:14:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 823/1 [0m                       

                       Computation: 720063 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 336.16
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6663
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4197
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 0.14s
                      Time elapsed: 00:14:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 824/1 [0m                       

                       Computation: 817513 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 337.82
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8007
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4213
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 0.12s
                      Time elapsed: 00:14:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 825/1 [0m                       

                       Computation: 830835 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 331.57
               Mean episode length: 245.91
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.1466
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4155
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 0.12s
                      Time elapsed: 00:14:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 826/1 [0m                       

                       Computation: 840516 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 337.86
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.1142
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4229
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 0.12s
                      Time elapsed: 00:14:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 827/1 [0m                       

                       Computation: 822498 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 339.40
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3893
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4209
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 0.12s
                      Time elapsed: 00:14:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 828/1 [0m                       

                       Computation: 799785 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 340.32
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.7444
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4207
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 0.12s
                      Time elapsed: 00:14:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 829/1 [0m                       

                       Computation: 484501 steps/s (collection: 0.059s, learning 0.144s)
                       Mean reward: 341.54
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9728
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4206
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 0.20s
                      Time elapsed: 00:14:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 830/1 [0m                       

                       Computation: 642220 steps/s (collection: 0.045s, learning 0.108s)
                       Mean reward: 337.20
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8985
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4229
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 0.15s
                      Time elapsed: 00:14:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 831/1 [0m                       

                       Computation: 689798 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 335.41
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.6686
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4202
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 0.14s
                      Time elapsed: 00:15:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 832/1 [0m                       

                       Computation: 785926 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 340.24
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.5591
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4208
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 0.13s
                      Time elapsed: 00:15:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 833/1 [0m                       

                       Computation: 759409 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 330.54
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.6608
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4167
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 0.13s
                      Time elapsed: 00:15:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 834/1 [0m                       

                       Computation: 756429 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 337.64
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.9422
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4168
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 0.13s
                      Time elapsed: 00:15:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 835/1 [0m                       

                       Computation: 740314 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 336.48
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8592
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4190
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 0.13s
                      Time elapsed: 00:15:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 836/1 [0m                       

                       Computation: 839190 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 333.69
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.3419
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4190
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 0.12s
                      Time elapsed: 00:15:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 837/1 [0m                       

                       Computation: 798656 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 339.62
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.5133
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4204
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 0.12s
                      Time elapsed: 00:15:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 838/1 [0m                       

                       Computation: 878951 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 337.73
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.9947
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4220
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 0.11s
                      Time elapsed: 00:15:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 839/1 [0m                       

                       Computation: 873760 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 338.91
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4590
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 0.11s
                      Time elapsed: 00:15:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 840/1 [0m                       

                       Computation: 827543 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 339.81
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3959
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4221
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 0.12s
                      Time elapsed: 00:15:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 841/1 [0m                       

                       Computation: 832968 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 341.73
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8263
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4251
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 0.12s
                      Time elapsed: 00:15:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 842/1 [0m                       

                       Computation: 647855 steps/s (collection: 0.047s, learning 0.105s)
                       Mean reward: 331.63
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.0547
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 0.15s
                      Time elapsed: 00:15:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 843/1 [0m                       

                       Computation: 720085 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 340.94
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9427
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4245
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 0.14s
                      Time elapsed: 00:15:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 844/1 [0m                       

                       Computation: 823477 steps/s (collection: 0.045s, learning 0.074s)
                       Mean reward: 336.84
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7633
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 0.12s
                      Time elapsed: 00:15:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 845/1 [0m                       

                       Computation: 855248 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 340.11
               Mean episode length: 247.24
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4738
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4214
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 0.11s
                      Time elapsed: 00:15:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 846/1 [0m                       

                       Computation: 830557 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 340.28
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9619
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4233
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 0.12s
                      Time elapsed: 00:15:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 847/1 [0m                       

                       Computation: 867575 steps/s (collection: 0.040s, learning 0.074s)
                       Mean reward: 337.11
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8997
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4233
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 0.11s
                      Time elapsed: 00:15:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 848/1 [0m                       

                       Computation: 741106 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 337.41
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.9815
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 0.13s
                      Time elapsed: 00:15:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 849/1 [0m                       

                       Computation: 716235 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 337.44
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.9418
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4235
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 0.14s
                      Time elapsed: 00:15:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 850/1 [0m                       

                       Computation: 746983 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 341.87
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0721
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 0.13s
                      Time elapsed: 00:15:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 851/1 [0m                       

                       Computation: 721656 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 342.84
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.1538
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 0.14s
                      Time elapsed: 00:15:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 852/1 [0m                       

                       Computation: 604825 steps/s (collection: 0.052s, learning 0.111s)
                       Mean reward: 343.66
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.2192
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 0.16s
                      Time elapsed: 00:15:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 853/1 [0m                       

                       Computation: 657433 steps/s (collection: 0.049s, learning 0.101s)
                       Mean reward: 337.04
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7207
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 0.15s
                      Time elapsed: 00:15:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 854/1 [0m                       

                       Computation: 829958 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 344.40
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.6538
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 0.12s
                      Time elapsed: 00:15:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 855/1 [0m                       

                       Computation: 840300 steps/s (collection: 0.046s, learning 0.071s)
                       Mean reward: 342.42
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0497
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4259
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 0.12s
                      Time elapsed: 00:15:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 856/1 [0m                       

                       Computation: 806002 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 340.08
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.5355
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 0.12s
                      Time elapsed: 00:15:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 857/1 [0m                       

                       Computation: 843694 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 337.20
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.8381
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 0.12s
                      Time elapsed: 00:15:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 858/1 [0m                       

                       Computation: 833131 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 345.99
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.8710
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 0.12s
                      Time elapsed: 00:15:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 859/1 [0m                       

                       Computation: 844366 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 336.16
               Mean episode length: 247.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7736
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4256
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 0.12s
                      Time elapsed: 00:15:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 860/1 [0m                       

                       Computation: 780938 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 340.36
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6484
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 0.13s
                      Time elapsed: 00:15:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 861/1 [0m                       

                       Computation: 688356 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 339.67
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.5312
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 0.14s
                      Time elapsed: 00:15:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 862/1 [0m                       

                       Computation: 612251 steps/s (collection: 0.047s, learning 0.114s)
                       Mean reward: 338.21
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2405
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 0.16s
                      Time elapsed: 00:15:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 863/1 [0m                       

                       Computation: 697084 steps/s (collection: 0.048s, learning 0.093s)
                       Mean reward: 346.80
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.0736
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 0.14s
                      Time elapsed: 00:15:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 864/1 [0m                       

                       Computation: 779484 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 341.09
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.7568
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 0.13s
                      Time elapsed: 00:15:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 865/1 [0m                       

                       Computation: 783014 steps/s (collection: 0.047s, learning 0.079s)
                       Mean reward: 338.92
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.0789
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4294
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 18.9167
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 0.13s
                      Time elapsed: 00:15:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 866/1 [0m                       

                       Computation: 709723 steps/s (collection: 0.048s, learning 0.091s)
                       Mean reward: 346.53
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.0396
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4304
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 0.14s
                      Time elapsed: 00:15:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 867/1 [0m                       

                       Computation: 677865 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 343.68
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.2624
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 0.15s
                      Time elapsed: 00:15:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 868/1 [0m                       

                       Computation: 687365 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 340.76
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8089
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4255
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 0.14s
                      Time elapsed: 00:15:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 869/1 [0m                       

                       Computation: 664142 steps/s (collection: 0.052s, learning 0.097s)
                       Mean reward: 346.25
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.8423
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 0.15s
                      Time elapsed: 00:15:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 870/1 [0m                       

                       Computation: 610304 steps/s (collection: 0.041s, learning 0.120s)
                       Mean reward: 342.07
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9542
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4253
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 0.16s
                      Time elapsed: 00:15:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 871/1 [0m                       

                       Computation: 692025 steps/s (collection: 0.038s, learning 0.104s)
                       Mean reward: 344.63
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.5752
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 0.14s
                      Time elapsed: 00:15:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 872/1 [0m                       

                       Computation: 775397 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 342.33
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0496
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 0.13s
                      Time elapsed: 00:15:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 873/1 [0m                       

                       Computation: 802433 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 340.36
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.7795
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 0.12s
                      Time elapsed: 00:15:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 874/1 [0m                       

                       Computation: 765133 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 340.36
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9337
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 0.13s
                      Time elapsed: 00:15:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 875/1 [0m                       

                       Computation: 736291 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 344.09
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.3191
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 0.13s
                      Time elapsed: 00:15:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 876/1 [0m                       

                       Computation: 689741 steps/s (collection: 0.048s, learning 0.095s)
                       Mean reward: 342.04
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8111
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 0.14s
                      Time elapsed: 00:15:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 877/1 [0m                       

                       Computation: 742259 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 340.57
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8717
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 0.13s
                      Time elapsed: 00:15:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 878/1 [0m                       

                       Computation: 644363 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 341.38
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6754
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4326
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 0.15s
                      Time elapsed: 00:15:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 879/1 [0m                       

                       Computation: 724624 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 343.83
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.4047
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 0.14s
                      Time elapsed: 00:15:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 880/1 [0m                       

                       Computation: 632049 steps/s (collection: 0.047s, learning 0.109s)
                       Mean reward: 339.95
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4672
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 0.16s
                      Time elapsed: 00:15:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 881/1 [0m                       

                       Computation: 706084 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 341.10
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6926
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 0.14s
                      Time elapsed: 00:15:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 882/1 [0m                       

                       Computation: 592216 steps/s (collection: 0.047s, learning 0.119s)
                       Mean reward: 339.15
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2044
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 0.17s
                      Time elapsed: 00:15:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 883/1 [0m                       

                       Computation: 646482 steps/s (collection: 0.040s, learning 0.113s)
                       Mean reward: 340.87
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6994
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4304
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 0.15s
                      Time elapsed: 00:15:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 884/1 [0m                       

                       Computation: 834953 steps/s (collection: 0.046s, learning 0.072s)
                       Mean reward: 340.62
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.1341
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 0.12s
                      Time elapsed: 00:15:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 885/1 [0m                       

                       Computation: 786277 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 338.54
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3837
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 0.13s
                      Time elapsed: 00:16:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 886/1 [0m                       

                       Computation: 712298 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 340.03
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.7333
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.0833
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 0.14s
                      Time elapsed: 00:16:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 887/1 [0m                       

                       Computation: 657440 steps/s (collection: 0.046s, learning 0.104s)
                       Mean reward: 344.26
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7129
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 0.15s
                      Time elapsed: 00:16:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 888/1 [0m                       

                       Computation: 650602 steps/s (collection: 0.040s, learning 0.112s)
                       Mean reward: 344.49
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7506
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 0.15s
                      Time elapsed: 00:16:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 889/1 [0m                       

                       Computation: 597797 steps/s (collection: 0.041s, learning 0.123s)
                       Mean reward: 342.49
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0395
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 0.16s
                      Time elapsed: 00:16:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 890/1 [0m                       

                       Computation: 810285 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 343.37
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.1838
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 0.12s
                      Time elapsed: 00:16:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 891/1 [0m                       

                       Computation: 627592 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 342.22
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9117
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 0.16s
                      Time elapsed: 00:16:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 892/1 [0m                       

                       Computation: 724774 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 343.76
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.2241
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 0.14s
                      Time elapsed: 00:16:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 893/1 [0m                       

                       Computation: 712158 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 342.90
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.3731
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 0.14s
                      Time elapsed: 00:16:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 894/1 [0m                       

                       Computation: 711489 steps/s (collection: 0.048s, learning 0.090s)
                       Mean reward: 342.95
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.1013
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 0.14s
                      Time elapsed: 00:16:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 895/1 [0m                       

                       Computation: 687020 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 345.77
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.5994
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 0.14s
                      Time elapsed: 00:16:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 896/1 [0m                       

                       Computation: 795906 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 340.21
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.3580
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 0.12s
                      Time elapsed: 00:16:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 897/1 [0m                       

                       Computation: 773248 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 348.92
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.2946
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 0.13s
                      Time elapsed: 00:16:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 898/1 [0m                       

                       Computation: 709743 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 341.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8050
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 0.14s
                      Time elapsed: 00:16:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 899/1 [0m                       

                       Computation: 866015 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 342.32
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8971
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 0.11s
                      Time elapsed: 00:16:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 900/1 [0m                       

                       Computation: 829527 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 341.46
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9349
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 0.12s
                      Time elapsed: 00:16:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 901/1 [0m                       

                       Computation: 703254 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 343.93
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.3685
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 0.14s
                      Time elapsed: 00:16:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 902/1 [0m                       

                       Computation: 699560 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 340.11
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.4292
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 0.14s
                      Time elapsed: 00:16:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 903/1 [0m                       

                       Computation: 697105 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 345.97
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7005
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 0.14s
                      Time elapsed: 00:16:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 904/1 [0m                       

                       Computation: 738912 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 341.12
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8317
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 0.13s
                      Time elapsed: 00:16:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 905/1 [0m                       

                       Computation: 650651 steps/s (collection: 0.047s, learning 0.104s)
                       Mean reward: 340.83
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8339
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4374
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 0.15s
                      Time elapsed: 00:16:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 906/1 [0m                       

                       Computation: 723305 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 342.77
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0531
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 0.14s
                      Time elapsed: 00:16:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 907/1 [0m                       

                       Computation: 726128 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 342.14
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.1769
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 0.14s
                      Time elapsed: 00:16:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 908/1 [0m                       

                       Computation: 601210 steps/s (collection: 0.047s, learning 0.117s)
                       Mean reward: 351.44
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.7746
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 0.16s
                      Time elapsed: 00:16:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 909/1 [0m                       

                       Computation: 699088 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 343.18
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0205
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 0.14s
                      Time elapsed: 00:16:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 910/1 [0m                       

                       Computation: 603715 steps/s (collection: 0.043s, learning 0.120s)
                       Mean reward: 338.04
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.0120
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 0.16s
                      Time elapsed: 00:16:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 911/1 [0m                       

                       Computation: 692086 steps/s (collection: 0.045s, learning 0.097s)
                       Mean reward: 341.17
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6920
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 0.14s
                      Time elapsed: 00:16:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 912/1 [0m                       

                       Computation: 766030 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 344.90
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.6221
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 0.13s
                      Time elapsed: 00:16:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 913/1 [0m                       

                       Computation: 840500 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 345.06
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.4919
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 0.12s
                      Time elapsed: 00:16:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 914/1 [0m                       

                       Computation: 641456 steps/s (collection: 0.047s, learning 0.107s)
                       Mean reward: 345.24
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9477
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 0.15s
                      Time elapsed: 00:16:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 915/1 [0m                       

                       Computation: 656166 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 342.20
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6614
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 0.15s
                      Time elapsed: 00:16:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 916/1 [0m                       

                       Computation: 671993 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 343.58
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9471
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 0.15s
                      Time elapsed: 00:16:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 917/1 [0m                       

                       Computation: 689786 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 347.66
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.2569
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4371
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 0.14s
                      Time elapsed: 00:16:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 918/1 [0m                       

                       Computation: 649935 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 346.64
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9206
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 0.15s
                      Time elapsed: 00:16:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 919/1 [0m                       

                       Computation: 586712 steps/s (collection: 0.043s, learning 0.124s)
                       Mean reward: 342.38
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0997
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 0.17s
                      Time elapsed: 00:16:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 920/1 [0m                       

                       Computation: 582204 steps/s (collection: 0.051s, learning 0.118s)
                       Mean reward: 347.04
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9971
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 0.17s
                      Time elapsed: 00:16:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 921/1 [0m                       

                       Computation: 791956 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 342.49
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0387
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 0.12s
                      Time elapsed: 00:16:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 922/1 [0m                       

                       Computation: 836564 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 346.08
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7327
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 0.12s
                      Time elapsed: 00:16:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 923/1 [0m                       

                       Computation: 794241 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 349.86
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6597
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 0.12s
                      Time elapsed: 00:16:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 924/1 [0m                       

                       Computation: 597909 steps/s (collection: 0.067s, learning 0.097s)
                       Mean reward: 336.00
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.7392
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 0.16s
                      Time elapsed: 00:16:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 925/1 [0m                       

                       Computation: 759258 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 346.83
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9674
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 0.13s
                      Time elapsed: 00:16:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 926/1 [0m                       

                       Computation: 657297 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 342.86
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.1748
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 0.15s
                      Time elapsed: 00:16:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 927/1 [0m                       

                       Computation: 694589 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 345.33
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.6024
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 0.14s
                      Time elapsed: 00:16:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 928/1 [0m                       

                       Computation: 709517 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 348.16
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.1808
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 0.14s
                      Time elapsed: 00:16:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 929/1 [0m                       

                       Computation: 696146 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 346.82
               Mean episode length: 246.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.0284
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 0.14s
                      Time elapsed: 00:16:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 930/1 [0m                       

                       Computation: 717072 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 346.87
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.2417
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 0.14s
                      Time elapsed: 00:16:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 931/1 [0m                       

                       Computation: 701701 steps/s (collection: 0.048s, learning 0.092s)
                       Mean reward: 344.39
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.5527
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 0.14s
                      Time elapsed: 00:16:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 932/1 [0m                       

                       Computation: 744613 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 347.00
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.8357
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 0.13s
                      Time elapsed: 00:16:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 933/1 [0m                       

                       Computation: 548630 steps/s (collection: 0.041s, learning 0.139s)
                       Mean reward: 349.00
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.2908
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 0.18s
                      Time elapsed: 00:16:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 934/1 [0m                       

                       Computation: 689572 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 349.99
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.5947
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 0.14s
                      Time elapsed: 00:16:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 935/1 [0m                       

                       Computation: 701788 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 352.09
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1169
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 0.14s
                      Time elapsed: 00:16:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 936/1 [0m                       

                       Computation: 584791 steps/s (collection: 0.053s, learning 0.116s)
                       Mean reward: 344.18
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.2594
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 0.17s
                      Time elapsed: 00:16:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 937/1 [0m                       

                       Computation: 534112 steps/s (collection: 0.055s, learning 0.130s)
                       Mean reward: 344.76
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.4681
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 0.18s
                      Time elapsed: 00:16:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 938/1 [0m                       

                       Computation: 595294 steps/s (collection: 0.045s, learning 0.121s)
                       Mean reward: 347.79
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7763
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 0.17s
                      Time elapsed: 00:17:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 939/1 [0m                       

                       Computation: 635815 steps/s (collection: 0.041s, learning 0.114s)
                       Mean reward: 341.78
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.9238
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 0.15s
                      Time elapsed: 00:17:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 940/1 [0m                       

                       Computation: 447668 steps/s (collection: 0.058s, learning 0.162s)
                       Mean reward: 346.45
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.8490
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 0.22s
                      Time elapsed: 00:17:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 941/1 [0m                       

                       Computation: 352811 steps/s (collection: 0.041s, learning 0.238s)
                       Mean reward: 341.70
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8287
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 0.28s
                      Time elapsed: 00:17:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 942/1 [0m                       

                       Computation: 531257 steps/s (collection: 0.051s, learning 0.134s)
                       Mean reward: 347.07
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9195
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 0.19s
                      Time elapsed: 00:17:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 943/1 [0m                       

                       Computation: 668503 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 345.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.6935
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 0.15s
                      Time elapsed: 00:17:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 944/1 [0m                       

                       Computation: 503331 steps/s (collection: 0.048s, learning 0.148s)
                       Mean reward: 346.44
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7855
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 0.20s
                      Time elapsed: 00:17:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 945/1 [0m                       

                       Computation: 644134 steps/s (collection: 0.041s, learning 0.112s)
                       Mean reward: 347.49
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.0250
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 0.15s
                      Time elapsed: 00:17:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 946/1 [0m                       

                       Computation: 689506 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 348.20
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.4725
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 0.14s
                      Time elapsed: 00:17:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 947/1 [0m                       

                       Computation: 701787 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 351.35
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8388
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 0.14s
                      Time elapsed: 00:17:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 948/1 [0m                       

                       Computation: 703882 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 344.50
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.3655
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 0.14s
                      Time elapsed: 00:17:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 949/1 [0m                       

                       Computation: 670354 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 346.75
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9352
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 0.15s
                      Time elapsed: 00:17:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 950/1 [0m                       

                       Computation: 627708 steps/s (collection: 0.048s, learning 0.109s)
                       Mean reward: 346.71
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.8899
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 0.16s
                      Time elapsed: 00:17:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 951/1 [0m                       

                       Computation: 598765 steps/s (collection: 0.052s, learning 0.113s)
                       Mean reward: 344.55
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.3434
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 0.16s
                      Time elapsed: 00:17:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 952/1 [0m                       

                       Computation: 809025 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 345.88
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.8017
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 0.12s
                      Time elapsed: 00:17:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 953/1 [0m                       

                       Computation: 780786 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 352.43
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1091
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 0.13s
                      Time elapsed: 00:17:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 954/1 [0m                       

                       Computation: 818911 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 346.50
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7959
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 0.12s
                      Time elapsed: 00:17:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 955/1 [0m                       

                       Computation: 706920 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 346.14
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.0089
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4306
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 0.14s
                      Time elapsed: 00:17:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 956/1 [0m                       

                       Computation: 698669 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 346.74
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.1190
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 0.14s
                      Time elapsed: 00:17:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 957/1 [0m                       

                       Computation: 448078 steps/s (collection: 0.072s, learning 0.148s)
                       Mean reward: 344.99
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.4056
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 0.22s
                      Time elapsed: 00:17:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 958/1 [0m                       

                       Computation: 498495 steps/s (collection: 0.058s, learning 0.139s)
                       Mean reward: 348.86
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.2983
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 0.20s
                      Time elapsed: 00:17:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 959/1 [0m                       

                       Computation: 472895 steps/s (collection: 0.056s, learning 0.152s)
                       Mean reward: 347.10
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9535
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4260
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 0.21s
                      Time elapsed: 00:17:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 960/1 [0m                       

                       Computation: 517693 steps/s (collection: 0.052s, learning 0.138s)
                       Mean reward: 346.19
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.6429
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4252
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 0.19s
                      Time elapsed: 00:17:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 961/1 [0m                       

                       Computation: 766677 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 351.37
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.9363
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 0.13s
                      Time elapsed: 00:17:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 962/1 [0m                       

                       Computation: 736759 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 345.27
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7581
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4261
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 0.13s
                      Time elapsed: 00:17:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 963/1 [0m                       

                       Computation: 588062 steps/s (collection: 0.048s, learning 0.120s)
                       Mean reward: 344.29
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.5050
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 0.17s
                      Time elapsed: 00:17:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 964/1 [0m                       

                       Computation: 641643 steps/s (collection: 0.047s, learning 0.107s)
                       Mean reward: 348.59
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.2523
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 0.15s
                      Time elapsed: 00:17:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 965/1 [0m                       

                       Computation: 749549 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 348.47
               Mean episode length: 246.96
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.1447
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4230
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 0.13s
                      Time elapsed: 00:17:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 966/1 [0m                       

                       Computation: 804814 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 345.50
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.6746
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4274
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 0.12s
                      Time elapsed: 00:17:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 967/1 [0m                       

                       Computation: 737924 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 346.97
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.8993
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4252
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 0.13s
                      Time elapsed: 00:17:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 968/1 [0m                       

                       Computation: 735872 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 349.16
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.5614
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 0.13s
                      Time elapsed: 00:17:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 969/1 [0m                       

                       Computation: 751761 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 354.63
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6619
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4293
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 0.13s
                      Time elapsed: 00:17:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 970/1 [0m                       

                       Computation: 738062 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 352.22
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.2005
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 0.13s
                      Time elapsed: 00:17:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 971/1 [0m                       

                       Computation: 561565 steps/s (collection: 0.049s, learning 0.126s)
                       Mean reward: 348.44
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.3786
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4240
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 0.18s
                      Time elapsed: 00:17:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 972/1 [0m                       

                       Computation: 636953 steps/s (collection: 0.041s, learning 0.113s)
                       Mean reward: 353.29
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1050
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 0.15s
                      Time elapsed: 00:17:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 973/1 [0m                       

                       Computation: 743927 steps/s (collection: 0.048s, learning 0.084s)
                       Mean reward: 343.10
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.3310
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 0.13s
                      Time elapsed: 00:17:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 974/1 [0m                       

                       Computation: 727151 steps/s (collection: 0.049s, learning 0.087s)
                       Mean reward: 347.19
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.1757
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 0.14s
                      Time elapsed: 00:17:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 975/1 [0m                       

                       Computation: 753972 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 346.42
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7026
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 0.13s
                      Time elapsed: 00:17:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 976/1 [0m                       

                       Computation: 793043 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 352.49
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.9050
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 0.12s
                      Time elapsed: 00:17:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 977/1 [0m                       

                       Computation: 814626 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 344.10
               Mean episode length: 246.89
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.4365
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 0.12s
                      Time elapsed: 00:17:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 978/1 [0m                       

                       Computation: 756410 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 350.29
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8220
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 0.13s
                      Time elapsed: 00:17:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 979/1 [0m                       

                       Computation: 674644 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 344.45
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.2356
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 0.15s
                      Time elapsed: 00:17:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 980/1 [0m                       

                       Computation: 670619 steps/s (collection: 0.044s, learning 0.103s)
                       Mean reward: 351.26
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6628
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 0.15s
                      Time elapsed: 00:17:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 981/1 [0m                       

                       Computation: 771730 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 350.62
               Mean episode length: 246.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.3830
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4258
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 0.13s
                      Time elapsed: 00:17:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 982/1 [0m                       

                       Computation: 688777 steps/s (collection: 0.047s, learning 0.096s)
                       Mean reward: 350.72
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6738
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 0.14s
                      Time elapsed: 00:17:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 983/1 [0m                       

                       Computation: 681722 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 345.68
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.1055
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4234
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 0.14s
                      Time elapsed: 00:17:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 984/1 [0m                       

                       Computation: 804674 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 350.98
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.5388
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 0.12s
                      Time elapsed: 00:17:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 985/1 [0m                       

                       Computation: 824131 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 349.80
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.4698
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 0.12s
                      Time elapsed: 00:17:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 986/1 [0m                       

                       Computation: 816149 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 349.15
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.3297
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 0.12s
                      Time elapsed: 00:17:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 987/1 [0m                       

                       Computation: 738825 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 347.06
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9439
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 0.13s
                      Time elapsed: 00:18:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 988/1 [0m                       

                       Computation: 640732 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 346.09
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.6975
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 0.15s
                      Time elapsed: 00:18:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 989/1 [0m                       

                       Computation: 768465 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 350.97
               Mean episode length: 246.93
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8363
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 0.13s
                      Time elapsed: 00:18:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 990/1 [0m                       

                       Computation: 642927 steps/s (collection: 0.050s, learning 0.103s)
                       Mean reward: 351.49
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.9273
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 18.7500
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 0.15s
                      Time elapsed: 00:18:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 991/1 [0m                       

                       Computation: 806013 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 346.93
               Mean episode length: 245.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9762
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4246
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 0.12s
                      Time elapsed: 00:18:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 992/1 [0m                       

                       Computation: 796130 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 351.14
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.7116
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 0.12s
                      Time elapsed: 00:18:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 993/1 [0m                       

                       Computation: 671671 steps/s (collection: 0.048s, learning 0.098s)
                       Mean reward: 350.99
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6557
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4283
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 0.15s
                      Time elapsed: 00:18:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 994/1 [0m                       

                       Computation: 815509 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 351.02
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.7755
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 0.12s
                      Time elapsed: 00:18:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 995/1 [0m                       

                       Computation: 673542 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 352.95
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1092
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 0.15s
                      Time elapsed: 00:18:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 996/1 [0m                       

                       Computation: 774100 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 353.22
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1836
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 0.13s
                      Time elapsed: 00:18:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 997/1 [0m                       

                       Computation: 714494 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 352.15
               Mean episode length: 247.08
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8027
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 0.14s
                      Time elapsed: 00:18:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 998/1 [0m                       

                       Computation: 818300 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 349.52
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.5227
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 0.12s
                      Time elapsed: 00:18:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 999/1 [0m                       

                       Computation: 760273 steps/s (collection: 0.050s, learning 0.080s)
                       Mean reward: 351.72
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8657
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 0.13s
                      Time elapsed: 00:18:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1000/1 [0m                       

                       Computation: 708489 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 349.11
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.4802
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 0.14s
                      Time elapsed: 00:18:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1001/1 [0m                       

                       Computation: 730122 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 350.94
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.9184
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 0.13s
                      Time elapsed: 00:18:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1002/1 [0m                       

                       Computation: 686670 steps/s (collection: 0.047s, learning 0.096s)
                       Mean reward: 349.04
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.2401
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4256
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 0.14s
                      Time elapsed: 00:18:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1003/1 [0m                       

                       Computation: 666039 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 338.55
               Mean episode length: 245.27
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2033
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4204
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 0.15s
                      Time elapsed: 00:18:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1004/1 [0m                       

                       Computation: 515081 steps/s (collection: 0.056s, learning 0.135s)
                       Mean reward: 352.94
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.2497
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 0.19s
                      Time elapsed: 00:18:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1005/1 [0m                       

                       Computation: 636048 steps/s (collection: 0.046s, learning 0.109s)
                       Mean reward: 356.03
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8009
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 0.15s
                      Time elapsed: 00:18:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1006/1 [0m                       

                       Computation: 701835 steps/s (collection: 0.049s, learning 0.091s)
                       Mean reward: 349.98
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.4157
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4268
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 0.14s
                      Time elapsed: 00:18:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1007/1 [0m                       

                       Computation: 671718 steps/s (collection: 0.051s, learning 0.095s)
                       Mean reward: 346.47
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.0563
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4236
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 0.15s
                      Time elapsed: 00:18:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1008/1 [0m                       

                       Computation: 641845 steps/s (collection: 0.052s, learning 0.101s)
                       Mean reward: 346.51
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9605
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4259
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 0.15s
                      Time elapsed: 00:18:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1009/1 [0m                       

                       Computation: 535318 steps/s (collection: 0.064s, learning 0.120s)
                       Mean reward: 352.42
               Mean episode length: 246.38
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1028
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4236
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 0.18s
                      Time elapsed: 00:18:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1010/1 [0m                       

                       Computation: 525930 steps/s (collection: 0.049s, learning 0.138s)
                       Mean reward: 352.67
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1983
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4249
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 0.19s
                      Time elapsed: 00:18:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1011/1 [0m                       

                       Computation: 581592 steps/s (collection: 0.042s, learning 0.127s)
                       Mean reward: 342.89
               Mean episode length: 244.12
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8299
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4180
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 0.17s
                      Time elapsed: 00:18:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1012/1 [0m                       

                       Computation: 775304 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 351.22
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.7344
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4251
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 0.13s
                      Time elapsed: 00:18:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1013/1 [0m                       

                       Computation: 818826 steps/s (collection: 0.043s, learning 0.077s)
                       Mean reward: 348.02
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.1564
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4256
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 0.12s
                      Time elapsed: 00:18:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1014/1 [0m                       

                       Computation: 755988 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 348.96
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.5178
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4239
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 0.13s
                      Time elapsed: 00:18:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1015/1 [0m                       

                       Computation: 831579 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 348.75
               Mean episode length: 246.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.2788
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4252
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 0.12s
                      Time elapsed: 00:18:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1016/1 [0m                       

                       Computation: 836371 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 349.22
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6969
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4256
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 0.12s
                      Time elapsed: 00:18:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1017/1 [0m                       

                       Computation: 866849 steps/s (collection: 0.039s, learning 0.074s)
                       Mean reward: 351.22
               Mean episode length: 245.88
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.7425
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4241
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 0.11s
                      Time elapsed: 00:18:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1018/1 [0m                       

                       Computation: 744009 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 351.34
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.7031
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4220
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 0.13s
                      Time elapsed: 00:18:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1019/1 [0m                       

                       Computation: 793019 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 352.23
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6817
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 0.12s
                      Time elapsed: 00:18:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1020/1 [0m                       

                       Computation: 675805 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 349.65
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.5897
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4251
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 0.15s
                      Time elapsed: 00:18:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1021/1 [0m                       

                       Computation: 832075 steps/s (collection: 0.044s, learning 0.075s)
                       Mean reward: 350.68
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6420
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 0.12s
                      Time elapsed: 00:18:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1022/1 [0m                       

                       Computation: 631904 steps/s (collection: 0.041s, learning 0.115s)
                       Mean reward: 351.66
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8551
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4241
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 0.16s
                      Time elapsed: 00:18:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1023/1 [0m                       

                       Computation: 637550 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 353.72
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.2097
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 0.15s
                      Time elapsed: 00:18:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1024/1 [0m                       

                       Computation: 692098 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 351.20
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8644
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4208
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 0.14s
                      Time elapsed: 00:18:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1025/1 [0m                       

                       Computation: 472196 steps/s (collection: 0.056s, learning 0.152s)
                       Mean reward: 354.56
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6225
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4228
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 0.21s
                      Time elapsed: 00:18:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1026/1 [0m                       

                       Computation: 604540 steps/s (collection: 0.047s, learning 0.116s)
                       Mean reward: 350.28
               Mean episode length: 246.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6279
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4249
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 0.16s
                      Time elapsed: 00:18:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1027/1 [0m                       

                       Computation: 810540 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 350.48
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.7647
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 0.12s
                      Time elapsed: 00:18:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1028/1 [0m                       

                       Computation: 712253 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 342.32
               Mean episode length: 245.41
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.2479
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4204
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 0.14s
                      Time elapsed: 00:18:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1029/1 [0m                       

                       Computation: 733033 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 351.83
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.0200
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4268
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 0.13s
                      Time elapsed: 00:18:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1030/1 [0m                       

                       Computation: 768556 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 349.20
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.1904
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4268
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 0.13s
                      Time elapsed: 00:18:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1031/1 [0m                       

                       Computation: 773844 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 353.27
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.2183
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 0.13s
                      Time elapsed: 00:18:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1032/1 [0m                       

                       Computation: 758773 steps/s (collection: 0.047s, learning 0.083s)
                       Mean reward: 350.02
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6522
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4252
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 0.13s
                      Time elapsed: 00:18:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1033/1 [0m                       

                       Computation: 747103 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 353.95
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.3782
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 0.13s
                      Time elapsed: 00:18:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1034/1 [0m                       

                       Computation: 841354 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 348.36
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.2436
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4223
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 0.12s
                      Time elapsed: 00:18:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1035/1 [0m                       

                       Computation: 789234 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 351.97
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8603
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4227
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 0.12s
                      Time elapsed: 00:18:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1036/1 [0m                       

                       Computation: 824549 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 344.53
               Mean episode length: 245.92
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.3495
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4191
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 0.12s
                      Time elapsed: 00:18:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1037/1 [0m                       

                       Computation: 767745 steps/s (collection: 0.047s, learning 0.082s)
                       Mean reward: 354.58
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7141
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 0.13s
                      Time elapsed: 00:18:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1038/1 [0m                       

                       Computation: 802736 steps/s (collection: 0.046s, learning 0.077s)
                       Mean reward: 353.72
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.5333
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4251
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 0.12s
                      Time elapsed: 00:18:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1039/1 [0m                       

                       Computation: 818890 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 347.90
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.0881
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4202
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 0.12s
                      Time elapsed: 00:19:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1040/1 [0m                       

                       Computation: 644862 steps/s (collection: 0.044s, learning 0.109s)
                       Mean reward: 358.96
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1927
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 0.15s
                      Time elapsed: 00:19:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1041/1 [0m                       

                       Computation: 717996 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 353.81
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6111
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 0.14s
                      Time elapsed: 00:19:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1042/1 [0m                       

                       Computation: 684777 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 354.51
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.4771
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4260
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 18.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 0.14s
                      Time elapsed: 00:19:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1043/1 [0m                       

                       Computation: 764762 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 349.99
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.6062
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4214
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 0.13s
                      Time elapsed: 00:19:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1044/1 [0m                       

                       Computation: 708643 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 348.63
               Mean episode length: 246.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.0529
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4236
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 0.14s
                      Time elapsed: 00:19:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1045/1 [0m                       

                       Computation: 767420 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 356.20
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7604
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4245
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 0.13s
                      Time elapsed: 00:19:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1046/1 [0m                       

                       Computation: 584509 steps/s (collection: 0.050s, learning 0.119s)
                       Mean reward: 356.32
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7223
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 0.17s
                      Time elapsed: 00:19:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1047/1 [0m                       

                       Computation: 547604 steps/s (collection: 0.051s, learning 0.129s)
                       Mean reward: 360.62
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8055
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 0.18s
                      Time elapsed: 00:19:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1048/1 [0m                       

                       Computation: 614302 steps/s (collection: 0.052s, learning 0.108s)
                       Mean reward: 356.04
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8508
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 0.16s
                      Time elapsed: 00:19:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1049/1 [0m                       

                       Computation: 579672 steps/s (collection: 0.056s, learning 0.114s)
                       Mean reward: 350.17
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.5344
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 0.17s
                      Time elapsed: 00:19:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1050/1 [0m                       

                       Computation: 606387 steps/s (collection: 0.049s, learning 0.114s)
                       Mean reward: 353.43
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.3179
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 0.16s
                      Time elapsed: 00:19:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1051/1 [0m                       

                       Computation: 633867 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 352.75
               Mean episode length: 247.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.2067
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 0.16s
                      Time elapsed: 00:19:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1052/1 [0m                       

                       Computation: 620077 steps/s (collection: 0.048s, learning 0.111s)
                       Mean reward: 352.97
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.9659
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4244
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 0.16s
                      Time elapsed: 00:19:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1053/1 [0m                       

                       Computation: 600984 steps/s (collection: 0.050s, learning 0.114s)
                       Mean reward: 355.95
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6873
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4223
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 0.16s
                      Time elapsed: 00:19:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1054/1 [0m                       

                       Computation: 755822 steps/s (collection: 0.048s, learning 0.083s)
                       Mean reward: 352.86
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.2447
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4253
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 0.13s
                      Time elapsed: 00:19:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1055/1 [0m                       

                       Computation: 773987 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 349.76
               Mean episode length: 247.27
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.4937
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 0.13s
                      Time elapsed: 00:19:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1056/1 [0m                       

                       Computation: 694512 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 348.25
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.1950
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4226
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 0.14s
                      Time elapsed: 00:19:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1057/1 [0m                       

                       Computation: 709398 steps/s (collection: 0.048s, learning 0.091s)
                       Mean reward: 355.97
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8497
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4241
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 0.14s
                      Time elapsed: 00:19:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1058/1 [0m                       

                       Computation: 567948 steps/s (collection: 0.049s, learning 0.124s)
                       Mean reward: 352.63
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1886
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4239
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 0.17s
                      Time elapsed: 00:19:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1059/1 [0m                       

                       Computation: 722753 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 358.44
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4030
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4242
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 0.14s
                      Time elapsed: 00:19:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1060/1 [0m                       

                       Computation: 655060 steps/s (collection: 0.048s, learning 0.103s)
                       Mean reward: 356.31
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7858
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4229
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 0.15s
                      Time elapsed: 00:19:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1061/1 [0m                       

                       Computation: 799031 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 356.13
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8073
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 0.12s
                      Time elapsed: 00:19:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1062/1 [0m                       

                       Computation: 808749 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 356.84
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9430
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4238
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 0.12s
                      Time elapsed: 00:19:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1063/1 [0m                       

                       Computation: 822380 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 354.45
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.4605
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4217
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 0.12s
                      Time elapsed: 00:19:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1064/1 [0m                       

                       Computation: 705184 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 355.13
               Mean episode length: 246.13
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.5692
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4197
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 0.14s
                      Time elapsed: 00:19:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1065/1 [0m                       

                       Computation: 732459 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 354.78
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6490
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4196
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 0.13s
                      Time elapsed: 00:19:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1066/1 [0m                       

                       Computation: 635963 steps/s (collection: 0.048s, learning 0.107s)
                       Mean reward: 352.03
               Mean episode length: 245.66
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.9581
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4174
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 0.15s
                      Time elapsed: 00:19:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1067/1 [0m                       

                       Computation: 721170 steps/s (collection: 0.045s, learning 0.091s)
                       Mean reward: 353.99
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.4082
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4213
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 0.14s
                      Time elapsed: 00:19:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1068/1 [0m                       

                       Computation: 738780 steps/s (collection: 0.047s, learning 0.086s)
                       Mean reward: 358.39
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2486
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 0.13s
                      Time elapsed: 00:19:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1069/1 [0m                       

                       Computation: 801926 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 356.28
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8187
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4211
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 0.12s
                      Time elapsed: 00:19:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1070/1 [0m                       

                       Computation: 781495 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 357.68
               Mean episode length: 247.50
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2567
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4223
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 0.13s
                      Time elapsed: 00:19:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1071/1 [0m                       

                       Computation: 843404 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 354.48
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.2225
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4209
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 0.12s
                      Time elapsed: 00:19:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1072/1 [0m                       

                       Computation: 834943 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 353.72
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.0947
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4244
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 0.12s
                      Time elapsed: 00:19:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1073/1 [0m                       

                       Computation: 883904 steps/s (collection: 0.040s, learning 0.071s)
                       Mean reward: 358.40
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2459
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4246
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 0.11s
                      Time elapsed: 00:19:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1074/1 [0m                       

                       Computation: 869265 steps/s (collection: 0.040s, learning 0.074s)
                       Mean reward: 352.75
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.3054
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4209
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 0.11s
                      Time elapsed: 00:19:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1075/1 [0m                       

                       Computation: 869927 steps/s (collection: 0.041s, learning 0.072s)
                       Mean reward: 359.83
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5862
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4215
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 0.11s
                      Time elapsed: 00:19:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1076/1 [0m                       

                       Computation: 785160 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 356.80
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9883
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4197
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 0.13s
                      Time elapsed: 00:19:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1077/1 [0m                       

                       Computation: 699532 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 361.02
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8238
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4240
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 0.14s
                      Time elapsed: 00:19:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1078/1 [0m                       

                       Computation: 599867 steps/s (collection: 0.044s, learning 0.120s)
                       Mean reward: 358.21
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2463
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4255
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 0.16s
                      Time elapsed: 00:19:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1079/1 [0m                       

                       Computation: 600227 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 354.76
               Mean episode length: 245.88
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.5954
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4180
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 0.16s
                      Time elapsed: 00:19:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1080/1 [0m                       

                       Computation: 634481 steps/s (collection: 0.046s, learning 0.109s)
                       Mean reward: 359.67
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5360
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4259
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 0.15s
                      Time elapsed: 00:19:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1081/1 [0m                       

                       Computation: 806989 steps/s (collection: 0.046s, learning 0.076s)
                       Mean reward: 357.16
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9128
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 0.12s
                      Time elapsed: 00:19:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1082/1 [0m                       

                       Computation: 809580 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 358.43
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4802
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4246
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 0.12s
                      Time elapsed: 00:19:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1083/1 [0m                       

                       Computation: 783220 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 356.50
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6675
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4229
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 0.13s
                      Time elapsed: 00:19:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1084/1 [0m                       

                       Computation: 595522 steps/s (collection: 0.050s, learning 0.116s)
                       Mean reward: 356.95
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7150
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4229
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 0.17s
                      Time elapsed: 00:19:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1085/1 [0m                       

                       Computation: 628678 steps/s (collection: 0.051s, learning 0.106s)
                       Mean reward: 360.50
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4849
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4252
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 0.16s
                      Time elapsed: 00:19:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1086/1 [0m                       

                       Computation: 688153 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 358.96
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1179
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4240
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 0.14s
                      Time elapsed: 00:19:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1087/1 [0m                       

                       Computation: 812291 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 357.71
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2382
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4229
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 0.12s
                      Time elapsed: 00:19:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1088/1 [0m                       

                       Computation: 824602 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 354.64
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.4065
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 0.12s
                      Time elapsed: 00:19:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1089/1 [0m                       

                       Computation: 705375 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 359.20
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6561
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4249
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 0.14s
                      Time elapsed: 00:19:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1090/1 [0m                       

                       Computation: 728266 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 352.13
               Mean episode length: 246.77
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.0799
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4210
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 0.13s
                      Time elapsed: 00:20:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1091/1 [0m                       

                       Computation: 687357 steps/s (collection: 0.039s, learning 0.104s)
                       Mean reward: 358.02
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8836
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4242
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 0.14s
                      Time elapsed: 00:20:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1092/1 [0m                       

                       Computation: 847372 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 361.36
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8258
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 0.12s
                      Time elapsed: 00:20:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1093/1 [0m                       

                       Computation: 847318 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 357.78
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.0860
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 0.12s
                      Time elapsed: 00:20:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1094/1 [0m                       

                       Computation: 789361 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 361.85
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8778
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 0.12s
                      Time elapsed: 00:20:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1095/1 [0m                       

                       Computation: 792309 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 361.37
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9106
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4293
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 0.12s
                      Time elapsed: 00:20:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1096/1 [0m                       

                       Computation: 795827 steps/s (collection: 0.046s, learning 0.078s)
                       Mean reward: 353.64
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.3406
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 0.12s
                      Time elapsed: 00:20:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1097/1 [0m                       

                       Computation: 780440 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 358.93
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2894
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 0.13s
                      Time elapsed: 00:20:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1098/1 [0m                       

                       Computation: 789797 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 359.80
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5786
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 0.12s
                      Time elapsed: 00:20:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1099/1 [0m                       

                       Computation: 827875 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 354.03
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.2565
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4268
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 0.12s
                      Time elapsed: 00:20:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1100/1 [0m                       

                       Computation: 760555 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 358.66
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1302
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 0.13s
                      Time elapsed: 00:20:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1101/1 [0m                       

                       Computation: 602539 steps/s (collection: 0.043s, learning 0.121s)
                       Mean reward: 358.59
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4728
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 0.16s
                      Time elapsed: 00:20:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1102/1 [0m                       

                       Computation: 812182 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 355.37
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.5811
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 0.12s
                      Time elapsed: 00:20:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1103/1 [0m                       

                       Computation: 629929 steps/s (collection: 0.040s, learning 0.116s)
                       Mean reward: 356.82
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9609
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4283
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 0.16s
                      Time elapsed: 00:20:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1104/1 [0m                       

                       Computation: 657433 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 360.62
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3336
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 0.15s
                      Time elapsed: 00:20:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1105/1 [0m                       

                       Computation: 701998 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 363.04
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2291
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 0.14s
                      Time elapsed: 00:20:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1106/1 [0m                       

                       Computation: 745602 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 360.09
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6852
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 0.13s
                      Time elapsed: 00:20:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1107/1 [0m                       

                       Computation: 684858 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 356.80
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9712
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4273
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 0.14s
                      Time elapsed: 00:20:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1108/1 [0m                       

                       Computation: 726082 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 360.39
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7324
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4283
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 0.14s
                      Time elapsed: 00:20:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1109/1 [0m                       

                       Computation: 568903 steps/s (collection: 0.046s, learning 0.127s)
                       Mean reward: 358.55
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1538
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 0.17s
                      Time elapsed: 00:20:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1110/1 [0m                       

                       Computation: 739059 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 359.40
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6569
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 0.13s
                      Time elapsed: 00:20:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1111/1 [0m                       

                       Computation: 575562 steps/s (collection: 0.061s, learning 0.110s)
                       Mean reward: 359.62
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6450
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 0.17s
                      Time elapsed: 00:20:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1112/1 [0m                       

                       Computation: 675580 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 356.07
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7786
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 0.15s
                      Time elapsed: 00:20:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1113/1 [0m                       

                       Computation: 731665 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 363.65
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1803
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 0.13s
                      Time elapsed: 00:20:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1114/1 [0m                       

                       Computation: 837530 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 362.89
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8434
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 0.12s
                      Time elapsed: 00:20:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1115/1 [0m                       

                       Computation: 758775 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 363.85
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0852
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 0.13s
                      Time elapsed: 00:20:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1116/1 [0m                       

                       Computation: 750237 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 353.99
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1867
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4259
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 0.13s
                      Time elapsed: 00:20:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1117/1 [0m                       

                       Computation: 722702 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 360.00
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5493
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 0.14s
                      Time elapsed: 00:20:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1118/1 [0m                       

                       Computation: 737631 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 358.09
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1565
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 0.13s
                      Time elapsed: 00:20:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1119/1 [0m                       

                       Computation: 770897 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 359.29
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4703
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 0.13s
                      Time elapsed: 00:20:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1120/1 [0m                       

                       Computation: 798249 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 360.81
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7140
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 0.12s
                      Time elapsed: 00:20:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1121/1 [0m                       

                       Computation: 758877 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 359.75
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2760
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4244
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 0.13s
                      Time elapsed: 00:20:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1122/1 [0m                       

                       Computation: 755755 steps/s (collection: 0.050s, learning 0.080s)
                       Mean reward: 362.79
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2387
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 0.13s
                      Time elapsed: 00:20:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1123/1 [0m                       

                       Computation: 769143 steps/s (collection: 0.047s, learning 0.081s)
                       Mean reward: 363.25
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2058
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 0.13s
                      Time elapsed: 00:20:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1124/1 [0m                       

                       Computation: 618772 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 356.41
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7949
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 0.16s
                      Time elapsed: 00:20:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1125/1 [0m                       

                       Computation: 558320 steps/s (collection: 0.045s, learning 0.132s)
                       Mean reward: 361.42
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9087
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 0.18s
                      Time elapsed: 00:20:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1126/1 [0m                       

                       Computation: 759578 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 360.23
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8419
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 0.13s
                      Time elapsed: 00:20:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1127/1 [0m                       

                       Computation: 599182 steps/s (collection: 0.061s, learning 0.103s)
                       Mean reward: 354.90
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.3083
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 0.16s
                      Time elapsed: 00:20:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1128/1 [0m                       

                       Computation: 648726 steps/s (collection: 0.049s, learning 0.103s)
                       Mean reward: 361.04
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8410
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 0.15s
                      Time elapsed: 00:20:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1129/1 [0m                       

                       Computation: 644173 steps/s (collection: 0.048s, learning 0.105s)
                       Mean reward: 361.72
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9329
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 0.15s
                      Time elapsed: 00:20:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1130/1 [0m                       

                       Computation: 622050 steps/s (collection: 0.039s, learning 0.119s)
                       Mean reward: 361.31
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8487
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 0.16s
                      Time elapsed: 00:20:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1131/1 [0m                       

                       Computation: 630581 steps/s (collection: 0.038s, learning 0.118s)
                       Mean reward: 360.73
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5394
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 0.16s
                      Time elapsed: 00:20:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1132/1 [0m                       

                       Computation: 573104 steps/s (collection: 0.044s, learning 0.128s)
                       Mean reward: 355.90
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6181
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 0.17s
                      Time elapsed: 00:20:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1133/1 [0m                       

                       Computation: 655372 steps/s (collection: 0.045s, learning 0.105s)
                       Mean reward: 359.00
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5575
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 0.15s
                      Time elapsed: 00:20:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1134/1 [0m                       

                       Computation: 561843 steps/s (collection: 0.058s, learning 0.117s)
                       Mean reward: 365.74
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8414
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4294
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 0.17s
                      Time elapsed: 00:20:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1135/1 [0m                       

                       Computation: 547747 steps/s (collection: 0.048s, learning 0.131s)
                       Mean reward: 363.10
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1180
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 0.18s
                      Time elapsed: 00:20:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1136/1 [0m                       

                       Computation: 620279 steps/s (collection: 0.047s, learning 0.111s)
                       Mean reward: 359.74
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3251
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 0.16s
                      Time elapsed: 00:20:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1137/1 [0m                       

                       Computation: 858049 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 367.99
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1904
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 0.11s
                      Time elapsed: 00:20:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1138/1 [0m                       

                       Computation: 825905 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 362.57
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9384
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 0.12s
                      Time elapsed: 00:20:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1139/1 [0m                       

                       Computation: 860551 steps/s (collection: 0.040s, learning 0.074s)
                       Mean reward: 355.03
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.5763
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 0.11s
                      Time elapsed: 00:20:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1140/1 [0m                       

                       Computation: 680331 steps/s (collection: 0.044s, learning 0.101s)
                       Mean reward: 359.67
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7194
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 0.14s
                      Time elapsed: 00:20:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1141/1 [0m                       

                       Computation: 610424 steps/s (collection: 0.043s, learning 0.119s)
                       Mean reward: 357.96
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2457
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 0.16s
                      Time elapsed: 00:20:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1142/1 [0m                       

                       Computation: 663882 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 362.47
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7615
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 0.15s
                      Time elapsed: 00:20:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1143/1 [0m                       

                       Computation: 742655 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 366.15
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7471
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 0.13s
                      Time elapsed: 00:21:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1144/1 [0m                       

                       Computation: 792703 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 365.60
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4760
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4269
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 0.12s
                      Time elapsed: 00:21:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1145/1 [0m                       

                       Computation: 794339 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 363.63
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1634
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 0.12s
                      Time elapsed: 00:21:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1146/1 [0m                       

                       Computation: 851043 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 364.86
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5989
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 0.12s
                      Time elapsed: 00:21:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1147/1 [0m                       

                       Computation: 753629 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 362.75
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9568
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 0.13s
                      Time elapsed: 00:21:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1148/1 [0m                       

                       Computation: 822537 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 366.28
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8393
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 0.12s
                      Time elapsed: 00:21:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1149/1 [0m                       

                       Computation: 805639 steps/s (collection: 0.045s, learning 0.077s)
                       Mean reward: 366.06
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8663
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 0.12s
                      Time elapsed: 00:21:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1150/1 [0m                       

                       Computation: 794245 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 363.12
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3457
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 0.12s
                      Time elapsed: 00:21:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1151/1 [0m                       

                       Computation: 595611 steps/s (collection: 0.049s, learning 0.116s)
                       Mean reward: 362.44
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0200
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 0.17s
                      Time elapsed: 00:21:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1152/1 [0m                       

                       Computation: 699447 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 365.18
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5442
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 0.14s
                      Time elapsed: 00:21:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1153/1 [0m                       

                       Computation: 616293 steps/s (collection: 0.045s, learning 0.114s)
                       Mean reward: 363.09
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9685
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 0.16s
                      Time elapsed: 00:21:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1154/1 [0m                       

                       Computation: 763645 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 361.79
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1612
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 0.13s
                      Time elapsed: 00:21:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1155/1 [0m                       

                       Computation: 740001 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 361.89
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0766
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 0.13s
                      Time elapsed: 00:21:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1156/1 [0m                       

                       Computation: 838852 steps/s (collection: 0.041s, learning 0.076s)
                       Mean reward: 361.40
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0870
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4269
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 0.12s
                      Time elapsed: 00:21:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1157/1 [0m                       

                       Computation: 806721 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 364.68
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5414
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 0.12s
                      Time elapsed: 00:21:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1158/1 [0m                       

                       Computation: 652854 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 354.98
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6062
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 0.15s
                      Time elapsed: 00:21:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1159/1 [0m                       

                       Computation: 650518 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 360.71
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6133
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4261
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 0.15s
                      Time elapsed: 00:21:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1160/1 [0m                       

                       Computation: 684389 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 362.70
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2456
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 0.14s
                      Time elapsed: 00:21:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1161/1 [0m                       

                       Computation: 610550 steps/s (collection: 0.041s, learning 0.120s)
                       Mean reward: 363.89
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3767
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4293
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 0.16s
                      Time elapsed: 00:21:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1162/1 [0m                       

                       Computation: 581134 steps/s (collection: 0.051s, learning 0.118s)
                       Mean reward: 358.45
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2917
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 0.17s
                      Time elapsed: 00:21:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1163/1 [0m                       

                       Computation: 659642 steps/s (collection: 0.048s, learning 0.102s)
                       Mean reward: 362.32
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1084
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 0.15s
                      Time elapsed: 00:21:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1164/1 [0m                       

                       Computation: 635940 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 363.72
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0571
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 0.15s
                      Time elapsed: 00:21:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1165/1 [0m                       

                       Computation: 714217 steps/s (collection: 0.050s, learning 0.088s)
                       Mean reward: 361.90
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9346
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 0.14s
                      Time elapsed: 00:21:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1166/1 [0m                       

                       Computation: 703001 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 362.75
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9938
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 0.14s
                      Time elapsed: 00:21:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1167/1 [0m                       

                       Computation: 815961 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 365.40
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8181
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4249
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 0.12s
                      Time elapsed: 00:21:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1168/1 [0m                       

                       Computation: 664126 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 357.75
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2875
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 0.15s
                      Time elapsed: 00:21:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1169/1 [0m                       

                       Computation: 853048 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 363.55
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3076
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 0.12s
                      Time elapsed: 00:21:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1170/1 [0m                       

                       Computation: 859842 steps/s (collection: 0.040s, learning 0.075s)
                       Mean reward: 355.99
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8712
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4220
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 0.11s
                      Time elapsed: 00:21:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1171/1 [0m                       

                       Computation: 843561 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 362.75
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1985
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4227
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 0.12s
                      Time elapsed: 00:21:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1172/1 [0m                       

                       Computation: 795135 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 357.76
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.0496
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4229
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 0.12s
                      Time elapsed: 00:21:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1173/1 [0m                       

                       Computation: 797121 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 364.14
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2393
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4235
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 0.12s
                      Time elapsed: 00:21:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1174/1 [0m                       

                       Computation: 588368 steps/s (collection: 0.049s, learning 0.119s)
                       Mean reward: 360.65
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5847
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4246
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 0.17s
                      Time elapsed: 00:21:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1175/1 [0m                       

                       Computation: 767236 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 364.86
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7400
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4252
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 0.13s
                      Time elapsed: 00:21:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1176/1 [0m                       

                       Computation: 710124 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 360.79
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5933
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4192
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 0.14s
                      Time elapsed: 00:21:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1177/1 [0m                       

                       Computation: 686427 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 363.56
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9948
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4235
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 0.14s
                      Time elapsed: 00:21:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1178/1 [0m                       

                       Computation: 740986 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 359.99
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8390
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4236
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 0.13s
                      Time elapsed: 00:21:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1179/1 [0m                       

                       Computation: 729692 steps/s (collection: 0.048s, learning 0.087s)
                       Mean reward: 363.90
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4558
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4224
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 0.13s
                      Time elapsed: 00:21:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1180/1 [0m                       

                       Computation: 815463 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 361.97
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0697
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4206
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 0.12s
                      Time elapsed: 00:21:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1181/1 [0m                       

                       Computation: 751193 steps/s (collection: 0.047s, learning 0.084s)
                       Mean reward: 365.00
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6422
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4219
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 0.13s
                      Time elapsed: 00:21:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1182/1 [0m                       

                       Computation: 675271 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 357.16
               Mean episode length: 247.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.0017
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4209
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 0.15s
                      Time elapsed: 00:21:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1183/1 [0m                       

                       Computation: 666354 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 363.11
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1848
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4239
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 0.15s
                      Time elapsed: 00:21:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1184/1 [0m                       

                       Computation: 799268 steps/s (collection: 0.045s, learning 0.077s)
                       Mean reward: 361.14
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6384
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4246
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 0.12s
                      Time elapsed: 00:21:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1185/1 [0m                       

                       Computation: 824243 steps/s (collection: 0.042s, learning 0.077s)
                       Mean reward: 357.31
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1348
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4256
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 0.12s
                      Time elapsed: 00:21:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1186/1 [0m                       

                       Computation: 636617 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 362.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1067
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 0.15s
                      Time elapsed: 00:21:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1187/1 [0m                       

                       Computation: 761223 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 364.53
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5568
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 0.13s
                      Time elapsed: 00:21:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1188/1 [0m                       

                       Computation: 693925 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 360.12
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4529
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4269
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 0.14s
                      Time elapsed: 00:21:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1189/1 [0m                       

                       Computation: 715105 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 358.14
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3130
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 0.14s
                      Time elapsed: 00:21:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1190/1 [0m                       

                       Computation: 708935 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 363.05
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1577
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 0.14s
                      Time elapsed: 00:21:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1191/1 [0m                       

                       Computation: 709672 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 365.53
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7273
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 0.14s
                      Time elapsed: 00:21:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1192/1 [0m                       

                       Computation: 685150 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 364.14
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4373
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 0.14s
                      Time elapsed: 00:21:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1193/1 [0m                       

                       Computation: 669297 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 361.42
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0313
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 0.15s
                      Time elapsed: 00:21:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1194/1 [0m                       

                       Computation: 829145 steps/s (collection: 0.044s, learning 0.075s)
                       Mean reward: 359.89
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4252
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 0.12s
                      Time elapsed: 00:21:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1195/1 [0m                       

                       Computation: 854698 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 362.44
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0101
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 0.12s
                      Time elapsed: 00:21:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1196/1 [0m                       

                       Computation: 840004 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 362.42
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9388
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4274
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 0.12s
                      Time elapsed: 00:22:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1197/1 [0m                       

                       Computation: 740006 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 363.61
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4111
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 0.13s
                      Time elapsed: 00:22:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1198/1 [0m                       

                       Computation: 688766 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 362.52
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0111
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 0.14s
                      Time elapsed: 00:22:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1199/1 [0m                       

                       Computation: 714863 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 364.66
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3419
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 0.14s
                      Time elapsed: 00:22:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1200/1 [0m                       

                       Computation: 630063 steps/s (collection: 0.040s, learning 0.117s)
                       Mean reward: 361.34
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8631
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 0.16s
                      Time elapsed: 00:22:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1201/1 [0m                       

                       Computation: 673259 steps/s (collection: 0.043s, learning 0.103s)
                       Mean reward: 360.03
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6709
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 0.15s
                      Time elapsed: 00:22:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1202/1 [0m                       

                       Computation: 829262 steps/s (collection: 0.044s, learning 0.075s)
                       Mean reward: 357.84
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1997
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 0.12s
                      Time elapsed: 00:22:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1203/1 [0m                       

                       Computation: 856319 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 363.61
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2070
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4248
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 0.11s
                      Time elapsed: 00:22:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1204/1 [0m                       

                       Computation: 692155 steps/s (collection: 0.052s, learning 0.091s)
                       Mean reward: 366.24
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7044
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 0.14s
                      Time elapsed: 00:22:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1205/1 [0m                       

                       Computation: 812328 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 359.84
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6625
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 0.12s
                      Time elapsed: 00:22:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1206/1 [0m                       

                       Computation: 811808 steps/s (collection: 0.045s, learning 0.077s)
                       Mean reward: 367.06
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7817
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 0.12s
                      Time elapsed: 00:22:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1207/1 [0m                       

                       Computation: 858433 steps/s (collection: 0.040s, learning 0.075s)
                       Mean reward: 365.10
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7338
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 0.11s
                      Time elapsed: 00:22:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1208/1 [0m                       

                       Computation: 799066 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 360.75
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8444
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 0.12s
                      Time elapsed: 00:22:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1209/1 [0m                       

                       Computation: 807935 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 357.31
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.0575
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 0.12s
                      Time elapsed: 00:22:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1210/1 [0m                       

                       Computation: 822569 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 363.73
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2629
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 0.12s
                      Time elapsed: 00:22:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1211/1 [0m                       

                       Computation: 705879 steps/s (collection: 0.049s, learning 0.091s)
                       Mean reward: 360.58
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7686
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 0.14s
                      Time elapsed: 00:22:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1212/1 [0m                       

                       Computation: 871941 steps/s (collection: 0.039s, learning 0.074s)
                       Mean reward: 359.48
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5255
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4246
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 0.11s
                      Time elapsed: 00:22:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1213/1 [0m                       

                       Computation: 661745 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 364.25
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1481
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 0.15s
                      Time elapsed: 00:22:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1214/1 [0m                       

                       Computation: 729489 steps/s (collection: 0.050s, learning 0.085s)
                       Mean reward: 359.81
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3309
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 0.13s
                      Time elapsed: 00:22:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1215/1 [0m                       

                       Computation: 774883 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 363.75
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3183
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4294
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 0.13s
                      Time elapsed: 00:22:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1216/1 [0m                       

                       Computation: 696536 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 353.96
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.4376
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4234
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 0.14s
                      Time elapsed: 00:22:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1217/1 [0m                       

                       Computation: 620152 steps/s (collection: 0.050s, learning 0.109s)
                       Mean reward: 364.29
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4187
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 0.16s
                      Time elapsed: 00:22:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1218/1 [0m                       

                       Computation: 661822 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 359.71
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5787
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 0.15s
                      Time elapsed: 00:22:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1219/1 [0m                       

                       Computation: 532361 steps/s (collection: 0.056s, learning 0.129s)
                       Mean reward: 362.88
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2122
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 0.18s
                      Time elapsed: 00:22:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1220/1 [0m                       

                       Computation: 608404 steps/s (collection: 0.053s, learning 0.109s)
                       Mean reward: 362.66
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9293
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4256
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 0.16s
                      Time elapsed: 00:22:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1221/1 [0m                       

                       Computation: 624091 steps/s (collection: 0.050s, learning 0.108s)
                       Mean reward: 364.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5616
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 0.16s
                      Time elapsed: 00:22:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1222/1 [0m                       

                       Computation: 574502 steps/s (collection: 0.053s, learning 0.118s)
                       Mean reward: 365.02
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3592
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 0.17s
                      Time elapsed: 00:22:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1223/1 [0m                       

                       Computation: 808727 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 361.31
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6951
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4274
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 0.12s
                      Time elapsed: 00:22:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1224/1 [0m                       

                       Computation: 642805 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 362.62
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1025
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 0.15s
                      Time elapsed: 00:22:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1225/1 [0m                       

                       Computation: 661525 steps/s (collection: 0.039s, learning 0.110s)
                       Mean reward: 363.68
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2032
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 0.15s
                      Time elapsed: 00:22:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1226/1 [0m                       

                       Computation: 668458 steps/s (collection: 0.038s, learning 0.109s)
                       Mean reward: 359.54
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4301
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4276
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 0.15s
                      Time elapsed: 00:22:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1227/1 [0m                       

                       Computation: 814252 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 362.58
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2208
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 0.12s
                      Time elapsed: 00:22:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1228/1 [0m                       

                       Computation: 781237 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 364.55
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5436
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 0.13s
                      Time elapsed: 00:22:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1229/1 [0m                       

                       Computation: 779816 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 360.71
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8391
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4242
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 0.13s
                      Time elapsed: 00:22:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1230/1 [0m                       

                       Computation: 653009 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 355.93
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8628
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 0.15s
                      Time elapsed: 00:22:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1231/1 [0m                       

                       Computation: 614169 steps/s (collection: 0.045s, learning 0.115s)
                       Mean reward: 366.59
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0079
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 0.16s
                      Time elapsed: 00:22:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1232/1 [0m                       

                       Computation: 786358 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 365.48
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9475
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 0.13s
                      Time elapsed: 00:22:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1233/1 [0m                       

                       Computation: 714704 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 366.16
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7131
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4273
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 0.14s
                      Time elapsed: 00:22:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1234/1 [0m                       

                       Computation: 828947 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 365.75
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8007
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 0.12s
                      Time elapsed: 00:22:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1235/1 [0m                       

                       Computation: 842141 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 361.92
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0988
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4244
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 0.12s
                      Time elapsed: 00:22:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1236/1 [0m                       

                       Computation: 833251 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 359.58
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3410
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4256
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 0.12s
                      Time elapsed: 00:22:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1237/1 [0m                       

                       Computation: 736364 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 359.94
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7486
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4240
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 0.13s
                      Time elapsed: 00:22:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1238/1 [0m                       

                       Computation: 804845 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 365.19
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5948
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 0.12s
                      Time elapsed: 00:22:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1239/1 [0m                       

                       Computation: 585262 steps/s (collection: 0.052s, learning 0.116s)
                       Mean reward: 363.37
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3661
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 0.17s
                      Time elapsed: 00:22:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1240/1 [0m                       

                       Computation: 608588 steps/s (collection: 0.049s, learning 0.113s)
                       Mean reward: 366.96
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1580
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 0.16s
                      Time elapsed: 00:22:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1241/1 [0m                       

                       Computation: 588517 steps/s (collection: 0.050s, learning 0.118s)
                       Mean reward: 357.86
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9989
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 0.17s
                      Time elapsed: 00:22:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1242/1 [0m                       

                       Computation: 638533 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 361.90
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9429
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 0.15s
                      Time elapsed: 00:22:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1243/1 [0m                       

                       Computation: 597789 steps/s (collection: 0.054s, learning 0.110s)
                       Mean reward: 366.66
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9899
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 0.16s
                      Time elapsed: 00:22:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1244/1 [0m                       

                       Computation: 687214 steps/s (collection: 0.050s, learning 0.093s)
                       Mean reward: 367.74
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2270
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4273
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 0.14s
                      Time elapsed: 00:22:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1245/1 [0m                       

                       Computation: 733538 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 368.97
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3704
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 0.13s
                      Time elapsed: 00:22:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1246/1 [0m                       

                       Computation: 562545 steps/s (collection: 0.051s, learning 0.124s)
                       Mean reward: 365.89
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9557
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 0.17s
                      Time elapsed: 00:23:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1247/1 [0m                       

                       Computation: 756000 steps/s (collection: 0.049s, learning 0.081s)
                       Mean reward: 365.54
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6410
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 0.13s
                      Time elapsed: 00:23:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1248/1 [0m                       

                       Computation: 862149 steps/s (collection: 0.040s, learning 0.074s)
                       Mean reward: 360.23
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5822
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 0.11s
                      Time elapsed: 00:23:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1249/1 [0m                       

                       Computation: 677112 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 364.75
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6846
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4268
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 0.15s
                      Time elapsed: 00:23:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1250/1 [0m                       

                       Computation: 648281 steps/s (collection: 0.046s, learning 0.106s)
                       Mean reward: 362.38
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9056
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 0.15s
                      Time elapsed: 00:23:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1251/1 [0m                       

                       Computation: 644016 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 364.07
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4592
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 0.15s
                      Time elapsed: 00:23:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1252/1 [0m                       

                       Computation: 567702 steps/s (collection: 0.050s, learning 0.123s)
                       Mean reward: 366.38
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7553
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 0.17s
                      Time elapsed: 00:23:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1253/1 [0m                       

                       Computation: 655125 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 366.38
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6688
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 0.15s
                      Time elapsed: 00:23:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1254/1 [0m                       

                       Computation: 635275 steps/s (collection: 0.042s, learning 0.113s)
                       Mean reward: 364.60
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4870
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4251
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 0.15s
                      Time elapsed: 00:23:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1255/1 [0m                       

                       Computation: 706165 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 364.69
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4436
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4269
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 0.14s
                      Time elapsed: 00:23:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1256/1 [0m                       

                       Computation: 626891 steps/s (collection: 0.040s, learning 0.117s)
                       Mean reward: 367.45
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0068
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 0.16s
                      Time elapsed: 00:23:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1257/1 [0m                       

                       Computation: 574281 steps/s (collection: 0.051s, learning 0.121s)
                       Mean reward: 364.29
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4370
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4269
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 0.17s
                      Time elapsed: 00:23:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1258/1 [0m                       

                       Computation: 582643 steps/s (collection: 0.049s, learning 0.120s)
                       Mean reward: 363.77
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1106
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 0.17s
                      Time elapsed: 00:23:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1259/1 [0m                       

                       Computation: 645816 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 364.12
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4236
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 0.15s
                      Time elapsed: 00:23:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1260/1 [0m                       

                       Computation: 648765 steps/s (collection: 0.046s, learning 0.106s)
                       Mean reward: 366.38
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7610
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 0.15s
                      Time elapsed: 00:23:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1261/1 [0m                       

                       Computation: 708942 steps/s (collection: 0.048s, learning 0.091s)
                       Mean reward: 367.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0950
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 0.14s
                      Time elapsed: 00:23:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1262/1 [0m                       

                       Computation: 677822 steps/s (collection: 0.048s, learning 0.097s)
                       Mean reward: 364.89
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7244
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 0.15s
                      Time elapsed: 00:23:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1263/1 [0m                       

                       Computation: 669914 steps/s (collection: 0.052s, learning 0.095s)
                       Mean reward: 368.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4065
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 0.15s
                      Time elapsed: 00:23:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1264/1 [0m                       

                       Computation: 640251 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 365.57
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5635
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 0.15s
                      Time elapsed: 00:23:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1265/1 [0m                       

                       Computation: 566428 steps/s (collection: 0.053s, learning 0.121s)
                       Mean reward: 365.27
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5567
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4268
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 0.17s
                      Time elapsed: 00:23:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1266/1 [0m                       

                       Computation: 687280 steps/s (collection: 0.045s, learning 0.099s)
                       Mean reward: 363.27
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2328
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 0.14s
                      Time elapsed: 00:23:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1267/1 [0m                       

                       Computation: 800934 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 367.73
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2408
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4252
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 0.12s
                      Time elapsed: 00:23:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1268/1 [0m                       

                       Computation: 774805 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 367.14
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8535
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 0.13s
                      Time elapsed: 00:23:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1269/1 [0m                       

                       Computation: 716825 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 368.04
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0658
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 0.14s
                      Time elapsed: 00:23:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1270/1 [0m                       

                       Computation: 676155 steps/s (collection: 0.049s, learning 0.097s)
                       Mean reward: 364.28
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2976
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 0.15s
                      Time elapsed: 00:23:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1271/1 [0m                       

                       Computation: 781204 steps/s (collection: 0.045s, learning 0.081s)
                       Mean reward: 366.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0161
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 0.13s
                      Time elapsed: 00:23:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1272/1 [0m                       

                       Computation: 717574 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 362.92
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0218
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 0.14s
                      Time elapsed: 00:23:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1273/1 [0m                       

                       Computation: 584961 steps/s (collection: 0.055s, learning 0.113s)
                       Mean reward: 359.46
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5421
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4237
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 0.17s
                      Time elapsed: 00:23:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1274/1 [0m                       

                       Computation: 815640 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 368.29
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2320
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4294
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 0.12s
                      Time elapsed: 00:23:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1275/1 [0m                       

                       Computation: 770878 steps/s (collection: 0.045s, learning 0.082s)
                       Mean reward: 360.44
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5493
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 0.13s
                      Time elapsed: 00:23:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1276/1 [0m                       

                       Computation: 819135 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 361.99
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9307
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4250
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 0.12s
                      Time elapsed: 00:23:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1277/1 [0m                       

                       Computation: 798936 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 367.08
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8796
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 0.12s
                      Time elapsed: 00:23:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1278/1 [0m                       

                       Computation: 790225 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 363.54
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4686
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 0.12s
                      Time elapsed: 00:23:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1279/1 [0m                       

                       Computation: 740277 steps/s (collection: 0.052s, learning 0.081s)
                       Mean reward: 366.78
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1140
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 0.13s
                      Time elapsed: 00:23:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1280/1 [0m                       

                       Computation: 764142 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 365.54
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4630
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 0.13s
                      Time elapsed: 00:23:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1281/1 [0m                       

                       Computation: 688778 steps/s (collection: 0.055s, learning 0.088s)
                       Mean reward: 360.48
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5255
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 0.14s
                      Time elapsed: 00:23:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1282/1 [0m                       

                       Computation: 687576 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 367.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1951
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 0.14s
                      Time elapsed: 00:23:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1283/1 [0m                       

                       Computation: 773841 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 364.22
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4960
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 0.13s
                      Time elapsed: 00:23:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1284/1 [0m                       

                       Computation: 706973 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 365.88
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9392
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 0.14s
                      Time elapsed: 00:23:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1285/1 [0m                       

                       Computation: 775331 steps/s (collection: 0.045s, learning 0.082s)
                       Mean reward: 363.85
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0688
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 0.13s
                      Time elapsed: 00:23:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1286/1 [0m                       

                       Computation: 723515 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 365.03
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4809
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 0.14s
                      Time elapsed: 00:23:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1287/1 [0m                       

                       Computation: 744398 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 368.52
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2594
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 0.13s
                      Time elapsed: 00:23:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1288/1 [0m                       

                       Computation: 697480 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 368.28
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1359
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 0.14s
                      Time elapsed: 00:23:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1289/1 [0m                       

                       Computation: 776421 steps/s (collection: 0.047s, learning 0.079s)
                       Mean reward: 367.45
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7404
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 0.13s
                      Time elapsed: 00:23:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1290/1 [0m                       

                       Computation: 805540 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 369.38
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4763
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 0.12s
                      Time elapsed: 00:23:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1291/1 [0m                       

                       Computation: 725383 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 362.55
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1988
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 0.14s
                      Time elapsed: 00:23:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1292/1 [0m                       

                       Computation: 759651 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 365.10
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5492
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 0.13s
                      Time elapsed: 00:23:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1293/1 [0m                       

                       Computation: 707478 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 366.34
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8192
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 0.14s
                      Time elapsed: 00:23:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1294/1 [0m                       

                       Computation: 615980 steps/s (collection: 0.055s, learning 0.105s)
                       Mean reward: 368.71
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1395
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 0.16s
                      Time elapsed: 00:23:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1295/1 [0m                       

                       Computation: 635995 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 365.58
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7187
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 0.15s
                      Time elapsed: 00:23:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1296/1 [0m                       

                       Computation: 734234 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 371.04
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5995
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4304
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 0.13s
                      Time elapsed: 00:23:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1297/1 [0m                       

                       Computation: 812780 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 360.32
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9249
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 0.12s
                      Time elapsed: 00:23:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1298/1 [0m                       

                       Computation: 776857 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 364.35
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4974
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 0.13s
                      Time elapsed: 00:24:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1299/1 [0m                       

                       Computation: 805454 steps/s (collection: 0.045s, learning 0.078s)
                       Mean reward: 365.62
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8495
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 0.12s
                      Time elapsed: 00:24:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1300/1 [0m                       

                       Computation: 822237 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 366.03
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9680
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 0.12s
                      Time elapsed: 00:24:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1301/1 [0m                       

                       Computation: 840034 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 364.85
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5504
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 0.12s
                      Time elapsed: 00:24:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1302/1 [0m                       

                       Computation: 826980 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 369.01
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2887
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 0.12s
                      Time elapsed: 00:24:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1303/1 [0m                       

                       Computation: 809340 steps/s (collection: 0.043s, learning 0.078s)
                       Mean reward: 365.82
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0551
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 0.12s
                      Time elapsed: 00:24:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1304/1 [0m                       

                       Computation: 681481 steps/s (collection: 0.054s, learning 0.090s)
                       Mean reward: 362.61
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9886
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 0.14s
                      Time elapsed: 00:24:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1305/1 [0m                       

                       Computation: 733229 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 362.98
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3390
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 0.13s
                      Time elapsed: 00:24:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1306/1 [0m                       

                       Computation: 730723 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 365.66
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5530
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4348
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 0.13s
                      Time elapsed: 00:24:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1307/1 [0m                       

                       Computation: 707163 steps/s (collection: 0.047s, learning 0.092s)
                       Mean reward: 364.69
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5402
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 0.14s
                      Time elapsed: 00:24:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1308/1 [0m                       

                       Computation: 659558 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 358.88
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2601
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 0.15s
                      Time elapsed: 00:24:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1309/1 [0m                       

                       Computation: 767742 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 363.88
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6215
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 0.13s
                      Time elapsed: 00:24:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1310/1 [0m                       

                       Computation: 757538 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 362.34
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0058
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 0.13s
                      Time elapsed: 00:24:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1311/1 [0m                       

                       Computation: 767042 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 366.30
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7276
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 0.13s
                      Time elapsed: 00:24:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1312/1 [0m                       

                       Computation: 640227 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 362.62
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1952
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 0.15s
                      Time elapsed: 00:24:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1313/1 [0m                       

                       Computation: 792552 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 367.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9549
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 0.12s
                      Time elapsed: 00:24:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1314/1 [0m                       

                       Computation: 761794 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 365.40
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6202
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 0.13s
                      Time elapsed: 00:24:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1315/1 [0m                       

                       Computation: 770363 steps/s (collection: 0.047s, learning 0.081s)
                       Mean reward: 362.36
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1426
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 0.13s
                      Time elapsed: 00:24:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1316/1 [0m                       

                       Computation: 819845 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 358.24
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1445
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 0.12s
                      Time elapsed: 00:24:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1317/1 [0m                       

                       Computation: 667898 steps/s (collection: 0.055s, learning 0.092s)
                       Mean reward: 359.60
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3970
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 0.15s
                      Time elapsed: 00:24:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1318/1 [0m                       

                       Computation: 650371 steps/s (collection: 0.039s, learning 0.112s)
                       Mean reward: 360.78
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7245
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 0.15s
                      Time elapsed: 00:24:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1319/1 [0m                       

                       Computation: 737784 steps/s (collection: 0.054s, learning 0.079s)
                       Mean reward: 361.49
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8414
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 0.13s
                      Time elapsed: 00:24:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1320/1 [0m                       

                       Computation: 592057 steps/s (collection: 0.044s, learning 0.123s)
                       Mean reward: 366.45
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9385
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 0.17s
                      Time elapsed: 00:24:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1321/1 [0m                       

                       Computation: 612798 steps/s (collection: 0.049s, learning 0.112s)
                       Mean reward: 360.16
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5118
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 0.16s
                      Time elapsed: 00:24:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1322/1 [0m                       

                       Computation: 691060 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 362.82
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1885
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 0.14s
                      Time elapsed: 00:24:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1323/1 [0m                       

                       Computation: 643135 steps/s (collection: 0.044s, learning 0.108s)
                       Mean reward: 359.43
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7719
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 0.15s
                      Time elapsed: 00:24:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1324/1 [0m                       

                       Computation: 587824 steps/s (collection: 0.041s, learning 0.127s)
                       Mean reward: 363.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5739
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 0.17s
                      Time elapsed: 00:24:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1325/1 [0m                       

                       Computation: 742550 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 367.79
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0827
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4294
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 0.13s
                      Time elapsed: 00:24:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1326/1 [0m                       

                       Computation: 634267 steps/s (collection: 0.056s, learning 0.099s)
                       Mean reward: 365.95
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7309
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 0.15s
                      Time elapsed: 00:24:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1327/1 [0m                       

                       Computation: 713280 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 359.28
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.5273
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 0.14s
                      Time elapsed: 00:24:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1328/1 [0m                       

                       Computation: 773613 steps/s (collection: 0.045s, learning 0.083s)
                       Mean reward: 368.87
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1483
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4304
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 0.13s
                      Time elapsed: 00:24:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1329/1 [0m                       

                       Computation: 635004 steps/s (collection: 0.052s, learning 0.103s)
                       Mean reward: 366.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8391
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 0.15s
                      Time elapsed: 00:24:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1330/1 [0m                       

                       Computation: 704189 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 359.92
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6181
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4273
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 0.14s
                      Time elapsed: 00:24:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1331/1 [0m                       

                       Computation: 793722 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 360.62
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8640
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 0.12s
                      Time elapsed: 00:24:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1332/1 [0m                       

                       Computation: 821931 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 363.75
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2266
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 0.12s
                      Time elapsed: 00:24:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1333/1 [0m                       

                       Computation: 818028 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 368.83
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4630
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 0.12s
                      Time elapsed: 00:24:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1334/1 [0m                       

                       Computation: 719622 steps/s (collection: 0.053s, learning 0.084s)
                       Mean reward: 365.70
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5813
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 0.14s
                      Time elapsed: 00:24:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1335/1 [0m                       

                       Computation: 828524 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 362.11
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2124
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 0.12s
                      Time elapsed: 00:24:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1336/1 [0m                       

                       Computation: 795657 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 366.65
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9158
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 0.12s
                      Time elapsed: 00:24:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1337/1 [0m                       

                       Computation: 830895 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 367.09
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8746
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 0.12s
                      Time elapsed: 00:24:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1338/1 [0m                       

                       Computation: 761865 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 363.97
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1403
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 0.13s
                      Time elapsed: 00:24:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1339/1 [0m                       

                       Computation: 797484 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 367.25
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9231
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 0.12s
                      Time elapsed: 00:24:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1340/1 [0m                       

                       Computation: 703498 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 361.18
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7567
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 0.14s
                      Time elapsed: 00:24:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1341/1 [0m                       

                       Computation: 621970 steps/s (collection: 0.046s, learning 0.113s)
                       Mean reward: 370.55
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7057
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 0.16s
                      Time elapsed: 00:24:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1342/1 [0m                       

                       Computation: 791124 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 363.84
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3927
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 0.12s
                      Time elapsed: 00:24:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1343/1 [0m                       

                       Computation: 805298 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 365.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8293
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 0.12s
                      Time elapsed: 00:24:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1344/1 [0m                       

                       Computation: 743987 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 365.41
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9161
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 0.13s
                      Time elapsed: 00:24:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1345/1 [0m                       

                       Computation: 733152 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 369.32
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4709
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 0.13s
                      Time elapsed: 00:24:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1346/1 [0m                       

                       Computation: 834092 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 368.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3692
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4359
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 0.12s
                      Time elapsed: 00:24:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1347/1 [0m                       

                       Computation: 631607 steps/s (collection: 0.043s, learning 0.113s)
                       Mean reward: 364.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5340
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 0.16s
                      Time elapsed: 00:24:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1348/1 [0m                       

                       Computation: 638177 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 361.30
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7204
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4325
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 0.15s
                      Time elapsed: 00:24:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1349/1 [0m                       

                       Computation: 618663 steps/s (collection: 0.048s, learning 0.111s)
                       Mean reward: 364.71
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2357
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 0.16s
                      Time elapsed: 00:24:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1350/1 [0m                       

                       Computation: 712253 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 358.85
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1256
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 0.14s
                      Time elapsed: 00:25:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1351/1 [0m                       

                       Computation: 579309 steps/s (collection: 0.047s, learning 0.123s)
                       Mean reward: 361.51
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3024
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 0.17s
                      Time elapsed: 00:25:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1352/1 [0m                       

                       Computation: 617264 steps/s (collection: 0.045s, learning 0.115s)
                       Mean reward: 362.68
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9770
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 0.16s
                      Time elapsed: 00:25:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1353/1 [0m                       

                       Computation: 710499 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 364.91
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4103
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 0.14s
                      Time elapsed: 00:25:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1354/1 [0m                       

                       Computation: 680649 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 368.62
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1487
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 0.14s
                      Time elapsed: 00:25:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1355/1 [0m                       

                       Computation: 716509 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 369.77
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6079
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 0.14s
                      Time elapsed: 00:25:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1356/1 [0m                       

                       Computation: 696170 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 367.31
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7873
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 0.14s
                      Time elapsed: 00:25:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1357/1 [0m                       

                       Computation: 773783 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 363.18
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2785
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 0.13s
                      Time elapsed: 00:25:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1358/1 [0m                       

                       Computation: 693840 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 361.83
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0932
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 0.14s
                      Time elapsed: 00:25:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1359/1 [0m                       

                       Computation: 780371 steps/s (collection: 0.047s, learning 0.079s)
                       Mean reward: 366.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0582
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 0.13s
                      Time elapsed: 00:25:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1360/1 [0m                       

                       Computation: 679885 steps/s (collection: 0.056s, learning 0.089s)
                       Mean reward: 369.36
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5905
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 0.14s
                      Time elapsed: 00:25:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1361/1 [0m                       

                       Computation: 802308 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 369.18
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5209
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 0.12s
                      Time elapsed: 00:25:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1362/1 [0m                       

                       Computation: 756507 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 365.91
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7600
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 0.13s
                      Time elapsed: 00:25:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1363/1 [0m                       

                       Computation: 799323 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 362.77
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9991
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 0.12s
                      Time elapsed: 00:25:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1364/1 [0m                       

                       Computation: 786747 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 372.37
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1115
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 0.12s
                      Time elapsed: 00:25:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1365/1 [0m                       

                       Computation: 821993 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 369.59
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2890
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 0.12s
                      Time elapsed: 00:25:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1366/1 [0m                       

                       Computation: 703913 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 364.30
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5643
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 0.14s
                      Time elapsed: 00:25:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1367/1 [0m                       

                       Computation: 680918 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 359.51
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6017
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 0.14s
                      Time elapsed: 00:25:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1368/1 [0m                       

                       Computation: 746284 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 363.71
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3709
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 0.13s
                      Time elapsed: 00:25:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1369/1 [0m                       

                       Computation: 778136 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 372.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1349
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 0.13s
                      Time elapsed: 00:25:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1370/1 [0m                       

                       Computation: 660675 steps/s (collection: 0.046s, learning 0.102s)
                       Mean reward: 366.34
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0081
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 0.15s
                      Time elapsed: 00:25:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1371/1 [0m                       

                       Computation: 652194 steps/s (collection: 0.044s, learning 0.107s)
                       Mean reward: 368.66
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3894
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 0.15s
                      Time elapsed: 00:25:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1372/1 [0m                       

                       Computation: 683715 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 364.46
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4089
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 0.14s
                      Time elapsed: 00:25:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1373/1 [0m                       

                       Computation: 735406 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 367.07
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6725
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 0.13s
                      Time elapsed: 00:25:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1374/1 [0m                       

                       Computation: 670979 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 368.07
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2295
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 0.15s
                      Time elapsed: 00:25:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1375/1 [0m                       

                       Computation: 666265 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 360.60
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7733
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 0.15s
                      Time elapsed: 00:25:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1376/1 [0m                       

                       Computation: 604320 steps/s (collection: 0.048s, learning 0.115s)
                       Mean reward: 366.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0345
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 0.16s
                      Time elapsed: 00:25:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1377/1 [0m                       

                       Computation: 603673 steps/s (collection: 0.056s, learning 0.107s)
                       Mean reward: 365.04
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6950
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 0.16s
                      Time elapsed: 00:25:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1378/1 [0m                       

                       Computation: 731530 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 370.14
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6720
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 0.13s
                      Time elapsed: 00:25:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1379/1 [0m                       

                       Computation: 722551 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 366.16
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1585
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 0.14s
                      Time elapsed: 00:25:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1380/1 [0m                       

                       Computation: 648545 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 364.20
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3785
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 0.15s
                      Time elapsed: 00:25:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1381/1 [0m                       

                       Computation: 628957 steps/s (collection: 0.052s, learning 0.104s)
                       Mean reward: 368.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3253
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 0.16s
                      Time elapsed: 00:25:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1382/1 [0m                       

                       Computation: 764387 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 368.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3607
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 0.13s
                      Time elapsed: 00:25:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1383/1 [0m                       

                       Computation: 722218 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 372.14
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7930
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 0.14s
                      Time elapsed: 00:25:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1384/1 [0m                       

                       Computation: 717384 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 366.62
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9238
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4304
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 0.14s
                      Time elapsed: 00:25:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1385/1 [0m                       

                       Computation: 646451 steps/s (collection: 0.041s, learning 0.112s)
                       Mean reward: 370.06
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6141
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 0.15s
                      Time elapsed: 00:25:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1386/1 [0m                       

                       Computation: 751525 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 365.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8376
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 0.13s
                      Time elapsed: 00:25:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1387/1 [0m                       

                       Computation: 753988 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 365.99
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7898
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 0.13s
                      Time elapsed: 00:25:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1388/1 [0m                       

                       Computation: 640371 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 371.16
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7528
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 0.15s
                      Time elapsed: 00:25:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1389/1 [0m                       

                       Computation: 777007 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 363.56
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2557
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 0.13s
                      Time elapsed: 00:25:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1390/1 [0m                       

                       Computation: 760398 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 366.15
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8169
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4325
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 0.13s
                      Time elapsed: 00:25:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1391/1 [0m                       

                       Computation: 504023 steps/s (collection: 0.060s, learning 0.136s)
                       Mean reward: 368.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1886
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 0.20s
                      Time elapsed: 00:25:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1392/1 [0m                       

                       Computation: 576168 steps/s (collection: 0.050s, learning 0.121s)
                       Mean reward: 373.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0633
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 0.17s
                      Time elapsed: 00:25:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1393/1 [0m                       

                       Computation: 688621 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 363.80
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5747
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 0.14s
                      Time elapsed: 00:25:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1394/1 [0m                       

                       Computation: 711849 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 364.77
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4807
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 0.14s
                      Time elapsed: 00:25:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1395/1 [0m                       

                       Computation: 653220 steps/s (collection: 0.043s, learning 0.108s)
                       Mean reward: 364.87
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4016
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 0.15s
                      Time elapsed: 00:25:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1396/1 [0m                       

                       Computation: 654174 steps/s (collection: 0.044s, learning 0.107s)
                       Mean reward: 368.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1834
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 0.15s
                      Time elapsed: 00:25:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1397/1 [0m                       

                       Computation: 770518 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 364.24
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5306
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 0.13s
                      Time elapsed: 00:25:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1398/1 [0m                       

                       Computation: 626117 steps/s (collection: 0.041s, learning 0.116s)
                       Mean reward: 369.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5226
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 0.16s
                      Time elapsed: 00:25:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1399/1 [0m                       

                       Computation: 764864 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 366.34
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9818
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 0.13s
                      Time elapsed: 00:25:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1400/1 [0m                       

                       Computation: 618574 steps/s (collection: 0.044s, learning 0.115s)
                       Mean reward: 367.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9872
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 0.16s
                      Time elapsed: 00:25:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1401/1 [0m                       

                       Computation: 783692 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 363.55
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0850
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 0.13s
                      Time elapsed: 00:25:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1402/1 [0m                       

                       Computation: 789321 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 366.57
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8235
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 0.12s
                      Time elapsed: 00:25:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1403/1 [0m                       

                       Computation: 626287 steps/s (collection: 0.045s, learning 0.112s)
                       Mean reward: 363.91
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2289
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 0.16s
                      Time elapsed: 00:26:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1404/1 [0m                       

                       Computation: 716431 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 366.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6266
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4306
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 0.14s
                      Time elapsed: 00:26:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1405/1 [0m                       

                       Computation: 704169 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 366.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8732
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 0.14s
                      Time elapsed: 00:26:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1406/1 [0m                       

                       Computation: 665841 steps/s (collection: 0.051s, learning 0.097s)
                       Mean reward: 363.17
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0404
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4253
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 0.15s
                      Time elapsed: 00:26:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1407/1 [0m                       

                       Computation: 587615 steps/s (collection: 0.050s, learning 0.117s)
                       Mean reward: 366.82
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5847
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 0.17s
                      Time elapsed: 00:26:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1408/1 [0m                       

                       Computation: 646464 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 365.49
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5094
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 0.15s
                      Time elapsed: 00:26:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1409/1 [0m                       

                       Computation: 615351 steps/s (collection: 0.068s, learning 0.092s)
                       Mean reward: 364.39
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3097
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 0.16s
                      Time elapsed: 00:26:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1410/1 [0m                       

                       Computation: 722661 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 364.20
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5205
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4260
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 0.14s
                      Time elapsed: 00:26:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1411/1 [0m                       

                       Computation: 719909 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 371.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9120
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 0.14s
                      Time elapsed: 00:26:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1412/1 [0m                       

                       Computation: 751733 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 368.62
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3824
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 0.13s
                      Time elapsed: 00:26:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1413/1 [0m                       

                       Computation: 736253 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 371.17
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7491
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 0.13s
                      Time elapsed: 00:26:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1414/1 [0m                       

                       Computation: 733863 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 364.83
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7693
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 0.13s
                      Time elapsed: 00:26:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1415/1 [0m                       

                       Computation: 731263 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 366.24
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6937
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 0.13s
                      Time elapsed: 00:26:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1416/1 [0m                       

                       Computation: 592909 steps/s (collection: 0.053s, learning 0.113s)
                       Mean reward: 367.40
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0920
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 0.17s
                      Time elapsed: 00:26:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1417/1 [0m                       

                       Computation: 714817 steps/s (collection: 0.053s, learning 0.085s)
                       Mean reward: 365.91
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7127
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4283
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 0.14s
                      Time elapsed: 00:26:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1418/1 [0m                       

                       Computation: 828441 steps/s (collection: 0.042s, learning 0.077s)
                       Mean reward: 370.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7356
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 0.12s
                      Time elapsed: 00:26:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1419/1 [0m                       

                       Computation: 658053 steps/s (collection: 0.046s, learning 0.104s)
                       Mean reward: 371.58
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0152
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 0.15s
                      Time elapsed: 00:26:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1420/1 [0m                       

                       Computation: 725848 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 367.56
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1052
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 0.14s
                      Time elapsed: 00:26:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1421/1 [0m                       

                       Computation: 743028 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 370.41
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7715
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 0.13s
                      Time elapsed: 00:26:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1422/1 [0m                       

                       Computation: 732378 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 369.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4278
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 0.13s
                      Time elapsed: 00:26:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1423/1 [0m                       

                       Computation: 667081 steps/s (collection: 0.053s, learning 0.095s)
                       Mean reward: 363.52
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2037
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4304
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 0.15s
                      Time elapsed: 00:26:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1424/1 [0m                       

                       Computation: 692169 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 367.81
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9546
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 0.14s
                      Time elapsed: 00:26:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1425/1 [0m                       

                       Computation: 682392 steps/s (collection: 0.045s, learning 0.099s)
                       Mean reward: 369.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4444
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 0.14s
                      Time elapsed: 00:26:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1426/1 [0m                       

                       Computation: 642919 steps/s (collection: 0.053s, learning 0.100s)
                       Mean reward: 371.41
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8459
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 0.15s
                      Time elapsed: 00:26:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1427/1 [0m                       

                       Computation: 740998 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 372.24
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0030
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 0.13s
                      Time elapsed: 00:26:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1428/1 [0m                       

                       Computation: 677115 steps/s (collection: 0.046s, learning 0.099s)
                       Mean reward: 372.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8569
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 0.15s
                      Time elapsed: 00:26:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1429/1 [0m                       

                       Computation: 724181 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 367.77
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1198
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4325
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 0.14s
                      Time elapsed: 00:26:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1430/1 [0m                       

                       Computation: 488849 steps/s (collection: 0.054s, learning 0.147s)
                       Mean reward: 369.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5767
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 0.20s
                      Time elapsed: 00:26:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1431/1 [0m                       

                       Computation: 748934 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 361.85
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0641
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4326
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 0.13s
                      Time elapsed: 00:26:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1432/1 [0m                       

                       Computation: 589957 steps/s (collection: 0.047s, learning 0.120s)
                       Mean reward: 370.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5004
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 0.17s
                      Time elapsed: 00:26:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1433/1 [0m                       

                       Computation: 597473 steps/s (collection: 0.044s, learning 0.121s)
                       Mean reward: 371.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0063
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 0.16s
                      Time elapsed: 00:26:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1434/1 [0m                       

                       Computation: 623463 steps/s (collection: 0.046s, learning 0.112s)
                       Mean reward: 365.61
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4526
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 0.16s
                      Time elapsed: 00:26:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1435/1 [0m                       

                       Computation: 619989 steps/s (collection: 0.049s, learning 0.110s)
                       Mean reward: 367.27
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1352
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 0.16s
                      Time elapsed: 00:26:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1436/1 [0m                       

                       Computation: 681222 steps/s (collection: 0.044s, learning 0.101s)
                       Mean reward: 371.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9010
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 0.14s
                      Time elapsed: 00:26:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1437/1 [0m                       

                       Computation: 689411 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 368.20
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2970
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 0.14s
                      Time elapsed: 00:26:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1438/1 [0m                       

                       Computation: 707498 steps/s (collection: 0.047s, learning 0.092s)
                       Mean reward: 367.22
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9933
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 0.14s
                      Time elapsed: 00:26:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1439/1 [0m                       

                       Computation: 662788 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 370.03
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5709
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 0.15s
                      Time elapsed: 00:26:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1440/1 [0m                       

                       Computation: 668597 steps/s (collection: 0.048s, learning 0.100s)
                       Mean reward: 367.11
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0116
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 0.15s
                      Time elapsed: 00:26:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1441/1 [0m                       

                       Computation: 677529 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 369.91
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6955
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 0.15s
                      Time elapsed: 00:26:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1442/1 [0m                       

                       Computation: 714812 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 372.26
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5988
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 0.14s
                      Time elapsed: 00:26:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1443/1 [0m                       

                       Computation: 780467 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 369.65
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4110
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 0.13s
                      Time elapsed: 00:26:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1444/1 [0m                       

                       Computation: 710313 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 365.46
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5172
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 0.14s
                      Time elapsed: 00:26:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1445/1 [0m                       

                       Computation: 770039 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 371.08
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7121
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 0.13s
                      Time elapsed: 00:26:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1446/1 [0m                       

                       Computation: 709663 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 371.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8864
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 0.14s
                      Time elapsed: 00:26:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1447/1 [0m                       

                       Computation: 669794 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 368.24
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1968
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 0.15s
                      Time elapsed: 00:26:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1448/1 [0m                       

                       Computation: 664209 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 370.65
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6140
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 0.15s
                      Time elapsed: 00:26:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1449/1 [0m                       

                       Computation: 675418 steps/s (collection: 0.050s, learning 0.096s)
                       Mean reward: 367.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0130
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 0.15s
                      Time elapsed: 00:26:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1450/1 [0m                       

                       Computation: 726465 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 372.63
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1690
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 0.14s
                      Time elapsed: 00:26:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1451/1 [0m                       

                       Computation: 733631 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 370.77
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6024
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 0.13s
                      Time elapsed: 00:26:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1452/1 [0m                       

                       Computation: 587541 steps/s (collection: 0.047s, learning 0.120s)
                       Mean reward: 377.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.1191
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 0.17s
                      Time elapsed: 00:26:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1453/1 [0m                       

                       Computation: 743087 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 370.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6144
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 0.13s
                      Time elapsed: 00:26:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1454/1 [0m                       

                       Computation: 722147 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 372.30
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0629
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 0.14s
                      Time elapsed: 00:26:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1455/1 [0m                       

                       Computation: 674048 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 370.80
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7272
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 0.15s
                      Time elapsed: 00:26:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1456/1 [0m                       

                       Computation: 722069 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 369.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5370
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 0.14s
                      Time elapsed: 00:27:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1457/1 [0m                       

                       Computation: 661342 steps/s (collection: 0.048s, learning 0.100s)
                       Mean reward: 368.71
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2697
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 0.15s
                      Time elapsed: 00:27:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1458/1 [0m                       

                       Computation: 571399 steps/s (collection: 0.050s, learning 0.123s)
                       Mean reward: 375.45
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6726
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 0.17s
                      Time elapsed: 00:27:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1459/1 [0m                       

                       Computation: 595553 steps/s (collection: 0.053s, learning 0.113s)
                       Mean reward: 370.74
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8017
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 0.17s
                      Time elapsed: 00:27:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1460/1 [0m                       

                       Computation: 641260 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 365.29
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7884
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 0.15s
                      Time elapsed: 00:27:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1461/1 [0m                       

                       Computation: 676080 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 365.99
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6440
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4283
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 0.15s
                      Time elapsed: 00:27:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1462/1 [0m                       

                       Computation: 653125 steps/s (collection: 0.047s, learning 0.103s)
                       Mean reward: 370.49
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6935
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 0.15s
                      Time elapsed: 00:27:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1463/1 [0m                       

                       Computation: 679153 steps/s (collection: 0.047s, learning 0.098s)
                       Mean reward: 375.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6558
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 0.14s
                      Time elapsed: 00:27:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1464/1 [0m                       

                       Computation: 621645 steps/s (collection: 0.044s, learning 0.114s)
                       Mean reward: 367.43
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9374
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4276
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 0.16s
                      Time elapsed: 00:27:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1465/1 [0m                       

                       Computation: 832803 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 370.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5381
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 0.12s
                      Time elapsed: 00:27:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1466/1 [0m                       

                       Computation: 881608 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 365.56
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7563
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 0.11s
                      Time elapsed: 00:27:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1467/1 [0m                       

                       Computation: 704511 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 370.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7486
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 0.14s
                      Time elapsed: 00:27:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1468/1 [0m                       

                       Computation: 785313 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 370.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7043
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 0.13s
                      Time elapsed: 00:27:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1469/1 [0m                       

                       Computation: 638022 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 363.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3348
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 0.15s
                      Time elapsed: 00:27:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1470/1 [0m                       

                       Computation: 736211 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 365.69
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6223
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4294
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 0.13s
                      Time elapsed: 00:27:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1471/1 [0m                       

                       Computation: 652642 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 368.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3243
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 0.15s
                      Time elapsed: 00:27:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1472/1 [0m                       

                       Computation: 727277 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 368.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4049
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 0.14s
                      Time elapsed: 00:27:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1473/1 [0m                       

                       Computation: 761489 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 365.77
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6851
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 0.13s
                      Time elapsed: 00:27:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1474/1 [0m                       

                       Computation: 626076 steps/s (collection: 0.040s, learning 0.117s)
                       Mean reward: 366.28
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4636
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 0.16s
                      Time elapsed: 00:27:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1475/1 [0m                       

                       Computation: 659591 steps/s (collection: 0.050s, learning 0.099s)
                       Mean reward: 368.80
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2517
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 0.15s
                      Time elapsed: 00:27:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1476/1 [0m                       

                       Computation: 666370 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 365.86
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8607
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 0.15s
                      Time elapsed: 00:27:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1477/1 [0m                       

                       Computation: 752892 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 365.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7870
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 0.13s
                      Time elapsed: 00:27:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1478/1 [0m                       

                       Computation: 702228 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 371.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8224
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 0.14s
                      Time elapsed: 00:27:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1479/1 [0m                       

                       Computation: 776595 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 371.40
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9190
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 0.13s
                      Time elapsed: 00:27:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1480/1 [0m                       

                       Computation: 695061 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 362.05
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8625
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 0.14s
                      Time elapsed: 00:27:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1481/1 [0m                       

                       Computation: 717825 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 366.51
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8227
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 0.14s
                      Time elapsed: 00:27:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1482/1 [0m                       

                       Computation: 687953 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 370.43
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6218
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 0.14s
                      Time elapsed: 00:27:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1483/1 [0m                       

                       Computation: 649797 steps/s (collection: 0.042s, learning 0.109s)
                       Mean reward: 369.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3153
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 0.15s
                      Time elapsed: 00:27:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1484/1 [0m                       

                       Computation: 692387 steps/s (collection: 0.042s, learning 0.100s)
                       Mean reward: 370.68
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9921
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 0.14s
                      Time elapsed: 00:27:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1485/1 [0m                       

                       Computation: 724351 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 371.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8251
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 0.14s
                      Time elapsed: 00:27:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1486/1 [0m                       

                       Computation: 657176 steps/s (collection: 0.039s, learning 0.110s)
                       Mean reward: 372.38
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9361
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 0.15s
                      Time elapsed: 00:27:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1487/1 [0m                       

                       Computation: 658072 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 365.16
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7380
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4326
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 0.15s
                      Time elapsed: 00:27:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1488/1 [0m                       

                       Computation: 698935 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 375.60
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5826
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 0.14s
                      Time elapsed: 00:27:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1489/1 [0m                       

                       Computation: 648004 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 364.97
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4982
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 0.15s
                      Time elapsed: 00:27:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1490/1 [0m                       

                       Computation: 629492 steps/s (collection: 0.040s, learning 0.116s)
                       Mean reward: 365.36
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5792
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 0.16s
                      Time elapsed: 00:27:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1491/1 [0m                       

                       Computation: 630070 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 367.97
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1123
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 0.16s
                      Time elapsed: 00:27:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1492/1 [0m                       

                       Computation: 647360 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 368.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3724
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 0.15s
                      Time elapsed: 00:27:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1493/1 [0m                       

                       Computation: 712283 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 370.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5928
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 0.14s
                      Time elapsed: 00:27:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1494/1 [0m                       

                       Computation: 723569 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 364.92
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3869
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 0.14s
                      Time elapsed: 00:27:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1495/1 [0m                       

                       Computation: 741774 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 365.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4513
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 0.13s
                      Time elapsed: 00:27:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1496/1 [0m                       

                       Computation: 728087 steps/s (collection: 0.045s, learning 0.090s)
                       Mean reward: 366.19
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7852
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 0.14s
                      Time elapsed: 00:27:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1497/1 [0m                       

                       Computation: 784662 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 371.04
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7824
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 0.13s
                      Time elapsed: 00:27:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1498/1 [0m                       

                       Computation: 792423 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 370.39
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8646
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 0.12s
                      Time elapsed: 00:27:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1499/1 [0m                       

                       Computation: 723351 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 374.33
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3792
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4325
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 0.14s
                      Time elapsed: 00:27:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1500/1 [0m                       

                       Computation: 602655 steps/s (collection: 0.043s, learning 0.121s)
                       Mean reward: 373.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3872
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 0.16s
                      Time elapsed: 00:27:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1501/1 [0m                       

                       Computation: 689233 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 373.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1677
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 147554304
                    Iteration time: 0.14s
                      Time elapsed: 00:27:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1502/1 [0m                       

                       Computation: 704237 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 369.43
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4084
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 147652608
                    Iteration time: 0.14s
                      Time elapsed: 00:27:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1503/1 [0m                       

                       Computation: 697923 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 361.19
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8007
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 147750912
                    Iteration time: 0.14s
                      Time elapsed: 00:27:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1504/1 [0m                       

                       Computation: 681411 steps/s (collection: 0.038s, learning 0.106s)
                       Mean reward: 368.38
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2255
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 147849216
                    Iteration time: 0.14s
                      Time elapsed: 00:27:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1505/1 [0m                       

                       Computation: 596474 steps/s (collection: 0.041s, learning 0.124s)
                       Mean reward: 365.04
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3209
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 147947520
                    Iteration time: 0.16s
                      Time elapsed: 00:27:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1506/1 [0m                       

                       Computation: 614320 steps/s (collection: 0.051s, learning 0.109s)
                       Mean reward: 367.21
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9870
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 148045824
                    Iteration time: 0.16s
                      Time elapsed: 00:27:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1507/1 [0m                       

                       Computation: 666340 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 370.17
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5973
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 148144128
                    Iteration time: 0.15s
                      Time elapsed: 00:27:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1508/1 [0m                       

                       Computation: 670736 steps/s (collection: 0.048s, learning 0.099s)
                       Mean reward: 373.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2715
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 148242432
                    Iteration time: 0.15s
                      Time elapsed: 00:27:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1509/1 [0m                       

                       Computation: 667820 steps/s (collection: 0.047s, learning 0.100s)
                       Mean reward: 368.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3272
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 148340736
                    Iteration time: 0.15s
                      Time elapsed: 00:27:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1510/1 [0m                       

                       Computation: 754810 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 367.13
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0620
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4273
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 148439040
                    Iteration time: 0.13s
                      Time elapsed: 00:28:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1511/1 [0m                       

                       Computation: 774005 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 368.38
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0932
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 148537344
                    Iteration time: 0.13s
                      Time elapsed: 00:28:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1512/1 [0m                       

                       Computation: 750984 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 368.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2380
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 148635648
                    Iteration time: 0.13s
                      Time elapsed: 00:28:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1513/1 [0m                       

                       Computation: 714761 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 372.88
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0642
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4293
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 148733952
                    Iteration time: 0.14s
                      Time elapsed: 00:28:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1514/1 [0m                       

                       Computation: 741727 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 370.56
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6608
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 148832256
                    Iteration time: 0.13s
                      Time elapsed: 00:28:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1515/1 [0m                       

                       Computation: 638180 steps/s (collection: 0.040s, learning 0.115s)
                       Mean reward: 367.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2381
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 148930560
                    Iteration time: 0.15s
                      Time elapsed: 00:28:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1516/1 [0m                       

                       Computation: 671102 steps/s (collection: 0.043s, learning 0.103s)
                       Mean reward: 367.48
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0535
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 149028864
                    Iteration time: 0.15s
                      Time elapsed: 00:28:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1517/1 [0m                       

                       Computation: 590327 steps/s (collection: 0.045s, learning 0.122s)
                       Mean reward: 363.49
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2933
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4269
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 149127168
                    Iteration time: 0.17s
                      Time elapsed: 00:28:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1518/1 [0m                       

                       Computation: 677866 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 365.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8536
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4293
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 149225472
                    Iteration time: 0.15s
                      Time elapsed: 00:28:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1519/1 [0m                       

                       Computation: 626158 steps/s (collection: 0.044s, learning 0.113s)
                       Mean reward: 369.00
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6128
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 149323776
                    Iteration time: 0.16s
                      Time elapsed: 00:28:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1520/1 [0m                       

                       Computation: 675497 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 367.06
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1327
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4276
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 149422080
                    Iteration time: 0.15s
                      Time elapsed: 00:28:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1521/1 [0m                       

                       Computation: 722708 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 369.64
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2636
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 149520384
                    Iteration time: 0.14s
                      Time elapsed: 00:28:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1522/1 [0m                       

                       Computation: 739064 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 366.34
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9151
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4269
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 149618688
                    Iteration time: 0.13s
                      Time elapsed: 00:28:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1523/1 [0m                       

                       Computation: 717191 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 372.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2653
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 149716992
                    Iteration time: 0.14s
                      Time elapsed: 00:28:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1524/1 [0m                       

                       Computation: 843166 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 368.70
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2544
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4283
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 149815296
                    Iteration time: 0.12s
                      Time elapsed: 00:28:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1525/1 [0m                       

                       Computation: 749617 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 369.38
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5889
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 149913600
                    Iteration time: 0.13s
                      Time elapsed: 00:28:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1526/1 [0m                       

                       Computation: 730757 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 375.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4907
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4306
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 150011904
                    Iteration time: 0.13s
                      Time elapsed: 00:28:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1527/1 [0m                       

                       Computation: 750309 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 365.28
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7774
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4294
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 150110208
                    Iteration time: 0.13s
                      Time elapsed: 00:28:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1528/1 [0m                       

                       Computation: 734769 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 370.59
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5570
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 150208512
                    Iteration time: 0.13s
                      Time elapsed: 00:28:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1529/1 [0m                       

                       Computation: 706122 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 368.93
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3816
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 150306816
                    Iteration time: 0.14s
                      Time elapsed: 00:28:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1530/1 [0m                       

                       Computation: 670133 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 370.33
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7503
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 150405120
                    Iteration time: 0.15s
                      Time elapsed: 00:28:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1531/1 [0m                       

                       Computation: 706064 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 370.41
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3985
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 150503424
                    Iteration time: 0.14s
                      Time elapsed: 00:28:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1532/1 [0m                       

                       Computation: 854918 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 368.62
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4722
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 150601728
                    Iteration time: 0.11s
                      Time elapsed: 00:28:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1533/1 [0m                       

                       Computation: 822501 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 371.30
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7936
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 150700032
                    Iteration time: 0.12s
                      Time elapsed: 00:28:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1534/1 [0m                       

                       Computation: 730452 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 375.56
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5800
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 150798336
                    Iteration time: 0.13s
                      Time elapsed: 00:28:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1535/1 [0m                       

                       Computation: 800944 steps/s (collection: 0.049s, learning 0.073s)
                       Mean reward: 369.49
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4920
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 150896640
                    Iteration time: 0.12s
                      Time elapsed: 00:28:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1536/1 [0m                       

                       Computation: 842203 steps/s (collection: 0.043s, learning 0.074s)
                       Mean reward: 371.63
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7764
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 150994944
                    Iteration time: 0.12s
                      Time elapsed: 00:28:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1537/1 [0m                       

                       Computation: 803775 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 369.87
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5161
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 151093248
                    Iteration time: 0.12s
                      Time elapsed: 00:28:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1538/1 [0m                       

                       Computation: 858746 steps/s (collection: 0.039s, learning 0.075s)
                       Mean reward: 372.77
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7670
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 151191552
                    Iteration time: 0.11s
                      Time elapsed: 00:28:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1539/1 [0m                       

                       Computation: 810877 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 373.13
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1773
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 151289856
                    Iteration time: 0.12s
                      Time elapsed: 00:28:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1540/1 [0m                       

                       Computation: 764935 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 370.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6182
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 151388160
                    Iteration time: 0.13s
                      Time elapsed: 00:28:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1541/1 [0m                       

                       Computation: 868671 steps/s (collection: 0.040s, learning 0.073s)
                       Mean reward: 370.93
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6879
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 151486464
                    Iteration time: 0.11s
                      Time elapsed: 00:28:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1542/1 [0m                       

                       Computation: 799354 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 366.40
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9767
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 151584768
                    Iteration time: 0.12s
                      Time elapsed: 00:28:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1543/1 [0m                       

                       Computation: 692119 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 369.16
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3526
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 151683072
                    Iteration time: 0.14s
                      Time elapsed: 00:28:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1544/1 [0m                       

                       Computation: 675397 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 372.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0385
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 151781376
                    Iteration time: 0.15s
                      Time elapsed: 00:28:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1545/1 [0m                       

                       Computation: 638030 steps/s (collection: 0.039s, learning 0.115s)
                       Mean reward: 369.19
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3680
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 151879680
                    Iteration time: 0.15s
                      Time elapsed: 00:28:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1546/1 [0m                       

                       Computation: 623398 steps/s (collection: 0.040s, learning 0.118s)
                       Mean reward: 373.39
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2802
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 151977984
                    Iteration time: 0.16s
                      Time elapsed: 00:28:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1547/1 [0m                       

                       Computation: 661534 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 368.46
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0192
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152076288
                    Iteration time: 0.15s
                      Time elapsed: 00:28:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1548/1 [0m                       

                       Computation: 650139 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 373.22
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2056
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 152174592
                    Iteration time: 0.15s
                      Time elapsed: 00:28:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1549/1 [0m                       

                       Computation: 759030 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 361.68
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8095
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 152272896
                    Iteration time: 0.13s
                      Time elapsed: 00:28:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1550/1 [0m                       

                       Computation: 863660 steps/s (collection: 0.040s, learning 0.073s)
                       Mean reward: 367.04
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8228
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 152371200
                    Iteration time: 0.11s
                      Time elapsed: 00:28:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1551/1 [0m                       

                       Computation: 764855 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 369.80
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3932
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 152469504
                    Iteration time: 0.13s
                      Time elapsed: 00:28:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1552/1 [0m                       

                       Computation: 802097 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 369.49
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4798
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 152567808
                    Iteration time: 0.12s
                      Time elapsed: 00:28:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1553/1 [0m                       

                       Computation: 699557 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 366.82
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9604
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4306
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 152666112
                    Iteration time: 0.14s
                      Time elapsed: 00:28:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1554/1 [0m                       

                       Computation: 661806 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 369.70
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7249
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 152764416
                    Iteration time: 0.15s
                      Time elapsed: 00:28:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1555/1 [0m                       

                       Computation: 767356 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 364.00
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2326
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 152862720
                    Iteration time: 0.13s
                      Time elapsed: 00:28:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1556/1 [0m                       

                       Computation: 703473 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 367.48
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2248
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 152961024
                    Iteration time: 0.14s
                      Time elapsed: 00:28:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1557/1 [0m                       

                       Computation: 639752 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 369.18
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3104
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 153059328
                    Iteration time: 0.15s
                      Time elapsed: 00:28:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1558/1 [0m                       

                       Computation: 684811 steps/s (collection: 0.047s, learning 0.097s)
                       Mean reward: 366.51
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9226
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 153157632
                    Iteration time: 0.14s
                      Time elapsed: 00:28:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1559/1 [0m                       

                       Computation: 795668 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 368.99
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4289
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 153255936
                    Iteration time: 0.12s
                      Time elapsed: 00:28:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1560/1 [0m                       

                       Computation: 722606 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 366.81
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9180
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 153354240
                    Iteration time: 0.14s
                      Time elapsed: 00:28:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1561/1 [0m                       

                       Computation: 659002 steps/s (collection: 0.043s, learning 0.106s)
                       Mean reward: 370.42
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8719
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 153452544
                    Iteration time: 0.15s
                      Time elapsed: 00:28:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1562/1 [0m                       

                       Computation: 650571 steps/s (collection: 0.039s, learning 0.112s)
                       Mean reward: 366.30
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8727
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 153550848
                    Iteration time: 0.15s
                      Time elapsed: 00:28:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1563/1 [0m                       

                       Computation: 668183 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 371.10
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7105
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 153649152
                    Iteration time: 0.15s
                      Time elapsed: 00:28:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1564/1 [0m                       

                       Computation: 659434 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 369.81
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7402
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 153747456
                    Iteration time: 0.15s
                      Time elapsed: 00:28:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1565/1 [0m                       

                       Computation: 701015 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 372.96
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2904
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 153845760
                    Iteration time: 0.14s
                      Time elapsed: 00:29:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1566/1 [0m                       

                       Computation: 704385 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 372.95
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0329
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 153944064
                    Iteration time: 0.14s
                      Time elapsed: 00:29:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1567/1 [0m                       

                       Computation: 719569 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 370.78
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7026
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 154042368
                    Iteration time: 0.14s
                      Time elapsed: 00:29:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1568/1 [0m                       

                       Computation: 749915 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 365.65
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6268
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 154140672
                    Iteration time: 0.13s
                      Time elapsed: 00:29:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1569/1 [0m                       

                       Computation: 689717 steps/s (collection: 0.049s, learning 0.094s)
                       Mean reward: 372.09
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8647
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 154238976
                    Iteration time: 0.14s
                      Time elapsed: 00:29:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1570/1 [0m                       

                       Computation: 629775 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 366.92
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6454
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 154337280
                    Iteration time: 0.16s
                      Time elapsed: 00:29:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1571/1 [0m                       

                       Computation: 635824 steps/s (collection: 0.054s, learning 0.101s)
                       Mean reward: 375.17
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6029
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 154435584
                    Iteration time: 0.15s
                      Time elapsed: 00:29:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1572/1 [0m                       

                       Computation: 605851 steps/s (collection: 0.044s, learning 0.118s)
                       Mean reward: 372.37
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0001
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 154533888
                    Iteration time: 0.16s
                      Time elapsed: 00:29:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1573/1 [0m                       

                       Computation: 606341 steps/s (collection: 0.045s, learning 0.117s)
                       Mean reward: 373.00
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0242
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 154632192
                    Iteration time: 0.16s
                      Time elapsed: 00:29:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1574/1 [0m                       

                       Computation: 627543 steps/s (collection: 0.044s, learning 0.113s)
                       Mean reward: 367.46
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1079
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 154730496
                    Iteration time: 0.16s
                      Time elapsed: 00:29:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1575/1 [0m                       

                       Computation: 608714 steps/s (collection: 0.045s, learning 0.116s)
                       Mean reward: 368.31
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4134
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 154828800
                    Iteration time: 0.16s
                      Time elapsed: 00:29:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1576/1 [0m                       

                       Computation: 739036 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 375.67
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4928
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 154927104
                    Iteration time: 0.13s
                      Time elapsed: 00:29:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1577/1 [0m                       

                       Computation: 659427 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 368.89
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2218
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 155025408
                    Iteration time: 0.15s
                      Time elapsed: 00:29:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1578/1 [0m                       

                       Computation: 623538 steps/s (collection: 0.043s, learning 0.115s)
                       Mean reward: 377.08
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.0665
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 155123712
                    Iteration time: 0.16s
                      Time elapsed: 00:29:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1579/1 [0m                       

                       Computation: 593446 steps/s (collection: 0.045s, learning 0.121s)
                       Mean reward: 374.00
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6561
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 155222016
                    Iteration time: 0.17s
                      Time elapsed: 00:29:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1580/1 [0m                       

                       Computation: 751924 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 371.39
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8956
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 155320320
                    Iteration time: 0.13s
                      Time elapsed: 00:29:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1581/1 [0m                       

                       Computation: 736114 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 367.13
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8799
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 155418624
                    Iteration time: 0.13s
                      Time elapsed: 00:29:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1582/1 [0m                       

                       Computation: 780032 steps/s (collection: 0.045s, learning 0.082s)
                       Mean reward: 373.61
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2980
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 155516928
                    Iteration time: 0.13s
                      Time elapsed: 00:29:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1583/1 [0m                       

                       Computation: 729291 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 374.68
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5555
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 155615232
                    Iteration time: 0.13s
                      Time elapsed: 00:29:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1584/1 [0m                       

                       Computation: 790228 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 373.01
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0247
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4348
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 155713536
                    Iteration time: 0.12s
                      Time elapsed: 00:29:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1585/1 [0m                       

                       Computation: 802397 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 372.89
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1767
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 155811840
                    Iteration time: 0.12s
                      Time elapsed: 00:29:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1586/1 [0m                       

                       Computation: 629537 steps/s (collection: 0.048s, learning 0.108s)
                       Mean reward: 372.53
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1460
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 155910144
                    Iteration time: 0.16s
                      Time elapsed: 00:29:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1587/1 [0m                       

                       Computation: 792753 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 370.21
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3763
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 156008448
                    Iteration time: 0.12s
                      Time elapsed: 00:29:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1588/1 [0m                       

                       Computation: 775390 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 364.12
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3609
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 156106752
                    Iteration time: 0.13s
                      Time elapsed: 00:29:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1589/1 [0m                       

                       Computation: 687341 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 374.77
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4639
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 156205056
                    Iteration time: 0.14s
                      Time elapsed: 00:29:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1590/1 [0m                       

                       Computation: 843618 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 374.18
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4385
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4325
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 156303360
                    Iteration time: 0.12s
                      Time elapsed: 00:29:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1591/1 [0m                       

                       Computation: 663118 steps/s (collection: 0.042s, learning 0.106s)
                       Mean reward: 374.59
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7665
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 156401664
                    Iteration time: 0.15s
                      Time elapsed: 00:29:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1592/1 [0m                       

                       Computation: 738307 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 371.46
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9001
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 156499968
                    Iteration time: 0.13s
                      Time elapsed: 00:29:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1593/1 [0m                       

                       Computation: 792848 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 371.72
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8360
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 156598272
                    Iteration time: 0.12s
                      Time elapsed: 00:29:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1594/1 [0m                       

                       Computation: 773870 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 368.21
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8962
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4283
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 156696576
                    Iteration time: 0.13s
                      Time elapsed: 00:29:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1595/1 [0m                       

                       Computation: 649562 steps/s (collection: 0.043s, learning 0.109s)
                       Mean reward: 373.80
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3231
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 156794880
                    Iteration time: 0.15s
                      Time elapsed: 00:29:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1596/1 [0m                       

                       Computation: 770891 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 372.61
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0281
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 156893184
                    Iteration time: 0.13s
                      Time elapsed: 00:29:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1597/1 [0m                       

                       Computation: 687018 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 368.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2035
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 156991488
                    Iteration time: 0.14s
                      Time elapsed: 00:29:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1598/1 [0m                       

                       Computation: 767838 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 372.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1818
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 157089792
                    Iteration time: 0.13s
                      Time elapsed: 00:29:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1599/1 [0m                       

                       Computation: 812136 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 367.16
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9199
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 157188096
                    Iteration time: 0.12s
                      Time elapsed: 00:29:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1600/1 [0m                       

                       Computation: 720401 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 368.13
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1626
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 157286400
                    Iteration time: 0.14s
                      Time elapsed: 00:29:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1601/1 [0m                       

                       Computation: 724164 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 370.42
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3365
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 157384704
                    Iteration time: 0.14s
                      Time elapsed: 00:29:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1602/1 [0m                       

                       Computation: 698104 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 372.71
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3424
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 157483008
                    Iteration time: 0.14s
                      Time elapsed: 00:29:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1603/1 [0m                       

                       Computation: 644126 steps/s (collection: 0.040s, learning 0.113s)
                       Mean reward: 367.16
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9716
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 157581312
                    Iteration time: 0.15s
                      Time elapsed: 00:29:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1604/1 [0m                       

                       Computation: 614169 steps/s (collection: 0.038s, learning 0.122s)
                       Mean reward: 372.24
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0139
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 157679616
                    Iteration time: 0.16s
                      Time elapsed: 00:29:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1605/1 [0m                       

                       Computation: 642675 steps/s (collection: 0.040s, learning 0.113s)
                       Mean reward: 370.47
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6044
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 157777920
                    Iteration time: 0.15s
                      Time elapsed: 00:29:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1606/1 [0m                       

                       Computation: 692227 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 376.84
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.9054
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 157876224
                    Iteration time: 0.14s
                      Time elapsed: 00:29:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1607/1 [0m                       

                       Computation: 850525 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 371.74
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6669
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 157974528
                    Iteration time: 0.12s
                      Time elapsed: 00:29:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1608/1 [0m                       

                       Computation: 821140 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 376.88
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8603
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 158072832
                    Iteration time: 0.12s
                      Time elapsed: 00:29:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1609/1 [0m                       

                       Computation: 791477 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 373.42
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4093
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 158171136
                    Iteration time: 0.12s
                      Time elapsed: 00:29:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1610/1 [0m                       

                       Computation: 849607 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 371.84
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8481
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 158269440
                    Iteration time: 0.12s
                      Time elapsed: 00:29:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1611/1 [0m                       

                       Computation: 865815 steps/s (collection: 0.040s, learning 0.074s)
                       Mean reward: 371.51
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9210
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 158367744
                    Iteration time: 0.11s
                      Time elapsed: 00:29:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1612/1 [0m                       

                       Computation: 860221 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 375.11
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7099
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 158466048
                    Iteration time: 0.11s
                      Time elapsed: 00:29:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1613/1 [0m                       

                       Computation: 836386 steps/s (collection: 0.043s, learning 0.075s)
                       Mean reward: 369.71
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5656
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 158564352
                    Iteration time: 0.12s
                      Time elapsed: 00:29:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1614/1 [0m                       

                       Computation: 885613 steps/s (collection: 0.037s, learning 0.074s)
                       Mean reward: 373.57
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3011
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 158662656
                    Iteration time: 0.11s
                      Time elapsed: 00:29:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1615/1 [0m                       

                       Computation: 805803 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 373.07
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0428
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 158760960
                    Iteration time: 0.12s
                      Time elapsed: 00:29:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1616/1 [0m                       

                       Computation: 706979 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 378.73
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.3209
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 158859264
                    Iteration time: 0.14s
                      Time elapsed: 00:29:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1617/1 [0m                       

                       Computation: 611680 steps/s (collection: 0.041s, learning 0.120s)
                       Mean reward: 372.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0686
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 158957568
                    Iteration time: 0.16s
                      Time elapsed: 00:29:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1618/1 [0m                       

                       Computation: 706635 steps/s (collection: 0.050s, learning 0.089s)
                       Mean reward: 366.71
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7717
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 159055872
                    Iteration time: 0.14s
                      Time elapsed: 00:29:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1619/1 [0m                       

                       Computation: 675610 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 374.50
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6730
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4359
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 159154176
                    Iteration time: 0.15s
                      Time elapsed: 00:30:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1620/1 [0m                       

                       Computation: 839817 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 374.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3993
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 159252480
                    Iteration time: 0.12s
                      Time elapsed: 00:30:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1621/1 [0m                       

                       Computation: 731234 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 375.71
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8689
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 159350784
                    Iteration time: 0.13s
                      Time elapsed: 00:30:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1622/1 [0m                       

                       Computation: 792717 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 372.56
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3048
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 159449088
                    Iteration time: 0.12s
                      Time elapsed: 00:30:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1623/1 [0m                       

                       Computation: 747453 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 372.08
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0225
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 159547392
                    Iteration time: 0.13s
                      Time elapsed: 00:30:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1624/1 [0m                       

                       Computation: 801349 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 376.10
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8585
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 159645696
                    Iteration time: 0.12s
                      Time elapsed: 00:30:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1625/1 [0m                       

                       Computation: 794143 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 372.15
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9542
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 159744000
                    Iteration time: 0.12s
                      Time elapsed: 00:30:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1626/1 [0m                       

                       Computation: 761353 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 372.43
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9749
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 159842304
                    Iteration time: 0.13s
                      Time elapsed: 00:30:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1627/1 [0m                       

                       Computation: 775273 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 369.00
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5593
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 159940608
                    Iteration time: 0.13s
                      Time elapsed: 00:30:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1628/1 [0m                       

                       Computation: 712008 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 372.56
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9740
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 160038912
                    Iteration time: 0.14s
                      Time elapsed: 00:30:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1629/1 [0m                       

                       Computation: 743964 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 372.25
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8639
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 160137216
                    Iteration time: 0.13s
                      Time elapsed: 00:30:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1630/1 [0m                       

                       Computation: 792170 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 379.15
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.5391
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 160235520
                    Iteration time: 0.12s
                      Time elapsed: 00:30:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1631/1 [0m                       

                       Computation: 739105 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 375.06
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6359
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 160333824
                    Iteration time: 0.13s
                      Time elapsed: 00:30:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1632/1 [0m                       

                       Computation: 727309 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 380.82
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.6303
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 160432128
                    Iteration time: 0.14s
                      Time elapsed: 00:30:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1633/1 [0m                       

                       Computation: 637817 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 374.96
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4258
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 160530432
                    Iteration time: 0.15s
                      Time elapsed: 00:30:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1634/1 [0m                       

                       Computation: 864274 steps/s (collection: 0.039s, learning 0.075s)
                       Mean reward: 373.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3272
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 160628736
                    Iteration time: 0.11s
                      Time elapsed: 00:30:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1635/1 [0m                       

                       Computation: 783123 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 372.17
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9547
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 160727040
                    Iteration time: 0.13s
                      Time elapsed: 00:30:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1636/1 [0m                       

                       Computation: 820697 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 373.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4077
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 160825344
                    Iteration time: 0.12s
                      Time elapsed: 00:30:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1637/1 [0m                       

                       Computation: 592114 steps/s (collection: 0.052s, learning 0.114s)
                       Mean reward: 374.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4608
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 160923648
                    Iteration time: 0.17s
                      Time elapsed: 00:30:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1638/1 [0m                       

                       Computation: 713439 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 369.40
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4712
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 161021952
                    Iteration time: 0.14s
                      Time elapsed: 00:30:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1639/1 [0m                       

                       Computation: 782080 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 373.47
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1134
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 161120256
                    Iteration time: 0.13s
                      Time elapsed: 00:30:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1640/1 [0m                       

                       Computation: 704660 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 370.30
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8513
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 161218560
                    Iteration time: 0.14s
                      Time elapsed: 00:30:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1641/1 [0m                       

                       Computation: 799860 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 375.72
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6782
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 161316864
                    Iteration time: 0.12s
                      Time elapsed: 00:30:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1642/1 [0m                       

                       Computation: 769407 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 372.08
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0923
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 161415168
                    Iteration time: 0.13s
                      Time elapsed: 00:30:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1643/1 [0m                       

                       Computation: 765827 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 373.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2524
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 161513472
                    Iteration time: 0.13s
                      Time elapsed: 00:30:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1644/1 [0m                       

                       Computation: 763035 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 367.77
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2391
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 161611776
                    Iteration time: 0.13s
                      Time elapsed: 00:30:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1645/1 [0m                       

                       Computation: 838708 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 372.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0694
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 161710080
                    Iteration time: 0.12s
                      Time elapsed: 00:30:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1646/1 [0m                       

                       Computation: 847391 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 375.09
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4668
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 161808384
                    Iteration time: 0.12s
                      Time elapsed: 00:30:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1647/1 [0m                       

                       Computation: 818888 steps/s (collection: 0.045s, learning 0.076s)
                       Mean reward: 374.77
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6997
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 161906688
                    Iteration time: 0.12s
                      Time elapsed: 00:30:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1648/1 [0m                       

                       Computation: 821359 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 372.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1919
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 162004992
                    Iteration time: 0.12s
                      Time elapsed: 00:30:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1649/1 [0m                       

                       Computation: 725351 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 372.78
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3468
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 162103296
                    Iteration time: 0.14s
                      Time elapsed: 00:30:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1650/1 [0m                       

                       Computation: 806189 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 373.74
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2600
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 162201600
                    Iteration time: 0.12s
                      Time elapsed: 00:30:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1651/1 [0m                       

                       Computation: 652846 steps/s (collection: 0.043s, learning 0.108s)
                       Mean reward: 378.66
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.3996
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 162299904
                    Iteration time: 0.15s
                      Time elapsed: 00:30:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1652/1 [0m                       

                       Computation: 736050 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 375.65
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7634
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 162398208
                    Iteration time: 0.13s
                      Time elapsed: 00:30:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1653/1 [0m                       

                       Computation: 751506 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 374.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5226
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 162496512
                    Iteration time: 0.13s
                      Time elapsed: 00:30:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1654/1 [0m                       

                       Computation: 826340 steps/s (collection: 0.045s, learning 0.074s)
                       Mean reward: 372.65
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1821
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4388
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 162594816
                    Iteration time: 0.12s
                      Time elapsed: 00:30:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1655/1 [0m                       

                       Computation: 781942 steps/s (collection: 0.044s, learning 0.082s)
                       Mean reward: 370.21
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7360
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 162693120
                    Iteration time: 0.13s
                      Time elapsed: 00:30:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1656/1 [0m                       

                       Computation: 666547 steps/s (collection: 0.050s, learning 0.098s)
                       Mean reward: 367.21
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1823
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 162791424
                    Iteration time: 0.15s
                      Time elapsed: 00:30:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1657/1 [0m                       

                       Computation: 687262 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 372.33
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9076
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 162889728
                    Iteration time: 0.14s
                      Time elapsed: 00:30:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1658/1 [0m                       

                       Computation: 717359 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 371.49
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8820
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4390
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 162988032
                    Iteration time: 0.14s
                      Time elapsed: 00:30:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1659/1 [0m                       

                       Computation: 680027 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 371.94
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8971
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 163086336
                    Iteration time: 0.14s
                      Time elapsed: 00:30:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1660/1 [0m                       

                       Computation: 631996 steps/s (collection: 0.042s, learning 0.113s)
                       Mean reward: 371.47
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8735
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 163184640
                    Iteration time: 0.16s
                      Time elapsed: 00:30:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1661/1 [0m                       

                       Computation: 661207 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 370.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6032
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 163282944
                    Iteration time: 0.15s
                      Time elapsed: 00:30:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1662/1 [0m                       

                       Computation: 747548 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 365.65
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6276
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 163381248
                    Iteration time: 0.13s
                      Time elapsed: 00:30:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1663/1 [0m                       

                       Computation: 829491 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 373.25
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1572
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 163479552
                    Iteration time: 0.12s
                      Time elapsed: 00:30:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1664/1 [0m                       

                       Computation: 597300 steps/s (collection: 0.053s, learning 0.112s)
                       Mean reward: 367.39
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8521
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 163577856
                    Iteration time: 0.16s
                      Time elapsed: 00:30:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1665/1 [0m                       

                       Computation: 621967 steps/s (collection: 0.050s, learning 0.108s)
                       Mean reward: 376.44
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.0167
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 163676160
                    Iteration time: 0.16s
                      Time elapsed: 00:30:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1666/1 [0m                       

                       Computation: 626022 steps/s (collection: 0.054s, learning 0.104s)
                       Mean reward: 368.21
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1738
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 163774464
                    Iteration time: 0.16s
                      Time elapsed: 00:30:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1667/1 [0m                       

                       Computation: 634063 steps/s (collection: 0.052s, learning 0.103s)
                       Mean reward: 365.73
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8711
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 163872768
                    Iteration time: 0.16s
                      Time elapsed: 00:30:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1668/1 [0m                       

                       Computation: 583143 steps/s (collection: 0.057s, learning 0.112s)
                       Mean reward: 373.19
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9500
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 163971072
                    Iteration time: 0.17s
                      Time elapsed: 00:30:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1669/1 [0m                       

                       Computation: 659698 steps/s (collection: 0.047s, learning 0.102s)
                       Mean reward: 365.50
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8141
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4374
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 164069376
                    Iteration time: 0.15s
                      Time elapsed: 00:30:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1670/1 [0m                       

                       Computation: 628485 steps/s (collection: 0.054s, learning 0.102s)
                       Mean reward: 372.09
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0969
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 164167680
                    Iteration time: 0.16s
                      Time elapsed: 00:30:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1671/1 [0m                       

                       Computation: 825991 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 368.43
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3301
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 164265984
                    Iteration time: 0.12s
                      Time elapsed: 00:30:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1672/1 [0m                       

                       Computation: 764740 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 373.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1132
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 164364288
                    Iteration time: 0.13s
                      Time elapsed: 00:31:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1673/1 [0m                       

                       Computation: 523976 steps/s (collection: 0.051s, learning 0.137s)
                       Mean reward: 372.05
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2713
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 164462592
                    Iteration time: 0.19s
                      Time elapsed: 00:31:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1674/1 [0m                       

                       Computation: 670816 steps/s (collection: 0.047s, learning 0.100s)
                       Mean reward: 369.75
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6368
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 164560896
                    Iteration time: 0.15s
                      Time elapsed: 00:31:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1675/1 [0m                       

                       Computation: 607260 steps/s (collection: 0.055s, learning 0.107s)
                       Mean reward: 371.50
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9339
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 164659200
                    Iteration time: 0.16s
                      Time elapsed: 00:31:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1676/1 [0m                       

                       Computation: 568020 steps/s (collection: 0.053s, learning 0.121s)
                       Mean reward: 373.03
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0946
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4359
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 164757504
                    Iteration time: 0.17s
                      Time elapsed: 00:31:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1677/1 [0m                       

                       Computation: 757011 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 372.04
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1853
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 164855808
                    Iteration time: 0.13s
                      Time elapsed: 00:31:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1678/1 [0m                       

                       Computation: 775763 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 371.38
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7232
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 164954112
                    Iteration time: 0.13s
                      Time elapsed: 00:31:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1679/1 [0m                       

                       Computation: 825897 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 366.28
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7243
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 165052416
                    Iteration time: 0.12s
                      Time elapsed: 00:31:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1680/1 [0m                       

                       Computation: 815669 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 371.83
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0378
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 165150720
                    Iteration time: 0.12s
                      Time elapsed: 00:31:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1681/1 [0m                       

                       Computation: 813246 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 371.89
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0050
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 165249024
                    Iteration time: 0.12s
                      Time elapsed: 00:31:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1682/1 [0m                       

                       Computation: 776184 steps/s (collection: 0.046s, learning 0.081s)
                       Mean reward: 370.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7774
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4402
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 165347328
                    Iteration time: 0.13s
                      Time elapsed: 00:31:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1683/1 [0m                       

                       Computation: 814398 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 370.27
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4311
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 165445632
                    Iteration time: 0.12s
                      Time elapsed: 00:31:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1684/1 [0m                       

                       Computation: 738830 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 365.56
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7233
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 165543936
                    Iteration time: 0.13s
                      Time elapsed: 00:31:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1685/1 [0m                       

                       Computation: 618172 steps/s (collection: 0.046s, learning 0.114s)
                       Mean reward: 374.99
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1065
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 165642240
                    Iteration time: 0.16s
                      Time elapsed: 00:31:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1686/1 [0m                       

                       Computation: 725385 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 372.88
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0714
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 165740544
                    Iteration time: 0.14s
                      Time elapsed: 00:31:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1687/1 [0m                       

                       Computation: 660917 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 375.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5486
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 165838848
                    Iteration time: 0.15s
                      Time elapsed: 00:31:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1688/1 [0m                       

                       Computation: 754189 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 372.99
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4401
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 165937152
                    Iteration time: 0.13s
                      Time elapsed: 00:31:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1689/1 [0m                       

                       Computation: 790062 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 371.42
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9999
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4377
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 166035456
                    Iteration time: 0.12s
                      Time elapsed: 00:31:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1690/1 [0m                       

                       Computation: 744193 steps/s (collection: 0.047s, learning 0.085s)
                       Mean reward: 370.65
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6992
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 166133760
                    Iteration time: 0.13s
                      Time elapsed: 00:31:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1691/1 [0m                       

                       Computation: 626069 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 371.32
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7316
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 166232064
                    Iteration time: 0.16s
                      Time elapsed: 00:31:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1692/1 [0m                       

                       Computation: 818984 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 374.16
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2913
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 166330368
                    Iteration time: 0.12s
                      Time elapsed: 00:31:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1693/1 [0m                       

                       Computation: 803797 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 369.90
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4894
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 166428672
                    Iteration time: 0.12s
                      Time elapsed: 00:31:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1694/1 [0m                       

                       Computation: 773908 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 370.57
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6611
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 166526976
                    Iteration time: 0.13s
                      Time elapsed: 00:31:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1695/1 [0m                       

                       Computation: 749532 steps/s (collection: 0.046s, learning 0.085s)
                       Mean reward: 371.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8142
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 166625280
                    Iteration time: 0.13s
                      Time elapsed: 00:31:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1696/1 [0m                       

                       Computation: 737714 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 371.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0186
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 166723584
                    Iteration time: 0.13s
                      Time elapsed: 00:31:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1697/1 [0m                       

                       Computation: 802371 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 370.49
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4946
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 166821888
                    Iteration time: 0.12s
                      Time elapsed: 00:31:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1698/1 [0m                       

                       Computation: 732199 steps/s (collection: 0.045s, learning 0.090s)
                       Mean reward: 374.62
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6299
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 166920192
                    Iteration time: 0.13s
                      Time elapsed: 00:31:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1699/1 [0m                       

                       Computation: 691595 steps/s (collection: 0.056s, learning 0.087s)
                       Mean reward: 372.22
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9860
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 167018496
                    Iteration time: 0.14s
                      Time elapsed: 00:31:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1700/1 [0m                       

                       Computation: 812397 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 366.57
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8949
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 167116800
                    Iteration time: 0.12s
                      Time elapsed: 00:31:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1701/1 [0m                       

                       Computation: 836525 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 372.43
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9744
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 167215104
                    Iteration time: 0.12s
                      Time elapsed: 00:31:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1702/1 [0m                       

                       Computation: 817582 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 374.91
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6639
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 167313408
                    Iteration time: 0.12s
                      Time elapsed: 00:31:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1703/1 [0m                       

                       Computation: 770955 steps/s (collection: 0.048s, learning 0.080s)
                       Mean reward: 371.48
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0494
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 167411712
                    Iteration time: 0.13s
                      Time elapsed: 00:31:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1704/1 [0m                       

                       Computation: 741811 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 379.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.6397
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 167510016
                    Iteration time: 0.13s
                      Time elapsed: 00:31:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1705/1 [0m                       

                       Computation: 721458 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 374.53
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3604
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 167608320
                    Iteration time: 0.14s
                      Time elapsed: 00:31:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1706/1 [0m                       

                       Computation: 725991 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 368.31
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3130
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 167706624
                    Iteration time: 0.14s
                      Time elapsed: 00:31:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1707/1 [0m                       

                       Computation: 732923 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 373.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2772
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 167804928
                    Iteration time: 0.13s
                      Time elapsed: 00:31:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1708/1 [0m                       

                       Computation: 718930 steps/s (collection: 0.050s, learning 0.087s)
                       Mean reward: 368.93
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4199
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 167903232
                    Iteration time: 0.14s
                      Time elapsed: 00:31:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1709/1 [0m                       

                       Computation: 651119 steps/s (collection: 0.055s, learning 0.096s)
                       Mean reward: 375.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4650
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 168001536
                    Iteration time: 0.15s
                      Time elapsed: 00:31:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1710/1 [0m                       

                       Computation: 665235 steps/s (collection: 0.039s, learning 0.109s)
                       Mean reward: 376.34
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7751
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 168099840
                    Iteration time: 0.15s
                      Time elapsed: 00:31:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1711/1 [0m                       

                       Computation: 668086 steps/s (collection: 0.041s, learning 0.106s)
                       Mean reward: 367.87
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1032
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 168198144
                    Iteration time: 0.15s
                      Time elapsed: 00:31:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1712/1 [0m                       

                       Computation: 645479 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 369.26
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3529
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 168296448
                    Iteration time: 0.15s
                      Time elapsed: 00:31:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1713/1 [0m                       

                       Computation: 630089 steps/s (collection: 0.050s, learning 0.106s)
                       Mean reward: 376.77
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7439
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 168394752
                    Iteration time: 0.16s
                      Time elapsed: 00:31:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1714/1 [0m                       

                       Computation: 668866 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 370.77
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8533
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 168493056
                    Iteration time: 0.15s
                      Time elapsed: 00:31:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1715/1 [0m                       

                       Computation: 732956 steps/s (collection: 0.045s, learning 0.090s)
                       Mean reward: 374.84
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5350
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 168591360
                    Iteration time: 0.13s
                      Time elapsed: 00:31:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1716/1 [0m                       

                       Computation: 666398 steps/s (collection: 0.046s, learning 0.101s)
                       Mean reward: 371.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1609
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 168689664
                    Iteration time: 0.15s
                      Time elapsed: 00:31:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1717/1 [0m                       

                       Computation: 744727 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 374.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6514
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 168787968
                    Iteration time: 0.13s
                      Time elapsed: 00:31:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1718/1 [0m                       

                       Computation: 815596 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 369.53
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5479
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 168886272
                    Iteration time: 0.12s
                      Time elapsed: 00:31:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1719/1 [0m                       

                       Computation: 730740 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 366.12
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8373
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 168984576
                    Iteration time: 0.13s
                      Time elapsed: 00:31:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1720/1 [0m                       

                       Computation: 661876 steps/s (collection: 0.058s, learning 0.090s)
                       Mean reward: 376.27
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7690
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 169082880
                    Iteration time: 0.15s
                      Time elapsed: 00:31:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1721/1 [0m                       

                       Computation: 821760 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 370.84
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6321
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 169181184
                    Iteration time: 0.12s
                      Time elapsed: 00:31:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1722/1 [0m                       

                       Computation: 770906 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 372.29
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8465
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4325
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 169279488
                    Iteration time: 0.13s
                      Time elapsed: 00:31:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1723/1 [0m                       

                       Computation: 784249 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 369.33
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4833
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 169377792
                    Iteration time: 0.13s
                      Time elapsed: 00:31:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1724/1 [0m                       

                       Computation: 793498 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 369.63
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3666
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 169476096
                    Iteration time: 0.12s
                      Time elapsed: 00:32:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1725/1 [0m                       

                       Computation: 806391 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 373.48
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3667
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 169574400
                    Iteration time: 0.12s
                      Time elapsed: 00:32:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1726/1 [0m                       

                       Computation: 745707 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 367.75
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1010
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 169672704
                    Iteration time: 0.13s
                      Time elapsed: 00:32:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1727/1 [0m                       

                       Computation: 729596 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 370.02
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7403
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 169771008
                    Iteration time: 0.13s
                      Time elapsed: 00:32:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1728/1 [0m                       

                       Computation: 697147 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 371.23
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9419
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 169869312
                    Iteration time: 0.14s
                      Time elapsed: 00:32:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1729/1 [0m                       

                       Computation: 780063 steps/s (collection: 0.045s, learning 0.081s)
                       Mean reward: 369.70
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7634
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 169967616
                    Iteration time: 0.13s
                      Time elapsed: 00:32:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1730/1 [0m                       

                       Computation: 749590 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 374.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5493
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 170065920
                    Iteration time: 0.13s
                      Time elapsed: 00:32:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1731/1 [0m                       

                       Computation: 749613 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 364.95
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6356
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 170164224
                    Iteration time: 0.13s
                      Time elapsed: 00:32:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1732/1 [0m                       

                       Computation: 842811 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 371.02
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6894
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4347
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 170262528
                    Iteration time: 0.12s
                      Time elapsed: 00:32:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1733/1 [0m                       

                       Computation: 852614 steps/s (collection: 0.041s, learning 0.074s)
                       Mean reward: 372.86
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0615
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4359
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 170360832
                    Iteration time: 0.12s
                      Time elapsed: 00:32:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1734/1 [0m                       

                       Computation: 849848 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 369.94
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4888
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 170459136
                    Iteration time: 0.12s
                      Time elapsed: 00:32:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1735/1 [0m                       

                       Computation: 775381 steps/s (collection: 0.045s, learning 0.082s)
                       Mean reward: 370.74
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6796
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 170557440
                    Iteration time: 0.13s
                      Time elapsed: 00:32:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1736/1 [0m                       

                       Computation: 667892 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 365.23
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7724
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 170655744
                    Iteration time: 0.15s
                      Time elapsed: 00:32:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1737/1 [0m                       

                       Computation: 721464 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 368.06
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0454
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4347
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 170754048
                    Iteration time: 0.14s
                      Time elapsed: 00:32:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1738/1 [0m                       

                       Computation: 728646 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 368.03
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2324
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 170852352
                    Iteration time: 0.13s
                      Time elapsed: 00:32:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1739/1 [0m                       

                       Computation: 616947 steps/s (collection: 0.041s, learning 0.118s)
                       Mean reward: 372.90
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1355
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 170950656
                    Iteration time: 0.16s
                      Time elapsed: 00:32:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1740/1 [0m                       

                       Computation: 699353 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 366.66
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2031
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 171048960
                    Iteration time: 0.14s
                      Time elapsed: 00:32:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1741/1 [0m                       

                       Computation: 680174 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 372.32
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7724
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 171147264
                    Iteration time: 0.14s
                      Time elapsed: 00:32:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1742/1 [0m                       

                       Computation: 712164 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 365.71
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7570
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 171245568
                    Iteration time: 0.14s
                      Time elapsed: 00:32:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1743/1 [0m                       

                       Computation: 806737 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 372.21
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1684
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 171343872
                    Iteration time: 0.12s
                      Time elapsed: 00:32:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1744/1 [0m                       

                       Computation: 632646 steps/s (collection: 0.050s, learning 0.106s)
                       Mean reward: 373.50
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2646
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 171442176
                    Iteration time: 0.16s
                      Time elapsed: 00:32:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1745/1 [0m                       

                       Computation: 617202 steps/s (collection: 0.050s, learning 0.110s)
                       Mean reward: 371.41
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8240
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 171540480
                    Iteration time: 0.16s
                      Time elapsed: 00:32:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1746/1 [0m                       

                       Computation: 638171 steps/s (collection: 0.050s, learning 0.105s)
                       Mean reward: 368.58
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1869
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 171638784
                    Iteration time: 0.15s
                      Time elapsed: 00:32:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1747/1 [0m                       

                       Computation: 673142 steps/s (collection: 0.050s, learning 0.096s)
                       Mean reward: 371.48
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7834
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 171737088
                    Iteration time: 0.15s
                      Time elapsed: 00:32:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1748/1 [0m                       

                       Computation: 599055 steps/s (collection: 0.050s, learning 0.115s)
                       Mean reward: 369.12
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2289
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 171835392
                    Iteration time: 0.16s
                      Time elapsed: 00:32:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1749/1 [0m                       

                       Computation: 653064 steps/s (collection: 0.053s, learning 0.098s)
                       Mean reward: 369.74
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5786
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 171933696
                    Iteration time: 0.15s
                      Time elapsed: 00:32:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1750/1 [0m                       

                       Computation: 634098 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 370.60
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0159
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 172032000
                    Iteration time: 0.16s
                      Time elapsed: 00:32:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1751/1 [0m                       

                       Computation: 572914 steps/s (collection: 0.054s, learning 0.118s)
                       Mean reward: 374.15
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4991
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 172130304
                    Iteration time: 0.17s
                      Time elapsed: 00:32:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1752/1 [0m                       

                       Computation: 610478 steps/s (collection: 0.050s, learning 0.111s)
                       Mean reward: 371.69
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7426
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 172228608
                    Iteration time: 0.16s
                      Time elapsed: 00:32:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1753/1 [0m                       

                       Computation: 655107 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 367.28
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2299
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 172326912
                    Iteration time: 0.15s
                      Time elapsed: 00:32:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1754/1 [0m                       

                       Computation: 623568 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 369.54
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3865
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 172425216
                    Iteration time: 0.16s
                      Time elapsed: 00:32:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1755/1 [0m                       

                       Computation: 655183 steps/s (collection: 0.048s, learning 0.102s)
                       Mean reward: 372.92
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0705
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 172523520
                    Iteration time: 0.15s
                      Time elapsed: 00:32:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1756/1 [0m                       

                       Computation: 604940 steps/s (collection: 0.050s, learning 0.113s)
                       Mean reward: 371.39
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8952
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 172621824
                    Iteration time: 0.16s
                      Time elapsed: 00:32:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1757/1 [0m                       

                       Computation: 625389 steps/s (collection: 0.051s, learning 0.107s)
                       Mean reward: 370.60
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8648
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 172720128
                    Iteration time: 0.16s
                      Time elapsed: 00:32:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1758/1 [0m                       

                       Computation: 819778 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 367.55
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9813
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 172818432
                    Iteration time: 0.12s
                      Time elapsed: 00:32:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1759/1 [0m                       

                       Computation: 798426 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 370.01
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6556
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 172916736
                    Iteration time: 0.12s
                      Time elapsed: 00:32:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1760/1 [0m                       

                       Computation: 761190 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 371.43
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6225
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 173015040
                    Iteration time: 0.13s
                      Time elapsed: 00:32:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1761/1 [0m                       

                       Computation: 836518 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 365.73
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7494
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 173113344
                    Iteration time: 0.12s
                      Time elapsed: 00:32:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1762/1 [0m                       

                       Computation: 779740 steps/s (collection: 0.046s, learning 0.081s)
                       Mean reward: 365.88
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5985
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 173211648
                    Iteration time: 0.13s
                      Time elapsed: 00:32:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1763/1 [0m                       

                       Computation: 710513 steps/s (collection: 0.048s, learning 0.090s)
                       Mean reward: 369.59
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3492
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 173309952
                    Iteration time: 0.14s
                      Time elapsed: 00:32:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1764/1 [0m                       

                       Computation: 705164 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 368.82
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4235
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4359
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 173408256
                    Iteration time: 0.14s
                      Time elapsed: 00:32:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1765/1 [0m                       

                       Computation: 651316 steps/s (collection: 0.048s, learning 0.103s)
                       Mean reward: 367.33
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9399
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 173506560
                    Iteration time: 0.15s
                      Time elapsed: 00:32:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1766/1 [0m                       

                       Computation: 745679 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 370.20
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5453
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 173604864
                    Iteration time: 0.13s
                      Time elapsed: 00:32:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1767/1 [0m                       

                       Computation: 637257 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 372.53
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0654
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 173703168
                    Iteration time: 0.15s
                      Time elapsed: 00:32:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1768/1 [0m                       

                       Computation: 646583 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 373.41
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2320
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 173801472
                    Iteration time: 0.15s
                      Time elapsed: 00:32:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1769/1 [0m                       

                       Computation: 675868 steps/s (collection: 0.046s, learning 0.099s)
                       Mean reward: 369.21
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4862
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 173899776
                    Iteration time: 0.15s
                      Time elapsed: 00:32:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1770/1 [0m                       

                       Computation: 677774 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 370.14
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6309
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 173998080
                    Iteration time: 0.15s
                      Time elapsed: 00:32:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1771/1 [0m                       

                       Computation: 705074 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 369.18
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3174
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 174096384
                    Iteration time: 0.14s
                      Time elapsed: 00:32:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1772/1 [0m                       

                       Computation: 730347 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 369.30
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4350
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 174194688
                    Iteration time: 0.13s
                      Time elapsed: 00:32:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1773/1 [0m                       

                       Computation: 612334 steps/s (collection: 0.052s, learning 0.109s)
                       Mean reward: 368.66
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4096
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 174292992
                    Iteration time: 0.16s
                      Time elapsed: 00:32:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1774/1 [0m                       

                       Computation: 644430 steps/s (collection: 0.050s, learning 0.103s)
                       Mean reward: 372.26
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6461
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 174391296
                    Iteration time: 0.15s
                      Time elapsed: 00:32:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1775/1 [0m                       

                       Computation: 510411 steps/s (collection: 0.054s, learning 0.139s)
                       Mean reward: 366.34
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6756
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 174489600
                    Iteration time: 0.19s
                      Time elapsed: 00:33:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1776/1 [0m                       

                       Computation: 659668 steps/s (collection: 0.052s, learning 0.098s)
                       Mean reward: 369.38
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5098
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 174587904
                    Iteration time: 0.15s
                      Time elapsed: 00:33:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1777/1 [0m                       

                       Computation: 601147 steps/s (collection: 0.055s, learning 0.109s)
                       Mean reward: 365.17
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5769
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 174686208
                    Iteration time: 0.16s
                      Time elapsed: 00:33:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1778/1 [0m                       

                       Computation: 550499 steps/s (collection: 0.052s, learning 0.127s)
                       Mean reward: 368.35
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1011
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 174784512
                    Iteration time: 0.18s
                      Time elapsed: 00:33:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1779/1 [0m                       

                       Computation: 650870 steps/s (collection: 0.050s, learning 0.101s)
                       Mean reward: 374.36
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4998
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 174882816
                    Iteration time: 0.15s
                      Time elapsed: 00:33:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1780/1 [0m                       

                       Computation: 552561 steps/s (collection: 0.050s, learning 0.128s)
                       Mean reward: 371.01
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8586
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4377
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 174981120
                    Iteration time: 0.18s
                      Time elapsed: 00:33:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1781/1 [0m                       

                       Computation: 569900 steps/s (collection: 0.055s, learning 0.117s)
                       Mean reward: 367.67
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3093
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 175079424
                    Iteration time: 0.17s
                      Time elapsed: 00:33:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1782/1 [0m                       

                       Computation: 655236 steps/s (collection: 0.050s, learning 0.101s)
                       Mean reward: 366.69
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0873
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 175177728
                    Iteration time: 0.15s
                      Time elapsed: 00:33:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1783/1 [0m                       

                       Computation: 627992 steps/s (collection: 0.056s, learning 0.101s)
                       Mean reward: 371.42
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8761
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 175276032
                    Iteration time: 0.16s
                      Time elapsed: 00:33:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1784/1 [0m                       

                       Computation: 627453 steps/s (collection: 0.049s, learning 0.108s)
                       Mean reward: 372.45
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1584
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 175374336
                    Iteration time: 0.16s
                      Time elapsed: 00:33:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1785/1 [0m                       

                       Computation: 631768 steps/s (collection: 0.051s, learning 0.105s)
                       Mean reward: 376.89
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8790
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 175472640
                    Iteration time: 0.16s
                      Time elapsed: 00:33:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1786/1 [0m                       

                       Computation: 789525 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 370.64
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5393
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 175570944
                    Iteration time: 0.12s
                      Time elapsed: 00:33:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1787/1 [0m                       

                       Computation: 789640 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 369.85
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5043
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4374
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 175669248
                    Iteration time: 0.12s
                      Time elapsed: 00:33:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1788/1 [0m                       

                       Computation: 774920 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 372.05
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7911
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 175767552
                    Iteration time: 0.13s
                      Time elapsed: 00:33:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1789/1 [0m                       

                       Computation: 626275 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 373.20
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3470
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 175865856
                    Iteration time: 0.16s
                      Time elapsed: 00:33:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1790/1 [0m                       

                       Computation: 658328 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 369.29
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4105
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 175964160
                    Iteration time: 0.15s
                      Time elapsed: 00:33:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1791/1 [0m                       

                       Computation: 605606 steps/s (collection: 0.046s, learning 0.117s)
                       Mean reward: 368.60
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1323
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4388
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 176062464
                    Iteration time: 0.16s
                      Time elapsed: 00:33:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1792/1 [0m                       

                       Computation: 673214 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 369.31
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4404
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 176160768
                    Iteration time: 0.15s
                      Time elapsed: 00:33:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1793/1 [0m                       

                       Computation: 695280 steps/s (collection: 0.050s, learning 0.092s)
                       Mean reward: 365.56
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7809
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 176259072
                    Iteration time: 0.14s
                      Time elapsed: 00:33:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1794/1 [0m                       

                       Computation: 827392 steps/s (collection: 0.042s, learning 0.077s)
                       Mean reward: 369.77
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4181
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 176357376
                    Iteration time: 0.12s
                      Time elapsed: 00:33:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1795/1 [0m                       

                       Computation: 799795 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 374.65
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5996
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4377
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 176455680
                    Iteration time: 0.12s
                      Time elapsed: 00:33:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1796/1 [0m                       

                       Computation: 811433 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 369.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4835
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 176553984
                    Iteration time: 0.12s
                      Time elapsed: 00:33:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1797/1 [0m                       

                       Computation: 799661 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 366.00
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0178
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 176652288
                    Iteration time: 0.12s
                      Time elapsed: 00:33:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1798/1 [0m                       

                       Computation: 799117 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 365.95
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9559
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 176750592
                    Iteration time: 0.12s
                      Time elapsed: 00:33:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1799/1 [0m                       

                       Computation: 638485 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 365.42
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5874
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 176848896
                    Iteration time: 0.15s
                      Time elapsed: 00:33:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1800/1 [0m                       

                       Computation: 581510 steps/s (collection: 0.050s, learning 0.120s)
                       Mean reward: 366.14
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5151
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 176947200
                    Iteration time: 0.17s
                      Time elapsed: 00:33:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1801/1 [0m                       

                       Computation: 600004 steps/s (collection: 0.053s, learning 0.110s)
                       Mean reward: 370.79
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8266
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 177045504
                    Iteration time: 0.16s
                      Time elapsed: 00:33:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1802/1 [0m                       

                       Computation: 609340 steps/s (collection: 0.046s, learning 0.115s)
                       Mean reward: 370.47
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4905
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 177143808
                    Iteration time: 0.16s
                      Time elapsed: 00:33:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1803/1 [0m                       

                       Computation: 584998 steps/s (collection: 0.048s, learning 0.120s)
                       Mean reward: 369.86
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3943
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 177242112
                    Iteration time: 0.17s
                      Time elapsed: 00:33:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1804/1 [0m                       

                       Computation: 606698 steps/s (collection: 0.051s, learning 0.111s)
                       Mean reward: 368.44
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9677
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 177340416
                    Iteration time: 0.16s
                      Time elapsed: 00:33:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1805/1 [0m                       

                       Computation: 544036 steps/s (collection: 0.053s, learning 0.128s)
                       Mean reward: 369.81
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5671
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 177438720
                    Iteration time: 0.18s
                      Time elapsed: 00:33:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1806/1 [0m                       

                       Computation: 602926 steps/s (collection: 0.052s, learning 0.112s)
                       Mean reward: 368.42
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4909
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 177537024
                    Iteration time: 0.16s
                      Time elapsed: 00:33:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1807/1 [0m                       

                       Computation: 642332 steps/s (collection: 0.047s, learning 0.106s)
                       Mean reward: 372.01
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9587
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 177635328
                    Iteration time: 0.15s
                      Time elapsed: 00:33:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1808/1 [0m                       

                       Computation: 544631 steps/s (collection: 0.062s, learning 0.119s)
                       Mean reward: 376.01
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8243
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 177733632
                    Iteration time: 0.18s
                      Time elapsed: 00:33:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1809/1 [0m                       

                       Computation: 601845 steps/s (collection: 0.053s, learning 0.111s)
                       Mean reward: 369.52
               Mean episode length: 246.99
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3722
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 177831936
                    Iteration time: 0.16s
                      Time elapsed: 00:33:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1810/1 [0m                       

                       Computation: 632010 steps/s (collection: 0.044s, learning 0.112s)
                       Mean reward: 372.59
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8408
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4348
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 177930240
                    Iteration time: 0.16s
                      Time elapsed: 00:33:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1811/1 [0m                       

                       Computation: 667059 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 372.23
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8725
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 178028544
                    Iteration time: 0.15s
                      Time elapsed: 00:33:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1812/1 [0m                       

                       Computation: 791159 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 375.07
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5795
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 178126848
                    Iteration time: 0.12s
                      Time elapsed: 00:33:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1813/1 [0m                       

                       Computation: 737431 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 373.29
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1072
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 178225152
                    Iteration time: 0.13s
                      Time elapsed: 00:33:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1814/1 [0m                       

                       Computation: 728080 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 373.47
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0070
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 178323456
                    Iteration time: 0.14s
                      Time elapsed: 00:33:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1815/1 [0m                       

                       Computation: 694571 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 372.63
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1671
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 178421760
                    Iteration time: 0.14s
                      Time elapsed: 00:33:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1816/1 [0m                       

                       Computation: 574669 steps/s (collection: 0.053s, learning 0.118s)
                       Mean reward: 373.85
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2982
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 178520064
                    Iteration time: 0.17s
                      Time elapsed: 00:33:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1817/1 [0m                       

                       Computation: 584744 steps/s (collection: 0.049s, learning 0.120s)
                       Mean reward: 377.84
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.1546
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4420
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 178618368
                    Iteration time: 0.17s
                      Time elapsed: 00:33:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1818/1 [0m                       

                       Computation: 601003 steps/s (collection: 0.047s, learning 0.117s)
                       Mean reward: 369.46
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3885
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 178716672
                    Iteration time: 0.16s
                      Time elapsed: 00:33:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1819/1 [0m                       

                       Computation: 540262 steps/s (collection: 0.050s, learning 0.132s)
                       Mean reward: 367.76
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1515
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 178814976
                    Iteration time: 0.18s
                      Time elapsed: 00:33:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1820/1 [0m                       

                       Computation: 553663 steps/s (collection: 0.050s, learning 0.128s)
                       Mean reward: 375.77
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6135
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4421
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 178913280
                    Iteration time: 0.18s
                      Time elapsed: 00:33:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1821/1 [0m                       

                       Computation: 590327 steps/s (collection: 0.056s, learning 0.111s)
                       Mean reward: 368.90
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1066
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 179011584
                    Iteration time: 0.17s
                      Time elapsed: 00:33:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1822/1 [0m                       

                       Computation: 590183 steps/s (collection: 0.051s, learning 0.116s)
                       Mean reward: 372.92
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0283
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4374
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 179109888
                    Iteration time: 0.17s
                      Time elapsed: 00:34:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1823/1 [0m                       

                       Computation: 608615 steps/s (collection: 0.050s, learning 0.112s)
                       Mean reward: 369.49
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4096
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 179208192
                    Iteration time: 0.16s
                      Time elapsed: 00:34:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1824/1 [0m                       

                       Computation: 653104 steps/s (collection: 0.049s, learning 0.102s)
                       Mean reward: 369.63
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2326
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4390
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 179306496
                    Iteration time: 0.15s
                      Time elapsed: 00:34:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1825/1 [0m                       

                       Computation: 609595 steps/s (collection: 0.052s, learning 0.110s)
                       Mean reward: 369.26
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5881
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 179404800
                    Iteration time: 0.16s
                      Time elapsed: 00:34:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1826/1 [0m                       

                       Computation: 618004 steps/s (collection: 0.059s, learning 0.100s)
                       Mean reward: 368.23
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3566
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 179503104
                    Iteration time: 0.16s
                      Time elapsed: 00:34:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1827/1 [0m                       

                       Computation: 686115 steps/s (collection: 0.052s, learning 0.092s)
                       Mean reward: 368.60
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2623
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 179601408
                    Iteration time: 0.14s
                      Time elapsed: 00:34:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1828/1 [0m                       

                       Computation: 792347 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 369.19
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5343
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 179699712
                    Iteration time: 0.12s
                      Time elapsed: 00:34:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1829/1 [0m                       

                       Computation: 727549 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 371.65
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9399
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 179798016
                    Iteration time: 0.14s
                      Time elapsed: 00:34:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1830/1 [0m                       

                       Computation: 715860 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 370.58
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8676
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4348
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 179896320
                    Iteration time: 0.14s
                      Time elapsed: 00:34:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1831/1 [0m                       

                       Computation: 629004 steps/s (collection: 0.044s, learning 0.112s)
                       Mean reward: 370.58
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7039
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 179994624
                    Iteration time: 0.16s
                      Time elapsed: 00:34:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1832/1 [0m                       

                       Computation: 631581 steps/s (collection: 0.042s, learning 0.114s)
                       Mean reward: 367.08
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9577
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 180092928
                    Iteration time: 0.16s
                      Time elapsed: 00:34:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1833/1 [0m                       

                       Computation: 728056 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 372.45
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2524
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 180191232
                    Iteration time: 0.14s
                      Time elapsed: 00:34:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1834/1 [0m                       

                       Computation: 756054 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 374.03
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5596
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 180289536
                    Iteration time: 0.13s
                      Time elapsed: 00:34:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1835/1 [0m                       

                       Computation: 666120 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 372.22
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2165
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4417
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 180387840
                    Iteration time: 0.15s
                      Time elapsed: 00:34:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1836/1 [0m                       

                       Computation: 810798 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 369.08
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3753
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 180486144
                    Iteration time: 0.12s
                      Time elapsed: 00:34:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1837/1 [0m                       

                       Computation: 722625 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 373.42
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2565
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4390
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 180584448
                    Iteration time: 0.14s
                      Time elapsed: 00:34:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1838/1 [0m                       

                       Computation: 793820 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 373.94
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2160
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 180682752
                    Iteration time: 0.12s
                      Time elapsed: 00:34:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1839/1 [0m                       

                       Computation: 808975 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 375.64
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6896
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4417
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 180781056
                    Iteration time: 0.12s
                      Time elapsed: 00:34:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1840/1 [0m                       

                       Computation: 661303 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 372.08
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9628
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 180879360
                    Iteration time: 0.15s
                      Time elapsed: 00:34:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1841/1 [0m                       

                       Computation: 721921 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 369.11
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4360
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 180977664
                    Iteration time: 0.14s
                      Time elapsed: 00:34:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1842/1 [0m                       

                       Computation: 547527 steps/s (collection: 0.043s, learning 0.137s)
                       Mean reward: 372.44
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1098
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4441
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 181075968
                    Iteration time: 0.18s
                      Time elapsed: 00:34:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1843/1 [0m                       

                       Computation: 763961 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 373.48
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1965
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4421
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 181174272
                    Iteration time: 0.13s
                      Time elapsed: 00:34:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1844/1 [0m                       

                       Computation: 800602 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 374.05
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3451
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 181272576
                    Iteration time: 0.12s
                      Time elapsed: 00:34:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1845/1 [0m                       

                       Computation: 759573 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 371.83
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6524
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 181370880
                    Iteration time: 0.13s
                      Time elapsed: 00:34:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1846/1 [0m                       

                       Computation: 832998 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 370.31
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5651
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 181469184
                    Iteration time: 0.12s
                      Time elapsed: 00:34:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1847/1 [0m                       

                       Computation: 782292 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 373.75
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2012
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4421
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 181567488
                    Iteration time: 0.13s
                      Time elapsed: 00:34:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1848/1 [0m                       

                       Computation: 811941 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 375.89
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8750
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 181665792
                    Iteration time: 0.12s
                      Time elapsed: 00:34:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1849/1 [0m                       

                       Computation: 642236 steps/s (collection: 0.044s, learning 0.109s)
                       Mean reward: 371.23
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9468
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 181764096
                    Iteration time: 0.15s
                      Time elapsed: 00:34:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1850/1 [0m                       

                       Computation: 700157 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 373.45
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3355
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 181862400
                    Iteration time: 0.14s
                      Time elapsed: 00:34:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1851/1 [0m                       

                       Computation: 774858 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 371.53
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9582
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4410
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 181960704
                    Iteration time: 0.13s
                      Time elapsed: 00:34:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1852/1 [0m                       

                       Computation: 666221 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 376.00
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.9024
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4444
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 182059008
                    Iteration time: 0.15s
                      Time elapsed: 00:34:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1853/1 [0m                       

                       Computation: 664033 steps/s (collection: 0.052s, learning 0.096s)
                       Mean reward: 376.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6796
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 182157312
                    Iteration time: 0.15s
                      Time elapsed: 00:34:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1854/1 [0m                       

                       Computation: 808573 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 371.74
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1370
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4424
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 182255616
                    Iteration time: 0.12s
                      Time elapsed: 00:34:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1855/1 [0m                       

                       Computation: 720489 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 372.98
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1373
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 182353920
                    Iteration time: 0.14s
                      Time elapsed: 00:34:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1856/1 [0m                       

                       Computation: 751085 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 367.77
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2531
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4439
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 182452224
                    Iteration time: 0.13s
                      Time elapsed: 00:34:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1857/1 [0m                       

                       Computation: 733002 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 370.75
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.4309
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 182550528
                    Iteration time: 0.13s
                      Time elapsed: 00:34:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1858/1 [0m                       

                       Computation: 734162 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 371.23
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9187
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 182648832
                    Iteration time: 0.13s
                      Time elapsed: 00:34:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1859/1 [0m                       

                       Computation: 739040 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 376.85
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6536
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 182747136
                    Iteration time: 0.13s
                      Time elapsed: 00:34:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1860/1 [0m                       

                       Computation: 760669 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 372.94
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1879
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4439
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 182845440
                    Iteration time: 0.13s
                      Time elapsed: 00:34:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1861/1 [0m                       

                       Computation: 782119 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 367.24
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9390
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4417
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 182943744
                    Iteration time: 0.13s
                      Time elapsed: 00:34:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1862/1 [0m                       

                       Computation: 808992 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 375.82
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7679
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 183042048
                    Iteration time: 0.12s
                      Time elapsed: 00:34:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1863/1 [0m                       

                       Computation: 760636 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 369.77
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5108
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4429
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 183140352
                    Iteration time: 0.13s
                      Time elapsed: 00:34:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1864/1 [0m                       

                       Computation: 668489 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 368.51
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.5701
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 183238656
                    Iteration time: 0.15s
                      Time elapsed: 00:34:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1865/1 [0m                       

                       Computation: 648295 steps/s (collection: 0.039s, learning 0.113s)
                       Mean reward: 371.05
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.6981
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 183336960
                    Iteration time: 0.15s
                      Time elapsed: 00:34:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1866/1 [0m                       

                       Computation: 652449 steps/s (collection: 0.045s, learning 0.106s)
                       Mean reward: 369.06
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.3433
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 183435264
                    Iteration time: 0.15s
                      Time elapsed: 00:34:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1867/1 [0m                       

                       Computation: 646104 steps/s (collection: 0.039s, learning 0.113s)
                       Mean reward: 371.36
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7514
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4424
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 183533568
                    Iteration time: 0.15s
                      Time elapsed: 00:34:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1868/1 [0m                       

                       Computation: 726730 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 370.12
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5017
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4436
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 183631872
                    Iteration time: 0.14s
                      Time elapsed: 00:34:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1869/1 [0m                       

                       Computation: 680051 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 372.93
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.0384
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 183730176
                    Iteration time: 0.14s
                      Time elapsed: 00:34:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1870/1 [0m                       

                       Computation: 675354 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 371.71
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.8683
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 183828480
                    Iteration time: 0.15s
                      Time elapsed: 00:34:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1871/1 [0m                       

                       Computation: 664071 steps/s (collection: 0.042s, learning 0.106s)
                       Mean reward: 371.59
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9734
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 183926784
                    Iteration time: 0.15s
                      Time elapsed: 00:34:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1872/1 [0m                       

                       Computation: 706675 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 369.64
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3423
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 184025088
                    Iteration time: 0.14s
                      Time elapsed: 00:34:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1873/1 [0m                       

                       Computation: 680093 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 377.19
               Mean episode length: 246.98
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 75.0036
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 184123392
                    Iteration time: 0.14s
                      Time elapsed: 00:34:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1874/1 [0m                       

                       Computation: 719608 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 373.29
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2397
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 184221696
                    Iteration time: 0.14s
                      Time elapsed: 00:34:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1875/1 [0m                       

                       Computation: 711683 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 365.80
               Mean episode length: 247.34
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 72.8653
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 184320000
                    Iteration time: 0.14s
                      Time elapsed: 00:35:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1876/1 [0m                       

                       Computation: 652584 steps/s (collection: 0.040s, learning 0.111s)
                       Mean reward: 371.20
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6983
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4390
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 184418304
                    Iteration time: 0.15s
                      Time elapsed: 00:35:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1877/1 [0m                       

                       Computation: 657322 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 369.52
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4976
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 184516608
                    Iteration time: 0.15s
                      Time elapsed: 00:35:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1878/1 [0m                       

                       Computation: 659690 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 368.21
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3148
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 184614912
                    Iteration time: 0.15s
                      Time elapsed: 00:35:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1879/1 [0m                       

                       Computation: 666235 steps/s (collection: 0.038s, learning 0.110s)
                       Mean reward: 364.89
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 72.4627
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 184713216
                    Iteration time: 0.15s
                      Time elapsed: 00:35:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1880/1 [0m                       

                       Computation: 663932 steps/s (collection: 0.039s, learning 0.110s)
                       Mean reward: 362.92
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 72.0822
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 184811520
                    Iteration time: 0.15s
                      Time elapsed: 00:35:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1881/1 [0m                       

                       Computation: 544268 steps/s (collection: 0.048s, learning 0.133s)
                       Mean reward: 369.94
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5587
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 184909824
                    Iteration time: 0.18s
                      Time elapsed: 00:35:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1882/1 [0m                       

                       Computation: 679403 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 370.06
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.3979
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4425
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 185008128
                    Iteration time: 0.14s
                      Time elapsed: 00:35:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1883/1 [0m                       

                       Computation: 599310 steps/s (collection: 0.047s, learning 0.117s)
                       Mean reward: 367.62
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 72.7477
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 185106432
                    Iteration time: 0.16s
                      Time elapsed: 00:35:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1884/1 [0m                       

                       Computation: 579645 steps/s (collection: 0.043s, learning 0.127s)
                       Mean reward: 370.93
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0082
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 185204736
                    Iteration time: 0.17s
                      Time elapsed: 00:35:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1885/1 [0m                       

                       Computation: 634000 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 368.96
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3987
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 185303040
                    Iteration time: 0.16s
                      Time elapsed: 00:35:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1886/1 [0m                       

                       Computation: 612299 steps/s (collection: 0.040s, learning 0.121s)
                       Mean reward: 372.41
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9662
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 185401344
                    Iteration time: 0.16s
                      Time elapsed: 00:35:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1887/1 [0m                       

                       Computation: 670746 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 368.79
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5684
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 185499648
                    Iteration time: 0.15s
                      Time elapsed: 00:35:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1888/1 [0m                       

                       Computation: 627640 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 375.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6231
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4442
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 185597952
                    Iteration time: 0.16s
                      Time elapsed: 00:35:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1889/1 [0m                       

                       Computation: 643155 steps/s (collection: 0.041s, learning 0.112s)
                       Mean reward: 369.22
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4923
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4417
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 185696256
                    Iteration time: 0.15s
                      Time elapsed: 00:35:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1890/1 [0m                       

                       Computation: 692169 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 373.09
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9803
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4425
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 185794560
                    Iteration time: 0.14s
                      Time elapsed: 00:35:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1891/1 [0m                       

                       Computation: 832788 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 377.47
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.1323
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4461
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 185892864
                    Iteration time: 0.12s
                      Time elapsed: 00:35:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1892/1 [0m                       

                       Computation: 795772 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 371.82
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9013
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 185991168
                    Iteration time: 0.12s
                      Time elapsed: 00:35:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1893/1 [0m                       

                       Computation: 850948 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 369.58
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.0878
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 186089472
                    Iteration time: 0.12s
                      Time elapsed: 00:35:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1894/1 [0m                       

                       Computation: 770548 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 369.80
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5844
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 186187776
                    Iteration time: 0.13s
                      Time elapsed: 00:35:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1895/1 [0m                       

                       Computation: 847373 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 373.15
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3626
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 186286080
                    Iteration time: 0.12s
                      Time elapsed: 00:35:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1896/1 [0m                       

                       Computation: 608706 steps/s (collection: 0.041s, learning 0.120s)
                       Mean reward: 377.02
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.9260
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4424
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 186384384
                    Iteration time: 0.16s
                      Time elapsed: 00:35:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1897/1 [0m                       

                       Computation: 632129 steps/s (collection: 0.050s, learning 0.106s)
                       Mean reward: 374.15
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3149
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 186482688
                    Iteration time: 0.16s
                      Time elapsed: 00:35:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1898/1 [0m                       

                       Computation: 624731 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 372.81
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1129
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 186580992
                    Iteration time: 0.16s
                      Time elapsed: 00:35:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1899/1 [0m                       

                       Computation: 602969 steps/s (collection: 0.043s, learning 0.120s)
                       Mean reward: 373.13
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1798
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 186679296
                    Iteration time: 0.16s
                      Time elapsed: 00:35:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1900/1 [0m                       

                       Computation: 619954 steps/s (collection: 0.046s, learning 0.113s)
                       Mean reward: 374.86
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5361
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 186777600
                    Iteration time: 0.16s
                      Time elapsed: 00:35:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1901/1 [0m                       

                       Computation: 717067 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 373.01
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9983
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4417
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 186875904
                    Iteration time: 0.14s
                      Time elapsed: 00:35:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1902/1 [0m                       

                       Computation: 709683 steps/s (collection: 0.057s, learning 0.082s)
                       Mean reward: 374.24
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3905
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4429
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 186974208
                    Iteration time: 0.14s
                      Time elapsed: 00:35:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1903/1 [0m                       

                       Computation: 766978 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 371.51
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7511
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 187072512
                    Iteration time: 0.13s
                      Time elapsed: 00:35:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1904/1 [0m                       

                       Computation: 786120 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 373.27
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8166
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 187170816
                    Iteration time: 0.13s
                      Time elapsed: 00:35:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1905/1 [0m                       

                       Computation: 757044 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 373.50
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2131
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 187269120
                    Iteration time: 0.13s
                      Time elapsed: 00:35:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1906/1 [0m                       

                       Computation: 773239 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 373.16
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3117
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 187367424
                    Iteration time: 0.13s
                      Time elapsed: 00:35:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1907/1 [0m                       

                       Computation: 761765 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 374.03
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3072
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4429
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 187465728
                    Iteration time: 0.13s
                      Time elapsed: 00:35:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1908/1 [0m                       

                       Computation: 777047 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 372.92
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1842
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 187564032
                    Iteration time: 0.13s
                      Time elapsed: 00:35:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1909/1 [0m                       

                       Computation: 769034 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 370.87
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5813
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 187662336
                    Iteration time: 0.13s
                      Time elapsed: 00:35:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1910/1 [0m                       

                       Computation: 753068 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 375.16
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5230
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 187760640
                    Iteration time: 0.13s
                      Time elapsed: 00:35:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1911/1 [0m                       

                       Computation: 634140 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 374.05
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2017
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187858944
                    Iteration time: 0.16s
                      Time elapsed: 00:35:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1912/1 [0m                       

                       Computation: 779922 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 373.69
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4241
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 187957248
                    Iteration time: 0.13s
                      Time elapsed: 00:35:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1913/1 [0m                       

                       Computation: 786127 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 375.52
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6960
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4443
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 188055552
                    Iteration time: 0.13s
                      Time elapsed: 00:35:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1914/1 [0m                       

                       Computation: 663310 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 372.75
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2250
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 188153856
                    Iteration time: 0.15s
                      Time elapsed: 00:35:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1915/1 [0m                       

                       Computation: 642750 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 369.78
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5871
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 188252160
                    Iteration time: 0.15s
                      Time elapsed: 00:35:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1916/1 [0m                       

                       Computation: 821040 steps/s (collection: 0.043s, learning 0.077s)
                       Mean reward: 369.90
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4709
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 188350464
                    Iteration time: 0.12s
                      Time elapsed: 00:35:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1917/1 [0m                       

                       Computation: 754044 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 368.18
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3608
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 188448768
                    Iteration time: 0.13s
                      Time elapsed: 00:35:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1918/1 [0m                       

                       Computation: 786144 steps/s (collection: 0.045s, learning 0.081s)
                       Mean reward: 372.07
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8174
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 188547072
                    Iteration time: 0.13s
                      Time elapsed: 00:35:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1919/1 [0m                       

                       Computation: 704545 steps/s (collection: 0.051s, learning 0.089s)
                       Mean reward: 369.78
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.5372
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 188645376
                    Iteration time: 0.14s
                      Time elapsed: 00:35:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1920/1 [0m                       

                       Computation: 723591 steps/s (collection: 0.045s, learning 0.091s)
                       Mean reward: 375.73
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7634
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 188743680
                    Iteration time: 0.14s
                      Time elapsed: 00:35:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1921/1 [0m                       

                       Computation: 825951 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 370.24
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6408
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 188841984
                    Iteration time: 0.12s
                      Time elapsed: 00:35:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1922/1 [0m                       

                       Computation: 732546 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 377.72
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.9499
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 188940288
                    Iteration time: 0.13s
                      Time elapsed: 00:35:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1923/1 [0m                       

                       Computation: 765808 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 374.23
               Mean episode length: 246.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.3897
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 189038592
                    Iteration time: 0.13s
                      Time elapsed: 00:35:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1924/1 [0m                       

                       Computation: 653915 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 368.25
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9876
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 189136896
                    Iteration time: 0.15s
                      Time elapsed: 00:35:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1925/1 [0m                       

                       Computation: 699274 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 368.63
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4571
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 189235200
                    Iteration time: 0.14s
                      Time elapsed: 00:35:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1926/1 [0m                       

                       Computation: 712587 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 370.87
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.7579
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4371
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 189333504
                    Iteration time: 0.14s
                      Time elapsed: 00:35:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1927/1 [0m                       

                       Computation: 675702 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 371.16
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.6381
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 189431808
                    Iteration time: 0.15s
                      Time elapsed: 00:35:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1928/1 [0m                       

                       Computation: 655948 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 373.59
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3555
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 189530112
                    Iteration time: 0.15s
                      Time elapsed: 00:36:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1929/1 [0m                       

                       Computation: 659654 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 372.29
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2305
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 189628416
                    Iteration time: 0.15s
                      Time elapsed: 00:36:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1930/1 [0m                       

                       Computation: 714810 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 372.62
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0586
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 189726720
                    Iteration time: 0.14s
                      Time elapsed: 00:36:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1931/1 [0m                       

                       Computation: 663492 steps/s (collection: 0.054s, learning 0.095s)
                       Mean reward: 373.75
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0363
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 189825024
                    Iteration time: 0.15s
                      Time elapsed: 00:36:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1932/1 [0m                       

                       Computation: 730097 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 369.61
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.4962
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 189923328
                    Iteration time: 0.13s
                      Time elapsed: 00:36:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1933/1 [0m                       

                       Computation: 713747 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 372.16
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1263
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 190021632
                    Iteration time: 0.14s
                      Time elapsed: 00:36:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1934/1 [0m                       

                       Computation: 607095 steps/s (collection: 0.047s, learning 0.115s)
                       Mean reward: 377.63
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.1584
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 190119936
                    Iteration time: 0.16s
                      Time elapsed: 00:36:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1935/1 [0m                       

                       Computation: 684876 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 375.49
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.8479
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 190218240
                    Iteration time: 0.14s
                      Time elapsed: 00:36:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1936/1 [0m                       

                       Computation: 817030 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 373.43
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2804
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 190316544
                    Iteration time: 0.12s
                      Time elapsed: 00:36:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1937/1 [0m                       

                       Computation: 755725 steps/s (collection: 0.045s, learning 0.086s)
                       Mean reward: 371.87
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.8574
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4377
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 190414848
                    Iteration time: 0.13s
                      Time elapsed: 00:36:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1938/1 [0m                       

                       Computation: 844517 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 371.99
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.6329
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 190513152
                    Iteration time: 0.12s
                      Time elapsed: 00:36:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1939/1 [0m                       

                       Computation: 824673 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 372.65
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.8935
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4374
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 190611456
                    Iteration time: 0.12s
                      Time elapsed: 00:36:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1940/1 [0m                       

                       Computation: 604819 steps/s (collection: 0.046s, learning 0.117s)
                       Mean reward: 371.48
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.0906
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 190709760
                    Iteration time: 0.16s
                      Time elapsed: 00:36:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1941/1 [0m                       

                       Computation: 611131 steps/s (collection: 0.048s, learning 0.113s)
                       Mean reward: 378.89
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.4341
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 190808064
                    Iteration time: 0.16s
                      Time elapsed: 00:36:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1942/1 [0m                       

                       Computation: 818262 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 370.36
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.5850
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 190906368
                    Iteration time: 0.12s
                      Time elapsed: 00:36:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1943/1 [0m                       

                       Computation: 707143 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 378.69
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.4058
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4401
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 191004672
                    Iteration time: 0.14s
                      Time elapsed: 00:36:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1944/1 [0m                       

                       Computation: 668626 steps/s (collection: 0.054s, learning 0.093s)
                       Mean reward: 376.94
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 75.2578
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 191102976
                    Iteration time: 0.15s
                      Time elapsed: 00:36:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1945/1 [0m                       

                       Computation: 734798 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 372.76
               Mean episode length: 247.28
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.0021
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 191201280
                    Iteration time: 0.13s
                      Time elapsed: 00:36:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1946/1 [0m                       

                       Computation: 741795 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 375.96
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7115
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4377
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 191299584
                    Iteration time: 0.13s
                      Time elapsed: 00:36:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1947/1 [0m                       

                       Computation: 644169 steps/s (collection: 0.048s, learning 0.105s)
                       Mean reward: 376.23
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.9151
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 191397888
                    Iteration time: 0.15s
                      Time elapsed: 00:36:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1948/1 [0m                       

                       Computation: 555009 steps/s (collection: 0.062s, learning 0.115s)
                       Mean reward: 379.46
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.4987
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4433
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 191496192
                    Iteration time: 0.18s
                      Time elapsed: 00:36:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1949/1 [0m                       

                       Computation: 638094 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 373.54
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.0844
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4388
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 191594496
                    Iteration time: 0.15s
                      Time elapsed: 00:36:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1950/1 [0m                       

                       Computation: 581613 steps/s (collection: 0.057s, learning 0.112s)
                       Mean reward: 372.34
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.8520
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 191692800
                    Iteration time: 0.17s
                      Time elapsed: 00:36:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1951/1 [0m                       

                       Computation: 561980 steps/s (collection: 0.054s, learning 0.121s)
                       Mean reward: 380.46
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.8535
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4402
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 191791104
                    Iteration time: 0.17s
                      Time elapsed: 00:36:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1952/1 [0m                       

                       Computation: 716468 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 374.09
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.3548
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4390
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 191889408
                    Iteration time: 0.14s
                      Time elapsed: 00:36:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1953/1 [0m                       

                       Computation: 674835 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 375.05
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.6565
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 191987712
                    Iteration time: 0.15s
                      Time elapsed: 00:36:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1954/1 [0m                       

                       Computation: 736341 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 374.30
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.4656
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 192086016
                    Iteration time: 0.13s
                      Time elapsed: 00:36:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1955/1 [0m                       

                       Computation: 729768 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 374.94
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.5760
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 192184320
                    Iteration time: 0.13s
                      Time elapsed: 00:36:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1956/1 [0m                       

                       Computation: 756421 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 372.45
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.7272
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 192282624
                    Iteration time: 0.13s
                      Time elapsed: 00:36:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1957/1 [0m                       

                       Computation: 577203 steps/s (collection: 0.051s, learning 0.120s)
                       Mean reward: 374.27
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.3322
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 192380928
                    Iteration time: 0.17s
                      Time elapsed: 00:36:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1958/1 [0m                       

                       Computation: 671301 steps/s (collection: 0.048s, learning 0.099s)
                       Mean reward: 367.93
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.3104
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 192479232
                    Iteration time: 0.15s
                      Time elapsed: 00:36:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1959/1 [0m                       

                       Computation: 640327 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 371.22
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.0705
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 192577536
                    Iteration time: 0.15s
                      Time elapsed: 00:36:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1960/1 [0m                       

                       Computation: 556698 steps/s (collection: 0.048s, learning 0.129s)
                       Mean reward: 376.79
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.7321
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 192675840
                    Iteration time: 0.18s
                      Time elapsed: 00:36:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1961/1 [0m                       

                       Computation: 658649 steps/s (collection: 0.047s, learning 0.102s)
                       Mean reward: 375.18
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.8533
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 192774144
                    Iteration time: 0.15s
                      Time elapsed: 00:36:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1962/1 [0m                       

                       Computation: 636012 steps/s (collection: 0.053s, learning 0.102s)
                       Mean reward: 377.06
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.8519
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 192872448
                    Iteration time: 0.15s
                      Time elapsed: 00:36:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1963/1 [0m                       

                       Computation: 743548 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 376.12
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.7689
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 192970752
                    Iteration time: 0.13s
                      Time elapsed: 00:36:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1964/1 [0m                       

                       Computation: 660041 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 378.68
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.4981
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 193069056
                    Iteration time: 0.15s
                      Time elapsed: 00:36:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1965/1 [0m                       

                       Computation: 732293 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 375.31
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8443
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 193167360
                    Iteration time: 0.13s
                      Time elapsed: 00:36:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1966/1 [0m                       

                       Computation: 677787 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 375.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8560
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 193265664
                    Iteration time: 0.15s
                      Time elapsed: 00:36:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1967/1 [0m                       

                       Computation: 758120 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 372.89
               Mean episode length: 246.15
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.4908
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 193363968
                    Iteration time: 0.13s
                      Time elapsed: 00:36:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1968/1 [0m                       

                       Computation: 750768 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 375.24
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.6269
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 193462272
                    Iteration time: 0.13s
                      Time elapsed: 00:36:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1969/1 [0m                       

                       Computation: 779839 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 377.78
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.0381
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 193560576
                    Iteration time: 0.13s
                      Time elapsed: 00:36:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1970/1 [0m                       

                       Computation: 795654 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 379.35
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.3870
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 193658880
                    Iteration time: 0.12s
                      Time elapsed: 00:36:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1971/1 [0m                       

                       Computation: 584732 steps/s (collection: 0.055s, learning 0.113s)
                       Mean reward: 377.87
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 75.3098
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 193757184
                    Iteration time: 0.17s
                      Time elapsed: 00:36:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1972/1 [0m                       

                       Computation: 701064 steps/s (collection: 0.046s, learning 0.094s)
                       Mean reward: 374.37
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.4271
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 193855488
                    Iteration time: 0.14s
                      Time elapsed: 00:36:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1973/1 [0m                       

                       Computation: 764902 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 374.79
               Mean episode length: 246.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.4951
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 193953792
                    Iteration time: 0.13s
                      Time elapsed: 00:36:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1974/1 [0m                       

                       Computation: 758819 steps/s (collection: 0.047s, learning 0.083s)
                       Mean reward: 371.73
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.6489
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 194052096
                    Iteration time: 0.13s
                      Time elapsed: 00:36:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1975/1 [0m                       

                       Computation: 708719 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 374.51
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.4739
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 194150400
                    Iteration time: 0.14s
                      Time elapsed: 00:36:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1976/1 [0m                       

                       Computation: 740407 steps/s (collection: 0.047s, learning 0.085s)
                       Mean reward: 370.59
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.6638
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 194248704
                    Iteration time: 0.13s
                      Time elapsed: 00:36:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1977/1 [0m                       

                       Computation: 744640 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 378.71
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 75.0024
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 194347008
                    Iteration time: 0.13s
                      Time elapsed: 00:36:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1978/1 [0m                       

                       Computation: 734402 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 374.76
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.4714
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 194445312
                    Iteration time: 0.13s
                      Time elapsed: 00:36:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1979/1 [0m                       

                       Computation: 719013 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 383.00
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 76.2027
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 194543616
                    Iteration time: 0.14s
                      Time elapsed: 00:37:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1980/1 [0m                       

                       Computation: 802207 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 372.49
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0959
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 194641920
                    Iteration time: 0.12s
                      Time elapsed: 00:37:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1981/1 [0m                       

                       Computation: 732728 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 371.49
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.9192
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 194740224
                    Iteration time: 0.13s
                      Time elapsed: 00:37:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1982/1 [0m                       

                       Computation: 708024 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 369.14
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.3928
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 194838528
                    Iteration time: 0.14s
                      Time elapsed: 00:37:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1983/1 [0m                       

                       Computation: 717430 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 379.15
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 75.4927
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 194936832
                    Iteration time: 0.14s
                      Time elapsed: 00:37:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1984/1 [0m                       

                       Computation: 761337 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 377.35
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.8879
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 195035136
                    Iteration time: 0.13s
                      Time elapsed: 00:37:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1985/1 [0m                       

                       Computation: 728782 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 374.07
               Mean episode length: 247.41
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.4187
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4348
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 195133440
                    Iteration time: 0.13s
                      Time elapsed: 00:37:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1986/1 [0m                       

                       Computation: 735489 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 371.80
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.7826
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 195231744
                    Iteration time: 0.13s
                      Time elapsed: 00:37:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1987/1 [0m                       

                       Computation: 694289 steps/s (collection: 0.049s, learning 0.093s)
                       Mean reward: 372.97
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.1043
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 195330048
                    Iteration time: 0.14s
                      Time elapsed: 00:37:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1988/1 [0m                       

                       Computation: 734966 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 371.81
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.9844
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 195428352
                    Iteration time: 0.13s
                      Time elapsed: 00:37:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1989/1 [0m                       

                       Computation: 608312 steps/s (collection: 0.051s, learning 0.110s)
                       Mean reward: 374.98
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.6076
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 195526656
                    Iteration time: 0.16s
                      Time elapsed: 00:37:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1990/1 [0m                       

                       Computation: 620067 steps/s (collection: 0.049s, learning 0.110s)
                       Mean reward: 374.43
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.3002
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 195624960
                    Iteration time: 0.16s
                      Time elapsed: 00:37:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1991/1 [0m                       

                       Computation: 588489 steps/s (collection: 0.055s, learning 0.113s)
                       Mean reward: 369.56
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.2724
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4347
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 195723264
                    Iteration time: 0.17s
                      Time elapsed: 00:37:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1992/1 [0m                       

                       Computation: 760130 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 369.24
               Mean episode length: 246.90
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.3218
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 195821568
                    Iteration time: 0.13s
                      Time elapsed: 00:37:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1993/1 [0m                       

                       Computation: 758387 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 373.65
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.4256
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 195919872
                    Iteration time: 0.13s
                      Time elapsed: 00:37:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1994/1 [0m                       

                       Computation: 788358 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 378.73
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 75.3569
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 196018176
                    Iteration time: 0.12s
                      Time elapsed: 00:37:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1995/1 [0m                       

                       Computation: 632092 steps/s (collection: 0.045s, learning 0.111s)
                       Mean reward: 373.59
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.2453
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 196116480
                    Iteration time: 0.16s
                      Time elapsed: 00:37:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1996/1 [0m                       

                       Computation: 805717 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 380.51
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 75.5290
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 196214784
                    Iteration time: 0.12s
                      Time elapsed: 00:37:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1997/1 [0m                       

                       Computation: 714670 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 377.60
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 75.3888
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 196313088
                    Iteration time: 0.14s
                      Time elapsed: 00:37:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1998/1 [0m                       

                       Computation: 711633 steps/s (collection: 0.047s, learning 0.092s)
                       Mean reward: 372.50
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.4312
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4377
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 196411392
                    Iteration time: 0.14s
                      Time elapsed: 00:37:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1999/1 [0m                       

                       Computation: 684859 steps/s (collection: 0.053s, learning 0.091s)
                       Mean reward: 376.23
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.9438
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 196509696
                    Iteration time: 0.14s
                      Time elapsed: 00:37:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 2000/1 [0m                       

                       Computation: 569659 steps/s (collection: 0.043s, learning 0.130s)
                       Mean reward: 370.25
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 73.7946
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 196608000
                    Iteration time: 0.17s
                      Time elapsed: 00:37:24
                               ETA: 00:00:00

