################################################################################
                        [1m Learning iteration 1/1 [0m                        

                       Computation: 319935 steps/s (collection: 0.036s, learning 0.271s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 0.31s
                      Time elapsed: 00:00:02
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 2/1 [0m                        

                       Computation: 656211 steps/s (collection: 0.034s, learning 0.116s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 0.15s
                      Time elapsed: 00:00:03
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 3/1 [0m                        

                       Computation: 679861 steps/s (collection: 0.031s, learning 0.114s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 0.14s
                      Time elapsed: 00:00:04
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 4/1 [0m                        

                       Computation: 659532 steps/s (collection: 0.034s, learning 0.115s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 0.15s
                      Time elapsed: 00:00:04
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 5/1 [0m                        

                       Computation: 689713 steps/s (collection: 0.030s, learning 0.113s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 0.14s
                      Time elapsed: 00:00:05
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 6/1 [0m                        

                       Computation: 720107 steps/s (collection: 0.030s, learning 0.106s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 0.14s
                      Time elapsed: 00:00:06
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 7/1 [0m                        

                       Computation: 620132 steps/s (collection: 0.033s, learning 0.126s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 0.16s
                      Time elapsed: 00:00:07
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 8/1 [0m                        

                       Computation: 602506 steps/s (collection: 0.037s, learning 0.127s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 0.16s
                      Time elapsed: 00:00:08
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 9/1 [0m                        

                       Computation: 709618 steps/s (collection: 0.033s, learning 0.106s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 0.14s
                      Time elapsed: 00:00:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 10/1 [0m                        

                       Computation: 657740 steps/s (collection: 0.032s, learning 0.117s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 0.15s
                      Time elapsed: 00:00:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 11/1 [0m                        

                       Computation: 610437 steps/s (collection: 0.033s, learning 0.129s)
                       Mean reward: 0.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 0.0010
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.0186
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2560.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 0.16s
                      Time elapsed: 00:00:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 12/1 [0m                        

                       Computation: 610322 steps/s (collection: 0.036s, learning 0.125s)
                       Mean reward: 0.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0016
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0297
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 0.16s
                      Time elapsed: 00:00:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 13/1 [0m                        

                       Computation: 551902 steps/s (collection: 0.043s, learning 0.136s)
                       Mean reward: 0.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0016
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0297
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 0.18s
                      Time elapsed: 00:00:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 14/1 [0m                        

                       Computation: 553710 steps/s (collection: 0.039s, learning 0.139s)
                       Mean reward: 0.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0016
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0297
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 0.18s
                      Time elapsed: 00:00:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 15/1 [0m                        

                       Computation: 474741 steps/s (collection: 0.048s, learning 0.159s)
                       Mean reward: 0.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0016
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0297
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 0.21s
                      Time elapsed: 00:00:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 16/1 [0m                        

                       Computation: 734865 steps/s (collection: 0.032s, learning 0.101s)
                       Mean reward: 0.30
               Mean episode length: 131.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 0.0013
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.0350
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 3413.3333
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 0.13s
                      Time elapsed: 00:00:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 17/1 [0m                        

                       Computation: 702060 steps/s (collection: 0.036s, learning 0.104s)
                       Mean reward: 8.51
               Mean episode length: 143.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0014
      Episode_Reward/lifting_object 1.0667
       Episode_Reward/object_height 0.0012
     Episode_Reward/reaching_object 0.0890
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 0.14s
                      Time elapsed: 00:00:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 18/1 [0m                        

                       Computation: 766449 steps/s (collection: 0.034s, learning 0.095s)
                       Mean reward: 2.32
               Mean episode length: 168.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 0.6000
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.0739
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 0.13s
                      Time elapsed: 00:00:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 19/1 [0m                        

                       Computation: 734296 steps/s (collection: 0.047s, learning 0.087s)
                       Mean reward: 2.32
               Mean episode length: 196.43
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 0.4333
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1173
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 0.13s
                      Time elapsed: 00:00:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 20/1 [0m                        

                       Computation: 790633 steps/s (collection: 0.031s, learning 0.093s)
                       Mean reward: 0.66
               Mean episode length: 221.86
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.1303
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 0.12s
                      Time elapsed: 00:00:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 21/1 [0m                        

                       Computation: 776239 steps/s (collection: 0.030s, learning 0.097s)
                       Mean reward: 1.25
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 0.0245
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.1520
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 848.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 0.13s
                      Time elapsed: 00:00:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 22/1 [0m                        

                       Computation: 727920 steps/s (collection: 0.035s, learning 0.100s)
                       Mean reward: 1.25
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.1178
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.1333
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4074.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 0.14s
                      Time elapsed: 00:00:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 23/1 [0m                        

                       Computation: 839598 steps/s (collection: 0.031s, learning 0.087s)
                       Mean reward: 0.09
               Mean episode length: 43.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0013
      Episode_Reward/lifting_object 0.0491
       Episode_Reward/object_height 0.0011
     Episode_Reward/reaching_object 0.0665
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 1697.5000
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 0.12s
                      Time elapsed: 00:00:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 24/1 [0m                        

                       Computation: 759048 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 3.44
               Mean episode length: 69.10
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0006
      Episode_Reward/lifting_object 0.2667
       Episode_Reward/object_height 0.0005
     Episode_Reward/reaching_object 0.0364
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 0.13s
                      Time elapsed: 00:00:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 25/1 [0m                        

                       Computation: 640309 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 0.29
               Mean episode length: 88.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0008
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0007
     Episode_Reward/reaching_object 0.0519
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 0.15s
                      Time elapsed: 00:00:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 26/1 [0m                        

                       Computation: 579686 steps/s (collection: 0.044s, learning 0.126s)
                       Mean reward: 1.88
               Mean episode length: 109.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0011
      Episode_Reward/lifting_object 0.4333
       Episode_Reward/object_height 0.0010
     Episode_Reward/reaching_object 0.0814
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 0.17s
                      Time elapsed: 00:00:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 27/1 [0m                        

                       Computation: 613573 steps/s (collection: 0.042s, learning 0.119s)
                       Mean reward: 0.54
               Mean episode length: 153.77
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0014
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.1155
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 0.16s
                      Time elapsed: 00:00:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 28/1 [0m                        

                       Computation: 813435 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 2.19
               Mean episode length: 163.45
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 0.2333
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1419
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 0.12s
                      Time elapsed: 00:00:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 29/1 [0m                        

                       Computation: 781163 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 5.08
               Mean episode length: 201.59
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 0.4111
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1578
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 0.13s
                      Time elapsed: 00:00:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 30/1 [0m                        

                       Computation: 753529 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 4.57
               Mean episode length: 222.58
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 0.7833
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.1987
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 0.13s
                      Time elapsed: 00:00:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 31/1 [0m                        

                       Computation: 667767 steps/s (collection: 0.049s, learning 0.098s)
                       Mean reward: 2.16
               Mean episode length: 236.50
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 0.2500
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.1734
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 0.15s
                      Time elapsed: 00:00:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 32/1 [0m                        

                       Computation: 743902 steps/s (collection: 0.031s, learning 0.102s)
                       Mean reward: 2.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.5051
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2001
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3143.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 0.13s
                      Time elapsed: 00:00:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 33/1 [0m                        

                       Computation: 627807 steps/s (collection: 0.045s, learning 0.112s)
                       Mean reward: 0.72
               Mean episode length: 144.50
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 0.3212
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.1838
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 3309.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 0.16s
                      Time elapsed: 00:00:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 34/1 [0m                        

                       Computation: 577951 steps/s (collection: 0.054s, learning 0.117s)
                       Mean reward: 4.58
               Mean episode length: 144.56
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0011
      Episode_Reward/lifting_object 0.3000
       Episode_Reward/object_height 0.0010
     Episode_Reward/reaching_object 0.0984
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 0.17s
                      Time elapsed: 00:00:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 35/1 [0m                        

                       Computation: 730840 steps/s (collection: 0.034s, learning 0.101s)
                       Mean reward: 5.66
               Mean episode length: 166.74
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 0.9417
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1339
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 0.13s
                      Time elapsed: 00:00:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 36/1 [0m                        

                       Computation: 621884 steps/s (collection: 0.041s, learning 0.118s)
                       Mean reward: 4.00
               Mean episode length: 160.50
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 0.9500
       Episode_Reward/object_height 0.0015
     Episode_Reward/reaching_object 0.1388
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 0.16s
                      Time elapsed: 00:00:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 37/1 [0m                        

                       Computation: 710519 steps/s (collection: 0.037s, learning 0.101s)
                       Mean reward: 4.19
               Mean episode length: 171.15
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 0.4778
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1532
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 0.14s
                      Time elapsed: 00:00:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 38/1 [0m                        

                       Computation: 771647 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 7.09
               Mean episode length: 194.53
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 1.4611
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1728
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 0.13s
                      Time elapsed: 00:00:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 39/1 [0m                        

                       Computation: 689714 steps/s (collection: 0.037s, learning 0.106s)
                       Mean reward: 4.45
               Mean episode length: 201.09
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 0.6139
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.1801
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 0.14s
                      Time elapsed: 00:00:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 40/1 [0m                        

                       Computation: 773313 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 5.33
               Mean episode length: 222.82
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 0.8667
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2144
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 0.13s
                      Time elapsed: 00:00:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 41/1 [0m                        

                       Computation: 741709 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 12.74
               Mean episode length: 231.29
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 1.8372
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2185
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 0.13s
                      Time elapsed: 00:00:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 42/1 [0m                        

                       Computation: 822549 steps/s (collection: 0.031s, learning 0.089s)
                       Mean reward: 8.62
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 1.8719
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2401
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 1426.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 0.12s
                      Time elapsed: 00:00:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 43/1 [0m                        

                       Computation: 750207 steps/s (collection: 0.035s, learning 0.096s)
                       Mean reward: 8.62
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 1.4866
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2349
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3802.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 0.13s
                      Time elapsed: 00:00:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 44/1 [0m                        

                       Computation: 741730 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 9.04
               Mean episode length: 152.09
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 2.0500
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.1333
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 0.13s
                      Time elapsed: 00:00:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 45/1 [0m                        

                       Computation: 616069 steps/s (collection: 0.047s, learning 0.113s)
                       Mean reward: 8.13
               Mean episode length: 162.26
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 1.3861
       Episode_Reward/object_height 0.0015
     Episode_Reward/reaching_object 0.1643
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 0.16s
                      Time elapsed: 00:00:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 46/1 [0m                        

                       Computation: 591457 steps/s (collection: 0.047s, learning 0.119s)
                       Mean reward: 8.42
               Mean episode length: 162.38
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 1.1667
       Episode_Reward/object_height 0.0015
     Episode_Reward/reaching_object 0.1476
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 0.17s
                      Time elapsed: 00:00:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 47/1 [0m                        

                       Computation: 629979 steps/s (collection: 0.043s, learning 0.114s)
                       Mean reward: 10.77
               Mean episode length: 181.70
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 2.1589
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1814
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 0.16s
                      Time elapsed: 00:00:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 48/1 [0m                        

                       Computation: 675575 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 12.57
               Mean episode length: 216.35
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 1.9111
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2145
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 0.15s
                      Time elapsed: 00:00:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 49/1 [0m                        

                       Computation: 655611 steps/s (collection: 0.043s, learning 0.107s)
                       Mean reward: 10.56
               Mean episode length: 230.46
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 1.7906
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2353
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 0.15s
                      Time elapsed: 00:00:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 50/1 [0m                        

                       Computation: 615637 steps/s (collection: 0.047s, learning 0.113s)
                       Mean reward: 12.37
               Mean episode length: 226.79
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 2.3389
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2343
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 0.16s
                      Time elapsed: 00:00:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 51/1 [0m                        

                       Computation: 638209 steps/s (collection: 0.046s, learning 0.109s)
                       Mean reward: 12.53
               Mean episode length: 235.77
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 2.5894
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2409
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 0.15s
                      Time elapsed: 00:00:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 52/1 [0m                        

                       Computation: 695016 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 13.32
               Mean episode length: 243.79
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 2.4496
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2658
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 0.14s
                      Time elapsed: 00:00:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 53/1 [0m                        

                       Computation: 670937 steps/s (collection: 0.037s, learning 0.109s)
                       Mean reward: 16.45
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 2.6616
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2422
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 3030.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 0.15s
                      Time elapsed: 00:00:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 54/1 [0m                        

                       Computation: 582247 steps/s (collection: 0.047s, learning 0.122s)
                       Mean reward: 16.16
               Mean episode length: 189.89
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 1.9333
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1989
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 0.17s
                      Time elapsed: 00:00:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 55/1 [0m                        

                       Computation: 491798 steps/s (collection: 0.063s, learning 0.136s)
                       Mean reward: 15.84
               Mean episode length: 191.24
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 4.1292
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2389
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 0.20s
                      Time elapsed: 00:01:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 56/1 [0m                        

                       Computation: 618159 steps/s (collection: 0.050s, learning 0.109s)
                       Mean reward: 17.35
               Mean episode length: 183.85
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 3.6500
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2183
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 0.16s
                      Time elapsed: 00:01:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 57/1 [0m                        

                       Computation: 584768 steps/s (collection: 0.055s, learning 0.114s)
                       Mean reward: 21.21
               Mean episode length: 182.27
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 4.5008
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.2044
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 0.17s
                      Time elapsed: 00:01:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 58/1 [0m                        

                       Computation: 583197 steps/s (collection: 0.051s, learning 0.118s)
                       Mean reward: 17.79
               Mean episode length: 194.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 3.1058
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2123
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 0.17s
                      Time elapsed: 00:01:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 59/1 [0m                        

                       Computation: 616310 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 21.89
               Mean episode length: 203.70
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 4.1823
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2279
Episode_Termination/object_dropping 2.1667
       Episode_Termination/time_out 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 0.16s
                      Time elapsed: 00:01:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 60/1 [0m                        

                       Computation: 575514 steps/s (collection: 0.047s, learning 0.124s)
                       Mean reward: 21.25
               Mean episode length: 208.81
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 4.0935
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2444
Episode_Termination/object_dropping 2.7500
       Episode_Termination/time_out 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 0.17s
                      Time elapsed: 00:01:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 61/1 [0m                        

                       Computation: 635883 steps/s (collection: 0.054s, learning 0.101s)
                       Mean reward: 22.51
               Mean episode length: 228.77
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 4.0635
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2590
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 0.15s
                      Time elapsed: 00:01:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 62/1 [0m                        

                       Computation: 770893 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 24.42
               Mean episode length: 239.41
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 4.2698
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2767
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 0.13s
                      Time elapsed: 00:01:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 63/1 [0m                        

                       Computation: 811136 steps/s (collection: 0.031s, learning 0.090s)
                       Mean reward: 23.34
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 3.8746
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2419
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 140.2917
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 0.12s
                      Time elapsed: 00:01:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 64/1 [0m                        

                       Computation: 764888 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 18.90
               Mean episode length: 200.86
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 2.6500
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2391
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 0.13s
                      Time elapsed: 00:01:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 65/1 [0m                        

                       Computation: 757734 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 20.37
               Mean episode length: 218.48
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 3.0722
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2491
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 0.13s
                      Time elapsed: 00:01:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 66/1 [0m                        

                       Computation: 783087 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 24.43
               Mean episode length: 218.52
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 4.7121
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2387
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 0.13s
                      Time elapsed: 00:01:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 67/1 [0m                        

                       Computation: 785482 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 26.02
               Mean episode length: 198.48
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 4.6883
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2221
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 0.13s
                      Time elapsed: 00:01:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 68/1 [0m                        

                       Computation: 793034 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 22.62
               Mean episode length: 213.36
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 4.5045
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2432
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 0.12s
                      Time elapsed: 00:01:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 69/1 [0m                        

                       Computation: 767443 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 27.75
               Mean episode length: 221.30
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 5.3495
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2636
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 0.13s
                      Time elapsed: 00:01:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 70/1 [0m                        

                       Computation: 739551 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 33.87
               Mean episode length: 231.27
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 6.8648
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2793
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 0.13s
                      Time elapsed: 00:01:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 71/1 [0m                        

                       Computation: 643656 steps/s (collection: 0.044s, learning 0.108s)
                       Mean reward: 32.88
               Mean episode length: 231.88
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 6.2301
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2812
Episode_Termination/object_dropping 2.0417
       Episode_Termination/time_out 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 0.15s
                      Time elapsed: 00:01:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 72/1 [0m                        

                       Computation: 689647 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 36.59
               Mean episode length: 239.02
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 7.3339
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2822
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 0.14s
                      Time elapsed: 00:01:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 73/1 [0m                        

                       Computation: 587681 steps/s (collection: 0.040s, learning 0.128s)
                       Mean reward: 34.47
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 6.9138
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2799
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 132.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 0.17s
                      Time elapsed: 00:01:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 74/1 [0m                        

                       Computation: 574660 steps/s (collection: 0.050s, learning 0.121s)
                       Mean reward: 24.55
               Mean episode length: 180.86
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 4.5333
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.2126
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 0.17s
                      Time elapsed: 00:01:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 75/1 [0m                        

                       Computation: 599994 steps/s (collection: 0.055s, learning 0.109s)
                       Mean reward: 26.71
               Mean episode length: 186.93
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 4.6556
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.2236
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 0.16s
                      Time elapsed: 00:01:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 76/1 [0m                        

                       Computation: 637939 steps/s (collection: 0.050s, learning 0.105s)
                       Mean reward: 30.55
               Mean episode length: 207.71
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 6.0908
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2419
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 0.15s
                      Time elapsed: 00:01:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 77/1 [0m                        

                       Computation: 618597 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 36.76
               Mean episode length: 209.50
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 6.5728
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2455
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 0.16s
                      Time elapsed: 00:01:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 78/1 [0m                        

                       Computation: 621971 steps/s (collection: 0.055s, learning 0.104s)
                       Mean reward: 34.33
               Mean episode length: 222.09
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 6.7903
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2606
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 0.16s
                      Time elapsed: 00:01:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 79/1 [0m                        

                       Computation: 625617 steps/s (collection: 0.047s, learning 0.110s)
                       Mean reward: 32.74
               Mean episode length: 227.53
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 6.1609
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2674
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 0.16s
                      Time elapsed: 00:01:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 80/1 [0m                        

                       Computation: 693561 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 38.74
               Mean episode length: 229.71
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 7.6264
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2839
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 0.14s
                      Time elapsed: 00:01:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 81/1 [0m                        

                       Computation: 686323 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 45.02
               Mean episode length: 242.07
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 8.5688
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2978
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 0.14s
                      Time elapsed: 00:01:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 82/1 [0m                        

                       Computation: 753141 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 38.25
               Mean episode length: 241.86
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 7.2769
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2901
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 0.13s
                      Time elapsed: 00:01:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 83/1 [0m                        

                       Computation: 749830 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 42.00
               Mean episode length: 240.90
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 8.0322
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3024
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 0.13s
                      Time elapsed: 00:01:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 84/1 [0m                        

                       Computation: 692068 steps/s (collection: 0.034s, learning 0.108s)
                       Mean reward: 44.89
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 10.6417
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2915
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 123.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 0.14s
                      Time elapsed: 00:01:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 85/1 [0m                        

                       Computation: 618091 steps/s (collection: 0.051s, learning 0.109s)
                       Mean reward: 40.46
               Mean episode length: 200.58
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 7.5056
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2542
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 0.16s
                      Time elapsed: 00:01:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 86/1 [0m                        

                       Computation: 618080 steps/s (collection: 0.047s, learning 0.113s)
                       Mean reward: 37.20
               Mean episode length: 220.08
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 7.8400
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2563
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 0.16s
                      Time elapsed: 00:01:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 87/1 [0m                        

                       Computation: 763463 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 44.17
               Mean episode length: 219.05
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 7.9725
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2781
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 0.13s
                      Time elapsed: 00:01:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 88/1 [0m                        

                       Computation: 774469 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 52.96
               Mean episode length: 223.21
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 10.1186
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2907
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 0.13s
                      Time elapsed: 00:01:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 89/1 [0m                        

                       Computation: 678045 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 49.57
               Mean episode length: 231.16
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 9.6233
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3028
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 0.14s
                      Time elapsed: 00:01:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 90/1 [0m                        

                       Computation: 765605 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 57.86
               Mean episode length: 237.65
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 11.3776
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3123
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 0.13s
                      Time elapsed: 00:01:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 91/1 [0m                        

                       Computation: 811867 steps/s (collection: 0.043s, learning 0.078s)
                       Mean reward: 55.47
               Mean episode length: 235.20
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 10.8628
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3044
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 0.12s
                      Time elapsed: 00:01:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 92/1 [0m                        

                       Computation: 566965 steps/s (collection: 0.043s, learning 0.131s)
                       Mean reward: 56.50
               Mean episode length: 240.23
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 10.9243
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3262
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 0.17s
                      Time elapsed: 00:01:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 93/1 [0m                        

                       Computation: 778216 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 56.81
               Mean episode length: 243.88
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 11.0186
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3221
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 0.13s
                      Time elapsed: 00:01:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 94/1 [0m                        

                       Computation: 726894 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 61.98
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 12.0881
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3218
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 463.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 0.14s
                      Time elapsed: 00:01:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 95/1 [0m                        

                       Computation: 799159 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 63.45
               Mean episode length: 220.30
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 14.8472
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3290
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 0.12s
                      Time elapsed: 00:01:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 96/1 [0m                        

                       Computation: 774871 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 60.35
               Mean episode length: 214.84
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 11.9417
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2950
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 0.13s
                      Time elapsed: 00:01:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 97/1 [0m                        

                       Computation: 764895 steps/s (collection: 0.048s, learning 0.081s)
                       Mean reward: 62.00
               Mean episode length: 224.92
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 12.6544
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3233
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 0.13s
                      Time elapsed: 00:01:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 98/1 [0m                        

                       Computation: 776936 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 67.10
               Mean episode length: 225.50
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 12.6999
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3257
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 0.13s
                      Time elapsed: 00:01:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 99/1 [0m                        

                       Computation: 823091 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 60.80
               Mean episode length: 226.78
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 11.6474
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3109
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 0.12s
                      Time elapsed: 00:01:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 100/1 [0m                       

                       Computation: 725293 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 71.04
               Mean episode length: 228.38
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 13.6625
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3318
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 0.14s
                      Time elapsed: 00:01:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 101/1 [0m                       

                       Computation: 692697 steps/s (collection: 0.038s, learning 0.104s)
                       Mean reward: 71.88
               Mean episode length: 233.13
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 14.2628
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3393
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 0.14s
                      Time elapsed: 00:01:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 102/1 [0m                       

                       Computation: 639851 steps/s (collection: 0.039s, learning 0.115s)
                       Mean reward: 75.57
               Mean episode length: 238.50
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 14.6223
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3398
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 0.15s
                      Time elapsed: 00:01:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 103/1 [0m                       

                       Computation: 671990 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 77.11
               Mean episode length: 239.91
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 14.8568
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3550
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 0.15s
                      Time elapsed: 00:01:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 104/1 [0m                       

                       Computation: 606753 steps/s (collection: 0.044s, learning 0.118s)
                       Mean reward: 74.29
               Mean episode length: 243.74
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 14.1311
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3488
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 0.16s
                      Time elapsed: 00:01:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 105/1 [0m                       

                       Computation: 751734 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 74.75
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 12.5279
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2875
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 108.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 0.13s
                      Time elapsed: 00:01:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 106/1 [0m                       

                       Computation: 777397 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 78.51
               Mean episode length: 227.69
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 16.1167
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3375
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 0.13s
                      Time elapsed: 00:01:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 107/1 [0m                       

                       Computation: 805606 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 68.67
               Mean episode length: 221.96
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 13.0561
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3338
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 0.12s
                      Time elapsed: 00:02:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 108/1 [0m                       

                       Computation: 769615 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 79.46
               Mean episode length: 222.71
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 15.8755
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3294
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 0.13s
                      Time elapsed: 00:02:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 109/1 [0m                       

                       Computation: 738488 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 73.73
               Mean episode length: 225.36
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 14.3147
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3226
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 0.13s
                      Time elapsed: 00:02:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 110/1 [0m                       

                       Computation: 743618 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 78.62
               Mean episode length: 234.02
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 15.4360
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3495
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 0.13s
                      Time elapsed: 00:02:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 111/1 [0m                       

                       Computation: 775310 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 84.74
               Mean episode length: 240.16
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 16.3055
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3574
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 0.13s
                      Time elapsed: 00:02:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 112/1 [0m                       

                       Computation: 748572 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 82.95
               Mean episode length: 239.72
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 16.6018
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3593
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 0.13s
                      Time elapsed: 00:02:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 113/1 [0m                       

                       Computation: 789438 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 87.06
               Mean episode length: 241.49
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 17.0735
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3603
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 0.12s
                      Time elapsed: 00:02:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 114/1 [0m                       

                       Computation: 783203 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 89.63
               Mean episode length: 246.36
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 17.5529
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3735
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 0.13s
                      Time elapsed: 00:02:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 115/1 [0m                       

                       Computation: 758283 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 98.76
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 22.3787
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3880
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 104.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 0.13s
                      Time elapsed: 00:02:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 116/1 [0m                       

                       Computation: 780120 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 103.99
               Mean episode length: 236.90
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 21.6139
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3888
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 0.13s
                      Time elapsed: 00:02:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 117/1 [0m                       

                       Computation: 808932 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 94.99
               Mean episode length: 231.49
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 17.7241
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3486
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 0.12s
                      Time elapsed: 00:02:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 118/1 [0m                       

                       Computation: 799652 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 95.52
               Mean episode length: 224.06
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 18.6077
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3521
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 0.12s
                      Time elapsed: 00:02:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 119/1 [0m                       

                       Computation: 790143 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 104.18
               Mean episode length: 230.72
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 20.7346
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3730
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 0.12s
                      Time elapsed: 00:02:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 120/1 [0m                       

                       Computation: 764876 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 102.88
               Mean episode length: 238.70
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 20.3667
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3817
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 0.13s
                      Time elapsed: 00:02:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 121/1 [0m                       

                       Computation: 786138 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 105.38
               Mean episode length: 238.74
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 20.9623
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3756
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 0.13s
                      Time elapsed: 00:02:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 122/1 [0m                       

                       Computation: 710639 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 104.40
               Mean episode length: 238.30
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 20.1929
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3735
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 0.14s
                      Time elapsed: 00:02:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 123/1 [0m                       

                       Computation: 720056 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 109.32
               Mean episode length: 243.41
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 21.7022
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3906
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 0.14s
                      Time elapsed: 00:02:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 124/1 [0m                       

                       Computation: 698853 steps/s (collection: 0.048s, learning 0.093s)
                       Mean reward: 105.52
               Mean episode length: 242.87
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 20.8028
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3918
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 0.14s
                      Time elapsed: 00:02:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 125/1 [0m                       

                       Computation: 738584 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 115.17
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 21.6738
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3932
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 101.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 0.13s
                      Time elapsed: 00:02:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 126/1 [0m                       

                       Computation: 580084 steps/s (collection: 0.053s, learning 0.117s)
                       Mean reward: 102.43
               Mean episode length: 231.30
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 19.5817
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3555
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 0.17s
                      Time elapsed: 00:02:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 127/1 [0m                       

                       Computation: 747634 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 114.15
               Mean episode length: 229.06
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 22.0843
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3732
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 0.13s
                      Time elapsed: 00:02:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 128/1 [0m                       

                       Computation: 661664 steps/s (collection: 0.044s, learning 0.105s)
                       Mean reward: 106.27
               Mean episode length: 229.01
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 21.1784
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3802
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 0.15s
                      Time elapsed: 00:02:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 129/1 [0m                       

                       Computation: 707265 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 109.05
               Mean episode length: 227.11
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 21.1891
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3726
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 0.14s
                      Time elapsed: 00:02:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 130/1 [0m                       

                       Computation: 627181 steps/s (collection: 0.044s, learning 0.112s)
                       Mean reward: 120.87
               Mean episode length: 237.36
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 23.6633
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3873
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 0.16s
                      Time elapsed: 00:02:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 131/1 [0m                       

                       Computation: 669577 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 128.37
               Mean episode length: 239.05
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 25.1798
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3947
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 0.15s
                      Time elapsed: 00:02:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 132/1 [0m                       

                       Computation: 608540 steps/s (collection: 0.040s, learning 0.122s)
                       Mean reward: 128.47
               Mean episode length: 239.56
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 25.3490
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.4027
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 0.16s
                      Time elapsed: 00:02:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 133/1 [0m                       

                       Computation: 636143 steps/s (collection: 0.043s, learning 0.112s)
                       Mean reward: 126.20
               Mean episode length: 239.80
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 24.7632
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3990
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 0.15s
                      Time elapsed: 00:02:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 134/1 [0m                       

                       Computation: 769595 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 124.70
               Mean episode length: 241.56
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 24.0093
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.4002
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 0.13s
                      Time elapsed: 00:02:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 135/1 [0m                       

                       Computation: 714662 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 133.81
               Mean episode length: 242.17
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 26.3773
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.4061
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 0.14s
                      Time elapsed: 00:02:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 136/1 [0m                       

                       Computation: 673098 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 131.67
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 25.3226
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.4010
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 92.6667
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 0.15s
                      Time elapsed: 00:02:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 137/1 [0m                       

                       Computation: 803094 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 134.59
               Mean episode length: 237.16
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 26.6528
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3970
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 0.12s
                      Time elapsed: 00:02:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 138/1 [0m                       

                       Computation: 769628 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 125.35
               Mean episode length: 228.16
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 24.6247
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3817
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 0.13s
                      Time elapsed: 00:02:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 139/1 [0m                       

                       Computation: 768028 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 126.11
               Mean episode length: 229.99
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 24.7346
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3860
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 0.13s
                      Time elapsed: 00:02:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 140/1 [0m                       

                       Computation: 777010 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 139.76
               Mean episode length: 239.30
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 27.8606
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4069
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 0.13s
                      Time elapsed: 00:02:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 141/1 [0m                       

                       Computation: 707177 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 138.68
               Mean episode length: 243.89
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 27.7393
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4144
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 0.14s
                      Time elapsed: 00:02:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 142/1 [0m                       

                       Computation: 778360 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 140.84
               Mean episode length: 242.19
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 27.6978
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4048
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 0.13s
                      Time elapsed: 00:02:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 143/1 [0m                       

                       Computation: 792453 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 143.09
               Mean episode length: 245.27
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 28.0803
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4118
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 0.12s
                      Time elapsed: 00:02:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 144/1 [0m                       

                       Computation: 756060 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 145.69
               Mean episode length: 245.03
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 28.5582
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4106
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 0.13s
                      Time elapsed: 00:02:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 145/1 [0m                       

                       Computation: 701959 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 147.10
               Mean episode length: 246.69
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 29.3490
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4090
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 0.14s
                      Time elapsed: 00:02:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 146/1 [0m                       

                       Computation: 717844 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 154.16
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.8372
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4123
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 91.1250
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 0.14s
                      Time elapsed: 00:02:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 147/1 [0m                       

                       Computation: 687652 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 146.92
               Mean episode length: 241.65
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.1783
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4033
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 0.14s
                      Time elapsed: 00:02:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 148/1 [0m                       

                       Computation: 749913 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 157.16
               Mean episode length: 242.04
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 31.0444
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4065
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 0.13s
                      Time elapsed: 00:02:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 149/1 [0m                       

                       Computation: 659632 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 150.52
               Mean episode length: 239.72
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.0899
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3946
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 0.15s
                      Time elapsed: 00:02:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 150/1 [0m                       

                       Computation: 789493 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 153.45
               Mean episode length: 242.77
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 30.4315
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4082
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 0.12s
                      Time elapsed: 00:02:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 151/1 [0m                       

                       Computation: 784888 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 149.55
               Mean episode length: 239.35
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.3739
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3959
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 0.13s
                      Time elapsed: 00:02:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 152/1 [0m                       

                       Computation: 798990 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 147.92
               Mean episode length: 240.43
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.3988
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3959
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 0.12s
                      Time elapsed: 00:02:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 153/1 [0m                       

                       Computation: 668551 steps/s (collection: 0.058s, learning 0.089s)
                       Mean reward: 150.57
               Mean episode length: 245.29
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.6649
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4014
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 0.15s
                      Time elapsed: 00:02:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 154/1 [0m                       

                       Computation: 812680 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 158.43
               Mean episode length: 245.69
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 31.3643
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4075
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 0.12s
                      Time elapsed: 00:02:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 155/1 [0m                       

                       Computation: 748309 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 155.38
               Mean episode length: 245.04
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 30.5031
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4062
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 0.13s
                      Time elapsed: 00:02:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 156/1 [0m                       

                       Computation: 667617 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 160.65
               Mean episode length: 243.88
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 31.1277
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4059
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 0.15s
                      Time elapsed: 00:02:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 157/1 [0m                       

                       Computation: 644567 steps/s (collection: 0.039s, learning 0.114s)
                       Mean reward: 163.12
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 33.0920
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4205
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 84.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 0.15s
                      Time elapsed: 00:02:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 158/1 [0m                       

                       Computation: 730397 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 150.63
               Mean episode length: 237.77
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.0994
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3912
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 0.13s
                      Time elapsed: 00:02:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 159/1 [0m                       

                       Computation: 674807 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 162.55
               Mean episode length: 244.98
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 31.4599
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4144
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 0.15s
                      Time elapsed: 00:02:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 160/1 [0m                       

                       Computation: 646461 steps/s (collection: 0.046s, learning 0.106s)
                       Mean reward: 156.68
               Mean episode length: 245.04
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 31.0377
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4072
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 0.15s
                      Time elapsed: 00:02:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 161/1 [0m                       

                       Computation: 765787 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 172.88
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 34.2373
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4200
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 0.13s
                      Time elapsed: 00:03:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 162/1 [0m                       

                       Computation: 728565 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 177.35
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 35.4747
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4211
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 0.13s
                      Time elapsed: 00:03:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 163/1 [0m                       

                       Computation: 762696 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 174.60
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 34.4288
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4213
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 0.13s
                      Time elapsed: 00:03:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 164/1 [0m                       

                       Computation: 790537 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 175.50
               Mean episode length: 246.82
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 34.5677
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4175
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 0.12s
                      Time elapsed: 00:03:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 165/1 [0m                       

                       Computation: 730701 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 173.39
               Mean episode length: 245.60
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 33.7440
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4134
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 0.13s
                      Time elapsed: 00:03:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 166/1 [0m                       

                       Computation: 725365 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 181.37
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 35.5221
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4194
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 0.14s
                      Time elapsed: 00:03:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 167/1 [0m                       

                       Computation: 704599 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 185.50
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 33.8149
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4054
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 86.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 0.14s
                      Time elapsed: 00:03:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 168/1 [0m                       

                       Computation: 688353 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 167.42
               Mean episode length: 241.69
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 33.4383
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4184
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 0.14s
                      Time elapsed: 00:03:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 169/1 [0m                       

                       Computation: 727238 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 180.42
               Mean episode length: 246.92
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 35.8184
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 0.14s
                      Time elapsed: 00:03:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 170/1 [0m                       

                       Computation: 763855 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 183.03
               Mean episode length: 246.56
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 36.1387
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4213
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 0.13s
                      Time elapsed: 00:03:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 171/1 [0m                       

                       Computation: 719992 steps/s (collection: 0.048s, learning 0.088s)
                       Mean reward: 181.42
               Mean episode length: 245.63
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 35.3899
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4146
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 0.14s
                      Time elapsed: 00:03:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 172/1 [0m                       

                       Computation: 782200 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 189.82
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 37.8378
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 0.13s
                      Time elapsed: 00:03:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 173/1 [0m                       

                       Computation: 788533 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 187.55
               Mean episode length: 245.33
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 37.2442
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4198
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 0.12s
                      Time elapsed: 00:03:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 174/1 [0m                       

                       Computation: 815729 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 191.80
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 38.1099
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 0.12s
                      Time elapsed: 00:03:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 175/1 [0m                       

                       Computation: 733503 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 184.64
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 35.5906
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4235
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 0.13s
                      Time elapsed: 00:03:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 176/1 [0m                       

                       Computation: 792549 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 189.79
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 37.3903
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4248
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 0.12s
                      Time elapsed: 00:03:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 177/1 [0m                       

                       Computation: 741942 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 198.08
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 39.0753
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 0.13s
                      Time elapsed: 00:03:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 178/1 [0m                       

                       Computation: 768360 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 195.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 39.8940
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 80.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 0.13s
                      Time elapsed: 00:03:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 179/1 [0m                       

                       Computation: 725103 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 183.16
               Mean episode length: 244.22
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 37.1575
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 0.14s
                      Time elapsed: 00:03:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 180/1 [0m                       

                       Computation: 736781 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 192.19
               Mean episode length: 243.10
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 38.2690
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4208
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 0.13s
                      Time elapsed: 00:03:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 181/1 [0m                       

                       Computation: 750905 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 193.19
               Mean episode length: 245.72
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 38.3518
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4200
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 0.13s
                      Time elapsed: 00:03:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 182/1 [0m                       

                       Computation: 789434 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 190.94
               Mean episode length: 246.86
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 37.7707
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4214
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 0.12s
                      Time elapsed: 00:03:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 183/1 [0m                       

                       Computation: 714794 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 191.18
               Mean episode length: 244.63
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 38.0154
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4194
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 0.14s
                      Time elapsed: 00:03:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 184/1 [0m                       

                       Computation: 588117 steps/s (collection: 0.055s, learning 0.113s)
                       Mean reward: 193.91
               Mean episode length: 246.69
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 38.2656
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4249
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 0.17s
                      Time elapsed: 00:03:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 185/1 [0m                       

                       Computation: 604812 steps/s (collection: 0.040s, learning 0.123s)
                       Mean reward: 199.78
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 39.4479
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 0.16s
                      Time elapsed: 00:03:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 186/1 [0m                       

                       Computation: 684630 steps/s (collection: 0.048s, learning 0.096s)
                       Mean reward: 195.52
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 38.5016
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 0.14s
                      Time elapsed: 00:03:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 187/1 [0m                       

                       Computation: 712820 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 202.79
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 40.1227
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 0.14s
                      Time elapsed: 00:03:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 188/1 [0m                       

                       Computation: 714810 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 202.19
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 40.9747
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 82.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 0.14s
                      Time elapsed: 00:03:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 189/1 [0m                       

                       Computation: 675369 steps/s (collection: 0.048s, learning 0.098s)
                       Mean reward: 211.80
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.2183
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 0.15s
                      Time elapsed: 00:03:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 190/1 [0m                       

                       Computation: 614164 steps/s (collection: 0.047s, learning 0.113s)
                       Mean reward: 208.94
               Mean episode length: 244.27
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 41.6841
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4251
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 0.16s
                      Time elapsed: 00:03:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 191/1 [0m                       

                       Computation: 674969 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 201.36
               Mean episode length: 245.98
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 39.4106
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.4220
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 0.15s
                      Time elapsed: 00:03:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 192/1 [0m                       

                       Computation: 652047 steps/s (collection: 0.052s, learning 0.099s)
                       Mean reward: 207.32
               Mean episode length: 246.80
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 40.7010
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 0.15s
                      Time elapsed: 00:03:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 193/1 [0m                       

                       Computation: 639970 steps/s (collection: 0.051s, learning 0.103s)
                       Mean reward: 199.53
               Mean episode length: 245.73
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 39.4682
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4258
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 0.15s
                      Time elapsed: 00:03:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 194/1 [0m                       

                       Computation: 709486 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 213.65
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.3257
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 0.14s
                      Time elapsed: 00:03:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 195/1 [0m                       

                       Computation: 727993 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 207.78
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 41.3998
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 0.14s
                      Time elapsed: 00:03:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 196/1 [0m                       

                       Computation: 763812 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 215.01
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.7772
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 0.13s
                      Time elapsed: 00:03:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 197/1 [0m                       

                       Computation: 707195 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 213.19
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.5582
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 0.14s
                      Time elapsed: 00:03:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 198/1 [0m                       

                       Computation: 682955 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 215.07
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 43.4419
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4388
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 84.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 0.14s
                      Time elapsed: 00:03:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 199/1 [0m                       

                       Computation: 650827 steps/s (collection: 0.047s, learning 0.104s)
                       Mean reward: 217.51
               Mean episode length: 241.84
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 43.6467
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 0.15s
                      Time elapsed: 00:03:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 200/1 [0m                       

                       Computation: 638106 steps/s (collection: 0.041s, learning 0.113s)
                       Mean reward: 203.57
               Mean episode length: 244.37
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 40.9594
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 0.15s
                      Time elapsed: 00:03:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 201/1 [0m                       

                       Computation: 680632 steps/s (collection: 0.053s, learning 0.092s)
                       Mean reward: 213.46
               Mean episode length: 246.32
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 42.1702
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 0.14s
                      Time elapsed: 00:03:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 202/1 [0m                       

                       Computation: 659414 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 211.09
               Mean episode length: 243.97
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 41.1626
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4253
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 0.15s
                      Time elapsed: 00:03:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 203/1 [0m                       

                       Computation: 682196 steps/s (collection: 0.045s, learning 0.099s)
                       Mean reward: 221.72
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.0076
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 0.14s
                      Time elapsed: 00:03:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 204/1 [0m                       

                       Computation: 699532 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 215.86
               Mean episode length: 246.73
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 42.5655
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 0.14s
                      Time elapsed: 00:03:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 205/1 [0m                       

                       Computation: 731823 steps/s (collection: 0.049s, learning 0.085s)
                       Mean reward: 213.17
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.2680
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 0.13s
                      Time elapsed: 00:03:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 206/1 [0m                       

                       Computation: 576360 steps/s (collection: 0.059s, learning 0.112s)
                       Mean reward: 225.43
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.7914
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4410
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 0.17s
                      Time elapsed: 00:03:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 207/1 [0m                       

                       Computation: 674370 steps/s (collection: 0.048s, learning 0.098s)
                       Mean reward: 216.35
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.7703
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 0.15s
                      Time elapsed: 00:03:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 208/1 [0m                       

                       Computation: 568169 steps/s (collection: 0.049s, learning 0.124s)
                       Mean reward: 226.75
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.9906
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4420
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 0.17s
                      Time elapsed: 00:03:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 209/1 [0m                       

                       Computation: 563232 steps/s (collection: 0.039s, learning 0.136s)
                       Mean reward: 224.52
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.0327
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4462
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 78.8333
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 0.17s
                      Time elapsed: 00:03:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 210/1 [0m                       

                       Computation: 517249 steps/s (collection: 0.053s, learning 0.137s)
                       Mean reward: 223.56
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 42.5228
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 0.19s
                      Time elapsed: 00:03:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 211/1 [0m                       

                       Computation: 577968 steps/s (collection: 0.050s, learning 0.121s)
                       Mean reward: 225.44
               Mean episode length: 247.02
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.6437
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4402
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 0.17s
                      Time elapsed: 00:04:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 212/1 [0m                       

                       Computation: 578171 steps/s (collection: 0.052s, learning 0.118s)
                       Mean reward: 226.56
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 44.7463
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 0.17s
                      Time elapsed: 00:04:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 213/1 [0m                       

                       Computation: 510962 steps/s (collection: 0.056s, learning 0.137s)
                       Mean reward: 230.35
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.5485
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 0.19s
                      Time elapsed: 00:04:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 214/1 [0m                       

                       Computation: 668628 steps/s (collection: 0.049s, learning 0.099s)
                       Mean reward: 227.89
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.2585
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 0.15s
                      Time elapsed: 00:04:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 215/1 [0m                       

                       Computation: 761644 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 232.21
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.3774
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4449
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 0.13s
                      Time elapsed: 00:04:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 216/1 [0m                       

                       Computation: 763722 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 233.97
               Mean episode length: 247.28
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 46.2856
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4421
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 0.13s
                      Time elapsed: 00:04:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 217/1 [0m                       

                       Computation: 753658 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 228.57
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.6185
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 0.13s
                      Time elapsed: 00:04:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 218/1 [0m                       

                       Computation: 773885 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 235.38
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.5488
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 0.13s
                      Time elapsed: 00:04:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 219/1 [0m                       

                       Computation: 777984 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 237.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.4003
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4460
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 81.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 0.13s
                      Time elapsed: 00:04:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 220/1 [0m                       

                       Computation: 768826 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 228.87
               Mean episode length: 245.28
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 44.2589
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4371
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 0.13s
                      Time elapsed: 00:04:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 221/1 [0m                       

                       Computation: 667013 steps/s (collection: 0.048s, learning 0.099s)
                       Mean reward: 241.13
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.0991
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 0.15s
                      Time elapsed: 00:04:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 222/1 [0m                       

                       Computation: 722332 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 234.63
               Mean episode length: 247.15
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.4609
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 0.14s
                      Time elapsed: 00:04:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 223/1 [0m                       

                       Computation: 786349 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 230.59
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 45.6080
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 0.13s
                      Time elapsed: 00:04:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 224/1 [0m                       

                       Computation: 783267 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 236.06
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.4965
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 0.13s
                      Time elapsed: 00:04:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 225/1 [0m                       

                       Computation: 765432 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 236.61
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.0168
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4450
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 0.13s
                      Time elapsed: 00:04:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 226/1 [0m                       

                       Computation: 724183 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 233.40
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 46.2290
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 0.14s
                      Time elapsed: 00:04:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 227/1 [0m                       

                       Computation: 778945 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 243.33
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.9995
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4425
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 0.13s
                      Time elapsed: 00:04:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 228/1 [0m                       

                       Computation: 731829 steps/s (collection: 0.051s, learning 0.084s)
                       Mean reward: 240.77
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.9025
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4455
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 0.13s
                      Time elapsed: 00:04:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 229/1 [0m                       

                       Computation: 783936 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 243.48
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.6978
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4442
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 0.13s
                      Time elapsed: 00:04:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 230/1 [0m                       

                       Computation: 725197 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 242.02
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 49.6699
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4447
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 76.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 0.14s
                      Time elapsed: 00:04:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 231/1 [0m                       

                       Computation: 686435 steps/s (collection: 0.047s, learning 0.097s)
                       Mean reward: 229.82
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 45.2767
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 0.14s
                      Time elapsed: 00:04:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 232/1 [0m                       

                       Computation: 789296 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 238.99
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.4274
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 0.12s
                      Time elapsed: 00:04:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 233/1 [0m                       

                       Computation: 722723 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 240.52
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.4725
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 0.14s
                      Time elapsed: 00:04:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 234/1 [0m                       

                       Computation: 733515 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 244.79
               Mean episode length: 246.29
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.2844
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 0.13s
                      Time elapsed: 00:04:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 235/1 [0m                       

                       Computation: 738563 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 245.32
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.5060
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 0.13s
                      Time elapsed: 00:04:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 236/1 [0m                       

                       Computation: 732495 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 244.72
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.4502
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 0.13s
                      Time elapsed: 00:04:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 237/1 [0m                       

                       Computation: 727999 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 241.23
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.6755
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4446
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 0.14s
                      Time elapsed: 00:04:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 238/1 [0m                       

                       Computation: 712216 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 242.97
               Mean episode length: 247.05
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.1405
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 0.14s
                      Time elapsed: 00:04:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 239/1 [0m                       

                       Computation: 666334 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 240.65
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.1846
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4421
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 0.15s
                      Time elapsed: 00:04:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 240/1 [0m                       

                       Computation: 719378 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 245.24
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 47.9443
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4402
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 78.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 0.14s
                      Time elapsed: 00:04:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 241/1 [0m                       

                       Computation: 678336 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 241.02
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.7422
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 0.14s
                      Time elapsed: 00:04:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 242/1 [0m                       

                       Computation: 766203 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 248.95
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.7795
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 0.13s
                      Time elapsed: 00:04:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 243/1 [0m                       

                       Computation: 705677 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 237.14
               Mean episode length: 244.16
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 47.1891
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 0.14s
                      Time elapsed: 00:04:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 244/1 [0m                       

                       Computation: 742952 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 244.24
               Mean episode length: 245.87
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.1186
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 0.13s
                      Time elapsed: 00:04:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 245/1 [0m                       

                       Computation: 691346 steps/s (collection: 0.045s, learning 0.097s)
                       Mean reward: 251.83
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 49.9373
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 0.14s
                      Time elapsed: 00:04:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 246/1 [0m                       

                       Computation: 822446 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 244.18
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 48.6295
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4455
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 0.12s
                      Time elapsed: 00:04:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 247/1 [0m                       

                       Computation: 795358 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 245.26
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.5615
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4457
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 0.12s
                      Time elapsed: 00:04:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 248/1 [0m                       

                       Computation: 780897 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 246.67
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.7824
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 0.13s
                      Time elapsed: 00:04:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 249/1 [0m                       

                       Computation: 709900 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 255.81
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.7637
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4518
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 0.14s
                      Time elapsed: 00:04:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 250/1 [0m                       

                       Computation: 737782 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 250.69
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 49.8197
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4481
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 81.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 0.13s
                      Time elapsed: 00:04:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 251/1 [0m                       

                       Computation: 781680 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 250.22
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.1489
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4484
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 0.13s
                      Time elapsed: 00:04:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 252/1 [0m                       

                       Computation: 770439 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 248.62
               Mean episode length: 245.41
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 49.0956
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 0.13s
                      Time elapsed: 00:04:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 253/1 [0m                       

                       Computation: 758962 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 251.75
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.0598
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4475
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 0.13s
                      Time elapsed: 00:04:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 254/1 [0m                       

                       Computation: 789520 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 254.65
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 50.5835
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4502
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 0.12s
                      Time elapsed: 00:04:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 255/1 [0m                       

                       Computation: 730823 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 255.55
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 50.4632
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 0.13s
                      Time elapsed: 00:04:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 256/1 [0m                       

                       Computation: 756000 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 260.11
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.7286
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4513
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 0.13s
                      Time elapsed: 00:04:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 257/1 [0m                       

                       Computation: 733542 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 268.00
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.2806
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4572
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 0.13s
                      Time elapsed: 00:04:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 258/1 [0m                       

                       Computation: 696548 steps/s (collection: 0.042s, learning 0.100s)
                       Mean reward: 258.27
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.0517
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4498
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 0.14s
                      Time elapsed: 00:04:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 259/1 [0m                       

                       Computation: 686801 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 267.55
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 53.2072
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4557
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 0.14s
                      Time elapsed: 00:04:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 260/1 [0m                       

                       Computation: 673776 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 269.29
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.3908
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4529
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 0.15s
                      Time elapsed: 00:04:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 261/1 [0m                       

                       Computation: 745290 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 271.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.1447
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4662
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 75.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 0.13s
                      Time elapsed: 00:04:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 262/1 [0m                       

                       Computation: 760823 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 268.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.5378
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4508
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 0.13s
                      Time elapsed: 00:04:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 263/1 [0m                       

                       Computation: 759018 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 267.76
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.6084
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4546
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 0.13s
                      Time elapsed: 00:04:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 264/1 [0m                       

                       Computation: 796470 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 274.35
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.8862
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4542
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 0.12s
                      Time elapsed: 00:05:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 265/1 [0m                       

                       Computation: 738285 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 269.28
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 53.4618
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4568
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 0.13s
                      Time elapsed: 00:05:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 266/1 [0m                       

                       Computation: 689580 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 275.47
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.4773
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4602
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 0.14s
                      Time elapsed: 00:05:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 267/1 [0m                       

                       Computation: 714355 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 271.69
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.9629
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4547
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 0.14s
                      Time elapsed: 00:05:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 268/1 [0m                       

                       Computation: 722387 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 273.68
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 54.0584
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4581
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 0.14s
                      Time elapsed: 00:05:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 269/1 [0m                       

                       Computation: 666054 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 275.05
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 54.7981
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4580
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 0.15s
                      Time elapsed: 00:05:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 270/1 [0m                       

                       Computation: 708861 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 272.01
               Mean episode length: 247.37
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.5150
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4547
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 0.14s
                      Time elapsed: 00:05:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 271/1 [0m                       

                       Computation: 696677 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 275.54
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 52.9986
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4525
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 78.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 0.14s
                      Time elapsed: 00:05:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 272/1 [0m                       

                       Computation: 672897 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 282.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 55.7833
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4622
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 0.15s
                      Time elapsed: 00:05:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 273/1 [0m                       

                       Computation: 681988 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 286.24
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.2091
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4635
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 0.14s
                      Time elapsed: 00:05:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 274/1 [0m                       

                       Computation: 709220 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 276.13
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.4225
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4617
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 0.14s
                      Time elapsed: 00:05:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 275/1 [0m                       

                       Computation: 639574 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 269.39
               Mean episode length: 246.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.5768
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4528
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 0.15s
                      Time elapsed: 00:05:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 276/1 [0m                       

                       Computation: 761727 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 276.47
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.8585
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4604
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 0.13s
                      Time elapsed: 00:05:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 277/1 [0m                       

                       Computation: 608462 steps/s (collection: 0.049s, learning 0.113s)
                       Mean reward: 275.76
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 54.8453
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4637
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 0.16s
                      Time elapsed: 00:05:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 278/1 [0m                       

                       Computation: 608145 steps/s (collection: 0.044s, learning 0.118s)
                       Mean reward: 281.54
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.1414
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4632
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 0.16s
                      Time elapsed: 00:05:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 279/1 [0m                       

                       Computation: 650730 steps/s (collection: 0.043s, learning 0.109s)
                       Mean reward: 279.36
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 55.6273
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4611
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 0.15s
                      Time elapsed: 00:05:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 280/1 [0m                       

                       Computation: 652868 steps/s (collection: 0.048s, learning 0.103s)
                       Mean reward: 275.27
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.7097
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4543
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 0.15s
                      Time elapsed: 00:05:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 281/1 [0m                       

                       Computation: 684433 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 276.76
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.0205
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4601
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 0.14s
                      Time elapsed: 00:05:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 282/1 [0m                       

                       Computation: 709186 steps/s (collection: 0.036s, learning 0.103s)
                       Mean reward: 277.87
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 48.9349
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 73.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 0.14s
                      Time elapsed: 00:05:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 283/1 [0m                       

                       Computation: 722332 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 288.16
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.6906
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4540
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 0.14s
                      Time elapsed: 00:05:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 284/1 [0m                       

                       Computation: 657560 steps/s (collection: 0.039s, learning 0.110s)
                       Mean reward: 289.53
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.1102
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4620
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 0.15s
                      Time elapsed: 00:05:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 285/1 [0m                       

                       Computation: 689103 steps/s (collection: 0.047s, learning 0.096s)
                       Mean reward: 282.84
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.2983
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4622
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 0.14s
                      Time elapsed: 00:05:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 286/1 [0m                       

                       Computation: 648642 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 281.50
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.9392
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4587
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 0.15s
                      Time elapsed: 00:05:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 287/1 [0m                       

                       Computation: 701777 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 291.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 57.8522
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4673
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 0.14s
                      Time elapsed: 00:05:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 288/1 [0m                       

                       Computation: 677552 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 283.49
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.1758
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4662
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 0.15s
                      Time elapsed: 00:05:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 289/1 [0m                       

                       Computation: 698954 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 283.08
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.0833
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4630
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 0.14s
                      Time elapsed: 00:05:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 290/1 [0m                       

                       Computation: 646221 steps/s (collection: 0.052s, learning 0.101s)
                       Mean reward: 279.73
               Mean episode length: 247.42
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.5908
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4606
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 0.15s
                      Time elapsed: 00:05:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 291/1 [0m                       

                       Computation: 746585 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 280.55
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.3717
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4587
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 0.13s
                      Time elapsed: 00:05:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 292/1 [0m                       

                       Computation: 794296 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 285.06
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.0602
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4600
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 75.8750
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 0.12s
                      Time elapsed: 00:05:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 293/1 [0m                       

                       Computation: 688096 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 276.27
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.0133
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4554
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 0.14s
                      Time elapsed: 00:05:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 294/1 [0m                       

                       Computation: 666265 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 277.13
               Mean episode length: 245.04
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.8218
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4497
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 0.15s
                      Time elapsed: 00:05:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 295/1 [0m                       

                       Computation: 696985 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 280.92
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.7867
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4611
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 0.14s
                      Time elapsed: 00:05:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 296/1 [0m                       

                       Computation: 661769 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 272.01
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.9955
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4509
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 0.15s
                      Time elapsed: 00:05:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 297/1 [0m                       

                       Computation: 689420 steps/s (collection: 0.039s, learning 0.104s)
                       Mean reward: 273.77
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.1094
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4565
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 0.14s
                      Time elapsed: 00:05:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 298/1 [0m                       

                       Computation: 763245 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 278.81
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.3698
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4564
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 0.13s
                      Time elapsed: 00:05:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 299/1 [0m                       

                       Computation: 691668 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 281.07
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.8229
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4570
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 0.14s
                      Time elapsed: 00:05:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 300/1 [0m                       

                       Computation: 726294 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 278.66
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.4337
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4587
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 0.14s
                      Time elapsed: 00:05:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 301/1 [0m                       

                       Computation: 768324 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 278.81
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.0686
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4582
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 0.13s
                      Time elapsed: 00:05:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 302/1 [0m                       

                       Computation: 774087 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 280.84
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.4437
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4565
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 0.13s
                      Time elapsed: 00:05:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 303/1 [0m                       

                       Computation: 732837 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 282.27
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.0084
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4526
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 71.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 0.13s
                      Time elapsed: 00:05:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 304/1 [0m                       

                       Computation: 828855 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 273.07
               Mean episode length: 245.78
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 53.3347
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4450
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 0.12s
                      Time elapsed: 00:05:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 305/1 [0m                       

                       Computation: 799133 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 289.56
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.9931
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4648
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 0.12s
                      Time elapsed: 00:05:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 306/1 [0m                       

                       Computation: 689368 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 283.01
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.3636
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4563
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 0.14s
                      Time elapsed: 00:05:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 307/1 [0m                       

                       Computation: 832791 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 286.60
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.9904
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4598
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 0.12s
                      Time elapsed: 00:05:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 308/1 [0m                       

                       Computation: 760496 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 289.39
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.6690
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4619
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 0.13s
                      Time elapsed: 00:05:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 309/1 [0m                       

                       Computation: 711060 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 285.48
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.5834
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4606
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 0.14s
                      Time elapsed: 00:05:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 310/1 [0m                       

                       Computation: 729186 steps/s (collection: 0.048s, learning 0.087s)
                       Mean reward: 291.69
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.9633
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4612
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 0.13s
                      Time elapsed: 00:05:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 311/1 [0m                       

                       Computation: 701350 steps/s (collection: 0.046s, learning 0.094s)
                       Mean reward: 281.99
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.9421
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4591
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 0.14s
                      Time elapsed: 00:05:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 312/1 [0m                       

                       Computation: 687769 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 285.32
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.4788
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4570
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 0.14s
                      Time elapsed: 00:05:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 313/1 [0m                       

                       Computation: 774536 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 286.69
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 55.8637
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4554
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 74.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 0.13s
                      Time elapsed: 00:05:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 314/1 [0m                       

                       Computation: 764811 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 282.88
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.8904
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4586
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 0.13s
                      Time elapsed: 00:05:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 315/1 [0m                       

                       Computation: 820113 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 294.98
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.7879
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4628
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 0.12s
                      Time elapsed: 00:05:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 316/1 [0m                       

                       Computation: 802733 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 293.64
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.5199
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4583
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 0.12s
                      Time elapsed: 00:05:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 317/1 [0m                       

                       Computation: 727271 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 293.20
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.2749
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4603
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 0.14s
                      Time elapsed: 00:05:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 318/1 [0m                       

                       Computation: 805701 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 293.26
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.0648
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4632
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 0.12s
                      Time elapsed: 00:06:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 319/1 [0m                       

                       Computation: 731479 steps/s (collection: 0.050s, learning 0.085s)
                       Mean reward: 291.62
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.6811
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4574
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 0.13s
                      Time elapsed: 00:06:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 320/1 [0m                       

                       Computation: 719715 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 295.55
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.9220
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4637
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 0.14s
                      Time elapsed: 00:06:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 321/1 [0m                       

                       Computation: 645618 steps/s (collection: 0.047s, learning 0.105s)
                       Mean reward: 291.15
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.9609
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4566
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 0.15s
                      Time elapsed: 00:06:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 322/1 [0m                       

                       Computation: 699331 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 295.62
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.4144
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4624
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 0.14s
                      Time elapsed: 00:06:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 323/1 [0m                       

                       Computation: 760444 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 298.51
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.0189
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4557
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 76.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 0.13s
                      Time elapsed: 00:06:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 324/1 [0m                       

                       Computation: 707159 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 301.18
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 61.2911
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4663
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 0.14s
                      Time elapsed: 00:06:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 325/1 [0m                       

                       Computation: 673228 steps/s (collection: 0.041s, learning 0.106s)
                       Mean reward: 301.08
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.1517
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4690
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 0.15s
                      Time elapsed: 00:06:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 326/1 [0m                       

                       Computation: 767825 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 297.11
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.8519
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4608
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 0.13s
                      Time elapsed: 00:06:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 327/1 [0m                       

                       Computation: 783135 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 303.64
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.6347
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4613
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 0.13s
                      Time elapsed: 00:06:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 328/1 [0m                       

                       Computation: 802257 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 302.27
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.8808
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4625
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 0.12s
                      Time elapsed: 00:06:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 329/1 [0m                       

                       Computation: 787934 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 296.25
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.1487
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4635
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 0.12s
                      Time elapsed: 00:06:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 330/1 [0m                       

                       Computation: 747472 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 300.80
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.6370
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4617
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 0.13s
                      Time elapsed: 00:06:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 331/1 [0m                       

                       Computation: 805580 steps/s (collection: 0.045s, learning 0.078s)
                       Mean reward: 298.60
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.2050
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4592
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 0.12s
                      Time elapsed: 00:06:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 332/1 [0m                       

                       Computation: 770376 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 291.54
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.6988
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4575
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 0.13s
                      Time elapsed: 00:06:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 333/1 [0m                       

                       Computation: 829276 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 293.87
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.0976
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4557
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 0.12s
                      Time elapsed: 00:06:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 334/1 [0m                       

                       Computation: 813182 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 295.80
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.9252
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 71.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 0.12s
                      Time elapsed: 00:06:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 335/1 [0m                       

                       Computation: 748916 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 298.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 59.3908
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4617
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 0.13s
                      Time elapsed: 00:06:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 336/1 [0m                       

                       Computation: 736244 steps/s (collection: 0.049s, learning 0.085s)
                       Mean reward: 292.28
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.0636
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4522
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 0.13s
                      Time elapsed: 00:06:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 337/1 [0m                       

                       Computation: 825933 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 301.00
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.6298
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4577
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 0.12s
                      Time elapsed: 00:06:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 338/1 [0m                       

                       Computation: 760975 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 295.78
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.6415
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4592
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 0.13s
                      Time elapsed: 00:06:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 339/1 [0m                       

                       Computation: 792437 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 302.54
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.5004
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4606
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 0.12s
                      Time elapsed: 00:06:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 340/1 [0m                       

                       Computation: 755840 steps/s (collection: 0.047s, learning 0.084s)
                       Mean reward: 299.39
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.5126
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4608
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 0.13s
                      Time elapsed: 00:06:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 341/1 [0m                       

                       Computation: 808846 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 304.57
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.4714
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4615
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 0.12s
                      Time elapsed: 00:06:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 342/1 [0m                       

                       Computation: 733375 steps/s (collection: 0.045s, learning 0.090s)
                       Mean reward: 300.24
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.4107
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4565
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 0.13s
                      Time elapsed: 00:06:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 343/1 [0m                       

                       Computation: 735423 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 301.47
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.5824
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4585
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 0.13s
                      Time elapsed: 00:06:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 344/1 [0m                       

                       Computation: 730194 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 304.70
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.5539
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4606
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 73.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 0.13s
                      Time elapsed: 00:06:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 345/1 [0m                       

                       Computation: 700039 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 307.29
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.1933
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4613
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 0.14s
                      Time elapsed: 00:06:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 346/1 [0m                       

                       Computation: 679682 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 308.15
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.3779
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4570
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 0.14s
                      Time elapsed: 00:06:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 347/1 [0m                       

                       Computation: 677765 steps/s (collection: 0.052s, learning 0.094s)
                       Mean reward: 297.21
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.3165
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4592
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 0.15s
                      Time elapsed: 00:06:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 348/1 [0m                       

                       Computation: 699325 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 292.10
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.1403
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4526
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 0.14s
                      Time elapsed: 00:06:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 349/1 [0m                       

                       Computation: 666267 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 306.56
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.8423
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4568
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 0.15s
                      Time elapsed: 00:06:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 350/1 [0m                       

                       Computation: 666106 steps/s (collection: 0.046s, learning 0.102s)
                       Mean reward: 297.17
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.8668
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4538
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 0.15s
                      Time elapsed: 00:06:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 351/1 [0m                       

                       Computation: 684844 steps/s (collection: 0.040s, learning 0.104s)
                       Mean reward: 303.48
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.2212
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4554
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 0.14s
                      Time elapsed: 00:06:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 352/1 [0m                       

                       Computation: 535623 steps/s (collection: 0.059s, learning 0.125s)
                       Mean reward: 304.08
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.8423
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4559
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 0.18s
                      Time elapsed: 00:06:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 353/1 [0m                       

                       Computation: 709716 steps/s (collection: 0.052s, learning 0.087s)
                       Mean reward: 301.62
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.6036
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4549
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 0.14s
                      Time elapsed: 00:06:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 354/1 [0m                       

                       Computation: 719970 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 305.68
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.1141
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4572
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 0.14s
                      Time elapsed: 00:06:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 355/1 [0m                       

                       Computation: 772301 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 309.30
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.9161
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4545
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 68.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 0.13s
                      Time elapsed: 00:06:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 356/1 [0m                       

                       Computation: 721739 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 301.05
               Mean episode length: 246.06
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.0802
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4546
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 0.14s
                      Time elapsed: 00:06:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 357/1 [0m                       

                       Computation: 798880 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 310.76
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.4282
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4608
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 0.12s
                      Time elapsed: 00:06:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 358/1 [0m                       

                       Computation: 786859 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 319.85
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.3601
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4614
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 0.12s
                      Time elapsed: 00:06:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 359/1 [0m                       

                       Computation: 775471 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 310.78
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.9663
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4633
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 0.13s
                      Time elapsed: 00:06:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 360/1 [0m                       

                       Computation: 750824 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 302.61
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.6951
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4565
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 0.13s
                      Time elapsed: 00:06:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 361/1 [0m                       

                       Computation: 773416 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 300.75
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.6444
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4548
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 0.13s
                      Time elapsed: 00:06:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 362/1 [0m                       

                       Computation: 758180 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 306.34
               Mean episode length: 247.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.7620
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4545
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 0.13s
                      Time elapsed: 00:06:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 363/1 [0m                       

                       Computation: 820606 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 311.56
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.8774
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4601
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 0.12s
                      Time elapsed: 00:06:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 364/1 [0m                       

                       Computation: 735475 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 312.91
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.3081
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4608
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 0.13s
                      Time elapsed: 00:06:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 365/1 [0m                       

                       Computation: 796904 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 314.54
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.6368
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4574
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 71.6667
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 0.12s
                      Time elapsed: 00:06:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 366/1 [0m                       

                       Computation: 675910 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 307.35
               Mean episode length: 246.99
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.5752
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 0.15s
                      Time elapsed: 00:06:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 367/1 [0m                       

                       Computation: 740478 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 305.66
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.8507
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4514
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 0.13s
                      Time elapsed: 00:06:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 368/1 [0m                       

                       Computation: 696555 steps/s (collection: 0.046s, learning 0.096s)
                       Mean reward: 313.66
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.0098
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4554
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 0.14s
                      Time elapsed: 00:06:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 369/1 [0m                       

                       Computation: 722766 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 311.51
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.8690
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4546
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 0.14s
                      Time elapsed: 00:06:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 370/1 [0m                       

                       Computation: 803446 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 307.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.2730
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4547
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 0.12s
                      Time elapsed: 00:06:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 371/1 [0m                       

                       Computation: 815735 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 316.26
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.5973
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4619
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 0.12s
                      Time elapsed: 00:07:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 372/1 [0m                       

                       Computation: 777391 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 312.93
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.1746
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4581
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 0.13s
                      Time elapsed: 00:07:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 373/1 [0m                       

                       Computation: 778299 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 307.24
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.9655
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4564
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 0.13s
                      Time elapsed: 00:07:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 374/1 [0m                       

                       Computation: 783056 steps/s (collection: 0.046s, learning 0.080s)
                       Mean reward: 316.38
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.4870
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4596
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 0.13s
                      Time elapsed: 00:07:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 375/1 [0m                       

                       Computation: 775813 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 315.97
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.0168
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4553
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 73.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 0.13s
                      Time elapsed: 00:07:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 376/1 [0m                       

                       Computation: 780855 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 308.06
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.8122
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4536
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 0.13s
                      Time elapsed: 00:07:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 377/1 [0m                       

                       Computation: 767226 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 309.69
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.4781
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4544
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 0.13s
                      Time elapsed: 00:07:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 378/1 [0m                       

                       Computation: 654277 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 312.61
               Mean episode length: 245.24
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.2839
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4500
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 0.15s
                      Time elapsed: 00:07:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 379/1 [0m                       

                       Computation: 665573 steps/s (collection: 0.041s, learning 0.106s)
                       Mean reward: 305.19
               Mean episode length: 246.86
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.5875
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4455
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 0.15s
                      Time elapsed: 00:07:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 380/1 [0m                       

                       Computation: 690955 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 315.86
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.7612
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4565
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 0.14s
                      Time elapsed: 00:07:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 381/1 [0m                       

                       Computation: 814729 steps/s (collection: 0.043s, learning 0.078s)
                       Mean reward: 310.59
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.1093
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4470
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 0.12s
                      Time elapsed: 00:07:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 382/1 [0m                       

                       Computation: 697104 steps/s (collection: 0.047s, learning 0.094s)
                       Mean reward: 310.48
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.6828
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4556
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 0.14s
                      Time elapsed: 00:07:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 383/1 [0m                       

                       Computation: 720040 steps/s (collection: 0.053s, learning 0.083s)
                       Mean reward: 317.53
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.2137
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4544
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 0.14s
                      Time elapsed: 00:07:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 384/1 [0m                       

                       Computation: 623098 steps/s (collection: 0.052s, learning 0.106s)
                       Mean reward: 314.18
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.4534
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 0.16s
                      Time elapsed: 00:07:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 385/1 [0m                       

                       Computation: 731322 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 313.01
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.3670
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4523
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 0.13s
                      Time elapsed: 00:07:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 386/1 [0m                       

                       Computation: 726921 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 317.98
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.8914
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4490
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 69.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 0.14s
                      Time elapsed: 00:07:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 387/1 [0m                       

                       Computation: 633997 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 292.85
               Mean episode length: 242.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.5493
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 0.16s
                      Time elapsed: 00:07:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 388/1 [0m                       

                       Computation: 728082 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 312.05
               Mean episode length: 247.09
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.2392
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 0.14s
                      Time elapsed: 00:07:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 389/1 [0m                       

                       Computation: 553237 steps/s (collection: 0.054s, learning 0.124s)
                       Mean reward: 314.01
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.4898
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4533
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 0.18s
                      Time elapsed: 00:07:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 390/1 [0m                       

                       Computation: 515793 steps/s (collection: 0.059s, learning 0.132s)
                       Mean reward: 308.41
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.2026
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4461
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 0.19s
                      Time elapsed: 00:07:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 391/1 [0m                       

                       Computation: 558380 steps/s (collection: 0.056s, learning 0.120s)
                       Mean reward: 304.86
               Mean episode length: 246.34
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.1584
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4474
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 0.18s
                      Time elapsed: 00:07:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 392/1 [0m                       

                       Computation: 655871 steps/s (collection: 0.049s, learning 0.100s)
                       Mean reward: 311.65
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.8979
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4509
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 0.15s
                      Time elapsed: 00:07:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 393/1 [0m                       

                       Computation: 650852 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 308.06
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.8933
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4470
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 0.15s
                      Time elapsed: 00:07:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 394/1 [0m                       

                       Computation: 608636 steps/s (collection: 0.057s, learning 0.105s)
                       Mean reward: 309.31
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.2524
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4475
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 0.16s
                      Time elapsed: 00:07:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 395/1 [0m                       

                       Computation: 631924 steps/s (collection: 0.049s, learning 0.107s)
                       Mean reward: 308.65
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.2118
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4513
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 0.16s
                      Time elapsed: 00:07:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 396/1 [0m                       

                       Computation: 752125 steps/s (collection: 0.046s, learning 0.085s)
                       Mean reward: 312.33
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.2643
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4485
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 70.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 0.13s
                      Time elapsed: 00:07:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 397/1 [0m                       

                       Computation: 656389 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 321.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.9517
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4577
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 0.15s
                      Time elapsed: 00:07:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 398/1 [0m                       

                       Computation: 719756 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 308.23
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.3172
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4510
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 0.14s
                      Time elapsed: 00:07:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 399/1 [0m                       

                       Computation: 759015 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 307.18
               Mean episode length: 245.67
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.9881
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 0.13s
                      Time elapsed: 00:07:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 400/1 [0m                       

                       Computation: 653983 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 304.95
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.7720
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 0.15s
                      Time elapsed: 00:07:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 401/1 [0m                       

                       Computation: 712142 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 309.68
               Mean episode length: 246.50
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.4461
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4464
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 0.14s
                      Time elapsed: 00:07:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 402/1 [0m                       

                       Computation: 578011 steps/s (collection: 0.056s, learning 0.115s)
                       Mean reward: 304.70
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.2538
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 0.17s
                      Time elapsed: 00:07:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 403/1 [0m                       

                       Computation: 657163 steps/s (collection: 0.043s, learning 0.107s)
                       Mean reward: 312.54
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.1990
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4485
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 0.15s
                      Time elapsed: 00:07:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 404/1 [0m                       

                       Computation: 682518 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 311.88
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.6911
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4484
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 0.14s
                      Time elapsed: 00:07:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 405/1 [0m                       

                       Computation: 666252 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 320.23
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.2526
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4520
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 0.15s
                      Time elapsed: 00:07:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 406/1 [0m                       

                       Computation: 679444 steps/s (collection: 0.047s, learning 0.098s)
                       Mean reward: 309.10
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.5865
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4493
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 0.14s
                      Time elapsed: 00:07:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 407/1 [0m                       

                       Computation: 746147 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 313.95
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.4085
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4503
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 65.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 0.13s
                      Time elapsed: 00:07:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 408/1 [0m                       

                       Computation: 553709 steps/s (collection: 0.051s, learning 0.127s)
                       Mean reward: 307.84
               Mean episode length: 244.53
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.8888
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 0.18s
                      Time elapsed: 00:07:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 409/1 [0m                       

                       Computation: 553674 steps/s (collection: 0.054s, learning 0.124s)
                       Mean reward: 307.52
               Mean episode length: 246.60
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.0875
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4439
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 0.18s
                      Time elapsed: 00:07:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 410/1 [0m                       

                       Computation: 601449 steps/s (collection: 0.049s, learning 0.114s)
                       Mean reward: 309.92
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.9348
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4489
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 0.16s
                      Time elapsed: 00:07:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 411/1 [0m                       

                       Computation: 638290 steps/s (collection: 0.059s, learning 0.096s)
                       Mean reward: 309.30
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.3854
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 0.15s
                      Time elapsed: 00:07:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 412/1 [0m                       

                       Computation: 612278 steps/s (collection: 0.050s, learning 0.111s)
                       Mean reward: 305.47
               Mean episode length: 245.52
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.6730
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 0.16s
                      Time elapsed: 00:07:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 413/1 [0m                       

                       Computation: 697848 steps/s (collection: 0.048s, learning 0.093s)
                       Mean reward: 308.76
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.6423
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4448
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 0.14s
                      Time elapsed: 00:07:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 414/1 [0m                       

                       Computation: 650848 steps/s (collection: 0.051s, learning 0.100s)
                       Mean reward: 309.66
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.4997
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4453
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 0.15s
                      Time elapsed: 00:07:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 415/1 [0m                       

                       Computation: 830676 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 313.24
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.5487
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4469
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 0.12s
                      Time elapsed: 00:07:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 416/1 [0m                       

                       Computation: 776723 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 312.65
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.9518
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4450
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 0.13s
                      Time elapsed: 00:07:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 417/1 [0m                       

                       Computation: 775401 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 314.04
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 58.8688
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 67.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 0.13s
                      Time elapsed: 00:07:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 418/1 [0m                       

                       Computation: 746931 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 306.51
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.2981
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4455
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 0.13s
                      Time elapsed: 00:07:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 419/1 [0m                       

                       Computation: 772600 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 311.05
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.6051
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 0.13s
                      Time elapsed: 00:07:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 420/1 [0m                       

                       Computation: 785329 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 307.31
               Mean episode length: 246.34
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.8966
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4371
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 0.13s
                      Time elapsed: 00:08:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 421/1 [0m                       

                       Computation: 745011 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 311.08
               Mean episode length: 245.76
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.6603
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 0.13s
                      Time elapsed: 00:08:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 422/1 [0m                       

                       Computation: 761597 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 315.53
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.7160
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 0.13s
                      Time elapsed: 00:08:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 423/1 [0m                       

                       Computation: 773165 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 314.92
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.6589
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4478
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 0.13s
                      Time elapsed: 00:08:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 424/1 [0m                       

                       Computation: 741237 steps/s (collection: 0.048s, learning 0.085s)
                       Mean reward: 314.28
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.4139
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 0.13s
                      Time elapsed: 00:08:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 425/1 [0m                       

                       Computation: 763703 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 307.76
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.4220
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 0.13s
                      Time elapsed: 00:08:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 426/1 [0m                       

                       Computation: 688621 steps/s (collection: 0.058s, learning 0.085s)
                       Mean reward: 313.41
               Mean episode length: 246.73
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.8176
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 0.14s
                      Time elapsed: 00:08:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 427/1 [0m                       

                       Computation: 722026 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 318.18
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.6954
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4484
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 0.14s
                      Time elapsed: 00:08:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 428/1 [0m                       

                       Computation: 760782 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 315.09
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 61.6973
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 62.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 0.13s
                      Time elapsed: 00:08:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 429/1 [0m                       

                       Computation: 667717 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 317.85
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.7724
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4485
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 0.15s
                      Time elapsed: 00:08:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 430/1 [0m                       

                       Computation: 633870 steps/s (collection: 0.042s, learning 0.114s)
                       Mean reward: 314.78
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.3362
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 0.16s
                      Time elapsed: 00:08:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 431/1 [0m                       

                       Computation: 663386 steps/s (collection: 0.044s, learning 0.105s)
                       Mean reward: 307.63
               Mean episode length: 246.75
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.3069
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 0.15s
                      Time elapsed: 00:08:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 432/1 [0m                       

                       Computation: 751415 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 314.66
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.2369
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 0.13s
                      Time elapsed: 00:08:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 433/1 [0m                       

                       Computation: 733820 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 319.00
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9313
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4496
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 0.13s
                      Time elapsed: 00:08:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 434/1 [0m                       

                       Computation: 805465 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 317.09
               Mean episode length: 247.18
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.2124
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 0.12s
                      Time elapsed: 00:08:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 435/1 [0m                       

                       Computation: 747351 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 324.67
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.3967
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4466
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 0.13s
                      Time elapsed: 00:08:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 436/1 [0m                       

                       Computation: 789177 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 324.15
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.2395
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4495
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 0.12s
                      Time elapsed: 00:08:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 437/1 [0m                       

                       Computation: 781579 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 321.06
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.6142
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4457
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 0.13s
                      Time elapsed: 00:08:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 438/1 [0m                       

                       Computation: 760223 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 323.05
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.7063
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4474
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 65.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 0.13s
                      Time elapsed: 00:08:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 439/1 [0m                       

                       Computation: 823438 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 316.34
               Mean episode length: 246.22
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 61.8303
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 0.12s
                      Time elapsed: 00:08:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 440/1 [0m                       

                       Computation: 780416 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 322.38
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9902
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4467
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 0.13s
                      Time elapsed: 00:08:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 441/1 [0m                       

                       Computation: 728164 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 321.67
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.1691
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4436
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 0.14s
                      Time elapsed: 00:08:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 442/1 [0m                       

                       Computation: 797427 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 316.99
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.0581
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 0.12s
                      Time elapsed: 00:08:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 443/1 [0m                       

                       Computation: 844012 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 323.46
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.1267
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4484
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 0.12s
                      Time elapsed: 00:08:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 444/1 [0m                       

                       Computation: 829339 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 320.36
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.3940
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4455
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 0.12s
                      Time elapsed: 00:08:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 445/1 [0m                       

                       Computation: 843666 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 322.00
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.7496
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4477
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 0.12s
                      Time elapsed: 00:08:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 446/1 [0m                       

                       Computation: 721629 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 321.68
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9467
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4473
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 0.14s
                      Time elapsed: 00:08:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 447/1 [0m                       

                       Computation: 792705 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 319.08
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.3842
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4470
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 0.12s
                      Time elapsed: 00:08:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 448/1 [0m                       

                       Computation: 843735 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 324.69
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.1281
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 67.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 0.12s
                      Time elapsed: 00:08:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 449/1 [0m                       

                       Computation: 737243 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 319.91
               Mean episode length: 244.68
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 63.7140
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 0.13s
                      Time elapsed: 00:08:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 450/1 [0m                       

                       Computation: 786264 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 324.24
               Mean episode length: 246.13
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.9367
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4485
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 0.13s
                      Time elapsed: 00:08:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 451/1 [0m                       

                       Computation: 747466 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 323.03
               Mean episode length: 245.37
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 64.1934
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 0.13s
                      Time elapsed: 00:08:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 452/1 [0m                       

                       Computation: 800904 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 322.77
               Mean episode length: 247.10
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.1790
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4499
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 0.12s
                      Time elapsed: 00:08:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 453/1 [0m                       

                       Computation: 700111 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 326.59
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.8377
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4482
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 0.14s
                      Time elapsed: 00:08:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 454/1 [0m                       

                       Computation: 723806 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 329.77
               Mean episode length: 247.01
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 64.4072
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 0.14s
                      Time elapsed: 00:08:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 455/1 [0m                       

                       Computation: 767292 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 325.64
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.4114
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4457
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 0.13s
                      Time elapsed: 00:08:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 456/1 [0m                       

                       Computation: 707718 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 323.08
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.1965
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4505
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 0.14s
                      Time elapsed: 00:08:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 457/1 [0m                       

                       Computation: 745655 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 332.98
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.0003
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4535
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 0.13s
                      Time elapsed: 00:08:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 458/1 [0m                       

                       Computation: 725576 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 329.74
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.3309
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4497
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 0.14s
                      Time elapsed: 00:08:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 459/1 [0m                       

                       Computation: 679771 steps/s (collection: 0.040s, learning 0.104s)
                       Mean reward: 329.87
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 63.4542
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4401
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 62.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 0.14s
                      Time elapsed: 00:08:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 460/1 [0m                       

                       Computation: 670178 steps/s (collection: 0.041s, learning 0.106s)
                       Mean reward: 323.53
               Mean episode length: 245.28
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.0349
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4462
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 0.15s
                      Time elapsed: 00:08:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 461/1 [0m                       

                       Computation: 761946 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 324.91
               Mean episode length: 245.80
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.7234
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4461
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 0.13s
                      Time elapsed: 00:08:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 462/1 [0m                       

                       Computation: 692264 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 329.74
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.3739
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4475
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 0.14s
                      Time elapsed: 00:08:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 463/1 [0m                       

                       Computation: 739060 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 322.76
               Mean episode length: 246.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.0331
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4467
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 0.13s
                      Time elapsed: 00:08:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 464/1 [0m                       

                       Computation: 728017 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 327.05
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.3752
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4485
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 0.14s
                      Time elapsed: 00:08:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 465/1 [0m                       

                       Computation: 640180 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 322.64
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.0600
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4525
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 0.15s
                      Time elapsed: 00:08:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 466/1 [0m                       

                       Computation: 750843 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 331.32
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.9724
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4521
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 0.13s
                      Time elapsed: 00:08:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 467/1 [0m                       

                       Computation: 774429 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 335.10
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6442
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4561
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 0.13s
                      Time elapsed: 00:08:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 468/1 [0m                       

                       Computation: 814079 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 331.88
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.4792
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4501
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 0.12s
                      Time elapsed: 00:08:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 469/1 [0m                       

                       Computation: 602915 steps/s (collection: 0.046s, learning 0.117s)
                       Mean reward: 327.06
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 62.9046
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4457
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 65.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 0.16s
                      Time elapsed: 00:08:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 470/1 [0m                       

                       Computation: 738985 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 311.91
               Mean episode length: 245.18
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 60.4266
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 0.13s
                      Time elapsed: 00:08:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 471/1 [0m                       

                       Computation: 664071 steps/s (collection: 0.047s, learning 0.102s)
                       Mean reward: 317.94
               Mean episode length: 242.18
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 63.4237
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 0.15s
                      Time elapsed: 00:08:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 472/1 [0m                       

                       Computation: 756154 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 328.93
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.2960
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4469
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 0.13s
                      Time elapsed: 00:08:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 473/1 [0m                       

                       Computation: 733901 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 333.60
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.3848
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4543
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 0.13s
                      Time elapsed: 00:08:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 474/1 [0m                       

                       Computation: 684808 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 326.16
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 64.5933
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4487
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 0.14s
                      Time elapsed: 00:09:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 475/1 [0m                       

                       Computation: 734306 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 324.59
               Mean episode length: 246.78
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 64.3063
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4452
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 0.13s
                      Time elapsed: 00:09:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 476/1 [0m                       

                       Computation: 675579 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 332.45
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.4166
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4494
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 0.15s
                      Time elapsed: 00:09:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 477/1 [0m                       

                       Computation: 787582 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 326.12
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.0313
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4486
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 0.12s
                      Time elapsed: 00:09:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 478/1 [0m                       

                       Computation: 790527 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 330.90
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.7142
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4518
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 0.12s
                      Time elapsed: 00:09:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 479/1 [0m                       

                       Computation: 605679 steps/s (collection: 0.047s, learning 0.116s)
                       Mean reward: 328.68
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.8847
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4481
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 0.16s
                      Time elapsed: 00:09:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 480/1 [0m                       

                       Computation: 770059 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 332.97
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.9302
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 59.7500
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 0.13s
                      Time elapsed: 00:09:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 481/1 [0m                       

                       Computation: 717343 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 333.84
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.6181
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4473
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 0.14s
                      Time elapsed: 00:09:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 482/1 [0m                       

                       Computation: 680302 steps/s (collection: 0.044s, learning 0.101s)
                       Mean reward: 330.48
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.6585
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4487
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 0.14s
                      Time elapsed: 00:09:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 483/1 [0m                       

                       Computation: 707063 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 326.89
               Mean episode length: 245.47
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.2347
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 0.14s
                      Time elapsed: 00:09:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 484/1 [0m                       

                       Computation: 717264 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 323.00
               Mean episode length: 246.59
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 63.9855
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 0.14s
                      Time elapsed: 00:09:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 485/1 [0m                       

                       Computation: 745929 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 321.42
               Mean episode length: 245.56
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 63.8025
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4452
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 0.13s
                      Time elapsed: 00:09:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 486/1 [0m                       

                       Computation: 642063 steps/s (collection: 0.047s, learning 0.107s)
                       Mean reward: 328.29
               Mean episode length: 246.42
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.0369
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4444
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 0.15s
                      Time elapsed: 00:09:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 487/1 [0m                       

                       Computation: 626083 steps/s (collection: 0.045s, learning 0.112s)
                       Mean reward: 329.82
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.4455
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4477
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 0.16s
                      Time elapsed: 00:09:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 488/1 [0m                       

                       Computation: 727339 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 331.95
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.9321
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4499
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 0.14s
                      Time elapsed: 00:09:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 489/1 [0m                       

                       Computation: 781627 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 320.92
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.8831
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4442
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 0.13s
                      Time elapsed: 00:09:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 490/1 [0m                       

                       Computation: 783007 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 332.35
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.7171
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4447
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 62.5833
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 0.13s
                      Time elapsed: 00:09:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 491/1 [0m                       

                       Computation: 802219 steps/s (collection: 0.045s, learning 0.078s)
                       Mean reward: 313.92
               Mean episode length: 241.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 62.7977
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 0.12s
                      Time elapsed: 00:09:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 492/1 [0m                       

                       Computation: 742200 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 327.79
               Mean episode length: 245.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.8102
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4484
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 0.13s
                      Time elapsed: 00:09:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 493/1 [0m                       

                       Computation: 752070 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 320.62
               Mean episode length: 246.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9499
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4464
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 0.13s
                      Time elapsed: 00:09:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 494/1 [0m                       

                       Computation: 769687 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 325.82
               Mean episode length: 246.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.5864
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 0.13s
                      Time elapsed: 00:09:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 495/1 [0m                       

                       Computation: 765985 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 322.55
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.6270
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 0.13s
                      Time elapsed: 00:09:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 496/1 [0m                       

                       Computation: 518625 steps/s (collection: 0.050s, learning 0.140s)
                       Mean reward: 328.79
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.3624
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4476
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 0.19s
                      Time elapsed: 00:09:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 497/1 [0m                       

                       Computation: 719421 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 329.37
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.4100
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4466
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 0.14s
                      Time elapsed: 00:09:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 498/1 [0m                       

                       Computation: 690183 steps/s (collection: 0.051s, learning 0.092s)
                       Mean reward: 335.16
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.4506
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4522
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 0.14s
                      Time elapsed: 00:09:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 499/1 [0m                       

                       Computation: 759615 steps/s (collection: 0.051s, learning 0.079s)
                       Mean reward: 326.65
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.5792
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 0.13s
                      Time elapsed: 00:09:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 500/1 [0m                       

                       Computation: 757989 steps/s (collection: 0.046s, learning 0.084s)
                       Mean reward: 331.91
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.5490
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4499
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 64.9583
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 0.13s
                      Time elapsed: 00:09:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 501/1 [0m                       

                       Computation: 791680 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 330.91
               Mean episode length: 246.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.7492
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4495
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 0.12s
                      Time elapsed: 00:09:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 502/1 [0m                       

                       Computation: 774888 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 335.50
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.4296
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4523
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 0.13s
                      Time elapsed: 00:09:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 503/1 [0m                       

                       Computation: 722654 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 323.28
               Mean episode length: 247.27
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.3950
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4441
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 0.14s
                      Time elapsed: 00:09:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 504/1 [0m                       

                       Computation: 754057 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 323.84
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.4117
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 0.13s
                      Time elapsed: 00:09:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 505/1 [0m                       

                       Computation: 756921 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 335.65
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.4351
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4495
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 0.13s
                      Time elapsed: 00:09:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 506/1 [0m                       

                       Computation: 713469 steps/s (collection: 0.048s, learning 0.090s)
                       Mean reward: 328.38
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.7703
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4463
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 0.14s
                      Time elapsed: 00:09:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 507/1 [0m                       

                       Computation: 684825 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 328.13
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.1319
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4490
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 0.14s
                      Time elapsed: 00:09:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 508/1 [0m                       

                       Computation: 759210 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 329.38
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.3397
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4448
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 0.13s
                      Time elapsed: 00:09:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 509/1 [0m                       

                       Computation: 638185 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 337.15
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.3611
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4515
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 0.15s
                      Time elapsed: 00:09:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 510/1 [0m                       

                       Computation: 747481 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 331.43
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.8807
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4497
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 0.13s
                      Time elapsed: 00:09:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 511/1 [0m                       

                       Computation: 657401 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 337.13
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.5825
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4459
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 59.7500
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 0.15s
                      Time elapsed: 00:09:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 512/1 [0m                       

                       Computation: 731434 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 331.00
               Mean episode length: 245.22
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.5086
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 0.13s
                      Time elapsed: 00:09:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 513/1 [0m                       

                       Computation: 654884 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 333.66
               Mean episode length: 246.41
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.8515
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4468
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 0.15s
                      Time elapsed: 00:09:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 514/1 [0m                       

                       Computation: 660084 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 334.96
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.3064
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4504
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 0.15s
                      Time elapsed: 00:09:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 515/1 [0m                       

                       Computation: 701980 steps/s (collection: 0.050s, learning 0.090s)
                       Mean reward: 333.59
               Mean episode length: 247.05
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.2739
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4508
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 0.14s
                      Time elapsed: 00:09:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 516/1 [0m                       

                       Computation: 701972 steps/s (collection: 0.050s, learning 0.090s)
                       Mean reward: 335.48
               Mean episode length: 246.47
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.5304
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4451
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 0.14s
                      Time elapsed: 00:09:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 517/1 [0m                       

                       Computation: 666513 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 336.19
               Mean episode length: 246.69
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.7764
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4467
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 0.15s
                      Time elapsed: 00:09:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 518/1 [0m                       

                       Computation: 660860 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 333.56
               Mean episode length: 245.83
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6173
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4454
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 0.15s
                      Time elapsed: 00:09:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 519/1 [0m                       

                       Computation: 736004 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 334.82
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.7371
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4534
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 0.13s
                      Time elapsed: 00:09:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 520/1 [0m                       

                       Computation: 613517 steps/s (collection: 0.048s, learning 0.113s)
                       Mean reward: 334.70
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.4086
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4469
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 0.16s
                      Time elapsed: 00:09:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 521/1 [0m                       

                       Computation: 643627 steps/s (collection: 0.051s, learning 0.102s)
                       Mean reward: 340.17
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.1734
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4490
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 61.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 0.15s
                      Time elapsed: 00:09:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 522/1 [0m                       

                       Computation: 668621 steps/s (collection: 0.050s, learning 0.097s)
                       Mean reward: 328.79
               Mean episode length: 244.79
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.1443
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4433
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 0.15s
                      Time elapsed: 00:09:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 523/1 [0m                       

                       Computation: 652839 steps/s (collection: 0.044s, learning 0.107s)
                       Mean reward: 344.03
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.9396
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4491
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 0.15s
                      Time elapsed: 00:09:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 524/1 [0m                       

                       Computation: 735301 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 336.13
               Mean episode length: 246.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.2413
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 0.13s
                      Time elapsed: 00:09:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 525/1 [0m                       

                       Computation: 770345 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 340.50
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.7500
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4494
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 0.13s
                      Time elapsed: 00:10:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 526/1 [0m                       

                       Computation: 688266 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 337.13
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6123
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4461
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 0.14s
                      Time elapsed: 00:10:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 527/1 [0m                       

                       Computation: 752139 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 335.11
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.3186
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4493
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 0.13s
                      Time elapsed: 00:10:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 528/1 [0m                       

                       Computation: 713448 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 333.98
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.3739
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4500
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 0.14s
                      Time elapsed: 00:10:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 529/1 [0m                       

                       Computation: 733294 steps/s (collection: 0.048s, learning 0.086s)
                       Mean reward: 332.82
               Mean episode length: 246.79
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.3108
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4458
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 0.13s
                      Time elapsed: 00:10:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 530/1 [0m                       

                       Computation: 758843 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 337.90
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6177
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 0.13s
                      Time elapsed: 00:10:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 531/1 [0m                       

                       Computation: 587212 steps/s (collection: 0.057s, learning 0.111s)
                       Mean reward: 344.77
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.4977
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4530
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 0.17s
                      Time elapsed: 00:10:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 532/1 [0m                       

                       Computation: 648701 steps/s (collection: 0.048s, learning 0.104s)
                       Mean reward: 341.04
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.1218
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4522
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 56.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 0.15s
                      Time elapsed: 00:10:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 533/1 [0m                       

                       Computation: 711353 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 330.68
               Mean episode length: 245.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.4464
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 0.14s
                      Time elapsed: 00:10:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 534/1 [0m                       

                       Computation: 627619 steps/s (collection: 0.049s, learning 0.108s)
                       Mean reward: 340.98
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.7886
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4481
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 0.16s
                      Time elapsed: 00:10:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 535/1 [0m                       

                       Computation: 631495 steps/s (collection: 0.050s, learning 0.106s)
                       Mean reward: 337.44
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.5032
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4495
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 0.16s
                      Time elapsed: 00:10:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 536/1 [0m                       

                       Computation: 538146 steps/s (collection: 0.056s, learning 0.127s)
                       Mean reward: 332.43
               Mean episode length: 247.02
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.2531
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 0.18s
                      Time elapsed: 00:10:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 537/1 [0m                       

                       Computation: 506460 steps/s (collection: 0.054s, learning 0.140s)
                       Mean reward: 332.07
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.6617
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 0.19s
                      Time elapsed: 00:10:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 538/1 [0m                       

                       Computation: 573653 steps/s (collection: 0.043s, learning 0.129s)
                       Mean reward: 333.85
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.3651
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4470
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 0.17s
                      Time elapsed: 00:10:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 539/1 [0m                       

                       Computation: 606517 steps/s (collection: 0.054s, learning 0.109s)
                       Mean reward: 332.25
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.9880
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4452
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 0.16s
                      Time elapsed: 00:10:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 540/1 [0m                       

                       Computation: 708006 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 332.76
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.9258
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 0.14s
                      Time elapsed: 00:10:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 541/1 [0m                       

                       Computation: 688381 steps/s (collection: 0.047s, learning 0.096s)
                       Mean reward: 332.91
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.6843
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4435
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 0.14s
                      Time elapsed: 00:10:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 542/1 [0m                       

                       Computation: 764134 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 338.30
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.4224
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 59.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 0.13s
                      Time elapsed: 00:10:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 543/1 [0m                       

                       Computation: 715908 steps/s (collection: 0.049s, learning 0.088s)
                       Mean reward: 335.86
               Mean episode length: 247.08
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.4658
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4401
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 0.14s
                      Time elapsed: 00:10:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 544/1 [0m                       

                       Computation: 773077 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 329.21
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.6288
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 0.13s
                      Time elapsed: 00:10:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 545/1 [0m                       

                       Computation: 706973 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 340.03
               Mean episode length: 246.02
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.6743
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4458
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 0.14s
                      Time elapsed: 00:10:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 546/1 [0m                       

                       Computation: 699394 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 339.17
               Mean episode length: 246.28
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.2937
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 0.14s
                      Time elapsed: 00:10:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 547/1 [0m                       

                       Computation: 767472 steps/s (collection: 0.045s, learning 0.083s)
                       Mean reward: 337.51
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.8479
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4475
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 0.13s
                      Time elapsed: 00:10:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 548/1 [0m                       

                       Computation: 766536 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 341.85
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.9992
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4470
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 0.13s
                      Time elapsed: 00:10:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 549/1 [0m                       

                       Computation: 736197 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 343.17
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.4657
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4521
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 0.13s
                      Time elapsed: 00:10:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 550/1 [0m                       

                       Computation: 798978 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 337.26
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.8792
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 0.12s
                      Time elapsed: 00:10:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 551/1 [0m                       

                       Computation: 788861 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 338.38
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.1619
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4452
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 0.12s
                      Time elapsed: 00:10:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 552/1 [0m                       

                       Computation: 674990 steps/s (collection: 0.047s, learning 0.098s)
                       Mean reward: 339.33
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.5490
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4491
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 0.15s
                      Time elapsed: 00:10:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 553/1 [0m                       

                       Computation: 803446 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 342.76
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.9832
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4468
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 54.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 0.12s
                      Time elapsed: 00:10:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 554/1 [0m                       

                       Computation: 701437 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 340.47
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.7261
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4467
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 0.14s
                      Time elapsed: 00:10:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 555/1 [0m                       

                       Computation: 783080 steps/s (collection: 0.046s, learning 0.080s)
                       Mean reward: 330.99
               Mean episode length: 245.58
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.3463
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 0.13s
                      Time elapsed: 00:10:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 556/1 [0m                       

                       Computation: 776207 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 337.97
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.3274
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4457
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 0.13s
                      Time elapsed: 00:10:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 557/1 [0m                       

                       Computation: 766947 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 343.16
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.3977
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4472
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 0.13s
                      Time elapsed: 00:10:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 558/1 [0m                       

                       Computation: 801144 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 335.66
               Mean episode length: 246.67
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6319
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 0.12s
                      Time elapsed: 00:10:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 559/1 [0m                       

                       Computation: 686575 steps/s (collection: 0.039s, learning 0.105s)
                       Mean reward: 341.70
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1477
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 0.14s
                      Time elapsed: 00:10:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 560/1 [0m                       

                       Computation: 682171 steps/s (collection: 0.040s, learning 0.104s)
                       Mean reward: 338.66
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.2155
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4458
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 0.14s
                      Time elapsed: 00:10:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 561/1 [0m                       

                       Computation: 794608 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 340.16
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.0106
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4489
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 0.12s
                      Time elapsed: 00:10:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 562/1 [0m                       

                       Computation: 710756 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 342.69
               Mean episode length: 246.86
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.2209
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 0.14s
                      Time elapsed: 00:10:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 563/1 [0m                       

                       Computation: 824284 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 344.47
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.0206
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 57.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 0.12s
                      Time elapsed: 00:10:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 564/1 [0m                       

                       Computation: 622079 steps/s (collection: 0.039s, learning 0.119s)
                       Mean reward: 343.07
               Mean episode length: 246.34
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.8364
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 0.16s
                      Time elapsed: 00:10:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 565/1 [0m                       

                       Computation: 702335 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 337.28
               Mean episode length: 247.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.6327
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4451
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 0.14s
                      Time elapsed: 00:10:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 566/1 [0m                       

                       Computation: 684917 steps/s (collection: 0.040s, learning 0.104s)
                       Mean reward: 335.81
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.9544
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4470
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 0.14s
                      Time elapsed: 00:10:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 567/1 [0m                       

                       Computation: 693454 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 335.89
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.8302
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 0.14s
                      Time elapsed: 00:10:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 568/1 [0m                       

                       Computation: 799108 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 336.31
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.7564
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 0.12s
                      Time elapsed: 00:10:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 569/1 [0m                       

                       Computation: 877551 steps/s (collection: 0.039s, learning 0.074s)
                       Mean reward: 342.13
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.9564
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 0.11s
                      Time elapsed: 00:10:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 570/1 [0m                       

                       Computation: 782512 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 332.48
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.9552
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 0.13s
                      Time elapsed: 00:10:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 571/1 [0m                       

                       Computation: 773635 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 340.35
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.4535
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4433
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 0.13s
                      Time elapsed: 00:10:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 572/1 [0m                       

                       Computation: 708394 steps/s (collection: 0.047s, learning 0.092s)
                       Mean reward: 335.84
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.5577
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 0.14s
                      Time elapsed: 00:10:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 573/1 [0m                       

                       Computation: 692457 steps/s (collection: 0.037s, learning 0.105s)
                       Mean reward: 337.55
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.3317
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 59.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 0.14s
                      Time elapsed: 00:10:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 574/1 [0m                       

                       Computation: 709558 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 338.35
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.3011
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4522
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 0.14s
                      Time elapsed: 00:10:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 575/1 [0m                       

                       Computation: 827910 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 335.98
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.1931
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 0.12s
                      Time elapsed: 00:10:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 576/1 [0m                       

                       Computation: 862241 steps/s (collection: 0.039s, learning 0.075s)
                       Mean reward: 334.75
               Mean episode length: 245.16
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.3302
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 0.11s
                      Time elapsed: 00:10:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 577/1 [0m                       

                       Computation: 800017 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 335.79
               Mean episode length: 246.33
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6778
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4388
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 0.12s
                      Time elapsed: 00:11:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 578/1 [0m                       

                       Computation: 648260 steps/s (collection: 0.038s, learning 0.114s)
                       Mean reward: 339.88
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.5205
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4438
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 0.15s
                      Time elapsed: 00:11:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 579/1 [0m                       

                       Computation: 630831 steps/s (collection: 0.042s, learning 0.114s)
                       Mean reward: 339.99
               Mean episode length: 246.09
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1603
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 0.16s
                      Time elapsed: 00:11:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 580/1 [0m                       

                       Computation: 727541 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 340.58
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.5816
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 0.14s
                      Time elapsed: 00:11:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 581/1 [0m                       

                       Computation: 639702 steps/s (collection: 0.038s, learning 0.115s)
                       Mean reward: 346.23
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.6589
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4474
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 0.15s
                      Time elapsed: 00:11:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 582/1 [0m                       

                       Computation: 767848 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 341.43
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.9892
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4459
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 0.13s
                      Time elapsed: 00:11:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 583/1 [0m                       

                       Computation: 572806 steps/s (collection: 0.041s, learning 0.131s)
                       Mean reward: 339.95
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.6966
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4453
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 0.17s
                      Time elapsed: 00:11:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 584/1 [0m                       

                       Computation: 604661 steps/s (collection: 0.044s, learning 0.119s)
                       Mean reward: 346.95
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.4650
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4508
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 54.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 0.16s
                      Time elapsed: 00:11:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 585/1 [0m                       

                       Computation: 706631 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 338.58
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6982
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4433
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 0.14s
                      Time elapsed: 00:11:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 586/1 [0m                       

                       Computation: 654923 steps/s (collection: 0.050s, learning 0.101s)
                       Mean reward: 342.06
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1586
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4451
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 0.15s
                      Time elapsed: 00:11:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 587/1 [0m                       

                       Computation: 717349 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 341.68
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.6069
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 0.14s
                      Time elapsed: 00:11:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 588/1 [0m                       

                       Computation: 675105 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 343.63
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1553
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4447
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 0.15s
                      Time elapsed: 00:11:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 589/1 [0m                       

                       Computation: 631906 steps/s (collection: 0.050s, learning 0.106s)
                       Mean reward: 346.26
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.0642
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4449
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 0.16s
                      Time elapsed: 00:11:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 590/1 [0m                       

                       Computation: 654540 steps/s (collection: 0.049s, learning 0.101s)
                       Mean reward: 340.19
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.7873
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 0.15s
                      Time elapsed: 00:11:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 591/1 [0m                       

                       Computation: 635671 steps/s (collection: 0.050s, learning 0.105s)
                       Mean reward: 347.82
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.2739
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 0.15s
                      Time elapsed: 00:11:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 592/1 [0m                       

                       Computation: 562943 steps/s (collection: 0.047s, learning 0.128s)
                       Mean reward: 346.08
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.8245
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4424
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 0.17s
                      Time elapsed: 00:11:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 593/1 [0m                       

                       Computation: 696948 steps/s (collection: 0.037s, learning 0.104s)
                       Mean reward: 345.78
               Mean episode length: 247.51
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.4419
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 0.14s
                      Time elapsed: 00:11:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 594/1 [0m                       

                       Computation: 633578 steps/s (collection: 0.039s, learning 0.117s)
                       Mean reward: 346.07
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.7952
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 56.9167
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 0.16s
                      Time elapsed: 00:11:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 595/1 [0m                       

                       Computation: 711556 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 346.26
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.4551
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4442
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 0.14s
                      Time elapsed: 00:11:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 596/1 [0m                       

                       Computation: 623517 steps/s (collection: 0.037s, learning 0.121s)
                       Mean reward: 345.52
               Mean episode length: 244.37
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0363
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 0.16s
                      Time elapsed: 00:11:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 597/1 [0m                       

                       Computation: 714234 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 342.58
               Mean episode length: 246.46
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8312
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 0.14s
                      Time elapsed: 00:11:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 598/1 [0m                       

                       Computation: 703595 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 344.12
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.0227
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4443
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 0.14s
                      Time elapsed: 00:11:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 599/1 [0m                       

                       Computation: 747075 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 345.17
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1651
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4451
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 0.13s
                      Time elapsed: 00:11:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 600/1 [0m                       

                       Computation: 608330 steps/s (collection: 0.040s, learning 0.122s)
                       Mean reward: 345.25
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.2456
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4449
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 0.16s
                      Time elapsed: 00:11:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 601/1 [0m                       

                       Computation: 686060 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 343.80
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.0598
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4442
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 0.14s
                      Time elapsed: 00:11:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 602/1 [0m                       

                       Computation: 679744 steps/s (collection: 0.038s, learning 0.107s)
                       Mean reward: 354.84
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.4763
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4525
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 0.14s
                      Time elapsed: 00:11:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 603/1 [0m                       

                       Computation: 597290 steps/s (collection: 0.047s, learning 0.117s)
                       Mean reward: 342.12
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.8935
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4468
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 0.16s
                      Time elapsed: 00:11:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 604/1 [0m                       

                       Computation: 638256 steps/s (collection: 0.050s, learning 0.105s)
                       Mean reward: 349.49
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.5125
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4508
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 0.15s
                      Time elapsed: 00:11:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 605/1 [0m                       

                       Computation: 667143 steps/s (collection: 0.041s, learning 0.106s)
                       Mean reward: 351.01
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.8857
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4455
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 51.8333
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 0.15s
                      Time elapsed: 00:11:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 606/1 [0m                       

                       Computation: 616159 steps/s (collection: 0.049s, learning 0.111s)
                       Mean reward: 347.89
               Mean episode length: 244.91
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.6262
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4443
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 0.16s
                      Time elapsed: 00:11:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 607/1 [0m                       

                       Computation: 753226 steps/s (collection: 0.048s, learning 0.083s)
                       Mean reward: 348.47
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.6386
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4521
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 0.13s
                      Time elapsed: 00:11:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 608/1 [0m                       

                       Computation: 847377 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 349.13
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.1794
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4492
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 0.12s
                      Time elapsed: 00:11:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 609/1 [0m                       

                       Computation: 776936 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 344.56
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.3691
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4459
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 0.13s
                      Time elapsed: 00:11:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 610/1 [0m                       

                       Computation: 591295 steps/s (collection: 0.058s, learning 0.108s)
                       Mean reward: 349.04
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.2094
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4488
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 0.17s
                      Time elapsed: 00:11:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 611/1 [0m                       

                       Computation: 663618 steps/s (collection: 0.051s, learning 0.097s)
                       Mean reward: 354.02
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.6897
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4536
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 0.15s
                      Time elapsed: 00:11:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 612/1 [0m                       

                       Computation: 728614 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 353.73
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.2633
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4513
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 0.13s
                      Time elapsed: 00:11:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 613/1 [0m                       

                       Computation: 755860 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 346.44
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.9113
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4479
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 0.13s
                      Time elapsed: 00:11:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 614/1 [0m                       

                       Computation: 722578 steps/s (collection: 0.048s, learning 0.089s)
                       Mean reward: 349.68
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.5622
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4510
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 0.14s
                      Time elapsed: 00:11:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 615/1 [0m                       

                       Computation: 730427 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 350.71
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1757
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4402
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 54.6667
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 0.13s
                      Time elapsed: 00:11:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 616/1 [0m                       

                       Computation: 843230 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 344.32
               Mean episode length: 243.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.4960
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 0.12s
                      Time elapsed: 00:11:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 617/1 [0m                       

                       Computation: 820949 steps/s (collection: 0.043s, learning 0.077s)
                       Mean reward: 338.71
               Mean episode length: 244.58
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.2865
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 0.12s
                      Time elapsed: 00:11:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 618/1 [0m                       

                       Computation: 724120 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 353.88
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.1767
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 0.14s
                      Time elapsed: 00:11:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 619/1 [0m                       

                       Computation: 672599 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 347.92
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.0629
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 0.15s
                      Time elapsed: 00:11:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 620/1 [0m                       

                       Computation: 751662 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 343.63
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.3284
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 0.13s
                      Time elapsed: 00:11:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 621/1 [0m                       

                       Computation: 645235 steps/s (collection: 0.045s, learning 0.108s)
                       Mean reward: 340.00
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.6375
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4421
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 0.15s
                      Time elapsed: 00:11:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 622/1 [0m                       

                       Computation: 675530 steps/s (collection: 0.053s, learning 0.093s)
                       Mean reward: 342.56
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.7171
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4401
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 0.15s
                      Time elapsed: 00:11:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 623/1 [0m                       

                       Computation: 613311 steps/s (collection: 0.053s, learning 0.108s)
                       Mean reward: 338.61
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.5276
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 0.16s
                      Time elapsed: 00:11:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 624/1 [0m                       

                       Computation: 792683 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 344.47
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1697
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4424
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 0.12s
                      Time elapsed: 00:11:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 625/1 [0m                       

                       Computation: 757751 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 343.76
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.6759
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 56.8750
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 0.13s
                      Time elapsed: 00:11:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 626/1 [0m                       

                       Computation: 739044 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 338.02
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.0956
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4424
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 0.13s
                      Time elapsed: 00:11:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 627/1 [0m                       

                       Computation: 753196 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 335.92
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.9522
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 0.13s
                      Time elapsed: 00:11:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 628/1 [0m                       

                       Computation: 767836 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 345.69
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.9059
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4471
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 0.13s
                      Time elapsed: 00:11:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 629/1 [0m                       

                       Computation: 824689 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 337.29
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.8602
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 0.12s
                      Time elapsed: 00:11:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 630/1 [0m                       

                       Computation: 774507 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 339.96
               Mean episode length: 246.93
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.4585
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 0.13s
                      Time elapsed: 00:12:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 631/1 [0m                       

                       Computation: 756057 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 343.98
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.4387
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 0.13s
                      Time elapsed: 00:12:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 632/1 [0m                       

                       Computation: 758990 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 339.41
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.3382
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 0.13s
                      Time elapsed: 00:12:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 633/1 [0m                       

                       Computation: 808553 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 337.73
               Mean episode length: 246.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.0410
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 0.12s
                      Time elapsed: 00:12:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 634/1 [0m                       

                       Computation: 826667 steps/s (collection: 0.042s, learning 0.077s)
                       Mean reward: 335.50
               Mean episode length: 245.39
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.5781
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 0.12s
                      Time elapsed: 00:12:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 635/1 [0m                       

                       Computation: 646612 steps/s (collection: 0.056s, learning 0.097s)
                       Mean reward: 345.05
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.7188
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4436
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 0.15s
                      Time elapsed: 00:12:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 636/1 [0m                       

                       Computation: 789428 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 348.08
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.9645
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 52.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 0.12s
                      Time elapsed: 00:12:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 637/1 [0m                       

                       Computation: 799014 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 332.08
               Mean episode length: 246.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.9197
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 0.12s
                      Time elapsed: 00:12:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 638/1 [0m                       

                       Computation: 843711 steps/s (collection: 0.041s, learning 0.075s)
                       Mean reward: 347.34
               Mean episode length: 247.41
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.4087
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4450
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 0.12s
                      Time elapsed: 00:12:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 639/1 [0m                       

                       Computation: 838685 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 344.22
               Mean episode length: 245.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.0398
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 0.12s
                      Time elapsed: 00:12:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 640/1 [0m                       

                       Computation: 847779 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 348.37
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.2457
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4479
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 0.12s
                      Time elapsed: 00:12:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 641/1 [0m                       

                       Computation: 868617 steps/s (collection: 0.039s, learning 0.074s)
                       Mean reward: 344.26
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1097
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 0.11s
                      Time elapsed: 00:12:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 642/1 [0m                       

                       Computation: 876445 steps/s (collection: 0.039s, learning 0.073s)
                       Mean reward: 342.17
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.7015
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 0.11s
                      Time elapsed: 00:12:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 643/1 [0m                       

                       Computation: 807343 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 348.33
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.4867
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4483
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 0.12s
                      Time elapsed: 00:12:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 644/1 [0m                       

                       Computation: 791029 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 347.67
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.3029
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4476
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 0.12s
                      Time elapsed: 00:12:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 645/1 [0m                       

                       Computation: 842851 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 353.55
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.1798
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4516
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 0.12s
                      Time elapsed: 00:12:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 646/1 [0m                       

                       Computation: 882531 steps/s (collection: 0.041s, learning 0.070s)
                       Mean reward: 350.01
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.2210
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4501
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 54.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 0.11s
                      Time elapsed: 00:12:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 647/1 [0m                       

                       Computation: 635342 steps/s (collection: 0.042s, learning 0.113s)
                       Mean reward: 337.80
               Mean episode length: 247.03
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.3917
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 0.15s
                      Time elapsed: 00:12:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 648/1 [0m                       

                       Computation: 641040 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 340.91
               Mean episode length: 246.02
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8948
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 0.15s
                      Time elapsed: 00:12:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 649/1 [0m                       

                       Computation: 679917 steps/s (collection: 0.046s, learning 0.098s)
                       Mean reward: 342.29
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.8465
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 0.14s
                      Time elapsed: 00:12:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 650/1 [0m                       

                       Computation: 675496 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 341.85
               Mean episode length: 246.37
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.8690
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 0.15s
                      Time elapsed: 00:12:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 651/1 [0m                       

                       Computation: 657036 steps/s (collection: 0.044s, learning 0.106s)
                       Mean reward: 339.68
               Mean episode length: 245.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6494
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 0.15s
                      Time elapsed: 00:12:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 652/1 [0m                       

                       Computation: 766425 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 347.20
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.7744
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4473
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 0.13s
                      Time elapsed: 00:12:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 653/1 [0m                       

                       Computation: 809467 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 347.13
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.1452
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 0.12s
                      Time elapsed: 00:12:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 654/1 [0m                       

                       Computation: 721297 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 344.87
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.5227
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4476
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 0.14s
                      Time elapsed: 00:12:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 655/1 [0m                       

                       Computation: 767845 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 352.04
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.1705
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4517
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 0.13s
                      Time elapsed: 00:12:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 656/1 [0m                       

                       Computation: 694434 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 348.98
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.5097
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4511
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 0.14s
                      Time elapsed: 00:12:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 657/1 [0m                       

                       Computation: 862950 steps/s (collection: 0.039s, learning 0.075s)
                       Mean reward: 352.66
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.2527
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 49.0833
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 0.11s
                      Time elapsed: 00:12:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 658/1 [0m                       

                       Computation: 811018 steps/s (collection: 0.044s, learning 0.077s)
                       Mean reward: 350.98
               Mean episode length: 245.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.4084
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 0.12s
                      Time elapsed: 00:12:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 659/1 [0m                       

                       Computation: 852547 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 345.64
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.1186
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4483
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 0.12s
                      Time elapsed: 00:12:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 660/1 [0m                       

                       Computation: 781210 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 351.87
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.8157
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4485
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 0.13s
                      Time elapsed: 00:12:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 661/1 [0m                       

                       Computation: 842198 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 341.04
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.9322
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4449
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 0.12s
                      Time elapsed: 00:12:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 662/1 [0m                       

                       Computation: 666116 steps/s (collection: 0.042s, learning 0.106s)
                       Mean reward: 353.45
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.9293
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4501
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 0.15s
                      Time elapsed: 00:12:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 663/1 [0m                       

                       Computation: 835160 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 340.37
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.8341
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4429
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 0.12s
                      Time elapsed: 00:12:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 664/1 [0m                       

                       Computation: 764830 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 343.19
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1614
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4464
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 0.13s
                      Time elapsed: 00:12:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 665/1 [0m                       

                       Computation: 730757 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 344.77
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.6396
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4467
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 0.13s
                      Time elapsed: 00:12:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 666/1 [0m                       

                       Computation: 826037 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 344.68
               Mean episode length: 247.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.3769
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4417
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 0.12s
                      Time elapsed: 00:12:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 667/1 [0m                       

                       Computation: 862264 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 351.97
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.1970
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 51.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 0.11s
                      Time elapsed: 00:12:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 668/1 [0m                       

                       Computation: 877647 steps/s (collection: 0.040s, learning 0.072s)
                       Mean reward: 352.50
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.3399
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4477
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 0.11s
                      Time elapsed: 00:12:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 669/1 [0m                       

                       Computation: 843672 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 341.56
               Mean episode length: 245.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.5407
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 0.12s
                      Time elapsed: 00:12:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 670/1 [0m                       

                       Computation: 806446 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 348.83
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.3073
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 0.12s
                      Time elapsed: 00:12:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 671/1 [0m                       

                       Computation: 592994 steps/s (collection: 0.068s, learning 0.098s)
                       Mean reward: 345.55
               Mean episode length: 247.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.6935
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4435
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 0.17s
                      Time elapsed: 00:12:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 672/1 [0m                       

                       Computation: 793548 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 344.42
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.3841
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 0.12s
                      Time elapsed: 00:12:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 673/1 [0m                       

                       Computation: 738889 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 349.80
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.7514
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4464
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 0.13s
                      Time elapsed: 00:12:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 674/1 [0m                       

                       Computation: 853507 steps/s (collection: 0.040s, learning 0.075s)
                       Mean reward: 344.96
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.6352
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 0.12s
                      Time elapsed: 00:12:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 675/1 [0m                       

                       Computation: 818321 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 347.90
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.1993
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4478
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 0.12s
                      Time elapsed: 00:12:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 676/1 [0m                       

                       Computation: 848966 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 351.63
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.7511
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4463
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 0.12s
                      Time elapsed: 00:12:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 677/1 [0m                       

                       Computation: 725574 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 352.71
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.3548
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4482
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 0.14s
                      Time elapsed: 00:12:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 678/1 [0m                       

                       Computation: 730751 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 354.86
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.7026
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 46.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 0.13s
                      Time elapsed: 00:12:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 679/1 [0m                       

                       Computation: 663079 steps/s (collection: 0.051s, learning 0.097s)
                       Mean reward: 339.90
               Mean episode length: 244.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.6932
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 0.15s
                      Time elapsed: 00:12:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 680/1 [0m                       

                       Computation: 665584 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 343.51
               Mean episode length: 246.98
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.0823
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 0.15s
                      Time elapsed: 00:12:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 681/1 [0m                       

                       Computation: 700721 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 347.69
               Mean episode length: 246.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.0031
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 0.14s
                      Time elapsed: 00:12:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 682/1 [0m                       

                       Computation: 657027 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 353.95
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.4267
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 0.15s
                      Time elapsed: 00:12:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 683/1 [0m                       

                       Computation: 804299 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 356.03
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.9546
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4461
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 0.12s
                      Time elapsed: 00:12:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 684/1 [0m                       

                       Computation: 796970 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 353.03
               Mean episode length: 246.37
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.3322
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 0.12s
                      Time elapsed: 00:12:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 685/1 [0m                       

                       Computation: 813362 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 354.14
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.5378
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4448
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 0.12s
                      Time elapsed: 00:12:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 686/1 [0m                       

                       Computation: 740262 steps/s (collection: 0.047s, learning 0.086s)
                       Mean reward: 346.48
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.1312
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4452
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 0.13s
                      Time elapsed: 00:13:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 687/1 [0m                       

                       Computation: 697066 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 350.90
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.4954
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 0.14s
                      Time elapsed: 00:13:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 688/1 [0m                       

                       Computation: 758910 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 353.02
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.0577
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 49.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 0.13s
                      Time elapsed: 00:13:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 689/1 [0m                       

                       Computation: 873656 steps/s (collection: 0.038s, learning 0.075s)
                       Mean reward: 346.64
               Mean episode length: 244.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.2638
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 0.11s
                      Time elapsed: 00:13:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 690/1 [0m                       

                       Computation: 873698 steps/s (collection: 0.039s, learning 0.074s)
                       Mean reward: 351.02
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.4297
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4466
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 0.11s
                      Time elapsed: 00:13:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 691/1 [0m                       

                       Computation: 714791 steps/s (collection: 0.059s, learning 0.079s)
                       Mean reward: 349.37
               Mean episode length: 246.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.5528
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 0.14s
                      Time elapsed: 00:13:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 692/1 [0m                       

                       Computation: 783078 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 348.03
               Mean episode length: 246.63
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.2409
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4425
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 0.13s
                      Time elapsed: 00:13:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 693/1 [0m                       

                       Computation: 862228 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 353.11
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.8798
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4459
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 0.11s
                      Time elapsed: 00:13:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 694/1 [0m                       

                       Computation: 827483 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 346.64
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.6324
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 0.12s
                      Time elapsed: 00:13:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 695/1 [0m                       

                       Computation: 801167 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 346.61
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.0640
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 0.12s
                      Time elapsed: 00:13:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 696/1 [0m                       

                       Computation: 786700 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 345.93
               Mean episode length: 246.94
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.8512
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 0.12s
                      Time elapsed: 00:13:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 697/1 [0m                       

                       Computation: 812469 steps/s (collection: 0.045s, learning 0.076s)
                       Mean reward: 346.81
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.9083
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 0.12s
                      Time elapsed: 00:13:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 698/1 [0m                       

                       Computation: 832754 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 352.14
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.1465
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 51.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 0.12s
                      Time elapsed: 00:13:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 699/1 [0m                       

                       Computation: 838311 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 350.42
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.2174
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 0.12s
                      Time elapsed: 00:13:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 700/1 [0m                       

                       Computation: 770808 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 341.98
               Mean episode length: 245.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.1498
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4347
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 0.13s
                      Time elapsed: 00:13:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 701/1 [0m                       

                       Computation: 738623 steps/s (collection: 0.049s, learning 0.084s)
                       Mean reward: 343.73
               Mean episode length: 246.80
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.4204
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 0.13s
                      Time elapsed: 00:13:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 702/1 [0m                       

                       Computation: 850709 steps/s (collection: 0.041s, learning 0.074s)
                       Mean reward: 349.45
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.4256
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 0.12s
                      Time elapsed: 00:13:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 703/1 [0m                       

                       Computation: 842301 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 346.79
               Mean episode length: 246.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.8199
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 0.12s
                      Time elapsed: 00:13:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 704/1 [0m                       

                       Computation: 891929 steps/s (collection: 0.039s, learning 0.071s)
                       Mean reward: 346.37
               Mean episode length: 247.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.5462
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 0.11s
                      Time elapsed: 00:13:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 705/1 [0m                       

                       Computation: 836853 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 352.55
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.9816
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 0.12s
                      Time elapsed: 00:13:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 706/1 [0m                       

                       Computation: 732516 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 344.60
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.8318
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 0.13s
                      Time elapsed: 00:13:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 707/1 [0m                       

                       Computation: 652090 steps/s (collection: 0.048s, learning 0.103s)
                       Mean reward: 351.41
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.9198
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 0.15s
                      Time elapsed: 00:13:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 708/1 [0m                       

                       Computation: 680154 steps/s (collection: 0.045s, learning 0.100s)
                       Mean reward: 341.15
               Mean episode length: 246.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 67.9202
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 0.14s
                      Time elapsed: 00:13:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 709/1 [0m                       

                       Computation: 779385 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 349.98
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 67.0768
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 46.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 0.13s
                      Time elapsed: 00:13:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 710/1 [0m                       

                       Computation: 706522 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 347.02
               Mean episode length: 246.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.7158
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 0.14s
                      Time elapsed: 00:13:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 711/1 [0m                       

                       Computation: 751658 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 348.07
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.0619
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 0.13s
                      Time elapsed: 00:13:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 712/1 [0m                       

                       Computation: 741613 steps/s (collection: 0.054s, learning 0.079s)
                       Mean reward: 352.02
               Mean episode length: 247.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.2093
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 0.13s
                      Time elapsed: 00:13:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 713/1 [0m                       

                       Computation: 854254 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 351.15
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.0678
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 0.12s
                      Time elapsed: 00:13:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 714/1 [0m                       

                       Computation: 694528 steps/s (collection: 0.046s, learning 0.096s)
                       Mean reward: 349.07
               Mean episode length: 246.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.0526
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 0.14s
                      Time elapsed: 00:13:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 715/1 [0m                       

                       Computation: 832753 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 356.12
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.7902
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4450
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 0.12s
                      Time elapsed: 00:13:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 716/1 [0m                       

                       Computation: 831980 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 357.87
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.9146
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4453
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 0.12s
                      Time elapsed: 00:13:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 717/1 [0m                       

                       Computation: 814411 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 355.52
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.6881
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4473
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 0.12s
                      Time elapsed: 00:13:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 718/1 [0m                       

                       Computation: 771878 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 357.98
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.4024
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 0.13s
                      Time elapsed: 00:13:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 719/1 [0m                       

                       Computation: 843730 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 358.99
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.5558
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4455
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 48.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 0.12s
                      Time elapsed: 00:13:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 720/1 [0m                       

                       Computation: 785277 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 344.93
               Mean episode length: 245.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.2077
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 0.13s
                      Time elapsed: 00:13:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 721/1 [0m                       

                       Computation: 759167 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 357.81
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.8059
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4451
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 0.13s
                      Time elapsed: 00:13:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 722/1 [0m                       

                       Computation: 712821 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 358.24
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.3885
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4476
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 0.14s
                      Time elapsed: 00:13:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 723/1 [0m                       

                       Computation: 802644 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 357.46
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.1605
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4477
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 0.12s
                      Time elapsed: 00:13:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 724/1 [0m                       

                       Computation: 822239 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 360.52
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.8041
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4507
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 0.12s
                      Time elapsed: 00:13:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 725/1 [0m                       

                       Computation: 786298 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 352.59
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.8966
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4443
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 0.13s
                      Time elapsed: 00:13:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 726/1 [0m                       

                       Computation: 756107 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 365.20
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.5078
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4495
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 0.13s
                      Time elapsed: 00:13:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 727/1 [0m                       

                       Computation: 805521 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 358.48
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.4812
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4484
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 0.12s
                      Time elapsed: 00:13:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 728/1 [0m                       

                       Computation: 836529 steps/s (collection: 0.043s, learning 0.075s)
                       Mean reward: 352.01
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.1468
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4482
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 0.12s
                      Time elapsed: 00:13:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 729/1 [0m                       

                       Computation: 881595 steps/s (collection: 0.039s, learning 0.073s)
                       Mean reward: 351.47
               Mean episode length: 246.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1047
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4462
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 0.11s
                      Time elapsed: 00:13:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 730/1 [0m                       

                       Computation: 873511 steps/s (collection: 0.039s, learning 0.074s)
                       Mean reward: 360.97
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.4305
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4485
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 44.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 0.11s
                      Time elapsed: 00:13:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 731/1 [0m                       

                       Computation: 897544 steps/s (collection: 0.041s, learning 0.068s)
                       Mean reward: 352.86
               Mean episode length: 246.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.5753
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 0.11s
                      Time elapsed: 00:13:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 732/1 [0m                       

                       Computation: 847459 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 355.12
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.5151
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4454
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 0.12s
                      Time elapsed: 00:13:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 733/1 [0m                       

                       Computation: 736131 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 354.49
               Mean episode length: 246.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.3305
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 0.13s
                      Time elapsed: 00:13:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 734/1 [0m                       

                       Computation: 801201 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 364.28
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.1312
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4460
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 0.12s
                      Time elapsed: 00:13:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 735/1 [0m                       

                       Computation: 690030 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 358.69
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.8099
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4460
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 0.14s
                      Time elapsed: 00:13:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 736/1 [0m                       

                       Computation: 801197 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 362.44
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.0742
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4457
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 0.12s
                      Time elapsed: 00:13:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 737/1 [0m                       

                       Computation: 779055 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 359.84
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.5503
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4458
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 0.13s
                      Time elapsed: 00:13:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 738/1 [0m                       

                       Computation: 837948 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 358.06
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.1591
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 0.12s
                      Time elapsed: 00:13:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 739/1 [0m                       

                       Computation: 692125 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 355.42
               Mean episode length: 247.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.3309
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4417
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 0.14s
                      Time elapsed: 00:13:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 740/1 [0m                       

                       Computation: 689365 steps/s (collection: 0.048s, learning 0.095s)
                       Mean reward: 357.24
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.7338
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 46.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 0.14s
                      Time elapsed: 00:13:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 741/1 [0m                       

                       Computation: 654339 steps/s (collection: 0.045s, learning 0.105s)
                       Mean reward: 356.28
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.0002
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 0.15s
                      Time elapsed: 00:13:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 742/1 [0m                       

                       Computation: 815248 steps/s (collection: 0.044s, learning 0.077s)
                       Mean reward: 357.78
               Mean episode length: 246.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.1628
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 0.12s
                      Time elapsed: 00:13:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 743/1 [0m                       

                       Computation: 676982 steps/s (collection: 0.047s, learning 0.098s)
                       Mean reward: 347.96
               Mean episode length: 246.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.9262
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4348
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 0.15s
                      Time elapsed: 00:14:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 744/1 [0m                       

                       Computation: 792405 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 345.54
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.8796
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 0.12s
                      Time elapsed: 00:14:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 745/1 [0m                       

                       Computation: 634537 steps/s (collection: 0.044s, learning 0.111s)
                       Mean reward: 349.42
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.3118
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 0.15s
                      Time elapsed: 00:14:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 746/1 [0m                       

                       Computation: 787466 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 349.27
               Mean episode length: 246.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.4743
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 0.12s
                      Time elapsed: 00:14:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 747/1 [0m                       

                       Computation: 764861 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 355.50
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.6394
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4388
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 0.13s
                      Time elapsed: 00:14:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 748/1 [0m                       

                       Computation: 802243 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 355.18
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.5588
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 0.12s
                      Time elapsed: 00:14:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 749/1 [0m                       

                       Computation: 761161 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 354.71
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.4692
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 0.13s
                      Time elapsed: 00:14:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 750/1 [0m                       

                       Computation: 815461 steps/s (collection: 0.043s, learning 0.078s)
                       Mean reward: 359.44
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.6527
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 48.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 0.12s
                      Time elapsed: 00:14:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 751/1 [0m                       

                       Computation: 835456 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 349.03
               Mean episode length: 246.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.4950
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 0.12s
                      Time elapsed: 00:14:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 752/1 [0m                       

                       Computation: 640206 steps/s (collection: 0.042s, learning 0.112s)
                       Mean reward: 359.30
               Mean episode length: 247.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.3731
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 0.15s
                      Time elapsed: 00:14:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 753/1 [0m                       

                       Computation: 879059 steps/s (collection: 0.038s, learning 0.074s)
                       Mean reward: 350.34
               Mean episode length: 247.18
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 69.5222
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 0.11s
                      Time elapsed: 00:14:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 754/1 [0m                       

                       Computation: 879952 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 362.95
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.1937
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4466
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 0.11s
                      Time elapsed: 00:14:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 755/1 [0m                       

                       Computation: 834441 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 360.89
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.5610
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 0.12s
                      Time elapsed: 00:14:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 756/1 [0m                       

                       Computation: 888091 steps/s (collection: 0.040s, learning 0.071s)
                       Mean reward: 367.42
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 73.0496
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 0.11s
                      Time elapsed: 00:14:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 757/1 [0m                       

                       Computation: 760576 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 364.44
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.5766
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4485
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 0.13s
                      Time elapsed: 00:14:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 758/1 [0m                       

                       Computation: 822480 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 356.75
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.1982
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4443
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 0.12s
                      Time elapsed: 00:14:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 759/1 [0m                       

                       Computation: 739165 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 357.56
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.0756
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 0.13s
                      Time elapsed: 00:14:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 760/1 [0m                       

                       Computation: 822528 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 356.89
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2255
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4444
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 0.12s
                      Time elapsed: 00:14:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 761/1 [0m                       

                       Computation: 717448 steps/s (collection: 0.049s, learning 0.088s)
                       Mean reward: 364.36
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.4041
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 44.8750
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 0.14s
                      Time elapsed: 00:14:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 762/1 [0m                       

                       Computation: 812219 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 355.02
               Mean episode length: 245.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8948
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 0.12s
                      Time elapsed: 00:14:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 763/1 [0m                       

                       Computation: 815680 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 366.14
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 73.2520
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4512
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 0.12s
                      Time elapsed: 00:14:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 764/1 [0m                       

                       Computation: 699706 steps/s (collection: 0.045s, learning 0.095s)
                       Mean reward: 360.76
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.7151
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4459
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 0.14s
                      Time elapsed: 00:14:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 765/1 [0m                       

                       Computation: 675431 steps/s (collection: 0.039s, learning 0.107s)
                       Mean reward: 366.57
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 73.0310
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4495
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 0.15s
                      Time elapsed: 00:14:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 766/1 [0m                       

                       Computation: 780592 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 363.62
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3859
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4478
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 0.13s
                      Time elapsed: 00:14:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 767/1 [0m                       

                       Computation: 655458 steps/s (collection: 0.049s, learning 0.101s)
                       Mean reward: 362.21
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8733
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 0.15s
                      Time elapsed: 00:14:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 768/1 [0m                       

                       Computation: 660459 steps/s (collection: 0.039s, learning 0.110s)
                       Mean reward: 365.12
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.7704
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4511
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 0.15s
                      Time elapsed: 00:14:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 769/1 [0m                       

                       Computation: 608474 steps/s (collection: 0.052s, learning 0.110s)
                       Mean reward: 357.81
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8214
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 0.16s
                      Time elapsed: 00:14:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 770/1 [0m                       

                       Computation: 843758 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 362.86
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2562
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4485
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 0.12s
                      Time elapsed: 00:14:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 771/1 [0m                       

                       Computation: 860177 steps/s (collection: 0.042s, learning 0.073s)
                       Mean reward: 363.73
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1897
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4483
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 46.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 0.11s
                      Time elapsed: 00:14:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 772/1 [0m                       

                       Computation: 776959 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 352.36
               Mean episode length: 246.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.4176
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 0.13s
                      Time elapsed: 00:14:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 773/1 [0m                       

                       Computation: 741733 steps/s (collection: 0.047s, learning 0.086s)
                       Mean reward: 357.62
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.8370
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 0.13s
                      Time elapsed: 00:14:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 774/1 [0m                       

                       Computation: 831968 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 357.02
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6486
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4436
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 0.12s
                      Time elapsed: 00:14:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 775/1 [0m                       

                       Computation: 854664 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 357.49
               Mean episode length: 244.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9367
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 0.12s
                      Time elapsed: 00:14:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 776/1 [0m                       

                       Computation: 720063 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 354.08
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.5148
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4451
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 0.14s
                      Time elapsed: 00:14:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 777/1 [0m                       

                       Computation: 812595 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 361.63
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.4765
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4462
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 0.12s
                      Time elapsed: 00:14:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 778/1 [0m                       

                       Computation: 773310 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 363.42
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.3411
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4477
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 0.13s
                      Time elapsed: 00:14:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 779/1 [0m                       

                       Computation: 767322 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 359.39
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1426
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4455
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 0.13s
                      Time elapsed: 00:14:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 780/1 [0m                       

                       Computation: 808588 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 364.48
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4099
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4489
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 0.12s
                      Time elapsed: 00:14:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 781/1 [0m                       

                       Computation: 783148 steps/s (collection: 0.045s, learning 0.081s)
                       Mean reward: 358.45
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.2584
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4446
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 0.13s
                      Time elapsed: 00:14:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 782/1 [0m                       

                       Computation: 835584 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 361.08
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9833
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4441
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 42.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 0.12s
                      Time elapsed: 00:14:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 783/1 [0m                       

                       Computation: 819042 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 353.08
               Mean episode length: 245.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.9122
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 0.12s
                      Time elapsed: 00:14:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 784/1 [0m                       

                       Computation: 807784 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 354.30
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.3540
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 0.12s
                      Time elapsed: 00:14:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 785/1 [0m                       

                       Computation: 774884 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 361.89
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.9410
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4495
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 0.13s
                      Time elapsed: 00:14:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 786/1 [0m                       

                       Computation: 831691 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 355.01
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.2623
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4436
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 0.12s
                      Time elapsed: 00:14:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 787/1 [0m                       

                       Computation: 776950 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 358.01
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.4502
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4458
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 0.13s
                      Time elapsed: 00:14:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 788/1 [0m                       

                       Computation: 709602 steps/s (collection: 0.048s, learning 0.091s)
                       Mean reward: 364.97
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.3723
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4496
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 0.14s
                      Time elapsed: 00:14:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 789/1 [0m                       

                       Computation: 789470 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 359.16
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1878
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 0.12s
                      Time elapsed: 00:14:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 790/1 [0m                       

                       Computation: 825821 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 357.58
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 70.9676
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 0.12s
                      Time elapsed: 00:14:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 791/1 [0m                       

                       Computation: 797806 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 362.61
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.2022
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4488
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 0.12s
                      Time elapsed: 00:14:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 792/1 [0m                       

                       Computation: 804462 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 358.72
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6512
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 44.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 0.12s
                      Time elapsed: 00:14:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 793/1 [0m                       

                       Computation: 851020 steps/s (collection: 0.041s, learning 0.075s)
                       Mean reward: 359.33
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1253
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4475
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 0.12s
                      Time elapsed: 00:14:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 794/1 [0m                       

                       Computation: 699586 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 347.48
               Mean episode length: 245.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 68.5368
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 0.14s
                      Time elapsed: 00:14:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 795/1 [0m                       

                       Computation: 647545 steps/s (collection: 0.047s, learning 0.105s)
                       Mean reward: 356.17
               Mean episode length: 246.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9161
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 0.15s
                      Time elapsed: 00:14:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 796/1 [0m                       

                       Computation: 699551 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 356.56
               Mean episode length: 247.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7514
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 0.14s
                      Time elapsed: 00:14:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 797/1 [0m                       

                       Computation: 712139 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 356.51
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7336
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 0.14s
                      Time elapsed: 00:14:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 798/1 [0m                       

                       Computation: 680140 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 357.25
               Mean episode length: 246.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2370
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4435
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 0.14s
                      Time elapsed: 00:15:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 799/1 [0m                       

                       Computation: 783459 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 358.27
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9789
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 0.13s
                      Time elapsed: 00:15:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 800/1 [0m                       

                       Computation: 711038 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 361.24
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6870
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4468
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 0.14s
                      Time elapsed: 00:15:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 801/1 [0m                       

                       Computation: 814723 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 357.86
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.0534
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4466
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 0.12s
                      Time elapsed: 00:15:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 802/1 [0m                       

                       Computation: 874928 steps/s (collection: 0.040s, learning 0.072s)
                       Mean reward: 365.76
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 72.9878
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4480
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 0.11s
                      Time elapsed: 00:15:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 803/1 [0m                       

                       Computation: 836729 steps/s (collection: 0.041s, learning 0.076s)
                       Mean reward: 364.07
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7161
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4474
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 39.9167
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 0.12s
                      Time elapsed: 00:15:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 804/1 [0m                       

                       Computation: 827196 steps/s (collection: 0.046s, learning 0.073s)
                       Mean reward: 351.66
               Mean episode length: 246.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.9178
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 0.12s
                      Time elapsed: 00:15:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 805/1 [0m                       

                       Computation: 804134 steps/s (collection: 0.047s, learning 0.076s)
                       Mean reward: 357.08
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.5325
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4463
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 0.12s
                      Time elapsed: 00:15:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 806/1 [0m                       

                       Computation: 869861 steps/s (collection: 0.041s, learning 0.072s)
                       Mean reward: 358.38
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.1166
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4483
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 0.11s
                      Time elapsed: 00:15:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 807/1 [0m                       

                       Computation: 840005 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 363.69
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4321
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4488
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 0.12s
                      Time elapsed: 00:15:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 808/1 [0m                       

                       Computation: 802432 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 366.21
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7293
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4516
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 0.12s
                      Time elapsed: 00:15:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 809/1 [0m                       

                       Computation: 870081 steps/s (collection: 0.040s, learning 0.073s)
                       Mean reward: 358.38
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2641
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 0.11s
                      Time elapsed: 00:15:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 810/1 [0m                       

                       Computation: 847116 steps/s (collection: 0.041s, learning 0.076s)
                       Mean reward: 360.68
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.6330
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4475
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 0.12s
                      Time elapsed: 00:15:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 811/1 [0m                       

                       Computation: 611997 steps/s (collection: 0.043s, learning 0.118s)
                       Mean reward: 367.11
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1587
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4492
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 0.16s
                      Time elapsed: 00:15:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 812/1 [0m                       

                       Computation: 829441 steps/s (collection: 0.043s, learning 0.076s)
                       Mean reward: 361.00
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4946
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 0.12s
                      Time elapsed: 00:15:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 813/1 [0m                       

                       Computation: 755808 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 364.06
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8257
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4512
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 42.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 0.13s
                      Time elapsed: 00:15:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 814/1 [0m                       

                       Computation: 758798 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 367.94
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4760
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4537
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 0.13s
                      Time elapsed: 00:15:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 815/1 [0m                       

                       Computation: 729577 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 358.27
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3267
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 0.13s
                      Time elapsed: 00:15:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 816/1 [0m                       

                       Computation: 724486 steps/s (collection: 0.045s, learning 0.091s)
                       Mean reward: 365.59
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4152
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4465
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 0.14s
                      Time elapsed: 00:15:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 817/1 [0m                       

                       Computation: 720742 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 365.10
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4135
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4464
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 0.14s
                      Time elapsed: 00:15:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 818/1 [0m                       

                       Computation: 847568 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 365.84
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7625
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4460
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 0.12s
                      Time elapsed: 00:15:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 819/1 [0m                       

                       Computation: 892895 steps/s (collection: 0.040s, learning 0.070s)
                       Mean reward: 362.26
               Mean episode length: 246.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0390
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4421
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 0.11s
                      Time elapsed: 00:15:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 820/1 [0m                       

                       Computation: 828616 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 364.71
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5800
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4446
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 0.12s
                      Time elapsed: 00:15:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 821/1 [0m                       

                       Computation: 822367 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 362.65
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9091
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4421
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 0.12s
                      Time elapsed: 00:15:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 822/1 [0m                       

                       Computation: 845899 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 368.73
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3433
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4447
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 0.12s
                      Time elapsed: 00:15:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 823/1 [0m                       

                       Computation: 693007 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 369.91
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2572
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4451
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 44.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 0.14s
                      Time elapsed: 00:15:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 824/1 [0m                       

                       Computation: 747412 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 365.99
               Mean episode length: 244.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4903
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 0.13s
                      Time elapsed: 00:15:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 825/1 [0m                       

                       Computation: 728013 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 364.03
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5263
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4441
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 0.14s
                      Time elapsed: 00:15:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 826/1 [0m                       

                       Computation: 677772 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 361.23
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9567
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4452
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 0.15s
                      Time elapsed: 00:15:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 827/1 [0m                       

                       Computation: 699459 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 368.12
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2150
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4462
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 0.14s
                      Time elapsed: 00:15:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 828/1 [0m                       

                       Computation: 697001 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 362.45
               Mean episode length: 247.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1021
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4454
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 0.14s
                      Time elapsed: 00:15:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 829/1 [0m                       

                       Computation: 808972 steps/s (collection: 0.046s, learning 0.075s)
                       Mean reward: 368.04
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4256
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4474
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 0.12s
                      Time elapsed: 00:15:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 830/1 [0m                       

                       Computation: 865988 steps/s (collection: 0.036s, learning 0.077s)
                       Mean reward: 370.55
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4772
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4484
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 0.11s
                      Time elapsed: 00:15:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 831/1 [0m                       

                       Computation: 787545 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 364.84
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6289
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4468
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 0.12s
                      Time elapsed: 00:15:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 832/1 [0m                       

                       Computation: 832712 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 367.49
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2210
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4466
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 0.12s
                      Time elapsed: 00:15:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 833/1 [0m                       

                       Computation: 800674 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 369.59
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5630
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4489
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 0.12s
                      Time elapsed: 00:15:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 834/1 [0m                       

                       Computation: 870908 steps/s (collection: 0.038s, learning 0.075s)
                       Mean reward: 372.26
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1661
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4475
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 41.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 0.11s
                      Time elapsed: 00:15:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 835/1 [0m                       

                       Computation: 787570 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 366.15
               Mean episode length: 246.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5515
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 0.12s
                      Time elapsed: 00:15:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 836/1 [0m                       

                       Computation: 693265 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 368.95
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2894
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4499
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 0.14s
                      Time elapsed: 00:15:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 837/1 [0m                       

                       Computation: 709713 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 371.57
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6025
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4499
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 0.14s
                      Time elapsed: 00:15:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 838/1 [0m                       

                       Computation: 872643 steps/s (collection: 0.038s, learning 0.075s)
                       Mean reward: 369.82
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6205
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4479
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 0.11s
                      Time elapsed: 00:15:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 839/1 [0m                       

                       Computation: 761927 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 372.71
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5584
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4506
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 0.13s
                      Time elapsed: 00:15:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 840/1 [0m                       

                       Computation: 725452 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 374.22
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3163
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4518
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 0.14s
                      Time elapsed: 00:15:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 841/1 [0m                       

                       Computation: 779213 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 372.69
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0143
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4502
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 0.13s
                      Time elapsed: 00:15:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 842/1 [0m                       

                       Computation: 719220 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 373.01
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4712
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4498
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 0.14s
                      Time elapsed: 00:15:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 843/1 [0m                       

                       Computation: 794258 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 372.19
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9745
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4496
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 0.12s
                      Time elapsed: 00:15:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 844/1 [0m                       

                       Computation: 873630 steps/s (collection: 0.038s, learning 0.075s)
                       Mean reward: 373.04
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5426
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4509
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 42.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 0.11s
                      Time elapsed: 00:15:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 845/1 [0m                       

                       Computation: 818984 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 369.95
               Mean episode length: 246.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5540
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 0.12s
                      Time elapsed: 00:15:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 846/1 [0m                       

                       Computation: 867202 steps/s (collection: 0.039s, learning 0.075s)
                       Mean reward: 367.54
               Mean episode length: 247.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3141
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4450
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 0.11s
                      Time elapsed: 00:15:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 847/1 [0m                       

                       Computation: 782799 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 365.39
               Mean episode length: 245.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8672
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 0.13s
                      Time elapsed: 00:15:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 848/1 [0m                       

                       Computation: 646560 steps/s (collection: 0.051s, learning 0.101s)
                       Mean reward: 368.84
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2585
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4452
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 0.15s
                      Time elapsed: 00:15:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 849/1 [0m                       

                       Computation: 750147 steps/s (collection: 0.052s, learning 0.079s)
                       Mean reward: 371.64
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5564
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4467
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 0.13s
                      Time elapsed: 00:15:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 850/1 [0m                       

                       Computation: 858431 steps/s (collection: 0.040s, learning 0.075s)
                       Mean reward: 377.93
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.2244
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4486
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 0.11s
                      Time elapsed: 00:15:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 851/1 [0m                       

                       Computation: 819625 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 370.85
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8843
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 0.12s
                      Time elapsed: 00:15:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 852/1 [0m                       

                       Computation: 856216 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 369.01
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4172
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4424
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 0.11s
                      Time elapsed: 00:15:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 853/1 [0m                       

                       Computation: 688730 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 366.67
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4181
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4438
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 0.14s
                      Time elapsed: 00:15:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 854/1 [0m                       

                       Computation: 727825 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 370.33
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5814
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4462
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 0.14s
                      Time elapsed: 00:15:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 855/1 [0m                       

                       Computation: 613950 steps/s (collection: 0.056s, learning 0.104s)
                       Mean reward: 368.65
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.4914
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 38.6667
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 0.16s
                      Time elapsed: 00:16:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 856/1 [0m                       

                       Computation: 683729 steps/s (collection: 0.052s, learning 0.092s)
                       Mean reward: 371.21
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3632
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 0.14s
                      Time elapsed: 00:16:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 857/1 [0m                       

                       Computation: 733479 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 373.49
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2502
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 0.13s
                      Time elapsed: 00:16:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 858/1 [0m                       

                       Computation: 776788 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 368.61
               Mean episode length: 247.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4160
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4456
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 0.13s
                      Time elapsed: 00:16:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 859/1 [0m                       

                       Computation: 704302 steps/s (collection: 0.046s, learning 0.094s)
                       Mean reward: 367.17
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8890
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 0.14s
                      Time elapsed: 00:16:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 860/1 [0m                       

                       Computation: 741758 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 367.78
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5444
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4435
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 0.13s
                      Time elapsed: 00:16:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 861/1 [0m                       

                       Computation: 731979 steps/s (collection: 0.049s, learning 0.086s)
                       Mean reward: 373.51
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.3532
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 0.13s
                      Time elapsed: 00:16:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 862/1 [0m                       

                       Computation: 670758 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 370.32
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8592
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4435
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 0.15s
                      Time elapsed: 00:16:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 863/1 [0m                       

                       Computation: 607843 steps/s (collection: 0.039s, learning 0.123s)
                       Mean reward: 366.75
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6849
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 0.16s
                      Time elapsed: 00:16:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 864/1 [0m                       

                       Computation: 765379 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 366.50
               Mean episode length: 246.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3924
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 0.13s
                      Time elapsed: 00:16:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 865/1 [0m                       

                       Computation: 747903 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 369.01
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1561
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 40.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 0.13s
                      Time elapsed: 00:16:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 866/1 [0m                       

                       Computation: 832593 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 368.90
               Mean episode length: 245.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4649
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 0.12s
                      Time elapsed: 00:16:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 867/1 [0m                       

                       Computation: 793800 steps/s (collection: 0.049s, learning 0.075s)
                       Mean reward: 364.93
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8806
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 0.12s
                      Time elapsed: 00:16:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 868/1 [0m                       

                       Computation: 707020 steps/s (collection: 0.049s, learning 0.090s)
                       Mean reward: 368.02
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9225
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 0.14s
                      Time elapsed: 00:16:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 869/1 [0m                       

                       Computation: 622060 steps/s (collection: 0.049s, learning 0.109s)
                       Mean reward: 362.35
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9614
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 0.16s
                      Time elapsed: 00:16:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 870/1 [0m                       

                       Computation: 789333 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 365.10
               Mean episode length: 247.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6332
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 0.12s
                      Time elapsed: 00:16:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 871/1 [0m                       

                       Computation: 673247 steps/s (collection: 0.058s, learning 0.089s)
                       Mean reward: 367.57
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1228
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4410
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 0.15s
                      Time elapsed: 00:16:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 872/1 [0m                       

                       Computation: 756129 steps/s (collection: 0.046s, learning 0.085s)
                       Mean reward: 363.16
               Mean episode length: 246.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0397
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 0.13s
                      Time elapsed: 00:16:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 873/1 [0m                       

                       Computation: 717291 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 360.97
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.9739
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 0.14s
                      Time elapsed: 00:16:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 874/1 [0m                       

                       Computation: 719958 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 365.28
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5581
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 0.14s
                      Time elapsed: 00:16:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 875/1 [0m                       

                       Computation: 729237 steps/s (collection: 0.048s, learning 0.087s)
                       Mean reward: 364.16
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8324
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4374
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 42.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 0.13s
                      Time elapsed: 00:16:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 876/1 [0m                       

                       Computation: 759005 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 365.32
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5031
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4402
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 0.13s
                      Time elapsed: 00:16:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 877/1 [0m                       

                       Computation: 581734 steps/s (collection: 0.060s, learning 0.109s)
                       Mean reward: 361.60
               Mean episode length: 246.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1522
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 0.17s
                      Time elapsed: 00:16:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 878/1 [0m                       

                       Computation: 629606 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 363.51
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5572
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4377
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 0.16s
                      Time elapsed: 00:16:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 879/1 [0m                       

                       Computation: 667991 steps/s (collection: 0.052s, learning 0.096s)
                       Mean reward: 365.56
               Mean episode length: 247.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6144
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 0.15s
                      Time elapsed: 00:16:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 880/1 [0m                       

                       Computation: 538574 steps/s (collection: 0.060s, learning 0.123s)
                       Mean reward: 359.47
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3228
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 0.18s
                      Time elapsed: 00:16:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 881/1 [0m                       

                       Computation: 642454 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 369.17
               Mean episode length: 246.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.3205
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 0.15s
                      Time elapsed: 00:16:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 882/1 [0m                       

                       Computation: 710974 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 364.12
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4708
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 0.14s
                      Time elapsed: 00:16:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 883/1 [0m                       

                       Computation: 697828 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 363.11
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3897
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 0.14s
                      Time elapsed: 00:16:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 884/1 [0m                       

                       Computation: 566380 steps/s (collection: 0.055s, learning 0.119s)
                       Mean reward: 364.87
               Mean episode length: 247.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8159
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 0.17s
                      Time elapsed: 00:16:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 885/1 [0m                       

                       Computation: 640158 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 360.71
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8073
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4371
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 0.15s
                      Time elapsed: 00:16:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 886/1 [0m                       

                       Computation: 607845 steps/s (collection: 0.055s, learning 0.107s)
                       Mean reward: 367.85
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.0323
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 38.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 0.16s
                      Time elapsed: 00:16:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 887/1 [0m                       

                       Computation: 687997 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 357.63
               Mean episode length: 244.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8803
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 0.14s
                      Time elapsed: 00:16:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 888/1 [0m                       

                       Computation: 687192 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 366.92
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.8124
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 0.14s
                      Time elapsed: 00:16:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 889/1 [0m                       

                       Computation: 704392 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 363.91
               Mean episode length: 247.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2835
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 0.14s
                      Time elapsed: 00:16:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 890/1 [0m                       

                       Computation: 581406 steps/s (collection: 0.048s, learning 0.121s)
                       Mean reward: 365.49
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6952
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 0.17s
                      Time elapsed: 00:16:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 891/1 [0m                       

                       Computation: 633984 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 367.78
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7542
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 0.16s
                      Time elapsed: 00:16:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 892/1 [0m                       

                       Computation: 710720 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 369.20
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.2922
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 0.14s
                      Time elapsed: 00:16:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 893/1 [0m                       

                       Computation: 692212 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 371.00
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5547
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 0.14s
                      Time elapsed: 00:16:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 894/1 [0m                       

                       Computation: 733058 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 373.11
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.7318
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4438
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 0.13s
                      Time elapsed: 00:16:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 895/1 [0m                       

                       Computation: 797987 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 371.70
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9183
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4442
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 0.12s
                      Time elapsed: 00:16:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 896/1 [0m                       

                       Computation: 767580 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 371.74
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4950
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 40.9167
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 0.13s
                      Time elapsed: 00:16:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 897/1 [0m                       

                       Computation: 766529 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 373.08
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4048
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 0.13s
                      Time elapsed: 00:16:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 898/1 [0m                       

                       Computation: 797505 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 367.29
               Mean episode length: 246.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7382
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 0.12s
                      Time elapsed: 00:16:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 899/1 [0m                       

                       Computation: 792554 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 373.44
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.2769
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 0.12s
                      Time elapsed: 00:16:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 900/1 [0m                       

                       Computation: 725543 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 375.64
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5687
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 0.14s
                      Time elapsed: 00:16:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 901/1 [0m                       

                       Computation: 825722 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 375.53
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.9023
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 0.12s
                      Time elapsed: 00:16:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 902/1 [0m                       

                       Computation: 776071 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 372.04
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4452
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 0.13s
                      Time elapsed: 00:16:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 903/1 [0m                       

                       Computation: 705270 steps/s (collection: 0.052s, learning 0.088s)
                       Mean reward: 372.70
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0187
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 0.14s
                      Time elapsed: 00:16:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 904/1 [0m                       

                       Computation: 731827 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 371.27
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.8865
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 0.13s
                      Time elapsed: 00:16:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 905/1 [0m                       

                       Computation: 770824 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 362.55
               Mean episode length: 246.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3988
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 0.13s
                      Time elapsed: 00:16:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 906/1 [0m                       

                       Computation: 727959 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 374.62
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.4598
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4420
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 0.14s
                      Time elapsed: 00:16:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 907/1 [0m                       

                       Computation: 748047 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 373.25
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6003
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4425
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 37.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 0.13s
                      Time elapsed: 00:17:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 908/1 [0m                       

                       Computation: 661736 steps/s (collection: 0.038s, learning 0.111s)
                       Mean reward: 372.11
               Mean episode length: 244.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.9565
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 0.15s
                      Time elapsed: 00:17:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 909/1 [0m                       

                       Computation: 730141 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 366.08
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6911
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 0.13s
                      Time elapsed: 00:17:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 910/1 [0m                       

                       Computation: 677860 steps/s (collection: 0.038s, learning 0.107s)
                       Mean reward: 366.23
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9899
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 0.15s
                      Time elapsed: 00:17:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 911/1 [0m                       

                       Computation: 722426 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 363.15
               Mean episode length: 247.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1815
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 0.14s
                      Time elapsed: 00:17:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 912/1 [0m                       

                       Computation: 668166 steps/s (collection: 0.042s, learning 0.106s)
                       Mean reward: 367.04
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.7928
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 0.15s
                      Time elapsed: 00:17:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 913/1 [0m                       

                       Computation: 709296 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 360.95
               Mean episode length: 246.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7123
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 0.14s
                      Time elapsed: 00:17:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 914/1 [0m                       

                       Computation: 696786 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 362.54
               Mean episode length: 246.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1234
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 0.14s
                      Time elapsed: 00:17:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 915/1 [0m                       

                       Computation: 750219 steps/s (collection: 0.049s, learning 0.083s)
                       Mean reward: 365.36
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2862
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 0.13s
                      Time elapsed: 00:17:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 916/1 [0m                       

                       Computation: 665722 steps/s (collection: 0.039s, learning 0.109s)
                       Mean reward: 363.94
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5275
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4348
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 0.15s
                      Time elapsed: 00:17:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 917/1 [0m                       

                       Computation: 641984 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 365.99
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.1431
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 38.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 0.15s
                      Time elapsed: 00:17:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 918/1 [0m                       

                       Computation: 615913 steps/s (collection: 0.046s, learning 0.114s)
                       Mean reward: 367.48
               Mean episode length: 246.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.9936
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 0.16s
                      Time elapsed: 00:17:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 919/1 [0m                       

                       Computation: 643986 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 361.57
               Mean episode length: 245.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7052
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 0.15s
                      Time elapsed: 00:17:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 920/1 [0m                       

                       Computation: 653122 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 363.58
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0664
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 0.15s
                      Time elapsed: 00:17:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 921/1 [0m                       

                       Computation: 615845 steps/s (collection: 0.044s, learning 0.116s)
                       Mean reward: 356.95
               Mean episode length: 246.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8845
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 0.16s
                      Time elapsed: 00:17:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 922/1 [0m                       

                       Computation: 619996 steps/s (collection: 0.041s, learning 0.118s)
                       Mean reward: 357.82
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2278
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 0.16s
                      Time elapsed: 00:17:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 923/1 [0m                       

                       Computation: 629629 steps/s (collection: 0.045s, learning 0.112s)
                       Mean reward: 357.52
               Mean episode length: 246.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3751
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4306
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 0.16s
                      Time elapsed: 00:17:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 924/1 [0m                       

                       Computation: 559986 steps/s (collection: 0.057s, learning 0.119s)
                       Mean reward: 360.64
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.7647
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 0.18s
                      Time elapsed: 00:17:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 925/1 [0m                       

                       Computation: 659223 steps/s (collection: 0.043s, learning 0.107s)
                       Mean reward: 352.09
               Mean episode length: 244.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1857
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4244
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 0.15s
                      Time elapsed: 00:17:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 926/1 [0m                       

                       Computation: 648116 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 357.90
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.9748
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 0.15s
                      Time elapsed: 00:17:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 927/1 [0m                       

                       Computation: 656753 steps/s (collection: 0.043s, learning 0.107s)
                       Mean reward: 360.37
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8122
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4325
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 0.15s
                      Time elapsed: 00:17:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 928/1 [0m                       

                       Computation: 672841 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 358.55
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.0897
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 34.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 0.15s
                      Time elapsed: 00:17:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 929/1 [0m                       

                       Computation: 495950 steps/s (collection: 0.054s, learning 0.144s)
                       Mean reward: 359.70
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3798
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 0.20s
                      Time elapsed: 00:17:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 930/1 [0m                       

                       Computation: 676654 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 364.07
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.6562
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 0.15s
                      Time elapsed: 00:17:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 931/1 [0m                       

                       Computation: 619346 steps/s (collection: 0.043s, learning 0.116s)
                       Mean reward: 354.47
               Mean episode length: 246.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.4652
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4260
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 0.16s
                      Time elapsed: 00:17:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 932/1 [0m                       

                       Computation: 698142 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 356.11
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6114
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 0.14s
                      Time elapsed: 00:17:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 933/1 [0m                       

                       Computation: 635814 steps/s (collection: 0.043s, learning 0.112s)
                       Mean reward: 351.16
               Mean episode length: 247.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.7100
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4203
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 0.15s
                      Time elapsed: 00:17:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 934/1 [0m                       

                       Computation: 667942 steps/s (collection: 0.043s, learning 0.104s)
                       Mean reward: 353.00
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.1728
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 0.15s
                      Time elapsed: 00:17:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 935/1 [0m                       

                       Computation: 724562 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 353.59
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.0567
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4268
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 0.14s
                      Time elapsed: 00:17:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 936/1 [0m                       

                       Computation: 616093 steps/s (collection: 0.053s, learning 0.107s)
                       Mean reward: 352.12
               Mean episode length: 246.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.7900
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4251
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 0.16s
                      Time elapsed: 00:17:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 937/1 [0m                       

                       Computation: 656701 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 357.81
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.8988
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 0.15s
                      Time elapsed: 00:17:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 938/1 [0m                       

                       Computation: 671567 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 361.55
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.8000
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 36.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 0.15s
                      Time elapsed: 00:17:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 939/1 [0m                       

                       Computation: 662570 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 358.76
               Mean episode length: 246.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2542
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 0.15s
                      Time elapsed: 00:17:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 940/1 [0m                       

                       Computation: 751534 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 359.82
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3857
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 0.13s
                      Time elapsed: 00:17:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 941/1 [0m                       

                       Computation: 670358 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 354.84
               Mean episode length: 245.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.7495
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4256
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 0.15s
                      Time elapsed: 00:17:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 942/1 [0m                       

                       Computation: 847140 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 352.74
               Mean episode length: 246.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.9422
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 0.12s
                      Time elapsed: 00:17:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 943/1 [0m                       

                       Computation: 696035 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 357.85
               Mean episode length: 246.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3026
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 0.14s
                      Time elapsed: 00:17:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 944/1 [0m                       

                       Computation: 822638 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 359.17
               Mean episode length: 247.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.0165
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 0.12s
                      Time elapsed: 00:17:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 945/1 [0m                       

                       Computation: 755876 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 358.73
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3278
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 0.13s
                      Time elapsed: 00:17:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 946/1 [0m                       

                       Computation: 765349 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 355.02
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6832
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 0.13s
                      Time elapsed: 00:17:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 947/1 [0m                       

                       Computation: 730144 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 359.20
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2773
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 0.13s
                      Time elapsed: 00:17:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 948/1 [0m                       

                       Computation: 689661 steps/s (collection: 0.038s, learning 0.105s)
                       Mean reward: 359.41
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.5640
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4276
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 38.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 0.14s
                      Time elapsed: 00:17:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 949/1 [0m                       

                       Computation: 661228 steps/s (collection: 0.047s, learning 0.102s)
                       Mean reward: 355.17
               Mean episode length: 246.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.3775
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 0.15s
                      Time elapsed: 00:17:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 950/1 [0m                       

                       Computation: 707064 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 351.59
               Mean episode length: 247.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8271
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4260
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 0.14s
                      Time elapsed: 00:17:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 951/1 [0m                       

                       Computation: 661790 steps/s (collection: 0.051s, learning 0.098s)
                       Mean reward: 351.50
               Mean episode length: 245.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 69.8106
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4240
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 0.15s
                      Time elapsed: 00:17:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 952/1 [0m                       

                       Computation: 728718 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 358.28
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2400
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 0.13s
                      Time elapsed: 00:17:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 953/1 [0m                       

                       Computation: 807049 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 364.58
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.1073
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 0.12s
                      Time elapsed: 00:17:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 954/1 [0m                       

                       Computation: 714776 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 360.13
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 71.2892
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 0.14s
                      Time elapsed: 00:17:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 955/1 [0m                       

                       Computation: 789219 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 362.80
               Mean episode length: 246.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.0940
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 0.12s
                      Time elapsed: 00:17:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 956/1 [0m                       

                       Computation: 815532 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 364.93
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5440
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 0.12s
                      Time elapsed: 00:17:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 957/1 [0m                       

                       Computation: 690112 steps/s (collection: 0.047s, learning 0.096s)
                       Mean reward: 364.29
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.3285
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 0.14s
                      Time elapsed: 00:17:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 958/1 [0m                       

                       Computation: 811719 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 366.31
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4818
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 0.12s
                      Time elapsed: 00:17:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 959/1 [0m                       

                       Computation: 739478 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 367.31
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.4870
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 35.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 0.13s
                      Time elapsed: 00:17:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 960/1 [0m                       

                       Computation: 727495 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 363.32
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.2628
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 0.14s
                      Time elapsed: 00:17:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 961/1 [0m                       

                       Computation: 766126 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 367.55
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5025
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 0.13s
                      Time elapsed: 00:18:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 962/1 [0m                       

                       Computation: 764807 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 369.88
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6632
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 0.13s
                      Time elapsed: 00:18:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 963/1 [0m                       

                       Computation: 775512 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 367.41
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.0844
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 0.13s
                      Time elapsed: 00:18:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 964/1 [0m                       

                       Computation: 581509 steps/s (collection: 0.047s, learning 0.123s)
                       Mean reward: 375.52
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6538
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 0.17s
                      Time elapsed: 00:18:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 965/1 [0m                       

                       Computation: 698906 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 368.62
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.5057
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 0.14s
                      Time elapsed: 00:18:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 966/1 [0m                       

                       Computation: 739495 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 368.79
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4836
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 0.13s
                      Time elapsed: 00:18:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 967/1 [0m                       

                       Computation: 728408 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 369.82
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6654
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 0.13s
                      Time elapsed: 00:18:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 968/1 [0m                       

                       Computation: 596445 steps/s (collection: 0.042s, learning 0.123s)
                       Mean reward: 370.95
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.6638
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 0.16s
                      Time elapsed: 00:18:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 969/1 [0m                       

                       Computation: 619831 steps/s (collection: 0.049s, learning 0.110s)
                       Mean reward: 372.89
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4514
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 37.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 0.16s
                      Time elapsed: 00:18:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 970/1 [0m                       

                       Computation: 692149 steps/s (collection: 0.048s, learning 0.094s)
                       Mean reward: 363.77
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 72.5251
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 0.14s
                      Time elapsed: 00:18:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 971/1 [0m                       

                       Computation: 759015 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 372.63
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1063
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 0.13s
                      Time elapsed: 00:18:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 972/1 [0m                       

                       Computation: 696674 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 368.62
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 73.4122
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4306
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 0.14s
                      Time elapsed: 00:18:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 973/1 [0m                       

                       Computation: 672750 steps/s (collection: 0.043s, learning 0.103s)
                       Mean reward: 372.97
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.1566
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 0.15s
                      Time elapsed: 00:18:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 974/1 [0m                       

                       Computation: 664055 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 376.86
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.2134
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 0.15s
                      Time elapsed: 00:18:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 975/1 [0m                       

                       Computation: 750297 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 375.29
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5960
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 0.13s
                      Time elapsed: 00:18:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 976/1 [0m                       

                       Computation: 720095 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 375.09
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6411
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 0.14s
                      Time elapsed: 00:18:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 977/1 [0m                       

                       Computation: 717367 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 375.86
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.6892
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 0.14s
                      Time elapsed: 00:18:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 978/1 [0m                       

                       Computation: 783241 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 376.58
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.9953
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 0.13s
                      Time elapsed: 00:18:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 979/1 [0m                       

                       Computation: 792913 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 376.83
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.9489
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 0.12s
                      Time elapsed: 00:18:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 980/1 [0m                       

                       Computation: 762740 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 381.55
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.7836
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 33.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 0.13s
                      Time elapsed: 00:18:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 981/1 [0m                       

                       Computation: 761820 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 375.72
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.5929
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 0.13s
                      Time elapsed: 00:18:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 982/1 [0m                       

                       Computation: 644022 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 385.28
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4199
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4444
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 0.15s
                      Time elapsed: 00:18:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 983/1 [0m                       

                       Computation: 691942 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 376.70
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.9925
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 0.14s
                      Time elapsed: 00:18:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 984/1 [0m                       

                       Computation: 737345 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 384.49
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3695
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 0.13s
                      Time elapsed: 00:18:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 985/1 [0m                       

                       Computation: 739082 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 379.47
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.4322
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 0.13s
                      Time elapsed: 00:18:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 986/1 [0m                       

                       Computation: 730483 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 376.59
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8109
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4347
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 0.13s
                      Time elapsed: 00:18:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 987/1 [0m                       

                       Computation: 759149 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 381.61
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.9475
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 0.13s
                      Time elapsed: 00:18:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 988/1 [0m                       

                       Computation: 792700 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 379.99
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.5637
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 0.12s
                      Time elapsed: 00:18:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 989/1 [0m                       

                       Computation: 850978 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 383.01
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3654
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 0.12s
                      Time elapsed: 00:18:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 990/1 [0m                       

                       Computation: 825900 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 378.01
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8885
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 35.7500
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 0.12s
                      Time elapsed: 00:18:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 991/1 [0m                       

                       Computation: 812062 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 376.21
               Mean episode length: 246.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.0912
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 0.12s
                      Time elapsed: 00:18:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 992/1 [0m                       

                       Computation: 697311 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 375.25
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.8287
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4348
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 0.14s
                      Time elapsed: 00:18:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 993/1 [0m                       

                       Computation: 656097 steps/s (collection: 0.043s, learning 0.107s)
                       Mean reward: 372.81
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0945
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 0.15s
                      Time elapsed: 00:18:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 994/1 [0m                       

                       Computation: 642839 steps/s (collection: 0.039s, learning 0.114s)
                       Mean reward: 379.33
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.5238
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 0.15s
                      Time elapsed: 00:18:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 995/1 [0m                       

                       Computation: 623786 steps/s (collection: 0.039s, learning 0.119s)
                       Mean reward: 380.45
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.7315
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 0.16s
                      Time elapsed: 00:18:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 996/1 [0m                       

                       Computation: 603455 steps/s (collection: 0.051s, learning 0.111s)
                       Mean reward: 384.75
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.2727
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 0.16s
                      Time elapsed: 00:18:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 997/1 [0m                       

                       Computation: 696896 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 382.53
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.1380
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 0.14s
                      Time elapsed: 00:18:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 998/1 [0m                       

                       Computation: 675955 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 380.32
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.5539
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 0.15s
                      Time elapsed: 00:18:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 999/1 [0m                       

                       Computation: 777275 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 377.12
               Mean episode length: 246.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.1171
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 0.13s
                      Time elapsed: 00:18:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1000/1 [0m                       

                       Computation: 620855 steps/s (collection: 0.044s, learning 0.114s)
                       Mean reward: 386.58
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.6211
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 37.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 0.16s
                      Time elapsed: 00:18:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1001/1 [0m                       

                       Computation: 773897 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 382.79
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3148
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 0.13s
                      Time elapsed: 00:18:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1002/1 [0m                       

                       Computation: 661977 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 385.11
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.7916
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 0.15s
                      Time elapsed: 00:18:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1003/1 [0m                       

                       Computation: 634452 steps/s (collection: 0.052s, learning 0.102s)
                       Mean reward: 382.17
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.0383
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4410
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 0.15s
                      Time elapsed: 00:18:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1004/1 [0m                       

                       Computation: 766887 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 379.75
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.4597
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 0.13s
                      Time elapsed: 00:18:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1005/1 [0m                       

                       Computation: 749677 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 385.31
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4454
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 0.13s
                      Time elapsed: 00:18:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1006/1 [0m                       

                       Computation: 706794 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 381.98
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.0451
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 0.14s
                      Time elapsed: 00:18:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1007/1 [0m                       

                       Computation: 774010 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 387.40
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1947
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4425
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 0.13s
                      Time elapsed: 00:18:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1008/1 [0m                       

                       Computation: 767778 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 383.43
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.1453
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 0.13s
                      Time elapsed: 00:18:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1009/1 [0m                       

                       Computation: 725459 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 385.66
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.5833
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4425
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 0.14s
                      Time elapsed: 00:18:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1010/1 [0m                       

                       Computation: 725964 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 388.47
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1420
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 0.14s
                      Time elapsed: 00:18:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1011/1 [0m                       

                       Computation: 810701 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 383.54
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.8649
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 34.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 0.12s
                      Time elapsed: 00:18:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1012/1 [0m                       

                       Computation: 697192 steps/s (collection: 0.047s, learning 0.094s)
                       Mean reward: 385.47
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8001
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 0.14s
                      Time elapsed: 00:18:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1013/1 [0m                       

                       Computation: 597508 steps/s (collection: 0.044s, learning 0.121s)
                       Mean reward: 386.10
               Mean episode length: 246.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4382
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 0.16s
                      Time elapsed: 00:18:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1014/1 [0m                       

                       Computation: 713201 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 384.42
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.5401
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 0.14s
                      Time elapsed: 00:19:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1015/1 [0m                       

                       Computation: 612424 steps/s (collection: 0.042s, learning 0.119s)
                       Mean reward: 384.71
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0124
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 0.16s
                      Time elapsed: 00:19:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1016/1 [0m                       

                       Computation: 655581 steps/s (collection: 0.046s, learning 0.104s)
                       Mean reward: 382.12
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.1129
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 0.15s
                      Time elapsed: 00:19:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1017/1 [0m                       

                       Computation: 749506 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 382.81
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.2237
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4390
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 0.13s
                      Time elapsed: 00:19:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1018/1 [0m                       

                       Computation: 719907 steps/s (collection: 0.053s, learning 0.084s)
                       Mean reward: 382.29
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.0193
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 0.14s
                      Time elapsed: 00:19:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1019/1 [0m                       

                       Computation: 756242 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 380.23
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.3886
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4371
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 0.13s
                      Time elapsed: 00:19:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1020/1 [0m                       

                       Computation: 623881 steps/s (collection: 0.045s, learning 0.113s)
                       Mean reward: 384.16
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4165
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 0.16s
                      Time elapsed: 00:19:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1021/1 [0m                       

                       Computation: 659625 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 386.63
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.5819
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 35.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 0.15s
                      Time elapsed: 00:19:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1022/1 [0m                       

                       Computation: 680787 steps/s (collection: 0.042s, learning 0.102s)
                       Mean reward: 389.14
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3544
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 0.14s
                      Time elapsed: 00:19:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1023/1 [0m                       

                       Computation: 713015 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 386.17
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.9106
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 0.14s
                      Time elapsed: 00:19:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1024/1 [0m                       

                       Computation: 666394 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 385.31
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3569
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 0.15s
                      Time elapsed: 00:19:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1025/1 [0m                       

                       Computation: 730558 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 385.18
               Mean episode length: 246.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.6164
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4377
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 0.13s
                      Time elapsed: 00:19:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1026/1 [0m                       

                       Computation: 736598 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 380.67
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.7710
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 0.13s
                      Time elapsed: 00:19:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1027/1 [0m                       

                       Computation: 718050 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 385.48
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.9985
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 0.14s
                      Time elapsed: 00:19:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1028/1 [0m                       

                       Computation: 680064 steps/s (collection: 0.049s, learning 0.096s)
                       Mean reward: 381.67
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.9984
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 0.14s
                      Time elapsed: 00:19:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1029/1 [0m                       

                       Computation: 751617 steps/s (collection: 0.045s, learning 0.086s)
                       Mean reward: 386.81
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.6483
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 0.13s
                      Time elapsed: 00:19:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1030/1 [0m                       

                       Computation: 783144 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 383.04
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3287
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 0.13s
                      Time elapsed: 00:19:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1031/1 [0m                       

                       Computation: 750826 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 380.74
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.7847
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 0.13s
                      Time elapsed: 00:19:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1032/1 [0m                       

                       Computation: 786351 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 384.21
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.9486
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 32.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 0.13s
                      Time elapsed: 00:19:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1033/1 [0m                       

                       Computation: 736286 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 374.25
               Mean episode length: 246.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 74.0522
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 0.13s
                      Time elapsed: 00:19:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1034/1 [0m                       

                       Computation: 779055 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 386.90
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.6947
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 0.13s
                      Time elapsed: 00:19:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1035/1 [0m                       

                       Computation: 791395 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 379.81
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.5742
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 0.12s
                      Time elapsed: 00:19:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1036/1 [0m                       

                       Computation: 737083 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 380.32
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.8539
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 0.13s
                      Time elapsed: 00:19:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1037/1 [0m                       

                       Computation: 696629 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 380.60
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.6757
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 0.14s
                      Time elapsed: 00:19:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1038/1 [0m                       

                       Computation: 668112 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 379.74
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.7235
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4371
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 0.15s
                      Time elapsed: 00:19:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1039/1 [0m                       

                       Computation: 706869 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 385.32
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4321
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 0.14s
                      Time elapsed: 00:19:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1040/1 [0m                       

                       Computation: 688700 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 383.51
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.2869
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 0.14s
                      Time elapsed: 00:19:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1041/1 [0m                       

                       Computation: 737653 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 381.50
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.0086
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 0.13s
                      Time elapsed: 00:19:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1042/1 [0m                       

                       Computation: 792545 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 383.96
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.0229
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 34.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 0.12s
                      Time elapsed: 00:19:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1043/1 [0m                       

                       Computation: 773952 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 378.89
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.1402
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 0.13s
                      Time elapsed: 00:19:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1044/1 [0m                       

                       Computation: 761973 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 386.03
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.9037
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4401
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 0.13s
                      Time elapsed: 00:19:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1045/1 [0m                       

                       Computation: 733474 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 376.82
               Mean episode length: 247.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.0773
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 0.13s
                      Time elapsed: 00:19:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1046/1 [0m                       

                       Computation: 733331 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 379.40
               Mean episode length: 247.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.5574
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 0.13s
                      Time elapsed: 00:19:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1047/1 [0m                       

                       Computation: 784530 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 387.50
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0318
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 0.13s
                      Time elapsed: 00:19:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1048/1 [0m                       

                       Computation: 647362 steps/s (collection: 0.040s, learning 0.111s)
                       Mean reward: 387.09
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0282
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 0.15s
                      Time elapsed: 00:19:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1049/1 [0m                       

                       Computation: 634111 steps/s (collection: 0.041s, learning 0.115s)
                       Mean reward: 385.90
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8555
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 0.16s
                      Time elapsed: 00:19:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1050/1 [0m                       

                       Computation: 681898 steps/s (collection: 0.042s, learning 0.102s)
                       Mean reward: 384.74
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3691
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4441
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 0.14s
                      Time elapsed: 00:19:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1051/1 [0m                       

                       Computation: 683063 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 389.18
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3446
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4461
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 0.14s
                      Time elapsed: 00:19:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1052/1 [0m                       

                       Computation: 643326 steps/s (collection: 0.047s, learning 0.106s)
                       Mean reward: 384.78
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.7322
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 0.15s
                      Time elapsed: 00:19:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1053/1 [0m                       

                       Computation: 714764 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 390.57
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.1514
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4435
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 31.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 0.14s
                      Time elapsed: 00:19:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1054/1 [0m                       

                       Computation: 753138 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 378.80
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.2782
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 0.13s
                      Time elapsed: 00:19:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1055/1 [0m                       

                       Computation: 718621 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 386.05
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.9287
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 0.14s
                      Time elapsed: 00:19:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1056/1 [0m                       

                       Computation: 741317 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 383.36
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.1844
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4443
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 0.13s
                      Time elapsed: 00:19:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1057/1 [0m                       

                       Computation: 713151 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 388.03
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.4605
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4441
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 0.14s
                      Time elapsed: 00:19:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1058/1 [0m                       

                       Computation: 772555 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 387.21
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.6407
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4427
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 0.13s
                      Time elapsed: 00:19:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1059/1 [0m                       

                       Computation: 648751 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 390.14
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.5534
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4433
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 0.15s
                      Time elapsed: 00:19:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1060/1 [0m                       

                       Computation: 569680 steps/s (collection: 0.052s, learning 0.121s)
                       Mean reward: 379.73
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.5957
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 0.17s
                      Time elapsed: 00:19:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1061/1 [0m                       

                       Computation: 700662 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 385.71
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.7798
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 0.14s
                      Time elapsed: 00:19:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1062/1 [0m                       

                       Computation: 685769 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 384.39
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.2616
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 0.14s
                      Time elapsed: 00:19:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1063/1 [0m                       

                       Computation: 601061 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 393.08
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6849
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 33.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 0.16s
                      Time elapsed: 00:19:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1064/1 [0m                       

                       Computation: 536610 steps/s (collection: 0.048s, learning 0.136s)
                       Mean reward: 385.87
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.7906
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 0.18s
                      Time elapsed: 00:19:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1065/1 [0m                       

                       Computation: 638114 steps/s (collection: 0.049s, learning 0.105s)
                       Mean reward: 383.57
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4444
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 0.15s
                      Time elapsed: 00:19:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1066/1 [0m                       

                       Computation: 688325 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 386.26
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.7914
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 0.14s
                      Time elapsed: 00:19:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1067/1 [0m                       

                       Computation: 752077 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 388.08
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1607
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4417
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 0.13s
                      Time elapsed: 00:20:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1068/1 [0m                       

                       Computation: 770212 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 382.43
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.8296
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 0.13s
                      Time elapsed: 00:20:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1069/1 [0m                       

                       Computation: 798052 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 390.59
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3234
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 0.12s
                      Time elapsed: 00:20:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1070/1 [0m                       

                       Computation: 718385 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 386.35
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0100
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 0.14s
                      Time elapsed: 00:20:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1071/1 [0m                       

                       Computation: 761948 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 386.29
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.7838
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 0.13s
                      Time elapsed: 00:20:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1072/1 [0m                       

                       Computation: 734183 steps/s (collection: 0.048s, learning 0.086s)
                       Mean reward: 387.38
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0179
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4463
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 0.13s
                      Time elapsed: 00:20:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1073/1 [0m                       

                       Computation: 747145 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 387.97
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3495
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 35.3333
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 0.13s
                      Time elapsed: 00:20:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1074/1 [0m                       

                       Computation: 733688 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 381.41
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.8326
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4441
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 0.13s
                      Time elapsed: 00:20:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1075/1 [0m                       

                       Computation: 720960 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 382.07
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.2191
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 0.14s
                      Time elapsed: 00:20:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1076/1 [0m                       

                       Computation: 750133 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 386.57
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4352
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 0.13s
                      Time elapsed: 00:20:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1077/1 [0m                       

                       Computation: 756078 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 384.75
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4540
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 0.13s
                      Time elapsed: 00:20:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1078/1 [0m                       

                       Computation: 659796 steps/s (collection: 0.044s, learning 0.105s)
                       Mean reward: 383.37
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.2661
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 0.15s
                      Time elapsed: 00:20:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1079/1 [0m                       

                       Computation: 701499 steps/s (collection: 0.046s, learning 0.094s)
                       Mean reward: 385.49
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.5630
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 0.14s
                      Time elapsed: 00:20:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1080/1 [0m                       

                       Computation: 623876 steps/s (collection: 0.049s, learning 0.109s)
                       Mean reward: 378.59
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.2496
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 0.16s
                      Time elapsed: 00:20:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1081/1 [0m                       

                       Computation: 710188 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 383.50
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.2573
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 0.14s
                      Time elapsed: 00:20:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1082/1 [0m                       

                       Computation: 693282 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 381.04
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.8199
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 0.14s
                      Time elapsed: 00:20:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1083/1 [0m                       

                       Computation: 712722 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 387.39
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.5132
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 0.14s
                      Time elapsed: 00:20:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1084/1 [0m                       

                       Computation: 661884 steps/s (collection: 0.048s, learning 0.101s)
                       Mean reward: 385.63
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3531
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 31.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 0.15s
                      Time elapsed: 00:20:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1085/1 [0m                       

                       Computation: 630042 steps/s (collection: 0.051s, learning 0.106s)
                       Mean reward: 377.15
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.3759
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 0.16s
                      Time elapsed: 00:20:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1086/1 [0m                       

                       Computation: 673134 steps/s (collection: 0.047s, learning 0.099s)
                       Mean reward: 383.46
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.7089
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 0.15s
                      Time elapsed: 00:20:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1087/1 [0m                       

                       Computation: 781892 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 385.40
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.7256
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 0.13s
                      Time elapsed: 00:20:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1088/1 [0m                       

                       Computation: 753909 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 382.73
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.8849
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 0.13s
                      Time elapsed: 00:20:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1089/1 [0m                       

                       Computation: 810167 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 382.91
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.2246
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 0.12s
                      Time elapsed: 00:20:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1090/1 [0m                       

                       Computation: 722481 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 386.58
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8438
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 0.14s
                      Time elapsed: 00:20:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1091/1 [0m                       

                       Computation: 749386 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 386.20
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.6764
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 0.13s
                      Time elapsed: 00:20:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1092/1 [0m                       

                       Computation: 739443 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 383.96
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3162
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 0.13s
                      Time elapsed: 00:20:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1093/1 [0m                       

                       Computation: 791665 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 382.65
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.1906
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 0.12s
                      Time elapsed: 00:20:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1094/1 [0m                       

                       Computation: 798856 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 389.73
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8613
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 33.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 0.12s
                      Time elapsed: 00:20:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1095/1 [0m                       

                       Computation: 819239 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 380.29
               Mean episode length: 246.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.8888
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 0.12s
                      Time elapsed: 00:20:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1096/1 [0m                       

                       Computation: 776985 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 385.95
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8679
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 0.13s
                      Time elapsed: 00:20:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1097/1 [0m                       

                       Computation: 795903 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 384.29
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.5196
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 0.12s
                      Time elapsed: 00:20:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1098/1 [0m                       

                       Computation: 649849 steps/s (collection: 0.048s, learning 0.104s)
                       Mean reward: 383.52
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.2493
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 0.15s
                      Time elapsed: 00:20:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1099/1 [0m                       

                       Computation: 770659 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 383.23
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.0364
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 0.13s
                      Time elapsed: 00:20:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1100/1 [0m                       

                       Computation: 627945 steps/s (collection: 0.047s, learning 0.110s)
                       Mean reward: 387.34
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.2174
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 0.16s
                      Time elapsed: 00:20:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1101/1 [0m                       

                       Computation: 640154 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 382.90
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.1632
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 0.15s
                      Time elapsed: 00:20:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1102/1 [0m                       

                       Computation: 661868 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 378.49
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.2343
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 0.15s
                      Time elapsed: 00:20:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1103/1 [0m                       

                       Computation: 575577 steps/s (collection: 0.046s, learning 0.125s)
                       Mean reward: 382.63
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.1832
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 0.17s
                      Time elapsed: 00:20:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1104/1 [0m                       

                       Computation: 567308 steps/s (collection: 0.048s, learning 0.126s)
                       Mean reward: 388.58
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1619
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 0.17s
                      Time elapsed: 00:20:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1105/1 [0m                       

                       Computation: 555086 steps/s (collection: 0.052s, learning 0.126s)
                       Mean reward: 384.77
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.7343
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 30.0000
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 0.18s
                      Time elapsed: 00:20:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1106/1 [0m                       

                       Computation: 754421 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 383.88
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3813
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 0.13s
                      Time elapsed: 00:20:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1107/1 [0m                       

                       Computation: 663737 steps/s (collection: 0.039s, learning 0.109s)
                       Mean reward: 383.91
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.5796
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 0.15s
                      Time elapsed: 00:20:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1108/1 [0m                       

                       Computation: 770919 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 385.28
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.5402
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 0.13s
                      Time elapsed: 00:20:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1109/1 [0m                       

                       Computation: 753445 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 383.47
               Mean episode length: 247.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4424
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 0.13s
                      Time elapsed: 00:20:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1110/1 [0m                       

                       Computation: 745190 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 390.66
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8633
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 0.13s
                      Time elapsed: 00:20:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1111/1 [0m                       

                       Computation: 648737 steps/s (collection: 0.046s, learning 0.106s)
                       Mean reward: 386.40
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8171
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 0.15s
                      Time elapsed: 00:20:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1112/1 [0m                       

                       Computation: 696630 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 384.56
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4492
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 0.14s
                      Time elapsed: 00:20:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1113/1 [0m                       

                       Computation: 624399 steps/s (collection: 0.043s, learning 0.114s)
                       Mean reward: 386.46
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0044
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4436
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 0.16s
                      Time elapsed: 00:20:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1114/1 [0m                       

                       Computation: 622997 steps/s (collection: 0.043s, learning 0.115s)
                       Mean reward: 383.18
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.0951
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 0.16s
                      Time elapsed: 00:20:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1115/1 [0m                       

                       Computation: 633183 steps/s (collection: 0.043s, learning 0.113s)
                       Mean reward: 392.03
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9868
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4444
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 31.7500
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 0.16s
                      Time elapsed: 00:20:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1116/1 [0m                       

                       Computation: 631726 steps/s (collection: 0.053s, learning 0.103s)
                       Mean reward: 386.98
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8954
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4438
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 0.16s
                      Time elapsed: 00:20:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1117/1 [0m                       

                       Computation: 720058 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 387.80
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3498
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 0.14s
                      Time elapsed: 00:20:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1118/1 [0m                       

                       Computation: 633005 steps/s (collection: 0.042s, learning 0.113s)
                       Mean reward: 387.37
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.9179
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 0.16s
                      Time elapsed: 00:20:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1119/1 [0m                       

                       Computation: 703883 steps/s (collection: 0.048s, learning 0.092s)
                       Mean reward: 388.27
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3059
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4429
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 0.14s
                      Time elapsed: 00:20:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1120/1 [0m                       

                       Computation: 677542 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 381.02
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.6589
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 0.15s
                      Time elapsed: 00:21:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1121/1 [0m                       

                       Computation: 722692 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 395.40
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7267
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4441
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 0.14s
                      Time elapsed: 00:21:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1122/1 [0m                       

                       Computation: 714636 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 388.05
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3448
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4438
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 0.14s
                      Time elapsed: 00:21:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1123/1 [0m                       

                       Computation: 767752 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 392.98
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2008
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4457
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 0.13s
                      Time elapsed: 00:21:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1124/1 [0m                       

                       Computation: 704195 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 386.99
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1506
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 0.14s
                      Time elapsed: 00:21:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1125/1 [0m                       

                       Computation: 590056 steps/s (collection: 0.050s, learning 0.117s)
                       Mean reward: 389.44
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.5445
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4455
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 33.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 0.17s
                      Time elapsed: 00:21:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1126/1 [0m                       

                       Computation: 627427 steps/s (collection: 0.052s, learning 0.105s)
                       Mean reward: 390.87
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.2272
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 0.16s
                      Time elapsed: 00:21:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1127/1 [0m                       

                       Computation: 569446 steps/s (collection: 0.049s, learning 0.124s)
                       Mean reward: 378.03
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.2086
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 0.17s
                      Time elapsed: 00:21:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1128/1 [0m                       

                       Computation: 769612 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 382.76
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.7418
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4374
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 0.13s
                      Time elapsed: 00:21:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1129/1 [0m                       

                       Computation: 592055 steps/s (collection: 0.047s, learning 0.119s)
                       Mean reward: 396.28
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7999
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4460
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 0.17s
                      Time elapsed: 00:21:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1130/1 [0m                       

                       Computation: 585773 steps/s (collection: 0.054s, learning 0.114s)
                       Mean reward: 392.60
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.0986
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4448
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 0.17s
                      Time elapsed: 00:21:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1131/1 [0m                       

                       Computation: 550641 steps/s (collection: 0.051s, learning 0.128s)
                       Mean reward: 389.99
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.2104
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 0.18s
                      Time elapsed: 00:21:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1132/1 [0m                       

                       Computation: 552189 steps/s (collection: 0.050s, learning 0.128s)
                       Mean reward: 386.94
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8806
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 0.18s
                      Time elapsed: 00:21:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1133/1 [0m                       

                       Computation: 648984 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 393.43
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.1004
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4468
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 0.15s
                      Time elapsed: 00:21:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1134/1 [0m                       

                       Computation: 762906 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 398.01
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2196
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4510
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 0.13s
                      Time elapsed: 00:21:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1135/1 [0m                       

                       Computation: 590585 steps/s (collection: 0.055s, learning 0.111s)
                       Mean reward: 384.96
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3335
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4447
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 0.17s
                      Time elapsed: 00:21:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1136/1 [0m                       

                       Computation: 705349 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 390.33
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3126
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 30.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 0.14s
                      Time elapsed: 00:21:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1137/1 [0m                       

                       Computation: 667126 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 382.95
               Mean episode length: 246.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.9876
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 0.15s
                      Time elapsed: 00:21:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1138/1 [0m                       

                       Computation: 635186 steps/s (collection: 0.045s, learning 0.110s)
                       Mean reward: 386.58
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.6196
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 0.15s
                      Time elapsed: 00:21:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1139/1 [0m                       

                       Computation: 737337 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 391.01
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.4249
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 0.13s
                      Time elapsed: 00:21:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1140/1 [0m                       

                       Computation: 641978 steps/s (collection: 0.044s, learning 0.109s)
                       Mean reward: 390.87
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6465
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 0.15s
                      Time elapsed: 00:21:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1141/1 [0m                       

                       Computation: 664026 steps/s (collection: 0.043s, learning 0.106s)
                       Mean reward: 391.21
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8557
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4447
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 0.15s
                      Time elapsed: 00:21:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1142/1 [0m                       

                       Computation: 778668 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 395.87
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9454
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4475
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 0.13s
                      Time elapsed: 00:21:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1143/1 [0m                       

                       Computation: 823419 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 393.48
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2009
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4462
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 0.12s
                      Time elapsed: 00:21:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1144/1 [0m                       

                       Computation: 701259 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 395.02
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5137
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4459
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 0.14s
                      Time elapsed: 00:21:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1145/1 [0m                       

                       Computation: 664746 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 392.52
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.1570
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4476
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 0.15s
                      Time elapsed: 00:21:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1146/1 [0m                       

                       Computation: 777818 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 390.79
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9678
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4454
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 32.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 0.13s
                      Time elapsed: 00:21:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1147/1 [0m                       

                       Computation: 747954 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 382.76
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.6555
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 0.13s
                      Time elapsed: 00:21:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1148/1 [0m                       

                       Computation: 590422 steps/s (collection: 0.040s, learning 0.127s)
                       Mean reward: 387.99
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6397
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 0.17s
                      Time elapsed: 00:21:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1149/1 [0m                       

                       Computation: 507263 steps/s (collection: 0.048s, learning 0.146s)
                       Mean reward: 395.28
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5528
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4448
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 0.19s
                      Time elapsed: 00:21:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1150/1 [0m                       

                       Computation: 737285 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 388.52
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3429
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4450
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 0.13s
                      Time elapsed: 00:21:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1151/1 [0m                       

                       Computation: 798069 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 390.67
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6787
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4462
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 0.12s
                      Time elapsed: 00:21:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1152/1 [0m                       

                       Computation: 830430 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 392.87
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.0386
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4446
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 0.12s
                      Time elapsed: 00:21:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1153/1 [0m                       

                       Computation: 824392 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 396.35
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7854
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4468
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 0.12s
                      Time elapsed: 00:21:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1154/1 [0m                       

                       Computation: 817613 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 394.48
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4097
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4460
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 0.12s
                      Time elapsed: 00:21:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1155/1 [0m                       

                       Computation: 623255 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 390.37
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7921
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 0.16s
                      Time elapsed: 00:21:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1156/1 [0m                       

                       Computation: 767778 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 393.81
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3382
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 0.13s
                      Time elapsed: 00:21:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1157/1 [0m                       

                       Computation: 676042 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 394.82
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0026
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4448
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 29.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 0.15s
                      Time elapsed: 00:21:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1158/1 [0m                       

                       Computation: 611603 steps/s (collection: 0.043s, learning 0.118s)
                       Mean reward: 383.91
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.3106
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4390
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 0.16s
                      Time elapsed: 00:21:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1159/1 [0m                       

                       Computation: 812752 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 392.03
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8491
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4424
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 0.12s
                      Time elapsed: 00:21:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1160/1 [0m                       

                       Computation: 667419 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 395.13
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5355
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4457
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 0.15s
                      Time elapsed: 00:21:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1161/1 [0m                       

                       Computation: 723592 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 393.63
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3697
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 0.14s
                      Time elapsed: 00:21:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1162/1 [0m                       

                       Computation: 724785 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 397.71
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2847
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4440
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 0.14s
                      Time elapsed: 00:21:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1163/1 [0m                       

                       Computation: 627953 steps/s (collection: 0.039s, learning 0.117s)
                       Mean reward: 389.97
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3082
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 0.16s
                      Time elapsed: 00:21:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1164/1 [0m                       

                       Computation: 748267 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 391.54
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9153
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 0.13s
                      Time elapsed: 00:21:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1165/1 [0m                       

                       Computation: 664685 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 389.94
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3691
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 0.15s
                      Time elapsed: 00:21:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1166/1 [0m                       

                       Computation: 734026 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 391.12
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9581
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 0.13s
                      Time elapsed: 00:21:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1167/1 [0m                       

                       Computation: 634072 steps/s (collection: 0.044s, learning 0.111s)
                       Mean reward: 387.23
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.9598
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 31.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 0.16s
                      Time elapsed: 00:21:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1168/1 [0m                       

                       Computation: 787447 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 388.43
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1059
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 0.12s
                      Time elapsed: 00:21:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1169/1 [0m                       

                       Computation: 843276 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 386.30
               Mean episode length: 245.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1156
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 0.12s
                      Time elapsed: 00:21:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1170/1 [0m                       

                       Computation: 745954 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 390.43
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.5397
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 0.13s
                      Time elapsed: 00:21:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1171/1 [0m                       

                       Computation: 714836 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 388.15
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1999
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 0.14s
                      Time elapsed: 00:21:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1172/1 [0m                       

                       Computation: 780430 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 388.07
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8187
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 0.13s
                      Time elapsed: 00:22:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1173/1 [0m                       

                       Computation: 701083 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 388.67
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3188
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 0.14s
                      Time elapsed: 00:22:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1174/1 [0m                       

                       Computation: 785877 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 389.44
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3822
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 0.13s
                      Time elapsed: 00:22:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1175/1 [0m                       

                       Computation: 842632 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 383.57
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.1939
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 0.12s
                      Time elapsed: 00:22:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1176/1 [0m                       

                       Computation: 863532 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 389.63
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.4475
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 0.11s
                      Time elapsed: 00:22:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1177/1 [0m                       

                       Computation: 771513 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 388.90
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.2056
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 0.13s
                      Time elapsed: 00:22:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1178/1 [0m                       

                       Computation: 813007 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 390.97
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0842
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 27.9583
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 0.12s
                      Time elapsed: 00:22:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1179/1 [0m                       

                       Computation: 744341 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 376.88
               Mean episode length: 245.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.2579
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 0.13s
                      Time elapsed: 00:22:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1180/1 [0m                       

                       Computation: 839995 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 393.36
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5057
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 0.12s
                      Time elapsed: 00:22:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1181/1 [0m                       

                       Computation: 586803 steps/s (collection: 0.045s, learning 0.123s)
                       Mean reward: 388.16
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0949
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 0.17s
                      Time elapsed: 00:22:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1182/1 [0m                       

                       Computation: 818267 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 393.19
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4557
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 0.12s
                      Time elapsed: 00:22:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1183/1 [0m                       

                       Computation: 689799 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 391.55
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9782
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 0.14s
                      Time elapsed: 00:22:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1184/1 [0m                       

                       Computation: 761108 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 390.31
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6129
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 0.13s
                      Time elapsed: 00:22:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1185/1 [0m                       

                       Computation: 704095 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 393.87
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4741
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 0.14s
                      Time elapsed: 00:22:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1186/1 [0m                       

                       Computation: 842737 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 394.74
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5523
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 0.12s
                      Time elapsed: 00:22:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1187/1 [0m                       

                       Computation: 803230 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 394.61
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3642
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 0.12s
                      Time elapsed: 00:22:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1188/1 [0m                       

                       Computation: 843682 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 396.76
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6553
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 29.9583
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 0.12s
                      Time elapsed: 00:22:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1189/1 [0m                       

                       Computation: 777611 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 402.41
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9059
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4438
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 0.13s
                      Time elapsed: 00:22:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1190/1 [0m                       

                       Computation: 862551 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 397.60
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2550
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4433
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 0.11s
                      Time elapsed: 00:22:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1191/1 [0m                       

                       Computation: 751228 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 389.92
               Mean episode length: 247.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6254
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 0.13s
                      Time elapsed: 00:22:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1192/1 [0m                       

                       Computation: 659609 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 389.93
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6529
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4401
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 0.15s
                      Time elapsed: 00:22:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1193/1 [0m                       

                       Computation: 812346 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 397.36
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3638
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 0.12s
                      Time elapsed: 00:22:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1194/1 [0m                       

                       Computation: 787233 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 392.78
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3807
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 0.12s
                      Time elapsed: 00:22:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1195/1 [0m                       

                       Computation: 759227 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 398.30
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2067
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 0.13s
                      Time elapsed: 00:22:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1196/1 [0m                       

                       Computation: 856710 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 396.64
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7643
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 0.11s
                      Time elapsed: 00:22:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1197/1 [0m                       

                       Computation: 887601 steps/s (collection: 0.037s, learning 0.074s)
                       Mean reward: 398.70
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4165
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 0.11s
                      Time elapsed: 00:22:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1198/1 [0m                       

                       Computation: 557554 steps/s (collection: 0.054s, learning 0.122s)
                       Mean reward: 399.30
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5741
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 32.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 0.18s
                      Time elapsed: 00:22:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1199/1 [0m                       

                       Computation: 813924 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 390.94
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.1207
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 0.12s
                      Time elapsed: 00:22:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1200/1 [0m                       

                       Computation: 801279 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 394.29
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3852
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 0.12s
                      Time elapsed: 00:22:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1201/1 [0m                       

                       Computation: 811768 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 396.42
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5888
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 0.12s
                      Time elapsed: 00:22:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1202/1 [0m                       

                       Computation: 778865 steps/s (collection: 0.035s, learning 0.091s)
                       Mean reward: 397.50
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3051
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 0.13s
                      Time elapsed: 00:22:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1203/1 [0m                       

                       Computation: 922419 steps/s (collection: 0.035s, learning 0.072s)
                       Mean reward: 399.67
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3739
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4434
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 0.11s
                      Time elapsed: 00:22:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1204/1 [0m                       

                       Computation: 829444 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 399.13
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5228
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 0.12s
                      Time elapsed: 00:22:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1205/1 [0m                       

                       Computation: 861918 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 393.29
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.1230
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 0.11s
                      Time elapsed: 00:22:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1206/1 [0m                       

                       Computation: 919399 steps/s (collection: 0.039s, learning 0.068s)
                       Mean reward: 395.33
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9310
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 0.11s
                      Time elapsed: 00:22:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1207/1 [0m                       

                       Computation: 945082 steps/s (collection: 0.035s, learning 0.069s)
                       Mean reward: 393.52
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4458
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 0.10s
                      Time elapsed: 00:22:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1208/1 [0m                       

                       Computation: 870081 steps/s (collection: 0.035s, learning 0.078s)
                       Mean reward: 400.87
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8140
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4429
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 0.11s
                      Time elapsed: 00:22:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1209/1 [0m                       

                       Computation: 699249 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 393.23
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1745
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 29.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 0.14s
                      Time elapsed: 00:22:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1210/1 [0m                       

                       Computation: 793206 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 388.12
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7212
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 0.12s
                      Time elapsed: 00:22:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1211/1 [0m                       

                       Computation: 788130 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 405.53
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6481
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4429
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 0.12s
                      Time elapsed: 00:22:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1212/1 [0m                       

                       Computation: 870853 steps/s (collection: 0.038s, learning 0.075s)
                       Mean reward: 398.39
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2616
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 0.11s
                      Time elapsed: 00:22:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1213/1 [0m                       

                       Computation: 814206 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 395.62
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4554
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 0.12s
                      Time elapsed: 00:22:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1214/1 [0m                       

                       Computation: 897673 steps/s (collection: 0.039s, learning 0.071s)
                       Mean reward: 397.57
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0196
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4433
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 0.11s
                      Time elapsed: 00:22:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1215/1 [0m                       

                       Computation: 717150 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 396.52
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0236
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 0.14s
                      Time elapsed: 00:22:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1216/1 [0m                       

                       Computation: 845818 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 399.06
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5678
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 0.12s
                      Time elapsed: 00:22:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1217/1 [0m                       

                       Computation: 649420 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 394.47
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3800
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 0.15s
                      Time elapsed: 00:22:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1218/1 [0m                       

                       Computation: 799077 steps/s (collection: 0.034s, learning 0.089s)
                       Mean reward: 397.39
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9931
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4410
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 0.12s
                      Time elapsed: 00:22:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1219/1 [0m                       

                       Computation: 763219 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 395.86
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9078
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 30.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 0.13s
                      Time elapsed: 00:22:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1220/1 [0m                       

                       Computation: 588575 steps/s (collection: 0.051s, learning 0.116s)
                       Mean reward: 399.34
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7221
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4436
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 0.17s
                      Time elapsed: 00:22:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1221/1 [0m                       

                       Computation: 559515 steps/s (collection: 0.043s, learning 0.133s)
                       Mean reward: 398.24
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1027
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 0.18s
                      Time elapsed: 00:22:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1222/1 [0m                       

                       Computation: 697385 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 399.83
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5792
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 0.14s
                      Time elapsed: 00:22:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1223/1 [0m                       

                       Computation: 789520 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 394.83
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2038
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 0.12s
                      Time elapsed: 00:22:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1224/1 [0m                       

                       Computation: 887542 steps/s (collection: 0.037s, learning 0.074s)
                       Mean reward: 398.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5120
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4442
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 0.11s
                      Time elapsed: 00:22:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1225/1 [0m                       

                       Computation: 856523 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 397.81
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9842
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4445
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 0.11s
                      Time elapsed: 00:22:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1226/1 [0m                       

                       Computation: 808041 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 399.63
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2733
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 0.12s
                      Time elapsed: 00:22:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1227/1 [0m                       

                       Computation: 714517 steps/s (collection: 0.055s, learning 0.083s)
                       Mean reward: 397.52
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9179
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 0.14s
                      Time elapsed: 00:22:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1228/1 [0m                       

                       Computation: 782153 steps/s (collection: 0.046s, learning 0.080s)
                       Mean reward: 388.55
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8632
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 0.13s
                      Time elapsed: 00:22:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1229/1 [0m                       

                       Computation: 715306 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 397.36
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0057
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 0.14s
                      Time elapsed: 00:22:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1230/1 [0m                       

                       Computation: 705287 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 397.78
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7200
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 27.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 0.14s
                      Time elapsed: 00:23:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1231/1 [0m                       

                       Computation: 602892 steps/s (collection: 0.038s, learning 0.126s)
                       Mean reward: 400.98
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7630
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4402
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 0.16s
                      Time elapsed: 00:23:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1232/1 [0m                       

                       Computation: 732910 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 399.48
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7445
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 0.13s
                      Time elapsed: 00:23:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1233/1 [0m                       

                       Computation: 510240 steps/s (collection: 0.041s, learning 0.152s)
                       Mean reward: 399.35
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5635
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 0.19s
                      Time elapsed: 00:23:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1234/1 [0m                       

                       Computation: 750043 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 398.25
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9970
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 0.13s
                      Time elapsed: 00:23:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1235/1 [0m                       

                       Computation: 508975 steps/s (collection: 0.056s, learning 0.137s)
                       Mean reward: 392.20
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9325
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4390
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 0.19s
                      Time elapsed: 00:23:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1236/1 [0m                       

                       Computation: 706210 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 400.71
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1143
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4421
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 0.14s
                      Time elapsed: 00:23:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1237/1 [0m                       

                       Computation: 825667 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 394.88
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5477
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 0.12s
                      Time elapsed: 00:23:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1238/1 [0m                       

                       Computation: 752896 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 393.39
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3485
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 0.13s
                      Time elapsed: 00:23:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1239/1 [0m                       

                       Computation: 792036 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 393.78
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4707
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 0.12s
                      Time elapsed: 00:23:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1240/1 [0m                       

                       Computation: 699560 steps/s (collection: 0.050s, learning 0.091s)
                       Mean reward: 396.05
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8880
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 29.5417
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 0.14s
                      Time elapsed: 00:23:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1241/1 [0m                       

                       Computation: 776634 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 394.32
               Mean episode length: 246.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4638
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 0.13s
                      Time elapsed: 00:23:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1242/1 [0m                       

                       Computation: 843644 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 394.26
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.1668
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 0.12s
                      Time elapsed: 00:23:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1243/1 [0m                       

                       Computation: 767472 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 395.90
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0232
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4371
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 0.13s
                      Time elapsed: 00:23:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1244/1 [0m                       

                       Computation: 858526 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 393.44
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3755
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 0.11s
                      Time elapsed: 00:23:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1245/1 [0m                       

                       Computation: 732710 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 396.00
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8362
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 0.13s
                      Time elapsed: 00:23:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1246/1 [0m                       

                       Computation: 704162 steps/s (collection: 0.037s, learning 0.102s)
                       Mean reward: 399.35
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6653
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 0.14s
                      Time elapsed: 00:23:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1247/1 [0m                       

                       Computation: 785730 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 387.48
               Mean episode length: 247.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3651
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 0.13s
                      Time elapsed: 00:23:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1248/1 [0m                       

                       Computation: 798597 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 392.45
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.0926
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 0.12s
                      Time elapsed: 00:23:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1249/1 [0m                       

                       Computation: 716883 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 392.74
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.0972
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 0.14s
                      Time elapsed: 00:23:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1250/1 [0m                       

                       Computation: 832939 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 393.87
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2082
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 30.8333
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 0.12s
                      Time elapsed: 00:23:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1251/1 [0m                       

                       Computation: 529529 steps/s (collection: 0.048s, learning 0.138s)
                       Mean reward: 391.04
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7761
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 0.19s
                      Time elapsed: 00:23:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1252/1 [0m                       

                       Computation: 795844 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 394.51
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0746
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 0.12s
                      Time elapsed: 00:23:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1253/1 [0m                       

                       Computation: 843442 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 388.55
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.2014
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 0.12s
                      Time elapsed: 00:23:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1254/1 [0m                       

                       Computation: 764645 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 395.21
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4911
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 0.13s
                      Time elapsed: 00:23:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1255/1 [0m                       

                       Computation: 746550 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 393.26
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.1512
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 0.13s
                      Time elapsed: 00:23:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1256/1 [0m                       

                       Computation: 822291 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 389.83
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7138
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 0.12s
                      Time elapsed: 00:23:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1257/1 [0m                       

                       Computation: 770433 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 394.90
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.6575
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 0.13s
                      Time elapsed: 00:23:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1258/1 [0m                       

                       Computation: 696863 steps/s (collection: 0.048s, learning 0.094s)
                       Mean reward: 394.03
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3396
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 0.14s
                      Time elapsed: 00:23:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1259/1 [0m                       

                       Computation: 733479 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 394.53
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2583
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4359
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 0.13s
                      Time elapsed: 00:23:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1260/1 [0m                       

                       Computation: 644479 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 394.70
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4809
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 0.15s
                      Time elapsed: 00:23:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1261/1 [0m                       

                       Computation: 680958 steps/s (collection: 0.039s, learning 0.105s)
                       Mean reward: 390.14
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.4395
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 28.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 0.14s
                      Time elapsed: 00:23:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1262/1 [0m                       

                       Computation: 805503 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 390.26
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.0018
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 0.12s
                      Time elapsed: 00:23:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1263/1 [0m                       

                       Computation: 829250 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 391.52
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8307
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 0.12s
                      Time elapsed: 00:23:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1264/1 [0m                       

                       Computation: 777019 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 388.81
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.2451
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 0.13s
                      Time elapsed: 00:23:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1265/1 [0m                       

                       Computation: 832342 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 387.20
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.1458
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 0.12s
                      Time elapsed: 00:23:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1266/1 [0m                       

                       Computation: 772733 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 393.26
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.1049
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 0.13s
                      Time elapsed: 00:23:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1267/1 [0m                       

                       Computation: 825966 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 391.28
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8016
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 0.12s
                      Time elapsed: 00:23:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1268/1 [0m                       

                       Computation: 794134 steps/s (collection: 0.044s, learning 0.080s)
                       Mean reward: 390.79
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8097
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 0.12s
                      Time elapsed: 00:23:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1269/1 [0m                       

                       Computation: 771637 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 395.62
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8889
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 0.13s
                      Time elapsed: 00:23:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1270/1 [0m                       

                       Computation: 732626 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 392.54
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8860
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 0.13s
                      Time elapsed: 00:23:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1271/1 [0m                       

                       Computation: 818371 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 395.76
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4488
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 30.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 0.12s
                      Time elapsed: 00:23:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1272/1 [0m                       

                       Computation: 869866 steps/s (collection: 0.040s, learning 0.073s)
                       Mean reward: 396.03
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3804
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 0.11s
                      Time elapsed: 00:23:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1273/1 [0m                       

                       Computation: 658551 steps/s (collection: 0.048s, learning 0.101s)
                       Mean reward: 395.86
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.6246
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 0.15s
                      Time elapsed: 00:23:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1274/1 [0m                       

                       Computation: 602924 steps/s (collection: 0.055s, learning 0.109s)
                       Mean reward: 398.53
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2737
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 0.16s
                      Time elapsed: 00:23:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1275/1 [0m                       

                       Computation: 608603 steps/s (collection: 0.039s, learning 0.123s)
                       Mean reward: 395.04
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2575
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 0.16s
                      Time elapsed: 00:23:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1276/1 [0m                       

                       Computation: 836510 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 388.50
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3770
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 0.12s
                      Time elapsed: 00:23:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1277/1 [0m                       

                       Computation: 725320 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 388.67
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6272
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 0.14s
                      Time elapsed: 00:23:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1278/1 [0m                       

                       Computation: 812320 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 394.77
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4915
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 0.12s
                      Time elapsed: 00:23:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1279/1 [0m                       

                       Computation: 799616 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 399.06
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3212
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 0.12s
                      Time elapsed: 00:23:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1280/1 [0m                       

                       Computation: 761744 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 396.45
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8492
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 0.13s
                      Time elapsed: 00:23:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1281/1 [0m                       

                       Computation: 815035 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 398.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2679
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 0.12s
                      Time elapsed: 00:23:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1282/1 [0m                       

                       Computation: 767974 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 398.17
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9268
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 26.7500
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 0.13s
                      Time elapsed: 00:23:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1283/1 [0m                       

                       Computation: 775646 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 404.56
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6561
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 0.13s
                      Time elapsed: 00:23:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1284/1 [0m                       

                       Computation: 795253 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 390.41
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.0845
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 0.12s
                      Time elapsed: 00:23:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1285/1 [0m                       

                       Computation: 788750 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 396.01
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9404
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 0.12s
                      Time elapsed: 00:24:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1286/1 [0m                       

                       Computation: 867900 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 393.45
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9038
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 0.11s
                      Time elapsed: 00:24:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1287/1 [0m                       

                       Computation: 808069 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 394.26
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5359
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 0.12s
                      Time elapsed: 00:24:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1288/1 [0m                       

                       Computation: 538691 steps/s (collection: 0.037s, learning 0.145s)
                       Mean reward: 392.33
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7391
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 0.18s
                      Time elapsed: 00:24:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1289/1 [0m                       

                       Computation: 396027 steps/s (collection: 0.045s, learning 0.203s)
                       Mean reward: 395.05
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4862
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 0.25s
                      Time elapsed: 00:24:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1290/1 [0m                       

                       Computation: 694592 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 391.14
               Mean episode length: 247.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9129
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 0.14s
                      Time elapsed: 00:24:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1291/1 [0m                       

                       Computation: 858478 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 391.97
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7987
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 0.11s
                      Time elapsed: 00:24:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1292/1 [0m                       

                       Computation: 867998 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 395.29
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7949
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 28.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 0.11s
                      Time elapsed: 00:24:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1293/1 [0m                       

                       Computation: 866044 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 392.94
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9713
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 0.11s
                      Time elapsed: 00:24:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1294/1 [0m                       

                       Computation: 711839 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 390.59
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9346
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 0.14s
                      Time elapsed: 00:24:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1295/1 [0m                       

                       Computation: 770550 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 397.84
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0994
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 0.13s
                      Time elapsed: 00:24:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1296/1 [0m                       

                       Computation: 810716 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 393.90
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2536
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 0.12s
                      Time elapsed: 00:24:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1297/1 [0m                       

                       Computation: 529744 steps/s (collection: 0.039s, learning 0.147s)
                       Mean reward: 390.75
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.5264
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 0.19s
                      Time elapsed: 00:24:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1298/1 [0m                       

                       Computation: 801662 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 395.57
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8351
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 0.12s
                      Time elapsed: 00:24:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1299/1 [0m                       

                       Computation: 599624 steps/s (collection: 0.040s, learning 0.123s)
                       Mean reward: 396.63
               Mean episode length: 247.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.6317
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 0.16s
                      Time elapsed: 00:24:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1300/1 [0m                       

                       Computation: 692044 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 398.12
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2631
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 0.14s
                      Time elapsed: 00:24:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1301/1 [0m                       

                       Computation: 697127 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 402.43
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2971
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 0.14s
                      Time elapsed: 00:24:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1302/1 [0m                       

                       Computation: 792587 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 386.44
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8508
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 0.12s
                      Time elapsed: 00:24:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1303/1 [0m                       

                       Computation: 744419 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 400.05
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8320
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 26.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 0.13s
                      Time elapsed: 00:24:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1304/1 [0m                       

                       Computation: 786169 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 396.02
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1176
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 0.13s
                      Time elapsed: 00:24:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1305/1 [0m                       

                       Computation: 808848 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 394.48
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3937
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 0.12s
                      Time elapsed: 00:24:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1306/1 [0m                       

                       Computation: 612428 steps/s (collection: 0.065s, learning 0.096s)
                       Mean reward: 395.01
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5479
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 0.16s
                      Time elapsed: 00:24:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1307/1 [0m                       

                       Computation: 609439 steps/s (collection: 0.041s, learning 0.121s)
                       Mean reward: 398.03
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2497
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 0.16s
                      Time elapsed: 00:24:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1308/1 [0m                       

                       Computation: 542387 steps/s (collection: 0.044s, learning 0.138s)
                       Mean reward: 391.75
               Mean episode length: 247.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9201
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 0.18s
                      Time elapsed: 00:24:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1309/1 [0m                       

                       Computation: 802219 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 396.13
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0908
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 0.12s
                      Time elapsed: 00:24:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1310/1 [0m                       

                       Computation: 747302 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 392.52
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.1129
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 0.13s
                      Time elapsed: 00:24:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1311/1 [0m                       

                       Computation: 829731 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 397.89
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1295
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 0.12s
                      Time elapsed: 00:24:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1312/1 [0m                       

                       Computation: 822491 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 400.11
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3450
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 0.12s
                      Time elapsed: 00:24:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1313/1 [0m                       

                       Computation: 769920 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 393.59
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2070
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 27.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 0.13s
                      Time elapsed: 00:24:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1314/1 [0m                       

                       Computation: 818958 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 388.33
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.2419
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 0.12s
                      Time elapsed: 00:24:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1315/1 [0m                       

                       Computation: 694497 steps/s (collection: 0.056s, learning 0.086s)
                       Mean reward: 388.77
               Mean episode length: 247.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3826
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 0.14s
                      Time elapsed: 00:24:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1316/1 [0m                       

                       Computation: 795709 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 391.71
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8707
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4240
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 0.12s
                      Time elapsed: 00:24:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1317/1 [0m                       

                       Computation: 850667 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 393.88
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2286
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 0.12s
                      Time elapsed: 00:24:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1318/1 [0m                       

                       Computation: 758583 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 393.86
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.1332
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 0.13s
                      Time elapsed: 00:24:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1319/1 [0m                       

                       Computation: 815738 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 389.12
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.4188
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 0.12s
                      Time elapsed: 00:24:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1320/1 [0m                       

                       Computation: 578120 steps/s (collection: 0.042s, learning 0.128s)
                       Mean reward: 390.95
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8102
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 0.17s
                      Time elapsed: 00:24:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1321/1 [0m                       

                       Computation: 788316 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 389.35
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6857
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4276
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 0.12s
                      Time elapsed: 00:24:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1322/1 [0m                       

                       Computation: 653164 steps/s (collection: 0.043s, learning 0.108s)
                       Mean reward: 394.55
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2743
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 0.15s
                      Time elapsed: 00:24:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1323/1 [0m                       

                       Computation: 681469 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 391.06
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.8700
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4276
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 29.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 0.14s
                      Time elapsed: 00:24:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1324/1 [0m                       

                       Computation: 795774 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 398.29
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4050
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 0.12s
                      Time elapsed: 00:24:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1325/1 [0m                       

                       Computation: 812088 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 385.06
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.4756
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4224
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 0.12s
                      Time elapsed: 00:24:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1326/1 [0m                       

                       Computation: 772042 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 398.46
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3833
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 0.13s
                      Time elapsed: 00:24:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1327/1 [0m                       

                       Computation: 776233 steps/s (collection: 0.047s, learning 0.080s)
                       Mean reward: 391.86
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9580
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 0.13s
                      Time elapsed: 00:24:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1328/1 [0m                       

                       Computation: 720739 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 393.48
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4830
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4253
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 0.14s
                      Time elapsed: 00:24:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1329/1 [0m                       

                       Computation: 803558 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 394.17
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4115
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 0.12s
                      Time elapsed: 00:24:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1330/1 [0m                       

                       Computation: 814847 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 381.77
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 75.5996
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4191
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 0.12s
                      Time elapsed: 00:24:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1331/1 [0m                       

                       Computation: 623269 steps/s (collection: 0.046s, learning 0.112s)
                       Mean reward: 392.86
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2813
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 0.16s
                      Time elapsed: 00:24:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1332/1 [0m                       

                       Computation: 601856 steps/s (collection: 0.045s, learning 0.118s)
                       Mean reward: 391.03
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7648
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 0.16s
                      Time elapsed: 00:24:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1333/1 [0m                       

                       Computation: 746678 steps/s (collection: 0.050s, learning 0.082s)
                       Mean reward: 395.19
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2959
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4253
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 0.13s
                      Time elapsed: 00:24:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1334/1 [0m                       

                       Computation: 761829 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 396.49
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3054
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 26.8333
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 0.13s
                      Time elapsed: 00:24:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1335/1 [0m                       

                       Computation: 784497 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 397.54
               Mean episode length: 246.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2068
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4230
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 0.13s
                      Time elapsed: 00:24:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1336/1 [0m                       

                       Computation: 788652 steps/s (collection: 0.046s, learning 0.079s)
                       Mean reward: 395.49
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5101
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 0.12s
                      Time elapsed: 00:24:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1337/1 [0m                       

                       Computation: 847384 steps/s (collection: 0.041s, learning 0.076s)
                       Mean reward: 397.75
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1655
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 0.12s
                      Time elapsed: 00:24:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1338/1 [0m                       

                       Computation: 706732 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 394.18
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5137
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4261
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 0.14s
                      Time elapsed: 00:24:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1339/1 [0m                       

                       Computation: 831036 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 395.54
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0582
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 0.12s
                      Time elapsed: 00:24:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1340/1 [0m                       

                       Computation: 380110 steps/s (collection: 0.043s, learning 0.216s)
                       Mean reward: 392.56
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9628
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 0.26s
                      Time elapsed: 00:25:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1341/1 [0m                       

                       Computation: 723071 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 392.07
               Mean episode length: 246.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8382
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4206
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 0.14s
                      Time elapsed: 00:25:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1342/1 [0m                       

                       Computation: 722916 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 390.03
               Mean episode length: 247.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.6972
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4260
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 0.14s
                      Time elapsed: 00:25:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1343/1 [0m                       

                       Computation: 792386 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 393.18
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2449
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 0.12s
                      Time elapsed: 00:25:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1344/1 [0m                       

                       Computation: 768975 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 397.87
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8097
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 28.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 0.13s
                      Time elapsed: 00:25:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1345/1 [0m                       

                       Computation: 756619 steps/s (collection: 0.046s, learning 0.084s)
                       Mean reward: 387.55
               Mean episode length: 247.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 76.9447
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4221
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 0.13s
                      Time elapsed: 00:25:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1346/1 [0m                       

                       Computation: 541358 steps/s (collection: 0.055s, learning 0.127s)
                       Mean reward: 389.98
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8405
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 0.18s
                      Time elapsed: 00:25:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1347/1 [0m                       

                       Computation: 825966 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 394.19
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5485
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 0.12s
                      Time elapsed: 00:25:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1348/1 [0m                       

                       Computation: 766497 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 391.86
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8289
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4236
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 0.13s
                      Time elapsed: 00:25:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1349/1 [0m                       

                       Computation: 465752 steps/s (collection: 0.052s, learning 0.159s)
                       Mean reward: 389.26
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.5379
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 0.21s
                      Time elapsed: 00:25:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1350/1 [0m                       

                       Computation: 809386 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 394.66
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5168
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 0.12s
                      Time elapsed: 00:25:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1351/1 [0m                       

                       Computation: 706363 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 399.21
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4497
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4295
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 0.14s
                      Time elapsed: 00:25:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1352/1 [0m                       

                       Computation: 776959 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 404.81
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4739
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4317
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 0.13s
                      Time elapsed: 00:25:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1353/1 [0m                       

                       Computation: 798800 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 399.19
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7302
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 0.12s
                      Time elapsed: 00:25:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1354/1 [0m                       

                       Computation: 747439 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 402.01
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9760
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 0.13s
                      Time elapsed: 00:25:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1355/1 [0m                       

                       Computation: 647787 steps/s (collection: 0.043s, learning 0.109s)
                       Mean reward: 398.09
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5173
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 25.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 0.15s
                      Time elapsed: 00:25:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1356/1 [0m                       

                       Computation: 587772 steps/s (collection: 0.054s, learning 0.113s)
                       Mean reward: 396.60
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8833
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 0.17s
                      Time elapsed: 00:25:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1357/1 [0m                       

                       Computation: 789440 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 389.87
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.5339
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 0.12s
                      Time elapsed: 00:25:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1358/1 [0m                       

                       Computation: 773226 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 399.99
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4730
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 0.13s
                      Time elapsed: 00:25:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1359/1 [0m                       

                       Computation: 756897 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 401.99
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0091
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 0.13s
                      Time elapsed: 00:25:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1360/1 [0m                       

                       Computation: 774401 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 396.89
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1178
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 0.13s
                      Time elapsed: 00:25:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1361/1 [0m                       

                       Computation: 598977 steps/s (collection: 0.046s, learning 0.118s)
                       Mean reward: 398.99
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4819
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 0.16s
                      Time elapsed: 00:25:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1362/1 [0m                       

                       Computation: 714768 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 402.56
               Mean episode length: 247.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1107
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 0.14s
                      Time elapsed: 00:25:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1363/1 [0m                       

                       Computation: 441595 steps/s (collection: 0.058s, learning 0.165s)
                       Mean reward: 400.23
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4669
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4326
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 0.22s
                      Time elapsed: 00:25:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1364/1 [0m                       

                       Computation: 741670 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 395.31
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0634
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 0.13s
                      Time elapsed: 00:25:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1365/1 [0m                       

                       Computation: 678581 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 400.71
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7068
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 27.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 0.14s
                      Time elapsed: 00:25:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1366/1 [0m                       

                       Computation: 795533 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 394.85
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5427
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 0.12s
                      Time elapsed: 00:25:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1367/1 [0m                       

                       Computation: 802600 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 396.18
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9443
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4326
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 0.12s
                      Time elapsed: 00:25:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1368/1 [0m                       

                       Computation: 515929 steps/s (collection: 0.041s, learning 0.150s)
                       Mean reward: 400.23
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4411
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 0.19s
                      Time elapsed: 00:25:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1369/1 [0m                       

                       Computation: 682978 steps/s (collection: 0.042s, learning 0.102s)
                       Mean reward: 400.14
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7364
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 0.14s
                      Time elapsed: 00:25:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1370/1 [0m                       

                       Computation: 756021 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 403.41
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1667
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 0.13s
                      Time elapsed: 00:25:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1371/1 [0m                       

                       Computation: 669758 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 398.60
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0581
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 0.15s
                      Time elapsed: 00:25:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1372/1 [0m                       

                       Computation: 737160 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 397.55
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0295
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 0.13s
                      Time elapsed: 00:25:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1373/1 [0m                       

                       Computation: 665360 steps/s (collection: 0.048s, learning 0.100s)
                       Mean reward: 397.34
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0043
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 0.15s
                      Time elapsed: 00:25:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1374/1 [0m                       

                       Computation: 518994 steps/s (collection: 0.056s, learning 0.133s)
                       Mean reward: 399.80
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3525
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 0.19s
                      Time elapsed: 00:25:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1375/1 [0m                       

                       Computation: 806711 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 404.15
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4840
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4359
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 28.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 0.12s
                      Time elapsed: 00:25:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1376/1 [0m                       

                       Computation: 642375 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 401.83
               Mean episode length: 246.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1734
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 0.15s
                      Time elapsed: 00:25:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1377/1 [0m                       

                       Computation: 685861 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 403.26
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2816
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 0.14s
                      Time elapsed: 00:25:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1378/1 [0m                       

                       Computation: 758060 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 397.75
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1407
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 0.13s
                      Time elapsed: 00:25:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1379/1 [0m                       

                       Computation: 680082 steps/s (collection: 0.044s, learning 0.101s)
                       Mean reward: 401.61
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9525
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 0.14s
                      Time elapsed: 00:25:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1380/1 [0m                       

                       Computation: 720366 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 402.85
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1793
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 0.14s
                      Time elapsed: 00:25:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1381/1 [0m                       

                       Computation: 737043 steps/s (collection: 0.047s, learning 0.087s)
                       Mean reward: 407.89
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2924
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4410
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 0.13s
                      Time elapsed: 00:25:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1382/1 [0m                       

                       Computation: 798682 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 406.88
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6981
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 0.12s
                      Time elapsed: 00:25:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1383/1 [0m                       

                       Computation: 808787 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 405.64
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5924
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 0.12s
                      Time elapsed: 00:25:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1384/1 [0m                       

                       Computation: 741711 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 403.16
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1352
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 0.13s
                      Time elapsed: 00:25:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1385/1 [0m                       

                       Computation: 733662 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 389.98
               Mean episode length: 246.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7395
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 0.13s
                      Time elapsed: 00:25:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1386/1 [0m                       

                       Computation: 633940 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 399.83
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8629
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 26.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 0.16s
                      Time elapsed: 00:25:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1387/1 [0m                       

                       Computation: 648771 steps/s (collection: 0.043s, learning 0.109s)
                       Mean reward: 403.23
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1741
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 0.15s
                      Time elapsed: 00:25:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1388/1 [0m                       

                       Computation: 730280 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 393.55
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9918
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 0.13s
                      Time elapsed: 00:25:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1389/1 [0m                       

                       Computation: 712550 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 400.68
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8604
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 0.14s
                      Time elapsed: 00:25:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1390/1 [0m                       

                       Computation: 590244 steps/s (collection: 0.042s, learning 0.125s)
                       Mean reward: 396.36
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9592
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 0.17s
                      Time elapsed: 00:25:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1391/1 [0m                       

                       Computation: 689708 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 393.29
               Mean episode length: 247.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.8690
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 0.14s
                      Time elapsed: 00:25:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1392/1 [0m                       

                       Computation: 610506 steps/s (collection: 0.048s, learning 0.114s)
                       Mean reward: 394.03
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3844
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 0.16s
                      Time elapsed: 00:26:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1393/1 [0m                       

                       Computation: 769092 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 392.66
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9080
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 0.13s
                      Time elapsed: 00:26:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1394/1 [0m                       

                       Computation: 792563 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 398.50
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1194
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 0.12s
                      Time elapsed: 00:26:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1395/1 [0m                       

                       Computation: 764910 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 395.05
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7261
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 0.13s
                      Time elapsed: 00:26:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1396/1 [0m                       

                       Computation: 755837 steps/s (collection: 0.046s, learning 0.084s)
                       Mean reward: 399.15
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4322
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 27.8333
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 0.13s
                      Time elapsed: 00:26:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1397/1 [0m                       

                       Computation: 764525 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 404.77
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.8285
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 0.13s
                      Time elapsed: 00:26:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1398/1 [0m                       

                       Computation: 764503 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 397.41
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0008
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 0.13s
                      Time elapsed: 00:26:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1399/1 [0m                       

                       Computation: 680073 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 400.29
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6698
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 0.14s
                      Time elapsed: 00:26:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1400/1 [0m                       

                       Computation: 595610 steps/s (collection: 0.043s, learning 0.122s)
                       Mean reward: 402.19
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0205
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 0.17s
                      Time elapsed: 00:26:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1401/1 [0m                       

                       Computation: 728029 steps/s (collection: 0.058s, learning 0.078s)
                       Mean reward: 403.03
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8143
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 0.14s
                      Time elapsed: 00:26:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1402/1 [0m                       

                       Computation: 792581 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 401.69
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9628
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 0.12s
                      Time elapsed: 00:26:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1403/1 [0m                       

                       Computation: 604208 steps/s (collection: 0.044s, learning 0.118s)
                       Mean reward: 400.70
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4761
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 0.16s
                      Time elapsed: 00:26:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1404/1 [0m                       

                       Computation: 727244 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 399.83
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4480
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 0.14s
                      Time elapsed: 00:26:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1405/1 [0m                       

                       Computation: 698316 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 396.86
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0087
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 0.14s
                      Time elapsed: 00:26:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1406/1 [0m                       

                       Computation: 789735 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 404.26
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4227
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 0.12s
                      Time elapsed: 00:26:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1407/1 [0m                       

                       Computation: 600734 steps/s (collection: 0.041s, learning 0.123s)
                       Mean reward: 396.34
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.0047
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 24.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 0.16s
                      Time elapsed: 00:26:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1408/1 [0m                       

                       Computation: 700902 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 401.27
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7202
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 0.14s
                      Time elapsed: 00:26:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1409/1 [0m                       

                       Computation: 708127 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 401.65
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9575
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 0.14s
                      Time elapsed: 00:26:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1410/1 [0m                       

                       Computation: 753110 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 399.64
               Mean episode length: 246.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7462
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 0.13s
                      Time elapsed: 00:26:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1411/1 [0m                       

                       Computation: 682278 steps/s (collection: 0.045s, learning 0.099s)
                       Mean reward: 407.20
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.0287
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 0.14s
                      Time elapsed: 00:26:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1412/1 [0m                       

                       Computation: 804804 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 399.50
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4126
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4325
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 0.12s
                      Time elapsed: 00:26:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1413/1 [0m                       

                       Computation: 721291 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 402.75
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0599
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 0.14s
                      Time elapsed: 00:26:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1414/1 [0m                       

                       Computation: 658836 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 395.24
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5596
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 0.15s
                      Time elapsed: 00:26:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1415/1 [0m                       

                       Computation: 501133 steps/s (collection: 0.046s, learning 0.151s)
                       Mean reward: 397.67
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0724
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 0.20s
                      Time elapsed: 00:26:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1416/1 [0m                       

                       Computation: 710194 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 402.73
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4993
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 0.14s
                      Time elapsed: 00:26:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1417/1 [0m                       

                       Computation: 664000 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 400.19
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3112
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 26.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 0.15s
                      Time elapsed: 00:26:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1418/1 [0m                       

                       Computation: 722036 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 395.25
               Mean episode length: 246.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.6400
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 0.14s
                      Time elapsed: 00:26:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1419/1 [0m                       

                       Computation: 759237 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 389.75
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.3128
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 0.13s
                      Time elapsed: 00:26:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1420/1 [0m                       

                       Computation: 684704 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 402.77
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0749
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 0.14s
                      Time elapsed: 00:26:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1421/1 [0m                       

                       Computation: 587411 steps/s (collection: 0.045s, learning 0.122s)
                       Mean reward: 402.90
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4741
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 0.17s
                      Time elapsed: 00:26:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1422/1 [0m                       

                       Computation: 643288 steps/s (collection: 0.050s, learning 0.103s)
                       Mean reward: 398.67
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3867
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 0.15s
                      Time elapsed: 00:26:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1423/1 [0m                       

                       Computation: 774270 steps/s (collection: 0.046s, learning 0.081s)
                       Mean reward: 397.86
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1053
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4294
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 0.13s
                      Time elapsed: 00:26:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1424/1 [0m                       

                       Computation: 766022 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 401.96
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9762
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 0.13s
                      Time elapsed: 00:26:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1425/1 [0m                       

                       Computation: 758553 steps/s (collection: 0.047s, learning 0.083s)
                       Mean reward: 398.70
               Mean episode length: 247.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1821
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4300
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 0.13s
                      Time elapsed: 00:26:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1426/1 [0m                       

                       Computation: 735812 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 396.85
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5587
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 0.13s
                      Time elapsed: 00:26:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1427/1 [0m                       

                       Computation: 815717 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 403.68
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.3876
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 0.12s
                      Time elapsed: 00:26:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1428/1 [0m                       

                       Computation: 712881 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 397.72
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9319
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 23.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 0.14s
                      Time elapsed: 00:26:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1429/1 [0m                       

                       Computation: 737052 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 406.66
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.8859
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 0.13s
                      Time elapsed: 00:26:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1430/1 [0m                       

                       Computation: 740100 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 392.04
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7864
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4326
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 0.13s
                      Time elapsed: 00:26:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1431/1 [0m                       

                       Computation: 718166 steps/s (collection: 0.048s, learning 0.089s)
                       Mean reward: 402.02
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.3033
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 0.14s
                      Time elapsed: 00:26:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1432/1 [0m                       

                       Computation: 811256 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 395.92
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.6218
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 0.12s
                      Time elapsed: 00:26:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1433/1 [0m                       

                       Computation: 802361 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 403.54
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.3599
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 0.12s
                      Time elapsed: 00:26:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1434/1 [0m                       

                       Computation: 758825 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 401.57
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9961
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 0.13s
                      Time elapsed: 00:26:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1435/1 [0m                       

                       Computation: 748400 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 400.88
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7204
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 0.13s
                      Time elapsed: 00:26:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1436/1 [0m                       

                       Computation: 765213 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 399.74
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5313
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 0.13s
                      Time elapsed: 00:26:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1437/1 [0m                       

                       Computation: 730586 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 395.03
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2639
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4293
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 0.13s
                      Time elapsed: 00:26:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1438/1 [0m                       

                       Computation: 565919 steps/s (collection: 0.046s, learning 0.128s)
                       Mean reward: 396.67
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3168
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4235
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 25.0000
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 0.17s
                      Time elapsed: 00:26:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1439/1 [0m                       

                       Computation: 811559 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 395.40
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3771
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 0.12s
                      Time elapsed: 00:26:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1440/1 [0m                       

                       Computation: 743942 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 392.03
               Mean episode length: 245.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.0332
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4231
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 0.13s
                      Time elapsed: 00:26:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1441/1 [0m                       

                       Computation: 741715 steps/s (collection: 0.049s, learning 0.084s)
                       Mean reward: 394.87
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5517
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4274
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 0.13s
                      Time elapsed: 00:26:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1442/1 [0m                       

                       Computation: 526469 steps/s (collection: 0.055s, learning 0.132s)
                       Mean reward: 401.68
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8376
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 0.19s
                      Time elapsed: 00:26:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1443/1 [0m                       

                       Computation: 773883 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 399.22
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5483
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 0.13s
                      Time elapsed: 00:26:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1444/1 [0m                       

                       Computation: 636648 steps/s (collection: 0.045s, learning 0.110s)
                       Mean reward: 394.75
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.4297
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4249
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 0.15s
                      Time elapsed: 00:26:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1445/1 [0m                       

                       Computation: 640771 steps/s (collection: 0.041s, learning 0.112s)
                       Mean reward: 397.74
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0814
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 0.15s
                      Time elapsed: 00:27:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1446/1 [0m                       

                       Computation: 696019 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 397.81
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4946
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 0.14s
                      Time elapsed: 00:27:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1447/1 [0m                       

                       Computation: 816878 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 398.73
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3575
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 0.12s
                      Time elapsed: 00:27:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1448/1 [0m                       

                       Computation: 785624 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 399.74
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9603
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4252
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 27.4583
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 0.13s
                      Time elapsed: 00:27:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1449/1 [0m                       

                       Computation: 763654 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 402.64
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9409
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4255
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 0.13s
                      Time elapsed: 00:27:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1450/1 [0m                       

                       Computation: 805020 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 397.00
               Mean episode length: 244.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8288
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4223
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 0.12s
                      Time elapsed: 00:27:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1451/1 [0m                       

                       Computation: 625262 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 390.53
               Mean episode length: 246.51
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.5073
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4212
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 0.16s
                      Time elapsed: 00:27:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1452/1 [0m                       

                       Computation: 552135 steps/s (collection: 0.048s, learning 0.131s)
                       Mean reward: 400.49
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6816
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4269
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 0.18s
                      Time elapsed: 00:27:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1453/1 [0m                       

                       Computation: 516608 steps/s (collection: 0.048s, learning 0.143s)
                       Mean reward: 397.83
               Mean episode length: 247.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9358
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 0.19s
                      Time elapsed: 00:27:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1454/1 [0m                       

                       Computation: 706819 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 399.86
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4920
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4237
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 0.14s
                      Time elapsed: 00:27:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1455/1 [0m                       

                       Computation: 665476 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 401.71
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9886
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4273
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 0.15s
                      Time elapsed: 00:27:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1456/1 [0m                       

                       Computation: 603117 steps/s (collection: 0.045s, learning 0.118s)
                       Mean reward: 403.34
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4686
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 0.16s
                      Time elapsed: 00:27:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1457/1 [0m                       

                       Computation: 533580 steps/s (collection: 0.060s, learning 0.125s)
                       Mean reward: 395.51
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8758
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4276
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 0.18s
                      Time elapsed: 00:27:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1458/1 [0m                       

                       Computation: 650868 steps/s (collection: 0.049s, learning 0.102s)
                       Mean reward: 399.30
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4503
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 0.15s
                      Time elapsed: 00:27:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1459/1 [0m                       

                       Computation: 484015 steps/s (collection: 0.045s, learning 0.159s)
                       Mean reward: 401.31
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1646
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 24.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 0.20s
                      Time elapsed: 00:27:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1460/1 [0m                       

                       Computation: 750323 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 402.94
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1141
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 0.13s
                      Time elapsed: 00:27:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1461/1 [0m                       

                       Computation: 770878 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 394.79
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2424
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4233
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 0.13s
                      Time elapsed: 00:27:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1462/1 [0m                       

                       Computation: 426320 steps/s (collection: 0.044s, learning 0.187s)
                       Mean reward: 399.66
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5669
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 0.23s
                      Time elapsed: 00:27:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1463/1 [0m                       

                       Computation: 723346 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 400.78
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7169
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 0.14s
                      Time elapsed: 00:27:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1464/1 [0m                       

                       Computation: 698392 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 400.10
               Mean episode length: 247.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4400
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4238
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 0.14s
                      Time elapsed: 00:27:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1465/1 [0m                       

                       Computation: 829301 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 404.01
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0517
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 0.12s
                      Time elapsed: 00:27:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1466/1 [0m                       

                       Computation: 659596 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 399.07
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3733
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 0.15s
                      Time elapsed: 00:27:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1467/1 [0m                       

                       Computation: 700434 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 396.78
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0281
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 0.14s
                      Time elapsed: 00:27:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1468/1 [0m                       

                       Computation: 545161 steps/s (collection: 0.046s, learning 0.135s)
                       Mean reward: 401.52
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8428
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 0.18s
                      Time elapsed: 00:27:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1469/1 [0m                       

                       Computation: 575744 steps/s (collection: 0.050s, learning 0.121s)
                       Mean reward: 405.32
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1110
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 26.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 0.17s
                      Time elapsed: 00:27:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1470/1 [0m                       

                       Computation: 743061 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 396.25
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0557
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4249
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 0.13s
                      Time elapsed: 00:27:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1471/1 [0m                       

                       Computation: 699211 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 405.16
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5334
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4259
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 0.14s
                      Time elapsed: 00:27:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1472/1 [0m                       

                       Computation: 574354 steps/s (collection: 0.046s, learning 0.125s)
                       Mean reward: 394.85
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7006
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4238
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 0.17s
                      Time elapsed: 00:27:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1473/1 [0m                       

                       Computation: 694331 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 397.98
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8082
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4245
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 0.14s
                      Time elapsed: 00:27:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1474/1 [0m                       

                       Computation: 442625 steps/s (collection: 0.089s, learning 0.133s)
                       Mean reward: 400.27
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6998
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4276
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 0.22s
                      Time elapsed: 00:27:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1475/1 [0m                       

                       Computation: 609865 steps/s (collection: 0.047s, learning 0.114s)
                       Mean reward: 400.73
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1094
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 0.16s
                      Time elapsed: 00:27:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1476/1 [0m                       

                       Computation: 691067 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 402.87
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0504
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4252
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 0.14s
                      Time elapsed: 00:27:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1477/1 [0m                       

                       Computation: 736364 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 398.33
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2189
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4242
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 0.13s
                      Time elapsed: 00:27:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1478/1 [0m                       

                       Computation: 689746 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 402.16
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2430
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4261
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 0.14s
                      Time elapsed: 00:27:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1479/1 [0m                       

                       Computation: 656754 steps/s (collection: 0.050s, learning 0.100s)
                       Mean reward: 404.44
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5054
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 0.15s
                      Time elapsed: 00:27:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1480/1 [0m                       

                       Computation: 528515 steps/s (collection: 0.062s, learning 0.124s)
                       Mean reward: 396.07
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.7421
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4188
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 23.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 0.19s
                      Time elapsed: 00:27:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1481/1 [0m                       

                       Computation: 800368 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 392.83
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.0210
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4197
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 0.12s
                      Time elapsed: 00:27:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1482/1 [0m                       

                       Computation: 818171 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 400.40
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8660
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4242
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 0.12s
                      Time elapsed: 00:27:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1483/1 [0m                       

                       Computation: 753485 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 405.26
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.8478
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 0.13s
                      Time elapsed: 00:27:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1484/1 [0m                       

                       Computation: 710985 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 404.05
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5611
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 0.14s
                      Time elapsed: 00:27:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1485/1 [0m                       

                       Computation: 562205 steps/s (collection: 0.047s, learning 0.127s)
                       Mean reward: 401.78
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9693
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4283
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 0.17s
                      Time elapsed: 00:27:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1486/1 [0m                       

                       Computation: 632335 steps/s (collection: 0.043s, learning 0.113s)
                       Mean reward: 405.09
               Mean episode length: 247.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6823
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4239
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 0.16s
                      Time elapsed: 00:27:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1487/1 [0m                       

                       Computation: 679561 steps/s (collection: 0.046s, learning 0.099s)
                       Mean reward: 402.61
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2905
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 0.14s
                      Time elapsed: 00:27:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1488/1 [0m                       

                       Computation: 564220 steps/s (collection: 0.056s, learning 0.118s)
                       Mean reward: 402.88
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0280
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 0.17s
                      Time elapsed: 00:27:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1489/1 [0m                       

                       Computation: 544858 steps/s (collection: 0.070s, learning 0.111s)
                       Mean reward: 400.80
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0299
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4249
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 0.18s
                      Time elapsed: 00:27:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1490/1 [0m                       

                       Computation: 754586 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 402.08
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0941
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4233
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 25.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 0.13s
                      Time elapsed: 00:27:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1491/1 [0m                       

                       Computation: 770834 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 402.91
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5178
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 0.13s
                      Time elapsed: 00:27:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1492/1 [0m                       

                       Computation: 605256 steps/s (collection: 0.040s, learning 0.123s)
                       Mean reward: 398.91
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2826
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 0.16s
                      Time elapsed: 00:27:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1493/1 [0m                       

                       Computation: 681409 steps/s (collection: 0.038s, learning 0.106s)
                       Mean reward: 402.10
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9480
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 0.14s
                      Time elapsed: 00:27:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1494/1 [0m                       

                       Computation: 729965 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 402.25
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1187
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4301
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 0.13s
                      Time elapsed: 00:27:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1495/1 [0m                       

                       Computation: 668398 steps/s (collection: 0.038s, learning 0.109s)
                       Mean reward: 399.44
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4980
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4276
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 0.15s
                      Time elapsed: 00:27:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1496/1 [0m                       

                       Computation: 756898 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 403.87
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2195
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4260
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 0.13s
                      Time elapsed: 00:28:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1497/1 [0m                       

                       Computation: 746991 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 400.19
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4734
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 0.13s
                      Time elapsed: 00:28:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1498/1 [0m                       

                       Computation: 571849 steps/s (collection: 0.053s, learning 0.119s)
                       Mean reward: 399.02
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4617
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4249
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 0.17s
                      Time elapsed: 00:28:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1499/1 [0m                       

                       Computation: 688850 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 399.75
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8751
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 0.14s
                      Time elapsed: 00:28:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1500/1 [0m                       

                       Computation: 703197 steps/s (collection: 0.045s, learning 0.095s)
                       Mean reward: 398.07
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7540
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4267
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 26.5833
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 0.14s
                      Time elapsed: 00:28:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1501/1 [0m                       

                       Computation: 615641 steps/s (collection: 0.048s, learning 0.112s)
                       Mean reward: 403.44
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1049
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 147554304
                    Iteration time: 0.16s
                      Time elapsed: 00:28:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1502/1 [0m                       

                       Computation: 544690 steps/s (collection: 0.053s, learning 0.127s)
                       Mean reward: 401.38
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0564
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4248
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 147652608
                    Iteration time: 0.18s
                      Time elapsed: 00:28:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1503/1 [0m                       

                       Computation: 604960 steps/s (collection: 0.046s, learning 0.117s)
                       Mean reward: 400.55
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7239
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4280
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 147750912
                    Iteration time: 0.16s
                      Time elapsed: 00:28:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1504/1 [0m                       

                       Computation: 751050 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 396.02
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5873
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4250
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 147849216
                    Iteration time: 0.13s
                      Time elapsed: 00:28:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1505/1 [0m                       

                       Computation: 582250 steps/s (collection: 0.041s, learning 0.128s)
                       Mean reward: 395.57
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5680
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4253
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 147947520
                    Iteration time: 0.17s
                      Time elapsed: 00:28:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1506/1 [0m                       

                       Computation: 675785 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 399.18
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5582
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4228
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 148045824
                    Iteration time: 0.15s
                      Time elapsed: 00:28:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1507/1 [0m                       

                       Computation: 648205 steps/s (collection: 0.038s, learning 0.113s)
                       Mean reward: 403.02
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2709
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 148144128
                    Iteration time: 0.15s
                      Time elapsed: 00:28:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1508/1 [0m                       

                       Computation: 697725 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 398.83
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2706
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 148242432
                    Iteration time: 0.14s
                      Time elapsed: 00:28:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1509/1 [0m                       

                       Computation: 666438 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 398.64
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0842
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4241
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 148340736
                    Iteration time: 0.15s
                      Time elapsed: 00:28:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1510/1 [0m                       

                       Computation: 640346 steps/s (collection: 0.039s, learning 0.115s)
                       Mean reward: 396.63
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8641
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 148439040
                    Iteration time: 0.15s
                      Time elapsed: 00:28:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1511/1 [0m                       

                       Computation: 800658 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 403.30
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0282
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4283
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 24.5417
--------------------------------------------------------------------------------
                   Total timesteps: 148537344
                    Iteration time: 0.12s
                      Time elapsed: 00:28:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1512/1 [0m                       

                       Computation: 790510 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 402.50
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0909
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 148635648
                    Iteration time: 0.12s
                      Time elapsed: 00:28:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1513/1 [0m                       

                       Computation: 692730 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 403.89
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1533
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4273
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 148733952
                    Iteration time: 0.14s
                      Time elapsed: 00:28:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1514/1 [0m                       

                       Computation: 697128 steps/s (collection: 0.049s, learning 0.092s)
                       Mean reward: 404.74
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6076
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4275
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 148832256
                    Iteration time: 0.14s
                      Time elapsed: 00:28:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1515/1 [0m                       

                       Computation: 817680 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 406.40
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7110
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4305
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 148930560
                    Iteration time: 0.12s
                      Time elapsed: 00:28:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1516/1 [0m                       

                       Computation: 741151 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 401.82
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6942
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 149028864
                    Iteration time: 0.13s
                      Time elapsed: 00:28:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1517/1 [0m                       

                       Computation: 808153 steps/s (collection: 0.047s, learning 0.075s)
                       Mean reward: 405.55
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6088
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4299
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 149127168
                    Iteration time: 0.12s
                      Time elapsed: 00:28:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1518/1 [0m                       

                       Computation: 789620 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 403.98
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4921
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4307
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 149225472
                    Iteration time: 0.12s
                      Time elapsed: 00:28:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1519/1 [0m                       

                       Computation: 796736 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 406.67
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6444
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4314
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 149323776
                    Iteration time: 0.12s
                      Time elapsed: 00:28:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1520/1 [0m                       

                       Computation: 740490 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 399.25
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.1153
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 149422080
                    Iteration time: 0.13s
                      Time elapsed: 00:28:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1521/1 [0m                       

                       Computation: 703877 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 403.19
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6721
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4271
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 26.2500
--------------------------------------------------------------------------------
                   Total timesteps: 149520384
                    Iteration time: 0.14s
                      Time elapsed: 00:28:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1522/1 [0m                       

                       Computation: 753716 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 404.09
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4522
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 149618688
                    Iteration time: 0.13s
                      Time elapsed: 00:28:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1523/1 [0m                       

                       Computation: 732355 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 406.87
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1489
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 149716992
                    Iteration time: 0.13s
                      Time elapsed: 00:28:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1524/1 [0m                       

                       Computation: 756368 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 410.87
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.8686
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 149815296
                    Iteration time: 0.13s
                      Time elapsed: 00:28:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1525/1 [0m                       

                       Computation: 844181 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 406.74
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.9240
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4330
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 149913600
                    Iteration time: 0.12s
                      Time elapsed: 00:28:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1526/1 [0m                       

                       Computation: 738847 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 411.18
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9227
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 150011904
                    Iteration time: 0.13s
                      Time elapsed: 00:28:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1527/1 [0m                       

                       Computation: 698573 steps/s (collection: 0.037s, learning 0.104s)
                       Mean reward: 406.50
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.0093
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 150110208
                    Iteration time: 0.14s
                      Time elapsed: 00:28:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1528/1 [0m                       

                       Computation: 702020 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 401.29
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8290
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4272
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 150208512
                    Iteration time: 0.14s
                      Time elapsed: 00:28:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1529/1 [0m                       

                       Computation: 644983 steps/s (collection: 0.052s, learning 0.100s)
                       Mean reward: 404.97
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5143
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4308
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 150306816
                    Iteration time: 0.15s
                      Time elapsed: 00:28:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1530/1 [0m                       

                       Computation: 633059 steps/s (collection: 0.039s, learning 0.116s)
                       Mean reward: 403.55
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4594
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 150405120
                    Iteration time: 0.16s
                      Time elapsed: 00:28:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1531/1 [0m                       

                       Computation: 817231 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 407.33
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2116
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4313
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 150503424
                    Iteration time: 0.12s
                      Time elapsed: 00:28:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1532/1 [0m                       

                       Computation: 843711 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 409.16
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5226
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4312
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 23.7917
--------------------------------------------------------------------------------
                   Total timesteps: 150601728
                    Iteration time: 0.12s
                      Time elapsed: 00:28:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1533/1 [0m                       

                       Computation: 861081 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 409.29
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.9515
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 150700032
                    Iteration time: 0.11s
                      Time elapsed: 00:28:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1534/1 [0m                       

                       Computation: 833755 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 401.77
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0636
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 150798336
                    Iteration time: 0.12s
                      Time elapsed: 00:28:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1535/1 [0m                       

                       Computation: 620358 steps/s (collection: 0.046s, learning 0.112s)
                       Mean reward: 402.71
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1646
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4326
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 150896640
                    Iteration time: 0.16s
                      Time elapsed: 00:28:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1536/1 [0m                       

                       Computation: 684268 steps/s (collection: 0.038s, learning 0.106s)
                       Mean reward: 405.73
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.8713
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 150994944
                    Iteration time: 0.14s
                      Time elapsed: 00:28:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1537/1 [0m                       

                       Computation: 613845 steps/s (collection: 0.038s, learning 0.122s)
                       Mean reward: 411.18
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.8361
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4347
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 151093248
                    Iteration time: 0.16s
                      Time elapsed: 00:28:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1538/1 [0m                       

                       Computation: 815621 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 403.00
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1311
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 151191552
                    Iteration time: 0.12s
                      Time elapsed: 00:28:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1539/1 [0m                       

                       Computation: 822319 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 402.05
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9340
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 151289856
                    Iteration time: 0.12s
                      Time elapsed: 00:28:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1540/1 [0m                       

                       Computation: 836491 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 407.88
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1937
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 151388160
                    Iteration time: 0.12s
                      Time elapsed: 00:28:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1541/1 [0m                       

                       Computation: 859308 steps/s (collection: 0.040s, learning 0.075s)
                       Mean reward: 410.60
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.4775
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 151486464
                    Iteration time: 0.11s
                      Time elapsed: 00:28:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1542/1 [0m                       

                       Computation: 868218 steps/s (collection: 0.040s, learning 0.073s)
                       Mean reward: 415.00
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8109
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 25.1250
--------------------------------------------------------------------------------
                   Total timesteps: 151584768
                    Iteration time: 0.11s
                      Time elapsed: 00:28:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1543/1 [0m                       

                       Computation: 793803 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 403.32
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6583
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 151683072
                    Iteration time: 0.12s
                      Time elapsed: 00:28:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1544/1 [0m                       

                       Computation: 691624 steps/s (collection: 0.037s, learning 0.106s)
                       Mean reward: 401.27
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7312
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 151781376
                    Iteration time: 0.14s
                      Time elapsed: 00:28:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1545/1 [0m                       

                       Computation: 766103 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 411.16
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7453
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 151879680
                    Iteration time: 0.13s
                      Time elapsed: 00:28:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1546/1 [0m                       

                       Computation: 798600 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 407.25
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.9770
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 151977984
                    Iteration time: 0.12s
                      Time elapsed: 00:28:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1547/1 [0m                       

                       Computation: 795723 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 403.92
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4777
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4285
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 152076288
                    Iteration time: 0.12s
                      Time elapsed: 00:28:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1548/1 [0m                       

                       Computation: 758548 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 403.20
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9608
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 152174592
                    Iteration time: 0.13s
                      Time elapsed: 00:28:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1549/1 [0m                       

                       Computation: 778951 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 399.05
               Mean episode length: 246.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4487
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4287
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 152272896
                    Iteration time: 0.13s
                      Time elapsed: 00:28:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1550/1 [0m                       

                       Computation: 891141 steps/s (collection: 0.040s, learning 0.070s)
                       Mean reward: 404.72
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5882
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 152371200
                    Iteration time: 0.11s
                      Time elapsed: 00:28:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1551/1 [0m                       

                       Computation: 664108 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 400.16
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.3599
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 152469504
                    Iteration time: 0.15s
                      Time elapsed: 00:29:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1552/1 [0m                       

                       Computation: 914471 steps/s (collection: 0.037s, learning 0.070s)
                       Mean reward: 404.99
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7157
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 152567808
                    Iteration time: 0.11s
                      Time elapsed: 00:29:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1553/1 [0m                       

                       Computation: 818696 steps/s (collection: 0.046s, learning 0.074s)
                       Mean reward: 406.98
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.0419
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 22.2083
--------------------------------------------------------------------------------
                   Total timesteps: 152666112
                    Iteration time: 0.12s
                      Time elapsed: 00:29:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1554/1 [0m                       

                       Computation: 733688 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 402.57
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0309
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4320
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 152764416
                    Iteration time: 0.13s
                      Time elapsed: 00:29:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1555/1 [0m                       

                       Computation: 712212 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 403.17
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4496
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 152862720
                    Iteration time: 0.14s
                      Time elapsed: 00:29:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1556/1 [0m                       

                       Computation: 730668 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 407.27
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1855
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 152961024
                    Iteration time: 0.13s
                      Time elapsed: 00:29:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1557/1 [0m                       

                       Computation: 696849 steps/s (collection: 0.034s, learning 0.107s)
                       Mean reward: 406.81
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6203
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 153059328
                    Iteration time: 0.14s
                      Time elapsed: 00:29:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1558/1 [0m                       

                       Computation: 679854 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 405.80
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6429
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 153157632
                    Iteration time: 0.14s
                      Time elapsed: 00:29:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1559/1 [0m                       

                       Computation: 671723 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 406.34
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7836
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4327
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 153255936
                    Iteration time: 0.15s
                      Time elapsed: 00:29:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1560/1 [0m                       

                       Computation: 727562 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 405.24
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7537
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 153354240
                    Iteration time: 0.14s
                      Time elapsed: 00:29:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1561/1 [0m                       

                       Computation: 620046 steps/s (collection: 0.036s, learning 0.123s)
                       Mean reward: 404.30
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4655
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4309
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 153452544
                    Iteration time: 0.16s
                      Time elapsed: 00:29:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1562/1 [0m                       

                       Computation: 716976 steps/s (collection: 0.036s, learning 0.101s)
                       Mean reward: 405.46
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1562
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 153550848
                    Iteration time: 0.14s
                      Time elapsed: 00:29:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1563/1 [0m                       

                       Computation: 708968 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 409.21
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.0137
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4323
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 23.7083
--------------------------------------------------------------------------------
                   Total timesteps: 153649152
                    Iteration time: 0.14s
                      Time elapsed: 00:29:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1564/1 [0m                       

                       Computation: 850811 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 400.31
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5442
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 153747456
                    Iteration time: 0.12s
                      Time elapsed: 00:29:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1565/1 [0m                       

                       Computation: 719401 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 404.30
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4684
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4327
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 153845760
                    Iteration time: 0.14s
                      Time elapsed: 00:29:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1566/1 [0m                       

                       Computation: 679759 steps/s (collection: 0.047s, learning 0.098s)
                       Mean reward: 401.18
               Mean episode length: 247.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8796
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 153944064
                    Iteration time: 0.14s
                      Time elapsed: 00:29:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1567/1 [0m                       

                       Computation: 635808 steps/s (collection: 0.039s, learning 0.116s)
                       Mean reward: 402.97
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1350
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4292
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 154042368
                    Iteration time: 0.15s
                      Time elapsed: 00:29:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1568/1 [0m                       

                       Computation: 758251 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 404.14
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4103
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 154140672
                    Iteration time: 0.13s
                      Time elapsed: 00:29:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1569/1 [0m                       

                       Computation: 705895 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 410.04
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.6866
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4310
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 154238976
                    Iteration time: 0.14s
                      Time elapsed: 00:29:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1570/1 [0m                       

                       Computation: 798568 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 407.13
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7669
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4289
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 154337280
                    Iteration time: 0.12s
                      Time elapsed: 00:29:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1571/1 [0m                       

                       Computation: 847117 steps/s (collection: 0.034s, learning 0.082s)
                       Mean reward: 404.55
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.3742
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 154435584
                    Iteration time: 0.12s
                      Time elapsed: 00:29:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1572/1 [0m                       

                       Computation: 735830 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 402.53
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6481
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 154533888
                    Iteration time: 0.13s
                      Time elapsed: 00:29:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1573/1 [0m                       

                       Computation: 850400 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 406.20
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2141
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 25.7500
--------------------------------------------------------------------------------
                   Total timesteps: 154632192
                    Iteration time: 0.12s
                      Time elapsed: 00:29:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1574/1 [0m                       

                       Computation: 686707 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 394.44
               Mean episode length: 245.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8312
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4245
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 154730496
                    Iteration time: 0.14s
                      Time elapsed: 00:29:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1575/1 [0m                       

                       Computation: 744555 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 402.57
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0490
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 154828800
                    Iteration time: 0.13s
                      Time elapsed: 00:29:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1576/1 [0m                       

                       Computation: 818485 steps/s (collection: 0.035s, learning 0.086s)
                       Mean reward: 399.79
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7883
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4268
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 154927104
                    Iteration time: 0.12s
                      Time elapsed: 00:29:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1577/1 [0m                       

                       Computation: 792123 steps/s (collection: 0.035s, learning 0.090s)
                       Mean reward: 402.42
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2017
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 155025408
                    Iteration time: 0.12s
                      Time elapsed: 00:29:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1578/1 [0m                       

                       Computation: 781907 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 399.52
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2337
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4274
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 155123712
                    Iteration time: 0.13s
                      Time elapsed: 00:29:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1579/1 [0m                       

                       Computation: 749984 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 406.13
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7472
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4284
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 155222016
                    Iteration time: 0.13s
                      Time elapsed: 00:29:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1580/1 [0m                       

                       Computation: 732788 steps/s (collection: 0.034s, learning 0.101s)
                       Mean reward: 403.74
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1722
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4274
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 155320320
                    Iteration time: 0.13s
                      Time elapsed: 00:29:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1581/1 [0m                       

                       Computation: 815031 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 405.44
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6883
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4259
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 155418624
                    Iteration time: 0.12s
                      Time elapsed: 00:29:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1582/1 [0m                       

                       Computation: 852433 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 400.47
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9713
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 155516928
                    Iteration time: 0.12s
                      Time elapsed: 00:29:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1583/1 [0m                       

                       Computation: 830886 steps/s (collection: 0.035s, learning 0.083s)
                       Mean reward: 397.22
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2491
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4268
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 155615232
                    Iteration time: 0.12s
                      Time elapsed: 00:29:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1584/1 [0m                       

                       Computation: 894796 steps/s (collection: 0.042s, learning 0.068s)
                       Mean reward: 406.73
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7107
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4293
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 23.3750
--------------------------------------------------------------------------------
                   Total timesteps: 155713536
                    Iteration time: 0.11s
                      Time elapsed: 00:29:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1585/1 [0m                       

                       Computation: 845877 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 403.57
               Mean episode length: 245.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 79.5902
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4211
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 155811840
                    Iteration time: 0.12s
                      Time elapsed: 00:29:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1586/1 [0m                       

                       Computation: 978405 steps/s (collection: 0.035s, learning 0.066s)
                       Mean reward: 400.95
               Mean episode length: 246.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8677
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 155910144
                    Iteration time: 0.10s
                      Time elapsed: 00:29:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1587/1 [0m                       

                       Computation: 885052 steps/s (collection: 0.035s, learning 0.076s)
                       Mean reward: 404.61
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5489
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 156008448
                    Iteration time: 0.11s
                      Time elapsed: 00:29:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1588/1 [0m                       

                       Computation: 950959 steps/s (collection: 0.034s, learning 0.070s)
                       Mean reward: 406.59
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5175
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 156106752
                    Iteration time: 0.10s
                      Time elapsed: 00:29:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1589/1 [0m                       

                       Computation: 821179 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 404.54
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6778
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 156205056
                    Iteration time: 0.12s
                      Time elapsed: 00:29:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1590/1 [0m                       

                       Computation: 922916 steps/s (collection: 0.037s, learning 0.070s)
                       Mean reward: 406.14
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7510
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 156303360
                    Iteration time: 0.11s
                      Time elapsed: 00:29:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1591/1 [0m                       

                       Computation: 873897 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 409.23
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2257
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 156401664
                    Iteration time: 0.11s
                      Time elapsed: 00:29:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1592/1 [0m                       

                       Computation: 712655 steps/s (collection: 0.049s, learning 0.089s)
                       Mean reward: 405.35
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1709
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4296
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 156499968
                    Iteration time: 0.14s
                      Time elapsed: 00:29:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1593/1 [0m                       

                       Computation: 812242 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 406.69
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.8730
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4304
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 156598272
                    Iteration time: 0.12s
                      Time elapsed: 00:29:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1594/1 [0m                       

                       Computation: 831867 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 406.40
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4631
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4327
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 24.7083
--------------------------------------------------------------------------------
                   Total timesteps: 156696576
                    Iteration time: 0.12s
                      Time elapsed: 00:29:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1595/1 [0m                       

                       Computation: 896118 steps/s (collection: 0.035s, learning 0.075s)
                       Mean reward: 402.57
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1659
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4324
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 156794880
                    Iteration time: 0.11s
                      Time elapsed: 00:29:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1596/1 [0m                       

                       Computation: 805589 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 398.91
               Mean episode length: 247.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8656
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4232
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 156893184
                    Iteration time: 0.12s
                      Time elapsed: 00:29:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1597/1 [0m                       

                       Computation: 786255 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 399.47
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2048
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 156991488
                    Iteration time: 0.13s
                      Time elapsed: 00:29:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1598/1 [0m                       

                       Computation: 940497 steps/s (collection: 0.037s, learning 0.068s)
                       Mean reward: 408.40
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2181
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4311
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 157089792
                    Iteration time: 0.10s
                      Time elapsed: 00:29:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1599/1 [0m                       

                       Computation: 666109 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 400.28
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6340
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4291
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 157188096
                    Iteration time: 0.15s
                      Time elapsed: 00:29:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1600/1 [0m                       

                       Computation: 825908 steps/s (collection: 0.034s, learning 0.085s)
                       Mean reward: 414.34
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5966
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 157286400
                    Iteration time: 0.12s
                      Time elapsed: 00:29:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1601/1 [0m                       

                       Computation: 927156 steps/s (collection: 0.036s, learning 0.071s)
                       Mean reward: 405.06
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5397
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 157384704
                    Iteration time: 0.11s
                      Time elapsed: 00:29:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1602/1 [0m                       

                       Computation: 979388 steps/s (collection: 0.035s, learning 0.065s)
                       Mean reward: 406.92
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7604
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 157483008
                    Iteration time: 0.10s
                      Time elapsed: 00:29:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1603/1 [0m                       

                       Computation: 910800 steps/s (collection: 0.034s, learning 0.074s)
                       Mean reward: 405.27
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6118
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4274
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 157581312
                    Iteration time: 0.11s
                      Time elapsed: 00:29:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1604/1 [0m                       

                       Computation: 903969 steps/s (collection: 0.033s, learning 0.075s)
                       Mean reward: 400.56
               Mean episode length: 247.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9847
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4255
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 157679616
                    Iteration time: 0.11s
                      Time elapsed: 00:29:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1605/1 [0m                       

                       Computation: 946384 steps/s (collection: 0.034s, learning 0.070s)
                       Mean reward: 407.00
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2015
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 22.5000
--------------------------------------------------------------------------------
                   Total timesteps: 157777920
                    Iteration time: 0.10s
                      Time elapsed: 00:29:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1606/1 [0m                       

                       Computation: 795201 steps/s (collection: 0.034s, learning 0.090s)
                       Mean reward: 404.11
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.3114
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4257
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 157876224
                    Iteration time: 0.12s
                      Time elapsed: 00:29:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1607/1 [0m                       

                       Computation: 821787 steps/s (collection: 0.034s, learning 0.086s)
                       Mean reward: 394.58
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.5413
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 157974528
                    Iteration time: 0.12s
                      Time elapsed: 00:29:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1608/1 [0m                       

                       Computation: 844191 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 401.09
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6242
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4260
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 158072832
                    Iteration time: 0.12s
                      Time elapsed: 00:29:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1609/1 [0m                       

                       Computation: 829254 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 405.96
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5414
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 158171136
                    Iteration time: 0.12s
                      Time elapsed: 00:29:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1610/1 [0m                       

                       Computation: 888613 steps/s (collection: 0.041s, learning 0.070s)
                       Mean reward: 395.29
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3776
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4248
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 158269440
                    Iteration time: 0.11s
                      Time elapsed: 00:29:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1611/1 [0m                       

                       Computation: 873519 steps/s (collection: 0.041s, learning 0.071s)
                       Mean reward: 399.44
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4575
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4264
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 158367744
                    Iteration time: 0.11s
                      Time elapsed: 00:30:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1612/1 [0m                       

                       Computation: 919397 steps/s (collection: 0.035s, learning 0.072s)
                       Mean reward: 401.00
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0353
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4266
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 158466048
                    Iteration time: 0.11s
                      Time elapsed: 00:30:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1613/1 [0m                       

                       Computation: 921615 steps/s (collection: 0.035s, learning 0.071s)
                       Mean reward: 406.48
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7313
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4261
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 158564352
                    Iteration time: 0.11s
                      Time elapsed: 00:30:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1614/1 [0m                       

                       Computation: 917521 steps/s (collection: 0.036s, learning 0.071s)
                       Mean reward: 409.12
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2774
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4278
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 158662656
                    Iteration time: 0.11s
                      Time elapsed: 00:30:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1615/1 [0m                       

                       Computation: 909755 steps/s (collection: 0.035s, learning 0.073s)
                       Mean reward: 397.54
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8068
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4233
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 23.3333
--------------------------------------------------------------------------------
                   Total timesteps: 158760960
                    Iteration time: 0.11s
                      Time elapsed: 00:30:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1616/1 [0m                       

                       Computation: 843975 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 403.42
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2111
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4243
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 158859264
                    Iteration time: 0.12s
                      Time elapsed: 00:30:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1617/1 [0m                       

                       Computation: 918247 steps/s (collection: 0.037s, learning 0.071s)
                       Mean reward: 399.16
               Mean episode length: 247.51
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4919
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4245
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 158957568
                    Iteration time: 0.11s
                      Time elapsed: 00:30:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1618/1 [0m                       

                       Computation: 832435 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 405.12
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5170
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4258
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 159055872
                    Iteration time: 0.12s
                      Time elapsed: 00:30:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1619/1 [0m                       

                       Computation: 927227 steps/s (collection: 0.035s, learning 0.072s)
                       Mean reward: 397.13
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8966
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4262
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 159154176
                    Iteration time: 0.11s
                      Time elapsed: 00:30:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1620/1 [0m                       

                       Computation: 766641 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 395.86
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8776
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4250
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 159252480
                    Iteration time: 0.13s
                      Time elapsed: 00:30:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1621/1 [0m                       

                       Computation: 908835 steps/s (collection: 0.037s, learning 0.071s)
                       Mean reward: 397.74
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0741
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4260
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 159350784
                    Iteration time: 0.11s
                      Time elapsed: 00:30:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1622/1 [0m                       

                       Computation: 773587 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 399.28
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4540
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4219
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 159449088
                    Iteration time: 0.13s
                      Time elapsed: 00:30:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1623/1 [0m                       

                       Computation: 670882 steps/s (collection: 0.044s, learning 0.103s)
                       Mean reward: 400.42
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.6231
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 159547392
                    Iteration time: 0.15s
                      Time elapsed: 00:30:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1624/1 [0m                       

                       Computation: 920072 steps/s (collection: 0.035s, learning 0.072s)
                       Mean reward: 392.10
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 77.9797
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4191
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 159645696
                    Iteration time: 0.11s
                      Time elapsed: 00:30:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1625/1 [0m                       

                       Computation: 851178 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 401.51
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8835
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4221
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 24.3750
--------------------------------------------------------------------------------
                   Total timesteps: 159744000
                    Iteration time: 0.12s
                      Time elapsed: 00:30:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1626/1 [0m                       

                       Computation: 864905 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 397.42
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7087
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4225
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 159842304
                    Iteration time: 0.11s
                      Time elapsed: 00:30:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1627/1 [0m                       

                       Computation: 906796 steps/s (collection: 0.036s, learning 0.072s)
                       Mean reward: 402.36
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5942
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4269
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 159940608
                    Iteration time: 0.11s
                      Time elapsed: 00:30:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1628/1 [0m                       

                       Computation: 792528 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 395.39
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.3944
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4218
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 160038912
                    Iteration time: 0.12s
                      Time elapsed: 00:30:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1629/1 [0m                       

                       Computation: 709024 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 404.18
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1491
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4258
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 160137216
                    Iteration time: 0.14s
                      Time elapsed: 00:30:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1630/1 [0m                       

                       Computation: 708202 steps/s (collection: 0.035s, learning 0.104s)
                       Mean reward: 398.39
               Mean episode length: 247.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2103
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4238
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 160235520
                    Iteration time: 0.14s
                      Time elapsed: 00:30:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1631/1 [0m                       

                       Computation: 931555 steps/s (collection: 0.036s, learning 0.069s)
                       Mean reward: 403.33
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2515
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4254
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 160333824
                    Iteration time: 0.11s
                      Time elapsed: 00:30:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1632/1 [0m                       

                       Computation: 951986 steps/s (collection: 0.035s, learning 0.068s)
                       Mean reward: 395.71
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.7789
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4201
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 160432128
                    Iteration time: 0.10s
                      Time elapsed: 00:30:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1633/1 [0m                       

                       Computation: 798831 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 396.13
               Mean episode length: 247.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.8527
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4217
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 160530432
                    Iteration time: 0.12s
                      Time elapsed: 00:30:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1634/1 [0m                       

                       Computation: 831621 steps/s (collection: 0.035s, learning 0.083s)
                       Mean reward: 396.41
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.9829
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4225
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 160628736
                    Iteration time: 0.12s
                      Time elapsed: 00:30:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1635/1 [0m                       

                       Computation: 903930 steps/s (collection: 0.035s, learning 0.073s)
                       Mean reward: 403.73
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6425
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4270
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 160727040
                    Iteration time: 0.11s
                      Time elapsed: 00:30:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1636/1 [0m                       

                       Computation: 946451 steps/s (collection: 0.035s, learning 0.069s)
                       Mean reward: 400.24
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.0343
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4234
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 23.5000
--------------------------------------------------------------------------------
                   Total timesteps: 160825344
                    Iteration time: 0.10s
                      Time elapsed: 00:30:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1637/1 [0m                       

                       Computation: 905651 steps/s (collection: 0.033s, learning 0.075s)
                       Mean reward: 401.42
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.0190
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4238
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 160923648
                    Iteration time: 0.11s
                      Time elapsed: 00:30:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1638/1 [0m                       

                       Computation: 865599 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 394.76
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 78.2920
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4204
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 161021952
                    Iteration time: 0.11s
                      Time elapsed: 00:30:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1639/1 [0m                       

                       Computation: 899526 steps/s (collection: 0.036s, learning 0.074s)
                       Mean reward: 399.02
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5610
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4236
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 161120256
                    Iteration time: 0.11s
                      Time elapsed: 00:30:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1640/1 [0m                       

                       Computation: 865326 steps/s (collection: 0.041s, learning 0.073s)
                       Mean reward: 398.23
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2634
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4240
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 161218560
                    Iteration time: 0.11s
                      Time elapsed: 00:30:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1641/1 [0m                       

                       Computation: 803177 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 398.95
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.2862
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4239
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 161316864
                    Iteration time: 0.12s
                      Time elapsed: 00:30:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1642/1 [0m                       

                       Computation: 858054 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 399.18
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4520
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4259
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 161415168
                    Iteration time: 0.11s
                      Time elapsed: 00:30:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1643/1 [0m                       

                       Computation: 743601 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 399.61
               Mean episode length: 247.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4607
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4217
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 161513472
                    Iteration time: 0.13s
                      Time elapsed: 00:30:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1644/1 [0m                       

                       Computation: 847934 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 400.79
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.8673
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4228
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 161611776
                    Iteration time: 0.12s
                      Time elapsed: 00:30:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1645/1 [0m                       

                       Computation: 958943 steps/s (collection: 0.036s, learning 0.067s)
                       Mean reward: 396.90
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4731
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4239
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 161710080
                    Iteration time: 0.10s
                      Time elapsed: 00:30:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1646/1 [0m                       

                       Computation: 922760 steps/s (collection: 0.036s, learning 0.071s)
                       Mean reward: 405.53
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2468
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4253
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 24.7500
--------------------------------------------------------------------------------
                   Total timesteps: 161808384
                    Iteration time: 0.11s
                      Time elapsed: 00:30:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1647/1 [0m                       

                       Computation: 866031 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 402.48
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5781
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4277
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 161906688
                    Iteration time: 0.11s
                      Time elapsed: 00:30:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1648/1 [0m                       

                       Computation: 799059 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 402.29
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.3288
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4288
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 162004992
                    Iteration time: 0.12s
                      Time elapsed: 00:30:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1649/1 [0m                       

                       Computation: 873706 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 405.91
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.9485
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4282
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 162103296
                    Iteration time: 0.11s
                      Time elapsed: 00:30:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1650/1 [0m                       

                       Computation: 847192 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 400.97
               Mean episode length: 247.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.9601
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4241
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 162201600
                    Iteration time: 0.12s
                      Time elapsed: 00:30:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1651/1 [0m                       

                       Computation: 767905 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 401.51
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7824
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4247
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 162299904
                    Iteration time: 0.13s
                      Time elapsed: 00:30:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1652/1 [0m                       

                       Computation: 792613 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 402.04
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2634
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4265
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 162398208
                    Iteration time: 0.12s
                      Time elapsed: 00:30:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1653/1 [0m                       

                       Computation: 851029 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 412.21
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.0139
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4332
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 162496512
                    Iteration time: 0.12s
                      Time elapsed: 00:30:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1654/1 [0m                       

                       Computation: 771377 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 403.62
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2507
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4286
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 162594816
                    Iteration time: 0.13s
                      Time elapsed: 00:30:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1655/1 [0m                       

                       Computation: 917052 steps/s (collection: 0.036s, learning 0.071s)
                       Mean reward: 408.42
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2259
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 162693120
                    Iteration time: 0.11s
                      Time elapsed: 00:30:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1656/1 [0m                       

                       Computation: 827564 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 404.15
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4836
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 162791424
                    Iteration time: 0.12s
                      Time elapsed: 00:30:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1657/1 [0m                       

                       Computation: 943987 steps/s (collection: 0.035s, learning 0.069s)
                       Mean reward: 402.70
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.7954
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4298
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 22.9167
--------------------------------------------------------------------------------
                   Total timesteps: 162889728
                    Iteration time: 0.10s
                      Time elapsed: 00:30:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1658/1 [0m                       

                       Computation: 929646 steps/s (collection: 0.035s, learning 0.071s)
                       Mean reward: 403.23
               Mean episode length: 246.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4781
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4263
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 162988032
                    Iteration time: 0.11s
                      Time elapsed: 00:30:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1659/1 [0m                       

                       Computation: 833915 steps/s (collection: 0.044s, learning 0.074s)
                       Mean reward: 408.54
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2593
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4306
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 163086336
                    Iteration time: 0.12s
                      Time elapsed: 00:30:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1660/1 [0m                       

                       Computation: 750134 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 402.14
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1936
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4303
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 163184640
                    Iteration time: 0.13s
                      Time elapsed: 00:30:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1661/1 [0m                       

                       Computation: 885510 steps/s (collection: 0.036s, learning 0.076s)
                       Mean reward: 406.46
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1991
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 163282944
                    Iteration time: 0.11s
                      Time elapsed: 00:30:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1662/1 [0m                       

                       Computation: 812805 steps/s (collection: 0.034s, learning 0.087s)
                       Mean reward: 404.72
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.3977
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4321
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 163381248
                    Iteration time: 0.12s
                      Time elapsed: 00:30:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1663/1 [0m                       

                       Computation: 921030 steps/s (collection: 0.037s, learning 0.069s)
                       Mean reward: 407.80
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.0350
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 163479552
                    Iteration time: 0.11s
                      Time elapsed: 00:30:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1664/1 [0m                       

                       Computation: 770891 steps/s (collection: 0.035s, learning 0.093s)
                       Mean reward: 399.32
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.4893
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4279
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 163577856
                    Iteration time: 0.13s
                      Time elapsed: 00:30:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1665/1 [0m                       

                       Computation: 912225 steps/s (collection: 0.041s, learning 0.067s)
                       Mean reward: 403.54
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1326
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4293
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 163676160
                    Iteration time: 0.11s
                      Time elapsed: 00:30:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1666/1 [0m                       

                       Computation: 880005 steps/s (collection: 0.036s, learning 0.076s)
                       Mean reward: 411.07
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.8530
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 163774464
                    Iteration time: 0.11s
                      Time elapsed: 00:30:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1667/1 [0m                       

                       Computation: 886253 steps/s (collection: 0.035s, learning 0.076s)
                       Mean reward: 404.04
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.9872
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 23.8333
--------------------------------------------------------------------------------
                   Total timesteps: 163872768
                    Iteration time: 0.11s
                      Time elapsed: 00:30:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1668/1 [0m                       

                       Computation: 761837 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 409.66
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2160
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4318
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 163971072
                    Iteration time: 0.13s
                      Time elapsed: 00:30:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1669/1 [0m                       

                       Computation: 843801 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 411.57
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9304
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 164069376
                    Iteration time: 0.12s
                      Time elapsed: 00:30:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1670/1 [0m                       

                       Computation: 861756 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 407.51
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7020
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 164167680
                    Iteration time: 0.11s
                      Time elapsed: 00:30:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1671/1 [0m                       

                       Computation: 886445 steps/s (collection: 0.036s, learning 0.075s)
                       Mean reward: 413.41
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.0330
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 164265984
                    Iteration time: 0.11s
                      Time elapsed: 00:30:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1672/1 [0m                       

                       Computation: 914386 steps/s (collection: 0.038s, learning 0.070s)
                       Mean reward: 409.22
               Mean episode length: 247.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.6475
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 164364288
                    Iteration time: 0.11s
                      Time elapsed: 00:31:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1673/1 [0m                       

                       Computation: 677789 steps/s (collection: 0.036s, learning 0.109s)
                       Mean reward: 404.03
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.2115
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 164462592
                    Iteration time: 0.15s
                      Time elapsed: 00:31:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1674/1 [0m                       

                       Computation: 719741 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 405.15
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6341
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 164560896
                    Iteration time: 0.14s
                      Time elapsed: 00:31:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1675/1 [0m                       

                       Computation: 885069 steps/s (collection: 0.034s, learning 0.077s)
                       Mean reward: 408.54
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.4972
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 164659200
                    Iteration time: 0.11s
                      Time elapsed: 00:31:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1676/1 [0m                       

                       Computation: 911406 steps/s (collection: 0.036s, learning 0.072s)
                       Mean reward: 410.89
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7493
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 164757504
                    Iteration time: 0.11s
                      Time elapsed: 00:31:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1677/1 [0m                       

                       Computation: 911876 steps/s (collection: 0.036s, learning 0.072s)
                       Mean reward: 401.04
               Mean episode length: 247.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 79.5055
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 164855808
                    Iteration time: 0.11s
                      Time elapsed: 00:31:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1678/1 [0m                       

                       Computation: 921506 steps/s (collection: 0.035s, learning 0.072s)
                       Mean reward: 406.19
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1548
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 21.2083
--------------------------------------------------------------------------------
                   Total timesteps: 164954112
                    Iteration time: 0.11s
                      Time elapsed: 00:31:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1679/1 [0m                       

                       Computation: 761157 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 409.60
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7116
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 165052416
                    Iteration time: 0.13s
                      Time elapsed: 00:31:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1680/1 [0m                       

                       Computation: 878486 steps/s (collection: 0.036s, learning 0.076s)
                       Mean reward: 412.65
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.0850
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 165150720
                    Iteration time: 0.11s
                      Time elapsed: 00:31:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1681/1 [0m                       

                       Computation: 773872 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 414.52
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4559
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 165249024
                    Iteration time: 0.13s
                      Time elapsed: 00:31:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1682/1 [0m                       

                       Computation: 812911 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 412.68
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.0354
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 165347328
                    Iteration time: 0.12s
                      Time elapsed: 00:31:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1683/1 [0m                       

                       Computation: 665325 steps/s (collection: 0.036s, learning 0.112s)
                       Mean reward: 406.89
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.9820
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4347
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 165445632
                    Iteration time: 0.15s
                      Time elapsed: 00:31:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1684/1 [0m                       

                       Computation: 823209 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 408.75
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2506
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 165543936
                    Iteration time: 0.12s
                      Time elapsed: 00:31:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1685/1 [0m                       

                       Computation: 778952 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 409.13
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.9841
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 165642240
                    Iteration time: 0.13s
                      Time elapsed: 00:31:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1686/1 [0m                       

                       Computation: 803343 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 411.77
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7163
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 165740544
                    Iteration time: 0.12s
                      Time elapsed: 00:31:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1687/1 [0m                       

                       Computation: 747850 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 408.89
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1021
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 165838848
                    Iteration time: 0.13s
                      Time elapsed: 00:31:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1688/1 [0m                       

                       Computation: 714717 steps/s (collection: 0.036s, learning 0.102s)
                       Mean reward: 409.27
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.2821
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4329
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 22.6667
--------------------------------------------------------------------------------
                   Total timesteps: 165937152
                    Iteration time: 0.14s
                      Time elapsed: 00:31:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1689/1 [0m                       

                       Computation: 799548 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 411.61
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9521
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 166035456
                    Iteration time: 0.12s
                      Time elapsed: 00:31:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1690/1 [0m                       

                       Computation: 818095 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 408.79
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.0444
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 166133760
                    Iteration time: 0.12s
                      Time elapsed: 00:31:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1691/1 [0m                       

                       Computation: 706682 steps/s (collection: 0.048s, learning 0.091s)
                       Mean reward: 412.08
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1753
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 166232064
                    Iteration time: 0.14s
                      Time elapsed: 00:31:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1692/1 [0m                       

                       Computation: 817080 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 413.65
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.2168
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 166330368
                    Iteration time: 0.12s
                      Time elapsed: 00:31:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1693/1 [0m                       

                       Computation: 775916 steps/s (collection: 0.047s, learning 0.080s)
                       Mean reward: 412.21
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9818
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 166428672
                    Iteration time: 0.13s
                      Time elapsed: 00:31:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1694/1 [0m                       

                       Computation: 859726 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 414.10
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3339
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 166526976
                    Iteration time: 0.11s
                      Time elapsed: 00:31:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1695/1 [0m                       

                       Computation: 770407 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 412.90
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1131
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 166625280
                    Iteration time: 0.13s
                      Time elapsed: 00:31:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1696/1 [0m                       

                       Computation: 737570 steps/s (collection: 0.035s, learning 0.098s)
                       Mean reward: 406.48
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.8576
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 166723584
                    Iteration time: 0.13s
                      Time elapsed: 00:31:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1697/1 [0m                       

                       Computation: 645673 steps/s (collection: 0.039s, learning 0.113s)
                       Mean reward: 412.65
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9459
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 166821888
                    Iteration time: 0.15s
                      Time elapsed: 00:31:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1698/1 [0m                       

                       Computation: 792166 steps/s (collection: 0.047s, learning 0.078s)
                       Mean reward: 410.51
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.6523
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 24.6250
--------------------------------------------------------------------------------
                   Total timesteps: 166920192
                    Iteration time: 0.12s
                      Time elapsed: 00:31:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1699/1 [0m                       

                       Computation: 905721 steps/s (collection: 0.037s, learning 0.072s)
                       Mean reward: 412.20
               Mean episode length: 246.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5831
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4347
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 167018496
                    Iteration time: 0.11s
                      Time elapsed: 00:31:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1700/1 [0m                       

                       Computation: 893917 steps/s (collection: 0.037s, learning 0.073s)
                       Mean reward: 418.73
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4417
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 167116800
                    Iteration time: 0.11s
                      Time elapsed: 00:31:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1701/1 [0m                       

                       Computation: 901761 steps/s (collection: 0.037s, learning 0.073s)
                       Mean reward: 414.57
               Mean episode length: 247.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3073
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 167215104
                    Iteration time: 0.11s
                      Time elapsed: 00:31:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1702/1 [0m                       

                       Computation: 737961 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 418.11
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0008
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 167313408
                    Iteration time: 0.13s
                      Time elapsed: 00:31:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1703/1 [0m                       

                       Computation: 887644 steps/s (collection: 0.035s, learning 0.075s)
                       Mean reward: 414.77
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4496
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 167411712
                    Iteration time: 0.11s
                      Time elapsed: 00:31:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1704/1 [0m                       

                       Computation: 809143 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 413.26
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1936
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 167510016
                    Iteration time: 0.12s
                      Time elapsed: 00:31:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1705/1 [0m                       

                       Computation: 728548 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 408.15
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.3527
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 167608320
                    Iteration time: 0.13s
                      Time elapsed: 00:31:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1706/1 [0m                       

                       Computation: 657431 steps/s (collection: 0.055s, learning 0.095s)
                       Mean reward: 412.90
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1324
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 167706624
                    Iteration time: 0.15s
                      Time elapsed: 00:31:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1707/1 [0m                       

                       Computation: 768586 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 411.54
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7655
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4425
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 167804928
                    Iteration time: 0.13s
                      Time elapsed: 00:31:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1708/1 [0m                       

                       Computation: 779838 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 409.90
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5467
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 167903232
                    Iteration time: 0.13s
                      Time elapsed: 00:31:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1709/1 [0m                       

                       Computation: 731588 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 413.16
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5114
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4426
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 23.0417
--------------------------------------------------------------------------------
                   Total timesteps: 168001536
                    Iteration time: 0.13s
                      Time elapsed: 00:31:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1710/1 [0m                       

                       Computation: 873684 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 417.22
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3074
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 168099840
                    Iteration time: 0.11s
                      Time elapsed: 00:31:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1711/1 [0m                       

                       Computation: 883988 steps/s (collection: 0.038s, learning 0.074s)
                       Mean reward: 412.50
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.0548
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 168198144
                    Iteration time: 0.11s
                      Time elapsed: 00:31:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1712/1 [0m                       

                       Computation: 621997 steps/s (collection: 0.040s, learning 0.118s)
                       Mean reward: 418.65
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3229
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 168296448
                    Iteration time: 0.16s
                      Time elapsed: 00:31:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1713/1 [0m                       

                       Computation: 856612 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 418.09
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9610
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 168394752
                    Iteration time: 0.11s
                      Time elapsed: 00:31:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1714/1 [0m                       

                       Computation: 753150 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 410.72
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.6658
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 168493056
                    Iteration time: 0.13s
                      Time elapsed: 00:31:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1715/1 [0m                       

                       Computation: 890044 steps/s (collection: 0.037s, learning 0.074s)
                       Mean reward: 411.06
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7761
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 168591360
                    Iteration time: 0.11s
                      Time elapsed: 00:31:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1716/1 [0m                       

                       Computation: 901859 steps/s (collection: 0.036s, learning 0.073s)
                       Mean reward: 415.31
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5941
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 168689664
                    Iteration time: 0.11s
                      Time elapsed: 00:31:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1717/1 [0m                       

                       Computation: 691860 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 411.62
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7704
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.6250
--------------------------------------------------------------------------------
                   Total timesteps: 168787968
                    Iteration time: 0.14s
                      Time elapsed: 00:31:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1718/1 [0m                       

                       Computation: 797937 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 411.91
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.0644
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4390
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 168886272
                    Iteration time: 0.12s
                      Time elapsed: 00:31:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1719/1 [0m                       

                       Computation: 788978 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 412.44
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7321
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 24.2917
--------------------------------------------------------------------------------
                   Total timesteps: 168984576
                    Iteration time: 0.12s
                      Time elapsed: 00:31:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1720/1 [0m                       

                       Computation: 797363 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 408.68
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5041
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 169082880
                    Iteration time: 0.12s
                      Time elapsed: 00:31:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1721/1 [0m                       

                       Computation: 819480 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 405.80
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.0692
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 169181184
                    Iteration time: 0.12s
                      Time elapsed: 00:31:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1722/1 [0m                       

                       Computation: 674389 steps/s (collection: 0.036s, learning 0.109s)
                       Mean reward: 413.70
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3482
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 169279488
                    Iteration time: 0.15s
                      Time elapsed: 00:31:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1723/1 [0m                       

                       Computation: 834158 steps/s (collection: 0.043s, learning 0.075s)
                       Mean reward: 418.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2449
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4441
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 169377792
                    Iteration time: 0.12s
                      Time elapsed: 00:31:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1724/1 [0m                       

                       Computation: 869476 steps/s (collection: 0.042s, learning 0.072s)
                       Mean reward: 418.95
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3369
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 169476096
                    Iteration time: 0.11s
                      Time elapsed: 00:31:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1725/1 [0m                       

                       Computation: 779020 steps/s (collection: 0.045s, learning 0.082s)
                       Mean reward: 414.88
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7534
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4420
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 169574400
                    Iteration time: 0.13s
                      Time elapsed: 00:31:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1726/1 [0m                       

                       Computation: 629314 steps/s (collection: 0.044s, learning 0.112s)
                       Mean reward: 414.30
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4121
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 169672704
                    Iteration time: 0.16s
                      Time elapsed: 00:31:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1727/1 [0m                       

                       Computation: 849556 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 414.64
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.6211
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 169771008
                    Iteration time: 0.12s
                      Time elapsed: 00:31:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1728/1 [0m                       

                       Computation: 706794 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 408.95
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.3679
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 169869312
                    Iteration time: 0.14s
                      Time elapsed: 00:31:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1729/1 [0m                       

                       Computation: 799323 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 408.71
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.8568
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 169967616
                    Iteration time: 0.12s
                      Time elapsed: 00:31:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1730/1 [0m                       

                       Computation: 679502 steps/s (collection: 0.045s, learning 0.100s)
                       Mean reward: 413.39
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4275
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 21.4167
--------------------------------------------------------------------------------
                   Total timesteps: 170065920
                    Iteration time: 0.14s
                      Time elapsed: 00:32:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1731/1 [0m                       

                       Computation: 746401 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 415.04
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5652
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 170164224
                    Iteration time: 0.13s
                      Time elapsed: 00:32:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1732/1 [0m                       

                       Computation: 732384 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 414.48
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3702
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 170262528
                    Iteration time: 0.13s
                      Time elapsed: 00:32:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1733/1 [0m                       

                       Computation: 714283 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 406.23
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.4557
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 170360832
                    Iteration time: 0.14s
                      Time elapsed: 00:32:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1734/1 [0m                       

                       Computation: 660480 steps/s (collection: 0.039s, learning 0.110s)
                       Mean reward: 415.08
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7113
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 170459136
                    Iteration time: 0.15s
                      Time elapsed: 00:32:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1735/1 [0m                       

                       Computation: 781924 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 411.62
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.8252
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 170557440
                    Iteration time: 0.13s
                      Time elapsed: 00:32:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1736/1 [0m                       

                       Computation: 766252 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 417.81
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1222
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4414
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 170655744
                    Iteration time: 0.13s
                      Time elapsed: 00:32:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1737/1 [0m                       

                       Computation: 826750 steps/s (collection: 0.042s, learning 0.077s)
                       Mean reward: 419.46
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4908
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 170754048
                    Iteration time: 0.12s
                      Time elapsed: 00:32:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1738/1 [0m                       

                       Computation: 667353 steps/s (collection: 0.039s, learning 0.109s)
                       Mean reward: 409.92
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5847
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4402
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 170852352
                    Iteration time: 0.15s
                      Time elapsed: 00:32:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1739/1 [0m                       

                       Computation: 728768 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 412.64
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9115
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 170950656
                    Iteration time: 0.13s
                      Time elapsed: 00:32:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1740/1 [0m                       

                       Computation: 646610 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 420.79
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9693
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4413
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 23.1250
--------------------------------------------------------------------------------
                   Total timesteps: 171048960
                    Iteration time: 0.15s
                      Time elapsed: 00:32:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1741/1 [0m                       

                       Computation: 631621 steps/s (collection: 0.039s, learning 0.117s)
                       Mean reward: 419.94
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2959
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4432
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 171147264
                    Iteration time: 0.16s
                      Time elapsed: 00:32:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1742/1 [0m                       

                       Computation: 696948 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 410.29
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9239
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4401
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 171245568
                    Iteration time: 0.14s
                      Time elapsed: 00:32:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1743/1 [0m                       

                       Computation: 622112 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 411.82
               Mean episode length: 247.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 82.1716
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 171343872
                    Iteration time: 0.16s
                      Time elapsed: 00:32:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1744/1 [0m                       

                       Computation: 692184 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 421.97
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.0560
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4449
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 171442176
                    Iteration time: 0.14s
                      Time elapsed: 00:32:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1745/1 [0m                       

                       Computation: 569762 steps/s (collection: 0.046s, learning 0.127s)
                       Mean reward: 419.53
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4883
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 171540480
                    Iteration time: 0.17s
                      Time elapsed: 00:32:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1746/1 [0m                       

                       Computation: 685209 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 420.78
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8861
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 171638784
                    Iteration time: 0.14s
                      Time elapsed: 00:32:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1747/1 [0m                       

                       Computation: 775708 steps/s (collection: 0.046s, learning 0.081s)
                       Mean reward: 414.51
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4737
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4420
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 171737088
                    Iteration time: 0.13s
                      Time elapsed: 00:32:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1748/1 [0m                       

                       Computation: 791867 steps/s (collection: 0.046s, learning 0.079s)
                       Mean reward: 414.10
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4898
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 171835392
                    Iteration time: 0.12s
                      Time elapsed: 00:32:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1749/1 [0m                       

                       Computation: 789387 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 414.30
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.2665
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 171933696
                    Iteration time: 0.12s
                      Time elapsed: 00:32:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1750/1 [0m                       

                       Computation: 474802 steps/s (collection: 0.056s, learning 0.151s)
                       Mean reward: 413.00
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.2312
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 23.7500
--------------------------------------------------------------------------------
                   Total timesteps: 172032000
                    Iteration time: 0.21s
                      Time elapsed: 00:32:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1751/1 [0m                       

                       Computation: 712865 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 416.95
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3228
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 172130304
                    Iteration time: 0.14s
                      Time elapsed: 00:32:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1752/1 [0m                       

                       Computation: 519785 steps/s (collection: 0.047s, learning 0.143s)
                       Mean reward: 414.69
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4395
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 172228608
                    Iteration time: 0.19s
                      Time elapsed: 00:32:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1753/1 [0m                       

                       Computation: 752295 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 412.70
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1439
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 172326912
                    Iteration time: 0.13s
                      Time elapsed: 00:32:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1754/1 [0m                       

                       Computation: 588101 steps/s (collection: 0.044s, learning 0.123s)
                       Mean reward: 419.94
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4146
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4431
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 172425216
                    Iteration time: 0.17s
                      Time elapsed: 00:32:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1755/1 [0m                       

                       Computation: 665150 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 405.73
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6828
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 172523520
                    Iteration time: 0.15s
                      Time elapsed: 00:32:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1756/1 [0m                       

                       Computation: 736295 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 414.75
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5008
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 172621824
                    Iteration time: 0.13s
                      Time elapsed: 00:32:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1757/1 [0m                       

                       Computation: 531223 steps/s (collection: 0.043s, learning 0.142s)
                       Mean reward: 414.52
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3674
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 172720128
                    Iteration time: 0.19s
                      Time elapsed: 00:32:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1758/1 [0m                       

                       Computation: 785507 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 417.17
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9733
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4402
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 172818432
                    Iteration time: 0.13s
                      Time elapsed: 00:32:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1759/1 [0m                       

                       Computation: 569047 steps/s (collection: 0.041s, learning 0.132s)
                       Mean reward: 418.07
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2738
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4415
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 172916736
                    Iteration time: 0.17s
                      Time elapsed: 00:32:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1760/1 [0m                       

                       Computation: 785974 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 406.67
               Mean episode length: 245.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 80.4072
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 173015040
                    Iteration time: 0.13s
                      Time elapsed: 00:32:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1761/1 [0m                       

                       Computation: 749502 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 415.82
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8513
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4436
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 22.8333
--------------------------------------------------------------------------------
                   Total timesteps: 173113344
                    Iteration time: 0.13s
                      Time elapsed: 00:32:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1762/1 [0m                       

                       Computation: 674560 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 405.47
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.3508
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 173211648
                    Iteration time: 0.15s
                      Time elapsed: 00:32:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1763/1 [0m                       

                       Computation: 721849 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 411.42
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5445
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 173309952
                    Iteration time: 0.14s
                      Time elapsed: 00:32:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1764/1 [0m                       

                       Computation: 715199 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 406.36
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1150
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 173408256
                    Iteration time: 0.14s
                      Time elapsed: 00:32:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1765/1 [0m                       

                       Computation: 734899 steps/s (collection: 0.049s, learning 0.085s)
                       Mean reward: 408.21
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1011
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4374
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 173506560
                    Iteration time: 0.13s
                      Time elapsed: 00:32:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1766/1 [0m                       

                       Computation: 822240 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 409.43
               Mean episode length: 246.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.4278
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4388
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 173604864
                    Iteration time: 0.12s
                      Time elapsed: 00:32:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1767/1 [0m                       

                       Computation: 726166 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 420.12
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.5095
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4418
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 173703168
                    Iteration time: 0.14s
                      Time elapsed: 00:32:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1768/1 [0m                       

                       Computation: 645413 steps/s (collection: 0.048s, learning 0.105s)
                       Mean reward: 414.24
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5834
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 173801472
                    Iteration time: 0.15s
                      Time elapsed: 00:32:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1769/1 [0m                       

                       Computation: 716908 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 410.23
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5475
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 173899776
                    Iteration time: 0.14s
                      Time elapsed: 00:32:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1770/1 [0m                       

                       Computation: 623683 steps/s (collection: 0.041s, learning 0.117s)
                       Mean reward: 406.14
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6128
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 173998080
                    Iteration time: 0.16s
                      Time elapsed: 00:32:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1771/1 [0m                       

                       Computation: 658804 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 412.85
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9560
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 23.7500
--------------------------------------------------------------------------------
                   Total timesteps: 174096384
                    Iteration time: 0.15s
                      Time elapsed: 00:32:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1772/1 [0m                       

                       Computation: 681504 steps/s (collection: 0.042s, learning 0.102s)
                       Mean reward: 405.41
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.6419
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 174194688
                    Iteration time: 0.14s
                      Time elapsed: 00:32:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1773/1 [0m                       

                       Computation: 596201 steps/s (collection: 0.041s, learning 0.124s)
                       Mean reward: 414.30
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9566
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 174292992
                    Iteration time: 0.16s
                      Time elapsed: 00:32:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1774/1 [0m                       

                       Computation: 636574 steps/s (collection: 0.049s, learning 0.105s)
                       Mean reward: 404.00
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.1946
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 174391296
                    Iteration time: 0.15s
                      Time elapsed: 00:32:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1775/1 [0m                       

                       Computation: 799793 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 411.48
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.6023
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 174489600
                    Iteration time: 0.12s
                      Time elapsed: 00:32:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1776/1 [0m                       

                       Computation: 579506 steps/s (collection: 0.046s, learning 0.124s)
                       Mean reward: 415.21
               Mean episode length: 247.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7404
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 174587904
                    Iteration time: 0.17s
                      Time elapsed: 00:32:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1777/1 [0m                       

                       Computation: 550763 steps/s (collection: 0.049s, learning 0.130s)
                       Mean reward: 417.62
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9740
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4448
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 174686208
                    Iteration time: 0.18s
                      Time elapsed: 00:32:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1778/1 [0m                       

                       Computation: 732324 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 414.26
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1256
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 174784512
                    Iteration time: 0.13s
                      Time elapsed: 00:32:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1779/1 [0m                       

                       Computation: 785245 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 413.44
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1411
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4444
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 174882816
                    Iteration time: 0.13s
                      Time elapsed: 00:32:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1780/1 [0m                       

                       Computation: 670380 steps/s (collection: 0.052s, learning 0.095s)
                       Mean reward: 415.50
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7698
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 174981120
                    Iteration time: 0.15s
                      Time elapsed: 00:32:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1781/1 [0m                       

                       Computation: 608600 steps/s (collection: 0.039s, learning 0.122s)
                       Mean reward: 411.23
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1464
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 175079424
                    Iteration time: 0.16s
                      Time elapsed: 00:32:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1782/1 [0m                       

                       Computation: 797387 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 408.63
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.4433
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 21.9167
--------------------------------------------------------------------------------
                   Total timesteps: 175177728
                    Iteration time: 0.12s
                      Time elapsed: 00:32:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1783/1 [0m                       

                       Computation: 529327 steps/s (collection: 0.040s, learning 0.146s)
                       Mean reward: 416.90
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0537
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 175276032
                    Iteration time: 0.19s
                      Time elapsed: 00:33:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1784/1 [0m                       

                       Computation: 792053 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 405.71
               Mean episode length: 247.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.7872
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 175374336
                    Iteration time: 0.12s
                      Time elapsed: 00:33:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1785/1 [0m                       

                       Computation: 683970 steps/s (collection: 0.047s, learning 0.097s)
                       Mean reward: 413.83
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3487
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4406
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 175472640
                    Iteration time: 0.14s
                      Time elapsed: 00:33:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1786/1 [0m                       

                       Computation: 658288 steps/s (collection: 0.048s, learning 0.101s)
                       Mean reward: 416.04
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8367
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 175570944
                    Iteration time: 0.15s
                      Time elapsed: 00:33:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1787/1 [0m                       

                       Computation: 549889 steps/s (collection: 0.044s, learning 0.135s)
                       Mean reward: 412.17
               Mean episode length: 247.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.0931
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 175669248
                    Iteration time: 0.18s
                      Time elapsed: 00:33:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1788/1 [0m                       

                       Computation: 689706 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 414.66
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5217
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 175767552
                    Iteration time: 0.14s
                      Time elapsed: 00:33:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1789/1 [0m                       

                       Computation: 819873 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 412.07
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.0469
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4394
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 175865856
                    Iteration time: 0.12s
                      Time elapsed: 00:33:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1790/1 [0m                       

                       Computation: 661121 steps/s (collection: 0.043s, learning 0.106s)
                       Mean reward: 409.68
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.4457
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 175964160
                    Iteration time: 0.15s
                      Time elapsed: 00:33:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1791/1 [0m                       

                       Computation: 768700 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 406.22
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.8441
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 176062464
                    Iteration time: 0.13s
                      Time elapsed: 00:33:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1792/1 [0m                       

                       Computation: 477994 steps/s (collection: 0.045s, learning 0.161s)
                       Mean reward: 411.26
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9581
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 23.3333
--------------------------------------------------------------------------------
                   Total timesteps: 176160768
                    Iteration time: 0.21s
                      Time elapsed: 00:33:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1793/1 [0m                       

                       Computation: 562342 steps/s (collection: 0.054s, learning 0.121s)
                       Mean reward: 409.71
               Mean episode length: 246.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 81.1370
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 176259072
                    Iteration time: 0.17s
                      Time elapsed: 00:33:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1794/1 [0m                       

                       Computation: 686955 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 402.29
               Mean episode length: 246.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 79.6588
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4290
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 176357376
                    Iteration time: 0.14s
                      Time elapsed: 00:33:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1795/1 [0m                       

                       Computation: 570600 steps/s (collection: 0.040s, learning 0.132s)
                       Mean reward: 411.83
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7101
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 176455680
                    Iteration time: 0.17s
                      Time elapsed: 00:33:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1796/1 [0m                       

                       Computation: 614330 steps/s (collection: 0.042s, learning 0.119s)
                       Mean reward: 414.60
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5296
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4437
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 176553984
                    Iteration time: 0.16s
                      Time elapsed: 00:33:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1797/1 [0m                       

                       Computation: 614239 steps/s (collection: 0.042s, learning 0.118s)
                       Mean reward: 412.28
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.2822
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 176652288
                    Iteration time: 0.16s
                      Time elapsed: 00:33:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1798/1 [0m                       

                       Computation: 516808 steps/s (collection: 0.050s, learning 0.140s)
                       Mean reward: 415.07
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7983
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 176750592
                    Iteration time: 0.19s
                      Time elapsed: 00:33:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1799/1 [0m                       

                       Computation: 571398 steps/s (collection: 0.048s, learning 0.124s)
                       Mean reward: 417.74
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1055
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 176848896
                    Iteration time: 0.17s
                      Time elapsed: 00:33:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1800/1 [0m                       

                       Computation: 640130 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 410.35
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.6610
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 176947200
                    Iteration time: 0.15s
                      Time elapsed: 00:33:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1801/1 [0m                       

                       Computation: 644640 steps/s (collection: 0.040s, learning 0.112s)
                       Mean reward: 409.40
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.4602
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 177045504
                    Iteration time: 0.15s
                      Time elapsed: 00:33:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1802/1 [0m                       

                       Computation: 799145 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 408.44
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.5059
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 177143808
                    Iteration time: 0.12s
                      Time elapsed: 00:33:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1803/1 [0m                       

                       Computation: 805340 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 408.34
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.4819
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 20.7500
--------------------------------------------------------------------------------
                   Total timesteps: 177242112
                    Iteration time: 0.12s
                      Time elapsed: 00:33:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1804/1 [0m                       

                       Computation: 619991 steps/s (collection: 0.040s, learning 0.119s)
                       Mean reward: 415.31
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7950
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4438
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 177340416
                    Iteration time: 0.16s
                      Time elapsed: 00:33:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1805/1 [0m                       

                       Computation: 613083 steps/s (collection: 0.041s, learning 0.119s)
                       Mean reward: 416.17
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8267
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4428
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 177438720
                    Iteration time: 0.16s
                      Time elapsed: 00:33:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1806/1 [0m                       

                       Computation: 622998 steps/s (collection: 0.040s, learning 0.118s)
                       Mean reward: 410.54
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5518
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4396
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 177537024
                    Iteration time: 0.16s
                      Time elapsed: 00:33:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1807/1 [0m                       

                       Computation: 755709 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 407.88
               Mean episode length: 247.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 80.9668
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 177635328
                    Iteration time: 0.13s
                      Time elapsed: 00:33:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1808/1 [0m                       

                       Computation: 755619 steps/s (collection: 0.048s, learning 0.082s)
                       Mean reward: 414.00
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.6709
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 177733632
                    Iteration time: 0.13s
                      Time elapsed: 00:33:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1809/1 [0m                       

                       Computation: 574930 steps/s (collection: 0.046s, learning 0.124s)
                       Mean reward: 418.22
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2381
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 177831936
                    Iteration time: 0.17s
                      Time elapsed: 00:33:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1810/1 [0m                       

                       Computation: 640947 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 410.67
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7881
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4367
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 177930240
                    Iteration time: 0.15s
                      Time elapsed: 00:33:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1811/1 [0m                       

                       Computation: 608657 steps/s (collection: 0.045s, learning 0.117s)
                       Mean reward: 414.50
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5559
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4411
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 178028544
                    Iteration time: 0.16s
                      Time elapsed: 00:33:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1812/1 [0m                       

                       Computation: 709909 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 410.60
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5338
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 178126848
                    Iteration time: 0.14s
                      Time elapsed: 00:33:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1813/1 [0m                       

                       Computation: 747222 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 414.34
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.4268
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 21.9583
--------------------------------------------------------------------------------
                   Total timesteps: 178225152
                    Iteration time: 0.13s
                      Time elapsed: 00:33:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1814/1 [0m                       

                       Computation: 749153 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 416.26
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0687
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 178323456
                    Iteration time: 0.13s
                      Time elapsed: 00:33:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1815/1 [0m                       

                       Computation: 663613 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 410.37
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.8186
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 178421760
                    Iteration time: 0.15s
                      Time elapsed: 00:33:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1816/1 [0m                       

                       Computation: 758009 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 413.37
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3614
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 178520064
                    Iteration time: 0.13s
                      Time elapsed: 00:33:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1817/1 [0m                       

                       Computation: 552402 steps/s (collection: 0.045s, learning 0.133s)
                       Mean reward: 421.65
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.9293
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 178618368
                    Iteration time: 0.18s
                      Time elapsed: 00:33:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1818/1 [0m                       

                       Computation: 538283 steps/s (collection: 0.043s, learning 0.140s)
                       Mean reward: 417.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0441
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 178716672
                    Iteration time: 0.18s
                      Time elapsed: 00:33:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1819/1 [0m                       

                       Computation: 707773 steps/s (collection: 0.050s, learning 0.089s)
                       Mean reward: 418.02
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1510
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 178814976
                    Iteration time: 0.14s
                      Time elapsed: 00:33:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1820/1 [0m                       

                       Computation: 624964 steps/s (collection: 0.040s, learning 0.117s)
                       Mean reward: 411.59
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7923
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4359
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 178913280
                    Iteration time: 0.16s
                      Time elapsed: 00:33:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1821/1 [0m                       

                       Computation: 663010 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 421.72
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.0086
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4422
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 179011584
                    Iteration time: 0.15s
                      Time elapsed: 00:33:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1822/1 [0m                       

                       Computation: 697846 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 419.06
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.5359
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4425
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 179109888
                    Iteration time: 0.14s
                      Time elapsed: 00:33:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1823/1 [0m                       

                       Computation: 672211 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 413.00
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1887
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 22.9167
--------------------------------------------------------------------------------
                   Total timesteps: 179208192
                    Iteration time: 0.15s
                      Time elapsed: 00:33:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1824/1 [0m                       

                       Computation: 586267 steps/s (collection: 0.052s, learning 0.116s)
                       Mean reward: 414.61
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.8698
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 179306496
                    Iteration time: 0.17s
                      Time elapsed: 00:33:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1825/1 [0m                       

                       Computation: 643614 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 414.76
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3880
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 179404800
                    Iteration time: 0.15s
                      Time elapsed: 00:33:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1826/1 [0m                       

                       Computation: 692030 steps/s (collection: 0.046s, learning 0.096s)
                       Mean reward: 415.25
               Mean episode length: 247.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 82.3069
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 179503104
                    Iteration time: 0.14s
                      Time elapsed: 00:33:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1827/1 [0m                       

                       Computation: 663472 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 408.67
               Mean episode length: 245.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 81.3233
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 179601408
                    Iteration time: 0.15s
                      Time elapsed: 00:33:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1828/1 [0m                       

                       Computation: 734104 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 418.24
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2994
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 179699712
                    Iteration time: 0.13s
                      Time elapsed: 00:33:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1829/1 [0m                       

                       Computation: 688785 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 410.62
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.3876
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 179798016
                    Iteration time: 0.14s
                      Time elapsed: 00:33:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1830/1 [0m                       

                       Computation: 713024 steps/s (collection: 0.050s, learning 0.088s)
                       Mean reward: 414.64
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.2830
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 179896320
                    Iteration time: 0.14s
                      Time elapsed: 00:33:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1831/1 [0m                       

                       Computation: 755282 steps/s (collection: 0.050s, learning 0.081s)
                       Mean reward: 418.99
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4221
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4410
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 179994624
                    Iteration time: 0.13s
                      Time elapsed: 00:33:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1832/1 [0m                       

                       Computation: 792709 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 414.92
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5879
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 180092928
                    Iteration time: 0.12s
                      Time elapsed: 00:33:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1833/1 [0m                       

                       Computation: 586749 steps/s (collection: 0.055s, learning 0.113s)
                       Mean reward: 412.85
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7765
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 180191232
                    Iteration time: 0.17s
                      Time elapsed: 00:33:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1834/1 [0m                       

                       Computation: 517793 steps/s (collection: 0.045s, learning 0.145s)
                       Mean reward: 416.74
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5442
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 21.7917
--------------------------------------------------------------------------------
                   Total timesteps: 180289536
                    Iteration time: 0.19s
                      Time elapsed: 00:34:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1835/1 [0m                       

                       Computation: 576421 steps/s (collection: 0.048s, learning 0.123s)
                       Mean reward: 415.89
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8316
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 180387840
                    Iteration time: 0.17s
                      Time elapsed: 00:34:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1836/1 [0m                       

                       Computation: 608206 steps/s (collection: 0.041s, learning 0.121s)
                       Mean reward: 412.59
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4074
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 180486144
                    Iteration time: 0.16s
                      Time elapsed: 00:34:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1837/1 [0m                       

                       Computation: 757610 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 417.31
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8146
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 180584448
                    Iteration time: 0.13s
                      Time elapsed: 00:34:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1838/1 [0m                       

                       Computation: 750077 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 411.66
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7797
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 180682752
                    Iteration time: 0.13s
                      Time elapsed: 00:34:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1839/1 [0m                       

                       Computation: 617065 steps/s (collection: 0.039s, learning 0.121s)
                       Mean reward: 422.00
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.0193
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4430
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 180781056
                    Iteration time: 0.16s
                      Time elapsed: 00:34:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1840/1 [0m                       

                       Computation: 670781 steps/s (collection: 0.037s, learning 0.110s)
                       Mean reward: 412.55
               Mean episode length: 246.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 82.0192
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4337
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 180879360
                    Iteration time: 0.15s
                      Time elapsed: 00:34:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1841/1 [0m                       

                       Computation: 604113 steps/s (collection: 0.042s, learning 0.121s)
                       Mean reward: 423.73
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.3232
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4419
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 180977664
                    Iteration time: 0.16s
                      Time elapsed: 00:34:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1842/1 [0m                       

                       Computation: 699996 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 418.72
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3986
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 181075968
                    Iteration time: 0.14s
                      Time elapsed: 00:34:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1843/1 [0m                       

                       Computation: 773824 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 420.10
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.6220
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 181174272
                    Iteration time: 0.13s
                      Time elapsed: 00:34:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1844/1 [0m                       

                       Computation: 805476 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 414.73
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9420
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 22.3333
--------------------------------------------------------------------------------
                   Total timesteps: 181272576
                    Iteration time: 0.12s
                      Time elapsed: 00:34:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1845/1 [0m                       

                       Computation: 763582 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 414.56
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5570
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 181370880
                    Iteration time: 0.13s
                      Time elapsed: 00:34:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1846/1 [0m                       

                       Computation: 694638 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 414.17
               Mean episode length: 247.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4445
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 181469184
                    Iteration time: 0.14s
                      Time elapsed: 00:34:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1847/1 [0m                       

                       Computation: 754734 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 417.10
               Mean episode length: 246.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8148
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 181567488
                    Iteration time: 0.13s
                      Time elapsed: 00:34:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1848/1 [0m                       

                       Computation: 644124 steps/s (collection: 0.066s, learning 0.087s)
                       Mean reward: 417.10
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8723
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 181665792
                    Iteration time: 0.15s
                      Time elapsed: 00:34:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1849/1 [0m                       

                       Computation: 782577 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 420.82
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4722
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 181764096
                    Iteration time: 0.13s
                      Time elapsed: 00:34:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1850/1 [0m                       

                       Computation: 701798 steps/s (collection: 0.046s, learning 0.094s)
                       Mean reward: 417.04
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8875
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4408
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 181862400
                    Iteration time: 0.14s
                      Time elapsed: 00:34:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1851/1 [0m                       

                       Computation: 783169 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 417.83
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0838
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4409
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 181960704
                    Iteration time: 0.13s
                      Time elapsed: 00:34:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1852/1 [0m                       

                       Computation: 787501 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 419.90
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4027
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4400
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 182059008
                    Iteration time: 0.12s
                      Time elapsed: 00:34:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1853/1 [0m                       

                       Computation: 715125 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 417.02
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9681
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 182157312
                    Iteration time: 0.14s
                      Time elapsed: 00:34:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1854/1 [0m                       

                       Computation: 558423 steps/s (collection: 0.040s, learning 0.136s)
                       Mean reward: 412.68
               Mean episode length: 246.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 81.5454
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 182255616
                    Iteration time: 0.18s
                      Time elapsed: 00:34:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1855/1 [0m                       

                       Computation: 808999 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 417.75
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.4092
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 20.1250
--------------------------------------------------------------------------------
                   Total timesteps: 182353920
                    Iteration time: 0.12s
                      Time elapsed: 00:34:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1856/1 [0m                       

                       Computation: 644379 steps/s (collection: 0.038s, learning 0.114s)
                       Mean reward: 419.35
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.5301
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4423
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 182452224
                    Iteration time: 0.15s
                      Time elapsed: 00:34:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1857/1 [0m                       

                       Computation: 724069 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 407.14
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.1531
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 182550528
                    Iteration time: 0.14s
                      Time elapsed: 00:34:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1858/1 [0m                       

                       Computation: 639232 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 418.48
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2561
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 182648832
                    Iteration time: 0.15s
                      Time elapsed: 00:34:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1859/1 [0m                       

                       Computation: 662518 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 423.89
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.1675
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 182747136
                    Iteration time: 0.15s
                      Time elapsed: 00:34:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1860/1 [0m                       

                       Computation: 773879 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 420.79
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8691
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 182845440
                    Iteration time: 0.13s
                      Time elapsed: 00:34:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1861/1 [0m                       

                       Computation: 765875 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 419.63
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4042
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 182943744
                    Iteration time: 0.13s
                      Time elapsed: 00:34:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1862/1 [0m                       

                       Computation: 841533 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 413.16
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.0123
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 183042048
                    Iteration time: 0.12s
                      Time elapsed: 00:34:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1863/1 [0m                       

                       Computation: 887703 steps/s (collection: 0.037s, learning 0.074s)
                       Mean reward: 418.96
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1959
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 183140352
                    Iteration time: 0.11s
                      Time elapsed: 00:34:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1864/1 [0m                       

                       Computation: 710024 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 418.18
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2837
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 183238656
                    Iteration time: 0.14s
                      Time elapsed: 00:34:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1865/1 [0m                       

                       Computation: 844406 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 419.62
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2338
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4369
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 21.6667
--------------------------------------------------------------------------------
                   Total timesteps: 183336960
                    Iteration time: 0.12s
                      Time elapsed: 00:34:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1866/1 [0m                       

                       Computation: 808334 steps/s (collection: 0.047s, learning 0.075s)
                       Mean reward: 416.39
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1564
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4399
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 183435264
                    Iteration time: 0.12s
                      Time elapsed: 00:34:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1867/1 [0m                       

                       Computation: 857464 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 410.22
               Mean episode length: 247.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.8551
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4353
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 183533568
                    Iteration time: 0.11s
                      Time elapsed: 00:34:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1868/1 [0m                       

                       Computation: 873726 steps/s (collection: 0.041s, learning 0.072s)
                       Mean reward: 412.56
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.2855
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 183631872
                    Iteration time: 0.11s
                      Time elapsed: 00:34:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1869/1 [0m                       

                       Computation: 911674 steps/s (collection: 0.036s, learning 0.072s)
                       Mean reward: 419.83
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4948
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 183730176
                    Iteration time: 0.11s
                      Time elapsed: 00:34:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1870/1 [0m                       

                       Computation: 709577 steps/s (collection: 0.049s, learning 0.090s)
                       Mean reward: 416.60
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7609
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 183828480
                    Iteration time: 0.14s
                      Time elapsed: 00:34:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1871/1 [0m                       

                       Computation: 497134 steps/s (collection: 0.045s, learning 0.153s)
                       Mean reward: 416.81
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0147
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4388
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 183926784
                    Iteration time: 0.20s
                      Time elapsed: 00:34:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1872/1 [0m                       

                       Computation: 720044 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 416.48
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9396
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 184025088
                    Iteration time: 0.14s
                      Time elapsed: 00:34:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1873/1 [0m                       

                       Computation: 882482 steps/s (collection: 0.036s, learning 0.075s)
                       Mean reward: 413.34
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3353
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 184123392
                    Iteration time: 0.11s
                      Time elapsed: 00:34:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1874/1 [0m                       

                       Computation: 866381 steps/s (collection: 0.036s, learning 0.077s)
                       Mean reward: 415.59
               Mean episode length: 247.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7547
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 184221696
                    Iteration time: 0.11s
                      Time elapsed: 00:34:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1875/1 [0m                       

                       Computation: 785639 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 417.65
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8676
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 22.4167
--------------------------------------------------------------------------------
                   Total timesteps: 184320000
                    Iteration time: 0.13s
                      Time elapsed: 00:34:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1876/1 [0m                       

                       Computation: 849334 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 411.54
               Mean episode length: 246.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 81.9307
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 184418304
                    Iteration time: 0.12s
                      Time elapsed: 00:34:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1877/1 [0m                       

                       Computation: 879018 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 412.29
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.7101
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 184516608
                    Iteration time: 0.11s
                      Time elapsed: 00:34:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1878/1 [0m                       

                       Computation: 792627 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 414.19
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5126
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 184614912
                    Iteration time: 0.12s
                      Time elapsed: 00:34:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1879/1 [0m                       

                       Computation: 759015 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 420.46
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3163
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 184713216
                    Iteration time: 0.13s
                      Time elapsed: 00:34:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1880/1 [0m                       

                       Computation: 683931 steps/s (collection: 0.045s, learning 0.099s)
                       Mean reward: 422.31
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.9566
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 184811520
                    Iteration time: 0.14s
                      Time elapsed: 00:34:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1881/1 [0m                       

                       Computation: 715095 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 419.53
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.5500
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 184909824
                    Iteration time: 0.14s
                      Time elapsed: 00:34:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1882/1 [0m                       

                       Computation: 633634 steps/s (collection: 0.042s, learning 0.113s)
                       Mean reward: 416.84
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1594
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4391
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 185008128
                    Iteration time: 0.16s
                      Time elapsed: 00:34:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1883/1 [0m                       

                       Computation: 909996 steps/s (collection: 0.036s, learning 0.073s)
                       Mean reward: 416.91
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5135
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 185106432
                    Iteration time: 0.11s
                      Time elapsed: 00:34:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1884/1 [0m                       

                       Computation: 813996 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 417.84
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7787
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 185204736
                    Iteration time: 0.12s
                      Time elapsed: 00:34:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1885/1 [0m                       

                       Computation: 822808 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 419.30
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.5868
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 185303040
                    Iteration time: 0.12s
                      Time elapsed: 00:34:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1886/1 [0m                       

                       Computation: 945154 steps/s (collection: 0.036s, learning 0.068s)
                       Mean reward: 417.53
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7430
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 21.5417
--------------------------------------------------------------------------------
                   Total timesteps: 185401344
                    Iteration time: 0.10s
                      Time elapsed: 00:34:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1887/1 [0m                       

                       Computation: 836250 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 423.65
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.1442
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4403
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 185499648
                    Iteration time: 0.12s
                      Time elapsed: 00:34:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1888/1 [0m                       

                       Computation: 790149 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 415.22
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8065
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 185597952
                    Iteration time: 0.12s
                      Time elapsed: 00:34:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1889/1 [0m                       

                       Computation: 829788 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 420.00
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8839
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 185696256
                    Iteration time: 0.12s
                      Time elapsed: 00:35:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1890/1 [0m                       

                       Computation: 842565 steps/s (collection: 0.041s, learning 0.076s)
                       Mean reward: 419.50
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.5199
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4383
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 185794560
                    Iteration time: 0.12s
                      Time elapsed: 00:35:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1891/1 [0m                       

                       Computation: 843320 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 419.96
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.7189
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4385
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 185892864
                    Iteration time: 0.12s
                      Time elapsed: 00:35:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1892/1 [0m                       

                       Computation: 606665 steps/s (collection: 0.066s, learning 0.096s)
                       Mean reward: 418.90
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3145
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 185991168
                    Iteration time: 0.16s
                      Time elapsed: 00:35:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1893/1 [0m                       

                       Computation: 828914 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 418.49
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1225
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 186089472
                    Iteration time: 0.12s
                      Time elapsed: 00:35:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1894/1 [0m                       

                       Computation: 854378 steps/s (collection: 0.034s, learning 0.081s)
                       Mean reward: 421.19
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.6080
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 186187776
                    Iteration time: 0.12s
                      Time elapsed: 00:35:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1895/1 [0m                       

                       Computation: 727995 steps/s (collection: 0.035s, learning 0.100s)
                       Mean reward: 416.59
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4308
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4347
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 186286080
                    Iteration time: 0.14s
                      Time elapsed: 00:35:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1896/1 [0m                       

                       Computation: 858240 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 420.18
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.5386
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4365
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 22.6250
--------------------------------------------------------------------------------
                   Total timesteps: 186384384
                    Iteration time: 0.11s
                      Time elapsed: 00:35:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1897/1 [0m                       

                       Computation: 808581 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 425.21
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.6431
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 186482688
                    Iteration time: 0.12s
                      Time elapsed: 00:35:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1898/1 [0m                       

                       Computation: 764569 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 416.56
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8682
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 186580992
                    Iteration time: 0.13s
                      Time elapsed: 00:35:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1899/1 [0m                       

                       Computation: 478281 steps/s (collection: 0.066s, learning 0.140s)
                       Mean reward: 421.49
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8232
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 186679296
                    Iteration time: 0.21s
                      Time elapsed: 00:35:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1900/1 [0m                       

                       Computation: 764129 steps/s (collection: 0.048s, learning 0.081s)
                       Mean reward: 414.57
               Mean episode length: 247.34
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4912
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 186777600
                    Iteration time: 0.13s
                      Time elapsed: 00:35:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1901/1 [0m                       

                       Computation: 681997 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 427.80
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.2147
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 186875904
                    Iteration time: 0.14s
                      Time elapsed: 00:35:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1902/1 [0m                       

                       Computation: 469037 steps/s (collection: 0.093s, learning 0.116s)
                       Mean reward: 417.16
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9581
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4370
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 186974208
                    Iteration time: 0.21s
                      Time elapsed: 00:35:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1903/1 [0m                       

                       Computation: 785893 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 417.77
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0742
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 187072512
                    Iteration time: 0.13s
                      Time elapsed: 00:35:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1904/1 [0m                       

                       Computation: 689244 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 418.77
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4958
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187170816
                    Iteration time: 0.14s
                      Time elapsed: 00:35:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1905/1 [0m                       

                       Computation: 752260 steps/s (collection: 0.035s, learning 0.096s)
                       Mean reward: 413.36
               Mean episode length: 247.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.4286
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4346
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 187269120
                    Iteration time: 0.13s
                      Time elapsed: 00:35:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1906/1 [0m                       

                       Computation: 479748 steps/s (collection: 0.070s, learning 0.135s)
                       Mean reward: 419.83
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4667
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 187367424
                    Iteration time: 0.20s
                      Time elapsed: 00:35:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1907/1 [0m                       

                       Computation: 659005 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 417.92
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2428
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 20.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187465728
                    Iteration time: 0.15s
                      Time elapsed: 00:35:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1908/1 [0m                       

                       Computation: 843414 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 418.71
               Mean episode length: 246.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3483
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4348
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 187564032
                    Iteration time: 0.12s
                      Time elapsed: 00:35:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1909/1 [0m                       

                       Computation: 722155 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 418.81
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.6353
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4335
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 187662336
                    Iteration time: 0.14s
                      Time elapsed: 00:35:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1910/1 [0m                       

                       Computation: 815422 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 422.73
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8405
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 187760640
                    Iteration time: 0.12s
                      Time elapsed: 00:35:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1911/1 [0m                       

                       Computation: 687211 steps/s (collection: 0.037s, learning 0.106s)
                       Mean reward: 419.50
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2357
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 187858944
                    Iteration time: 0.14s
                      Time elapsed: 00:35:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1912/1 [0m                       

                       Computation: 854702 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 416.78
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7886
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4342
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 187957248
                    Iteration time: 0.12s
                      Time elapsed: 00:35:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1913/1 [0m                       

                       Computation: 854578 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 419.82
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4665
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 188055552
                    Iteration time: 0.12s
                      Time elapsed: 00:35:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1914/1 [0m                       

                       Computation: 761398 steps/s (collection: 0.035s, learning 0.095s)
                       Mean reward: 422.40
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.1353
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 188153856
                    Iteration time: 0.13s
                      Time elapsed: 00:35:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1915/1 [0m                       

                       Computation: 375662 steps/s (collection: 0.081s, learning 0.181s)
                       Mean reward: 425.40
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.6531
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 188252160
                    Iteration time: 0.26s
                      Time elapsed: 00:35:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1916/1 [0m                       

                       Computation: 553715 steps/s (collection: 0.073s, learning 0.105s)
                       Mean reward: 420.42
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.7825
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4375
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 188350464
                    Iteration time: 0.18s
                      Time elapsed: 00:35:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1917/1 [0m                       

                       Computation: 713348 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 420.88
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.6465
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 21.8750
--------------------------------------------------------------------------------
                   Total timesteps: 188448768
                    Iteration time: 0.14s
                      Time elapsed: 00:35:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1918/1 [0m                       

                       Computation: 722421 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 412.26
               Mean episode length: 247.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9081
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 188547072
                    Iteration time: 0.14s
                      Time elapsed: 00:35:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1919/1 [0m                       

                       Computation: 655437 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 417.89
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8159
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 188645376
                    Iteration time: 0.15s
                      Time elapsed: 00:35:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1920/1 [0m                       

                       Computation: 767233 steps/s (collection: 0.035s, learning 0.093s)
                       Mean reward: 419.86
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.6592
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 188743680
                    Iteration time: 0.13s
                      Time elapsed: 00:35:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1921/1 [0m                       

                       Computation: 818045 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 413.48
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9074
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 188841984
                    Iteration time: 0.12s
                      Time elapsed: 00:35:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1922/1 [0m                       

                       Computation: 792462 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 418.94
               Mean episode length: 247.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2950
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 188940288
                    Iteration time: 0.12s
                      Time elapsed: 00:35:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1923/1 [0m                       

                       Computation: 740519 steps/s (collection: 0.036s, learning 0.097s)
                       Mean reward: 412.21
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1782
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 189038592
                    Iteration time: 0.13s
                      Time elapsed: 00:35:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1924/1 [0m                       

                       Computation: 836468 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 419.59
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.6173
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 189136896
                    Iteration time: 0.12s
                      Time elapsed: 00:35:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1925/1 [0m                       

                       Computation: 761917 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 417.02
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9970
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 189235200
                    Iteration time: 0.13s
                      Time elapsed: 00:35:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1926/1 [0m                       

                       Computation: 593940 steps/s (collection: 0.040s, learning 0.126s)
                       Mean reward: 418.22
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2148
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 189333504
                    Iteration time: 0.17s
                      Time elapsed: 00:35:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1927/1 [0m                       

                       Computation: 617746 steps/s (collection: 0.038s, learning 0.121s)
                       Mean reward: 410.46
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.5186
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 189431808
                    Iteration time: 0.16s
                      Time elapsed: 00:35:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1928/1 [0m                       

                       Computation: 626075 steps/s (collection: 0.039s, learning 0.119s)
                       Mean reward: 420.70
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1095
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4381
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 19.7917
--------------------------------------------------------------------------------
                   Total timesteps: 189530112
                    Iteration time: 0.16s
                      Time elapsed: 00:35:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1929/1 [0m                       

                       Computation: 759069 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 418.70
               Mean episode length: 247.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4785
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4354
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 189628416
                    Iteration time: 0.13s
                      Time elapsed: 00:35:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1930/1 [0m                       

                       Computation: 752740 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 418.97
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1157
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4368
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 189726720
                    Iteration time: 0.13s
                      Time elapsed: 00:35:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1931/1 [0m                       

                       Computation: 730761 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 420.65
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4859
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4386
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 189825024
                    Iteration time: 0.13s
                      Time elapsed: 00:35:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1932/1 [0m                       

                       Computation: 751523 steps/s (collection: 0.035s, learning 0.096s)
                       Mean reward: 424.46
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.4596
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4384
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 189923328
                    Iteration time: 0.13s
                      Time elapsed: 00:35:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1933/1 [0m                       

                       Computation: 845079 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 419.46
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4312
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4379
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 190021632
                    Iteration time: 0.12s
                      Time elapsed: 00:35:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1934/1 [0m                       

                       Computation: 846331 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 423.45
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.0329
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4382
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 190119936
                    Iteration time: 0.12s
                      Time elapsed: 00:35:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1935/1 [0m                       

                       Computation: 543355 steps/s (collection: 0.055s, learning 0.126s)
                       Mean reward: 417.12
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.9002
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 190218240
                    Iteration time: 0.18s
                      Time elapsed: 00:35:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1936/1 [0m                       

                       Computation: 551387 steps/s (collection: 0.046s, learning 0.132s)
                       Mean reward: 418.83
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3811
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 190316544
                    Iteration time: 0.18s
                      Time elapsed: 00:35:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1937/1 [0m                       

                       Computation: 713576 steps/s (collection: 0.037s, learning 0.101s)
                       Mean reward: 416.18
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0727
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4352
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 190414848
                    Iteration time: 0.14s
                      Time elapsed: 00:35:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1938/1 [0m                       

                       Computation: 722180 steps/s (collection: 0.048s, learning 0.089s)
                       Mean reward: 418.83
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2196
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 20.8333
--------------------------------------------------------------------------------
                   Total timesteps: 190513152
                    Iteration time: 0.14s
                      Time elapsed: 00:35:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1939/1 [0m                       

                       Computation: 750182 steps/s (collection: 0.035s, learning 0.096s)
                       Mean reward: 417.19
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0704
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4361
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 190611456
                    Iteration time: 0.13s
                      Time elapsed: 00:35:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1940/1 [0m                       

                       Computation: 600185 steps/s (collection: 0.037s, learning 0.127s)
                       Mean reward: 416.16
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8229
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 190709760
                    Iteration time: 0.16s
                      Time elapsed: 00:35:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1941/1 [0m                       

                       Computation: 653684 steps/s (collection: 0.037s, learning 0.113s)
                       Mean reward: 415.41
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5724
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4319
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 190808064
                    Iteration time: 0.15s
                      Time elapsed: 00:35:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1942/1 [0m                       

                       Computation: 701432 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 414.66
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.5410
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 190906368
                    Iteration time: 0.14s
                      Time elapsed: 00:35:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1943/1 [0m                       

                       Computation: 878224 steps/s (collection: 0.039s, learning 0.073s)
                       Mean reward: 417.77
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.1730
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 191004672
                    Iteration time: 0.11s
                      Time elapsed: 00:36:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1944/1 [0m                       

                       Computation: 835390 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 428.73
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.3549
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4393
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 191102976
                    Iteration time: 0.12s
                      Time elapsed: 00:36:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1945/1 [0m                       

                       Computation: 653025 steps/s (collection: 0.047s, learning 0.104s)
                       Mean reward: 420.02
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3871
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4366
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 191201280
                    Iteration time: 0.15s
                      Time elapsed: 00:36:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1946/1 [0m                       

                       Computation: 701772 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 425.02
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.5979
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4362
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.6250
--------------------------------------------------------------------------------
                   Total timesteps: 191299584
                    Iteration time: 0.14s
                      Time elapsed: 00:36:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1947/1 [0m                       

                       Computation: 776941 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 422.10
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.9280
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 191397888
                    Iteration time: 0.13s
                      Time elapsed: 00:36:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1948/1 [0m                       

                       Computation: 795984 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 422.10
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.2072
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 21.2917
--------------------------------------------------------------------------------
                   Total timesteps: 191496192
                    Iteration time: 0.12s
                      Time elapsed: 00:36:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1949/1 [0m                       

                       Computation: 754812 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 419.10
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0929
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4325
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 191594496
                    Iteration time: 0.13s
                      Time elapsed: 00:36:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1950/1 [0m                       

                       Computation: 789478 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 418.66
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0543
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4338
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 191692800
                    Iteration time: 0.12s
                      Time elapsed: 00:36:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1951/1 [0m                       

                       Computation: 642335 steps/s (collection: 0.049s, learning 0.105s)
                       Mean reward: 423.47
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8633
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4358
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 191791104
                    Iteration time: 0.15s
                      Time elapsed: 00:36:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1952/1 [0m                       

                       Computation: 950354 steps/s (collection: 0.036s, learning 0.068s)
                       Mean reward: 420.57
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.9515
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 191889408
                    Iteration time: 0.10s
                      Time elapsed: 00:36:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1953/1 [0m                       

                       Computation: 907587 steps/s (collection: 0.036s, learning 0.072s)
                       Mean reward: 418.77
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4450
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 191987712
                    Iteration time: 0.11s
                      Time elapsed: 00:36:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1954/1 [0m                       

                       Computation: 930131 steps/s (collection: 0.034s, learning 0.072s)
                       Mean reward: 418.85
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0241
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4344
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 192086016
                    Iteration time: 0.11s
                      Time elapsed: 00:36:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1955/1 [0m                       

                       Computation: 749638 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 417.08
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.0903
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 192184320
                    Iteration time: 0.13s
                      Time elapsed: 00:36:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1956/1 [0m                       

                       Computation: 838173 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 427.09
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.0129
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4395
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 192282624
                    Iteration time: 0.12s
                      Time elapsed: 00:36:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1957/1 [0m                       

                       Computation: 783599 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 424.04
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.5737
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4405
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 192380928
                    Iteration time: 0.13s
                      Time elapsed: 00:36:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1958/1 [0m                       

                       Computation: 837336 steps/s (collection: 0.043s, learning 0.074s)
                       Mean reward: 427.53
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.2871
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4416
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 192479232
                    Iteration time: 0.12s
                      Time elapsed: 00:36:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1959/1 [0m                       

                       Computation: 680229 steps/s (collection: 0.038s, learning 0.107s)
                       Mean reward: 426.09
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.5995
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4373
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 20.7500
--------------------------------------------------------------------------------
                   Total timesteps: 192577536
                    Iteration time: 0.14s
                      Time elapsed: 00:36:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1960/1 [0m                       

                       Computation: 583230 steps/s (collection: 0.051s, learning 0.117s)
                       Mean reward: 430.29
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.8725
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 192675840
                    Iteration time: 0.17s
                      Time elapsed: 00:36:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1961/1 [0m                       

                       Computation: 738912 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 420.72
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.7856
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4333
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 192774144
                    Iteration time: 0.13s
                      Time elapsed: 00:36:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1962/1 [0m                       

                       Computation: 936160 steps/s (collection: 0.036s, learning 0.069s)
                       Mean reward: 428.24
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.4200
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4404
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 192872448
                    Iteration time: 0.11s
                      Time elapsed: 00:36:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1963/1 [0m                       

                       Computation: 910833 steps/s (collection: 0.040s, learning 0.068s)
                       Mean reward: 421.24
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.7394
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 192970752
                    Iteration time: 0.11s
                      Time elapsed: 00:36:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1964/1 [0m                       

                       Computation: 755344 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 428.21
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.2761
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 193069056
                    Iteration time: 0.13s
                      Time elapsed: 00:36:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1965/1 [0m                       

                       Computation: 419928 steps/s (collection: 0.045s, learning 0.189s)
                       Mean reward: 429.19
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.3758
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4397
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 193167360
                    Iteration time: 0.23s
                      Time elapsed: 00:36:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1966/1 [0m                       

                       Computation: 675550 steps/s (collection: 0.048s, learning 0.098s)
                       Mean reward: 428.11
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.1441
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4401
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 193265664
                    Iteration time: 0.15s
                      Time elapsed: 00:36:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1967/1 [0m                       

                       Computation: 733084 steps/s (collection: 0.058s, learning 0.077s)
                       Mean reward: 426.60
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.8073
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4398
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 193363968
                    Iteration time: 0.13s
                      Time elapsed: 00:36:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1968/1 [0m                       

                       Computation: 825976 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 423.09
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.2210
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 193462272
                    Iteration time: 0.12s
                      Time elapsed: 00:36:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1969/1 [0m                       

                       Computation: 655098 steps/s (collection: 0.038s, learning 0.113s)
                       Mean reward: 419.75
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.0830
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4378
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 21.1667
--------------------------------------------------------------------------------
                   Total timesteps: 193560576
                    Iteration time: 0.15s
                      Time elapsed: 00:36:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1970/1 [0m                       

                       Computation: 720034 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 415.90
               Mean episode length: 247.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.1577
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4343
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 193658880
                    Iteration time: 0.14s
                      Time elapsed: 00:36:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1971/1 [0m                       

                       Computation: 850929 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 418.28
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3556
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4350
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 193757184
                    Iteration time: 0.12s
                      Time elapsed: 00:36:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1972/1 [0m                       

                       Computation: 630010 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 425.21
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.8480
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4389
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 193855488
                    Iteration time: 0.16s
                      Time elapsed: 00:36:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1973/1 [0m                       

                       Computation: 854680 steps/s (collection: 0.040s, learning 0.075s)
                       Mean reward: 427.95
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.3351
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4376
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 193953792
                    Iteration time: 0.12s
                      Time elapsed: 00:36:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1974/1 [0m                       

                       Computation: 836413 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 424.74
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.5417
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 194052096
                    Iteration time: 0.12s
                      Time elapsed: 00:36:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1975/1 [0m                       

                       Computation: 776115 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 420.61
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.6275
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 194150400
                    Iteration time: 0.13s
                      Time elapsed: 00:36:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1976/1 [0m                       

                       Computation: 791860 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 420.93
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3775
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 194248704
                    Iteration time: 0.12s
                      Time elapsed: 00:36:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1977/1 [0m                       

                       Computation: 639305 steps/s (collection: 0.036s, learning 0.118s)
                       Mean reward: 425.68
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.6592
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4364
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 194347008
                    Iteration time: 0.15s
                      Time elapsed: 00:36:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1978/1 [0m                       

                       Computation: 727035 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 423.46
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.4135
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4341
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 194445312
                    Iteration time: 0.14s
                      Time elapsed: 00:36:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1979/1 [0m                       

                       Computation: 597681 steps/s (collection: 0.043s, learning 0.122s)
                       Mean reward: 417.00
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.7919
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4336
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 194543616
                    Iteration time: 0.16s
                      Time elapsed: 00:36:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1980/1 [0m                       

                       Computation: 645958 steps/s (collection: 0.040s, learning 0.112s)
                       Mean reward: 416.41
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.3736
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4316
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 19.7500
--------------------------------------------------------------------------------
                   Total timesteps: 194641920
                    Iteration time: 0.15s
                      Time elapsed: 00:36:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1981/1 [0m                       

                       Computation: 621551 steps/s (collection: 0.041s, learning 0.117s)
                       Mean reward: 419.95
               Mean episode length: 246.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.5953
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4315
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 194740224
                    Iteration time: 0.16s
                      Time elapsed: 00:36:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1982/1 [0m                       

                       Computation: 625907 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 422.87
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.3826
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4334
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 194838528
                    Iteration time: 0.16s
                      Time elapsed: 00:36:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1983/1 [0m                       

                       Computation: 896481 steps/s (collection: 0.037s, learning 0.072s)
                       Mean reward: 426.87
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.7779
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4360
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 194936832
                    Iteration time: 0.11s
                      Time elapsed: 00:36:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1984/1 [0m                       

                       Computation: 492261 steps/s (collection: 0.039s, learning 0.161s)
                       Mean reward: 423.05
               Mean episode length: 246.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.4761
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4355
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 195035136
                    Iteration time: 0.20s
                      Time elapsed: 00:36:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1985/1 [0m                       

                       Computation: 674255 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 427.36
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.8869
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4387
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 195133440
                    Iteration time: 0.15s
                      Time elapsed: 00:36:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1986/1 [0m                       

                       Computation: 421830 steps/s (collection: 0.067s, learning 0.166s)
                       Mean reward: 419.56
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.4867
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4392
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 195231744
                    Iteration time: 0.23s
                      Time elapsed: 00:36:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1987/1 [0m                       

                       Computation: 831553 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 419.25
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3356
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 195330048
                    Iteration time: 0.12s
                      Time elapsed: 00:36:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1988/1 [0m                       

                       Computation: 743671 steps/s (collection: 0.036s, learning 0.097s)
                       Mean reward: 419.11
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.3028
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 195428352
                    Iteration time: 0.13s
                      Time elapsed: 00:36:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1989/1 [0m                       

                       Computation: 729233 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 427.14
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.9380
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4380
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 195526656
                    Iteration time: 0.13s
                      Time elapsed: 00:36:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1990/1 [0m                       

                       Computation: 684639 steps/s (collection: 0.051s, learning 0.093s)
                       Mean reward: 423.06
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 85.5496
       Episode_Reward/object_height 0.0048
     Episode_Reward/reaching_object 0.4374
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 20.7500
--------------------------------------------------------------------------------
                   Total timesteps: 195624960
                    Iteration time: 0.14s
                      Time elapsed: 00:36:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1991/1 [0m                       

                       Computation: 610510 steps/s (collection: 0.039s, learning 0.122s)
                       Mean reward: 421.16
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8077
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 195723264
                    Iteration time: 0.16s
                      Time elapsed: 00:36:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1992/1 [0m                       

                       Computation: 696442 steps/s (collection: 0.038s, learning 0.104s)
                       Mean reward: 423.68
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.0441
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4356
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 195821568
                    Iteration time: 0.14s
                      Time elapsed: 00:36:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1993/1 [0m                       

                       Computation: 823033 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 415.19
               Mean episode length: 246.19
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 82.8929
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4297
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 195919872
                    Iteration time: 0.12s
                      Time elapsed: 00:36:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1994/1 [0m                       

                       Computation: 717343 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 421.61
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8789
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4357
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 196018176
                    Iteration time: 0.14s
                      Time elapsed: 00:36:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1995/1 [0m                       

                       Computation: 532484 steps/s (collection: 0.073s, learning 0.112s)
                       Mean reward: 424.80
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.4838
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4349
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 196116480
                    Iteration time: 0.18s
                      Time elapsed: 00:36:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1996/1 [0m                       

                       Computation: 721200 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 422.42
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8350
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4363
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 196214784
                    Iteration time: 0.14s
                      Time elapsed: 00:36:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1997/1 [0m                       

                       Computation: 621987 steps/s (collection: 0.041s, learning 0.117s)
                       Mean reward: 422.88
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.1013
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4351
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 196313088
                    Iteration time: 0.16s
                      Time elapsed: 00:37:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1998/1 [0m                       

                       Computation: 720102 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 420.85
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.8895
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4340
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 196411392
                    Iteration time: 0.14s
                      Time elapsed: 00:37:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1999/1 [0m                       

                       Computation: 736664 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 425.38
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.6928
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4372
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 196509696
                    Iteration time: 0.13s
                      Time elapsed: 00:37:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 2000/1 [0m                       

                       Computation: 642035 steps/s (collection: 0.049s, learning 0.104s)
                       Mean reward: 423.72
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.0803
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4345
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 21.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608000
                    Iteration time: 0.15s
                      Time elapsed: 00:37:03
                               ETA: 00:00:00

