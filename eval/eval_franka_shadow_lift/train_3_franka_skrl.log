################################################################################
                        [1m Learning iteration 1/1 [0m                        

                       Computation: 408303 steps/s (collection: 0.029s, learning 0.212s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 0.24s
                      Time elapsed: 00:00:01
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 2/1 [0m                        

                       Computation: 661528 steps/s (collection: 0.034s, learning 0.115s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 0.15s
                      Time elapsed: 00:00:02
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 3/1 [0m                        

                       Computation: 846883 steps/s (collection: 0.029s, learning 0.087s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 0.12s
                      Time elapsed: 00:00:03
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 4/1 [0m                        

                       Computation: 716958 steps/s (collection: 0.027s, learning 0.111s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 0.14s
                      Time elapsed: 00:00:04
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 5/1 [0m                        

                       Computation: 893148 steps/s (collection: 0.030s, learning 0.081s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 0.11s
                      Time elapsed: 00:00:04
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 6/1 [0m                        

                       Computation: 904824 steps/s (collection: 0.028s, learning 0.081s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 0.11s
                      Time elapsed: 00:00:05
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 7/1 [0m                        

                       Computation: 914037 steps/s (collection: 0.026s, learning 0.081s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 0.11s
                      Time elapsed: 00:00:06
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 8/1 [0m                        

                       Computation: 889119 steps/s (collection: 0.029s, learning 0.082s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 0.11s
                      Time elapsed: 00:00:07
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 9/1 [0m                        

                       Computation: 829357 steps/s (collection: 0.029s, learning 0.090s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 0.12s
                      Time elapsed: 00:00:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 10/1 [0m                        

                       Computation: 815593 steps/s (collection: 0.030s, learning 0.091s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 0.12s
                      Time elapsed: 00:00:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 11/1 [0m                        

                       Computation: 873726 steps/s (collection: 0.028s, learning 0.084s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 0.0017
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.0213
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2560.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 0.11s
                      Time elapsed: 00:00:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 12/1 [0m                        

                       Computation: 889369 steps/s (collection: 0.027s, learning 0.084s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0027
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0340
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 0.11s
                      Time elapsed: 00:00:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 13/1 [0m                        

                       Computation: 897531 steps/s (collection: 0.031s, learning 0.079s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0027
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0340
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 0.11s
                      Time elapsed: 00:00:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 14/1 [0m                        

                       Computation: 931652 steps/s (collection: 0.026s, learning 0.080s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0027
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0340
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 0.11s
                      Time elapsed: 00:00:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 15/1 [0m                        

                       Computation: 893572 steps/s (collection: 0.028s, learning 0.082s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0027
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0340
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 0.11s
                      Time elapsed: 00:00:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 16/1 [0m                        

                       Computation: 889196 steps/s (collection: 0.031s, learning 0.080s)
                       Mean reward: 0.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0027
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0340
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 0.11s
                      Time elapsed: 00:00:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 17/1 [0m                        

                       Computation: 755228 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 0.36
               Mean episode length: 145.33
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0014
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0011
     Episode_Reward/reaching_object 0.0698
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 0.13s
                      Time elapsed: 00:00:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 18/1 [0m                        

                       Computation: 631670 steps/s (collection: 0.037s, learning 0.119s)
                       Mean reward: 0.33
               Mean episode length: 171.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.0610
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 0.16s
                      Time elapsed: 00:00:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 19/1 [0m                        

                       Computation: 699133 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 19.24
               Mean episode length: 196.67
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 5.1333
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.1146
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 0.14s
                      Time elapsed: 00:00:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 20/1 [0m                        

                       Computation: 747255 steps/s (collection: 0.047s, learning 0.085s)
                       Mean reward: 4.49
               Mean episode length: 216.50
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 0.5000
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.1198
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 0.13s
                      Time elapsed: 00:00:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 21/1 [0m                        

                       Computation: 818732 steps/s (collection: 0.031s, learning 0.089s)
                       Mean reward: 2.25
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 0.6946
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.1384
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 849.5833
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 0.12s
                      Time elapsed: 00:00:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 22/1 [0m                        

                       Computation: 881186 steps/s (collection: 0.028s, learning 0.084s)
                       Mean reward: 2.25
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.2941
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.1588
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4078.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 0.11s
                      Time elapsed: 00:00:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 23/1 [0m                        

                       Computation: 858435 steps/s (collection: 0.030s, learning 0.085s)
                       Mean reward: 2.25
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.2941
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.1588
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4078.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 0.11s
                      Time elapsed: 00:00:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 24/1 [0m                        

                       Computation: 822349 steps/s (collection: 0.034s, learning 0.086s)
                       Mean reward: 5.80
               Mean episode length: 64.40
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0010
      Episode_Reward/lifting_object 0.9490
       Episode_Reward/object_height 0.0008
     Episode_Reward/reaching_object 0.0638
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 679.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 0.12s
                      Time elapsed: 00:00:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 25/1 [0m                        

                       Computation: 799009 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 2.35
               Mean episode length: 87.20
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0009
      Episode_Reward/lifting_object 0.1667
       Episode_Reward/object_height 0.0008
     Episode_Reward/reaching_object 0.0645
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 0.12s
                      Time elapsed: 00:00:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 26/1 [0m                        

                       Computation: 825021 steps/s (collection: 0.029s, learning 0.090s)
                       Mean reward: 7.70
               Mean episode length: 113.30
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0011
      Episode_Reward/lifting_object 1.7000
       Episode_Reward/object_height 0.0010
     Episode_Reward/reaching_object 0.1062
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 0.12s
                      Time elapsed: 00:00:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 27/1 [0m                        

                       Computation: 758664 steps/s (collection: 0.034s, learning 0.095s)
                       Mean reward: 8.50
               Mean episode length: 148.42
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 0.8833
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1651
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 0.13s
                      Time elapsed: 00:00:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 28/1 [0m                        

                       Computation: 868626 steps/s (collection: 0.034s, learning 0.080s)
                       Mean reward: 7.77
               Mean episode length: 172.40
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 2.2667
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1620
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 0.11s
                      Time elapsed: 00:00:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 29/1 [0m                        

                       Computation: 880710 steps/s (collection: 0.033s, learning 0.079s)
                       Mean reward: 3.41
               Mean episode length: 193.48
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 0.4000
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1923
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 0.11s
                      Time elapsed: 00:00:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 30/1 [0m                        

                       Computation: 848451 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 12.83
               Mean episode length: 223.42
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 2.7333
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2420
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 0.12s
                      Time elapsed: 00:00:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 31/1 [0m                        

                       Computation: 765612 steps/s (collection: 0.050s, learning 0.079s)
                       Mean reward: 1.26
               Mean episode length: 239.75
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2487
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 0.13s
                      Time elapsed: 00:00:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 32/1 [0m                        

                       Computation: 900282 steps/s (collection: 0.028s, learning 0.081s)
                       Mean reward: 5.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.6668
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2550
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 3157.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 0.11s
                      Time elapsed: 00:00:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 33/1 [0m                        

                       Computation: 773990 steps/s (collection: 0.033s, learning 0.094s)
                       Mean reward: 5.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.7581
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2480
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3988.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 0.13s
                      Time elapsed: 00:00:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 34/1 [0m                        

                       Computation: 795926 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 14.84
               Mean episode length: 92.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0012
      Episode_Reward/lifting_object 2.6996
       Episode_Reward/object_height 0.0012
     Episode_Reward/reaching_object 0.1197
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 830.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 0.12s
                      Time elapsed: 00:00:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 35/1 [0m                        

                       Computation: 761952 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 13.39
               Mean episode length: 103.02
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0010
      Episode_Reward/lifting_object 2.4444
       Episode_Reward/object_height 0.0010
     Episode_Reward/reaching_object 0.0972
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 0.13s
                      Time elapsed: 00:00:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 36/1 [0m                        

                       Computation: 867918 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 10.50
               Mean episode length: 127.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0012
      Episode_Reward/lifting_object 1.6678
       Episode_Reward/object_height 0.0012
     Episode_Reward/reaching_object 0.1144
Episode_Termination/object_dropping 2.3333
       Episode_Termination/time_out 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 0.11s
                      Time elapsed: 00:00:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 37/1 [0m                        

                       Computation: 726991 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 8.54
               Mean episode length: 149.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 1.3606
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1417
Episode_Termination/object_dropping 2.4583
       Episode_Termination/time_out 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 0.14s
                      Time elapsed: 00:00:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 38/1 [0m                        

                       Computation: 829359 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 11.09
               Mean episode length: 166.52
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 2.7846
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1834
Episode_Termination/object_dropping 3.0833
       Episode_Termination/time_out 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 0.12s
                      Time elapsed: 00:00:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 39/1 [0m                        

                       Computation: 741718 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 10.14
               Mean episode length: 185.71
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 1.9081
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1738
Episode_Termination/object_dropping 3.6250
       Episode_Termination/time_out 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 0.13s
                      Time elapsed: 00:00:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 40/1 [0m                        

                       Computation: 731526 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 10.61
               Mean episode length: 210.03
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 1.6628
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.1976
Episode_Termination/object_dropping 2.1667
       Episode_Termination/time_out 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 0.13s
                      Time elapsed: 00:00:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 41/1 [0m                        

                       Computation: 801430 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 5.05
               Mean episode length: 222.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 1.7233
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2100
Episode_Termination/object_dropping 1.9583
       Episode_Termination/time_out 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 0.12s
                      Time elapsed: 00:00:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 42/1 [0m                        

                       Computation: 823133 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 5.00
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 3.3032
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.1880
Episode_Termination/object_dropping 2.1250
       Episode_Termination/time_out 148.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 0.12s
                      Time elapsed: 00:00:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 43/1 [0m                        

                       Computation: 859880 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 8.05
               Mean episode length: 130.71
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0014
      Episode_Reward/lifting_object 3.0667
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.1278
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 0.11s
                      Time elapsed: 00:00:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 44/1 [0m                        

                       Computation: 810925 steps/s (collection: 0.033s, learning 0.088s)
                       Mean reward: 12.26
               Mean episode length: 120.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0012
      Episode_Reward/lifting_object 1.3767
       Episode_Reward/object_height 0.0011
     Episode_Reward/reaching_object 0.1362
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 0.12s
                      Time elapsed: 00:00:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 45/1 [0m                        

                       Computation: 859133 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 19.30
               Mean episode length: 160.55
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 3.3047
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1763
Episode_Termination/object_dropping 2.3333
       Episode_Termination/time_out 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 0.11s
                      Time elapsed: 00:00:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 46/1 [0m                        

                       Computation: 802407 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 15.00
               Mean episode length: 157.17
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 2.8805
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1716
Episode_Termination/object_dropping 3.1667
       Episode_Termination/time_out 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 0.12s
                      Time elapsed: 00:00:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 47/1 [0m                        

                       Computation: 795735 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 24.14
               Mean episode length: 183.19
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 4.5343
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.1905
Episode_Termination/object_dropping 2.7083
       Episode_Termination/time_out 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 0.12s
                      Time elapsed: 00:00:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 48/1 [0m                        

                       Computation: 787327 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 13.83
               Mean episode length: 202.02
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 2.5440
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2078
Episode_Termination/object_dropping 2.7917
       Episode_Termination/time_out 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 0.12s
                      Time elapsed: 00:00:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 49/1 [0m                        

                       Computation: 827133 steps/s (collection: 0.043s, learning 0.076s)
                       Mean reward: 11.48
               Mean episode length: 209.90
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 3.7801
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2201
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 0.12s
                      Time elapsed: 00:00:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 50/1 [0m                        

                       Computation: 648864 steps/s (collection: 0.043s, learning 0.108s)
                       Mean reward: 14.78
               Mean episode length: 214.27
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 2.4809
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2235
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 0.15s
                      Time elapsed: 00:00:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 51/1 [0m                        

                       Computation: 710856 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 22.19
               Mean episode length: 216.17
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 4.9697
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2289
Episode_Termination/object_dropping 3.0000
       Episode_Termination/time_out 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 0.14s
                      Time elapsed: 00:00:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 52/1 [0m                        

                       Computation: 714105 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 17.49
               Mean episode length: 233.15
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 3.3641
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2405
Episode_Termination/object_dropping 2.2083
       Episode_Termination/time_out 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 0.14s
                      Time elapsed: 00:00:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 53/1 [0m                        

                       Computation: 807368 steps/s (collection: 0.033s, learning 0.089s)
                       Mean reward: 9.53
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 6.3930
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.1914
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 130.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 0.12s
                      Time elapsed: 00:00:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 54/1 [0m                        

                       Computation: 781739 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 12.42
               Mean episode length: 154.91
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0012
      Episode_Reward/lifting_object 2.1567
       Episode_Reward/object_height 0.0012
     Episode_Reward/reaching_object 0.1243
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 0.13s
                      Time elapsed: 00:00:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 55/1 [0m                        

                       Computation: 747133 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 13.63
               Mean episode length: 168.98
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 2.5213
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1606
Episode_Termination/object_dropping 2.3750
       Episode_Termination/time_out 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 0.13s
                      Time elapsed: 00:00:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 56/1 [0m                        

                       Computation: 761876 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 19.18
               Mean episode length: 194.56
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 4.3199
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2145
Episode_Termination/object_dropping 2.3333
       Episode_Termination/time_out 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 0.13s
                      Time elapsed: 00:00:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 57/1 [0m                        

                       Computation: 788294 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 12.67
               Mean episode length: 200.63
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 2.1641
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2167
Episode_Termination/object_dropping 2.4167
       Episode_Termination/time_out 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 0.12s
                      Time elapsed: 00:00:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 58/1 [0m                        

                       Computation: 673212 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 28.94
               Mean episode length: 208.74
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 4.6243
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2287
Episode_Termination/object_dropping 2.7083
       Episode_Termination/time_out 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 0.15s
                      Time elapsed: 00:00:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 59/1 [0m                        

                       Computation: 802350 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 21.14
               Mean episode length: 224.78
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 5.3535
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2441
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 0.12s
                      Time elapsed: 00:00:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 60/1 [0m                        

                       Computation: 752944 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 33.25
               Mean episode length: 231.09
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 5.4161
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2564
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 0.13s
                      Time elapsed: 00:01:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 61/1 [0m                        

                       Computation: 727559 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 16.03
               Mean episode length: 232.31
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 2.2633
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2347
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 0.14s
                      Time elapsed: 00:01:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 62/1 [0m                        

                       Computation: 675563 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 12.46
               Mean episode length: 233.58
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 2.7181
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2383
Episode_Termination/object_dropping 2.2500
       Episode_Termination/time_out 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 0.15s
                      Time elapsed: 00:01:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 63/1 [0m                        

                       Computation: 773822 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 21.64
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 3.1020
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2376
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 118.7500
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 0.13s
                      Time elapsed: 00:01:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 64/1 [0m                        

                       Computation: 680293 steps/s (collection: 0.052s, learning 0.092s)
                       Mean reward: 29.02
               Mean episode length: 206.45
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 7.6361
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2112
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 0.14s
                      Time elapsed: 00:01:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 65/1 [0m                        

                       Computation: 758793 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 28.31
               Mean episode length: 182.96
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 4.1616
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2002
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 0.13s
                      Time elapsed: 00:01:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 66/1 [0m                        

                       Computation: 712265 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 34.81
               Mean episode length: 186.65
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 6.8844
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2057
Episode_Termination/object_dropping 3.7500
       Episode_Termination/time_out 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 0.14s
                      Time elapsed: 00:01:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 67/1 [0m                        

                       Computation: 738921 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 26.40
               Mean episode length: 195.54
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 4.6926
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2051
Episode_Termination/object_dropping 3.4583
       Episode_Termination/time_out 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 0.13s
                      Time elapsed: 00:01:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 68/1 [0m                        

                       Computation: 794163 steps/s (collection: 0.044s, learning 0.080s)
                       Mean reward: 38.96
               Mean episode length: 211.90
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 7.2084
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2366
Episode_Termination/object_dropping 2.6667
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 0.12s
                      Time elapsed: 00:01:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 69/1 [0m                        

                       Computation: 781652 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 29.51
               Mean episode length: 218.53
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 5.7727
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2386
Episode_Termination/object_dropping 2.4583
       Episode_Termination/time_out 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 0.13s
                      Time elapsed: 00:01:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 70/1 [0m                        

                       Computation: 741661 steps/s (collection: 0.047s, learning 0.086s)
                       Mean reward: 34.18
               Mean episode length: 223.09
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 6.7672
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2473
Episode_Termination/object_dropping 2.2083
       Episode_Termination/time_out 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 0.13s
                      Time elapsed: 00:01:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 71/1 [0m                        

                       Computation: 825740 steps/s (collection: 0.044s, learning 0.075s)
                       Mean reward: 30.98
               Mean episode length: 217.61
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 5.9247
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2359
Episode_Termination/object_dropping 2.8333
       Episode_Termination/time_out 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 0.12s
                      Time elapsed: 00:01:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 72/1 [0m                        

                       Computation: 768893 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 23.65
               Mean episode length: 227.22
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 4.4653
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2464
Episode_Termination/object_dropping 2.7917
       Episode_Termination/time_out 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 0.13s
                      Time elapsed: 00:01:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 73/1 [0m                        

                       Computation: 819122 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 37.78
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 6.7298
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2483
Episode_Termination/object_dropping 1.9583
       Episode_Termination/time_out 104.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 0.12s
                      Time elapsed: 00:01:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 74/1 [0m                        

                       Computation: 812226 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 41.73
               Mean episode length: 192.71
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 6.5911
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2106
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 0.12s
                      Time elapsed: 00:01:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 75/1 [0m                        

                       Computation: 791363 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 39.79
               Mean episode length: 209.70
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 6.4357
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2252
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 0.12s
                      Time elapsed: 00:01:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 76/1 [0m                        

                       Computation: 772706 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 43.51
               Mean episode length: 189.07
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 8.3681
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2126
Episode_Termination/object_dropping 4.3333
       Episode_Termination/time_out 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 0.13s
                      Time elapsed: 00:01:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 77/1 [0m                        

                       Computation: 809734 steps/s (collection: 0.043s, learning 0.078s)
                       Mean reward: 39.25
               Mean episode length: 199.07
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 7.7715
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2227
Episode_Termination/object_dropping 4.2500
       Episode_Termination/time_out 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 0.12s
                      Time elapsed: 00:01:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 78/1 [0m                        

                       Computation: 776599 steps/s (collection: 0.048s, learning 0.079s)
                       Mean reward: 33.90
               Mean episode length: 214.21
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 6.5293
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2376
Episode_Termination/object_dropping 3.1250
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 0.13s
                      Time elapsed: 00:01:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 79/1 [0m                        

                       Computation: 755588 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 45.75
               Mean episode length: 214.56
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 8.8093
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2383
Episode_Termination/object_dropping 3.1667
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 0.13s
                      Time elapsed: 00:01:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 80/1 [0m                        

                       Computation: 751799 steps/s (collection: 0.047s, learning 0.084s)
                       Mean reward: 50.79
               Mean episode length: 220.74
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 9.2058
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2493
Episode_Termination/object_dropping 2.8750
       Episode_Termination/time_out 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 0.13s
                      Time elapsed: 00:01:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 81/1 [0m                        

                       Computation: 701851 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 34.16
               Mean episode length: 215.08
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 6.0571
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2346
Episode_Termination/object_dropping 3.5417
       Episode_Termination/time_out 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 0.14s
                      Time elapsed: 00:01:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 82/1 [0m                        

                       Computation: 820202 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 46.64
               Mean episode length: 217.72
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 9.8976
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2469
Episode_Termination/object_dropping 3.5417
       Episode_Termination/time_out 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 0.12s
                      Time elapsed: 00:01:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 83/1 [0m                        

                       Computation: 803039 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 31.17
               Mean episode length: 222.11
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 5.2529
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2393
Episode_Termination/object_dropping 3.0833
       Episode_Termination/time_out 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 0.12s
                      Time elapsed: 00:01:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 84/1 [0m                        

                       Computation: 733444 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 48.55
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 3.3584
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2106
Episode_Termination/object_dropping 2.4167
       Episode_Termination/time_out 86.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 0.13s
                      Time elapsed: 00:01:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 85/1 [0m                        

                       Computation: 691753 steps/s (collection: 0.056s, learning 0.086s)
                       Mean reward: 46.29
               Mean episode length: 184.30
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 9.0927
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2101
Episode_Termination/object_dropping 2.2500
       Episode_Termination/time_out 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 0.14s
                      Time elapsed: 00:01:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 86/1 [0m                        

                       Computation: 690207 steps/s (collection: 0.045s, learning 0.097s)
                       Mean reward: 47.83
               Mean episode length: 179.15
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 8.7225
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2003
Episode_Termination/object_dropping 4.7083
       Episode_Termination/time_out 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 0.14s
                      Time elapsed: 00:01:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 87/1 [0m                        

                       Computation: 737318 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 70.11
               Mean episode length: 210.81
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 13.4753
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2536
Episode_Termination/object_dropping 3.6667
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 0.13s
                      Time elapsed: 00:01:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 88/1 [0m                        

                       Computation: 724903 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 50.26
               Mean episode length: 208.94
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 9.6535
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2492
Episode_Termination/object_dropping 4.1667
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 0.14s
                      Time elapsed: 00:01:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 89/1 [0m                        

                       Computation: 777100 steps/s (collection: 0.048s, learning 0.079s)
                       Mean reward: 57.14
               Mean episode length: 219.61
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 11.6520
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2559
Episode_Termination/object_dropping 2.7500
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 0.13s
                      Time elapsed: 00:01:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 90/1 [0m                        

                       Computation: 774237 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 82.20
               Mean episode length: 213.51
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 16.4010
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2729
Episode_Termination/object_dropping 3.3750
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 0.13s
                      Time elapsed: 00:01:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 91/1 [0m                        

                       Computation: 590126 steps/s (collection: 0.058s, learning 0.109s)
                       Mean reward: 51.56
               Mean episode length: 208.46
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 11.2812
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2472
Episode_Termination/object_dropping 4.2083
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 0.17s
                      Time elapsed: 00:01:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 92/1 [0m                        

                       Computation: 777016 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 51.44
               Mean episode length: 222.10
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 10.6105
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2571
Episode_Termination/object_dropping 3.2917
       Episode_Termination/time_out 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 0.13s
                      Time elapsed: 00:01:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 93/1 [0m                        

                       Computation: 784592 steps/s (collection: 0.047s, learning 0.078s)
                       Mean reward: 74.97
               Mean episode length: 225.11
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 13.5931
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.2727
Episode_Termination/object_dropping 2.8750
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 0.13s
                      Time elapsed: 00:01:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 94/1 [0m                        

                       Computation: 700935 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 80.29
               Mean episode length: 246.79
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 9.4506
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2526
Episode_Termination/object_dropping 2.5833
       Episode_Termination/time_out 74.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 0.14s
                      Time elapsed: 00:01:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 95/1 [0m                        

                       Computation: 755769 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 48.67
               Mean episode length: 208.02
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 9.3175
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2525
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 0.13s
                      Time elapsed: 00:01:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 96/1 [0m                        

                       Computation: 776927 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 94.47
               Mean episode length: 194.90
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 15.3949
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2615
Episode_Termination/object_dropping 3.2917
       Episode_Termination/time_out 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 0.13s
                      Time elapsed: 00:01:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 97/1 [0m                        

                       Computation: 723175 steps/s (collection: 0.048s, learning 0.088s)
                       Mean reward: 74.94
               Mean episode length: 206.57
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 14.8600
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2680
Episode_Termination/object_dropping 3.7500
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 0.14s
                      Time elapsed: 00:01:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 98/1 [0m                        

                       Computation: 714763 steps/s (collection: 0.053s, learning 0.085s)
                       Mean reward: 80.84
               Mean episode length: 214.78
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 15.8221
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2695
Episode_Termination/object_dropping 4.1250
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 0.14s
                      Time elapsed: 00:01:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 99/1 [0m                        

                       Computation: 667328 steps/s (collection: 0.047s, learning 0.100s)
                       Mean reward: 90.18
               Mean episode length: 217.44
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 16.5549
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.2769
Episode_Termination/object_dropping 3.3333
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 0.15s
                      Time elapsed: 00:01:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 100/1 [0m                       

                       Computation: 736151 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 58.95
               Mean episode length: 219.98
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 11.4293
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2708
Episode_Termination/object_dropping 3.5000
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 0.13s
                      Time elapsed: 00:01:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 101/1 [0m                       

                       Computation: 762369 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 91.58
               Mean episode length: 223.79
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 18.2641
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.2818
Episode_Termination/object_dropping 2.5000
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 0.13s
                      Time elapsed: 00:01:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 102/1 [0m                       

                       Computation: 699292 steps/s (collection: 0.047s, learning 0.094s)
                       Mean reward: 89.43
               Mean episode length: 226.45
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 17.3366
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.2900
Episode_Termination/object_dropping 2.6250
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 0.14s
                      Time elapsed: 00:01:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 103/1 [0m                       

                       Computation: 654882 steps/s (collection: 0.053s, learning 0.097s)
                       Mean reward: 121.21
               Mean episode length: 232.28
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 23.6171
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3163
Episode_Termination/object_dropping 1.9167
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 0.15s
                      Time elapsed: 00:01:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 104/1 [0m                       

                       Computation: 642577 steps/s (collection: 0.045s, learning 0.108s)
                       Mean reward: 134.97
               Mean episode length: 227.56
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 25.6850
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3174
Episode_Termination/object_dropping 2.6250
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 0.15s
                      Time elapsed: 00:01:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 105/1 [0m                       

                       Computation: 622021 steps/s (collection: 0.049s, learning 0.110s)
                       Mean reward: 134.18
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 23.5787
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3011
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 61.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 0.16s
                      Time elapsed: 00:01:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 106/1 [0m                       

                       Computation: 630316 steps/s (collection: 0.043s, learning 0.113s)
                       Mean reward: 108.73
               Mean episode length: 206.72
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 19.9170
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2729
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 0.16s
                      Time elapsed: 00:01:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 107/1 [0m                       

                       Computation: 666938 steps/s (collection: 0.050s, learning 0.098s)
                       Mean reward: 126.18
               Mean episode length: 212.97
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 24.5715
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.2940
Episode_Termination/object_dropping 3.7917
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 0.15s
                      Time elapsed: 00:01:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 108/1 [0m                       

                       Computation: 610448 steps/s (collection: 0.049s, learning 0.112s)
                       Mean reward: 136.08
               Mean episode length: 221.96
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 27.0971
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3120
Episode_Termination/object_dropping 3.4167
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 0.16s
                      Time elapsed: 00:01:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 109/1 [0m                       

                       Computation: 640621 steps/s (collection: 0.046s, learning 0.108s)
                       Mean reward: 114.19
               Mean episode length: 221.27
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 24.5930
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3090
Episode_Termination/object_dropping 3.2917
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 0.15s
                      Time elapsed: 00:01:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 110/1 [0m                       

                       Computation: 726897 steps/s (collection: 0.051s, learning 0.084s)
                       Mean reward: 152.05
               Mean episode length: 223.80
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 29.9007
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3316
Episode_Termination/object_dropping 3.0417
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 0.14s
                      Time elapsed: 00:01:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 111/1 [0m                       

                       Computation: 797677 steps/s (collection: 0.044s, learning 0.079s)
                       Mean reward: 142.11
               Mean episode length: 219.12
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 28.0603
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3165
Episode_Termination/object_dropping 3.1250
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 0.12s
                      Time elapsed: 00:01:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 112/1 [0m                       

                       Computation: 761829 steps/s (collection: 0.048s, learning 0.082s)
                       Mean reward: 149.74
               Mean episode length: 222.49
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 28.1027
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3225
Episode_Termination/object_dropping 3.1667
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 0.13s
                      Time elapsed: 00:02:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 113/1 [0m                       

                       Computation: 822219 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 123.02
               Mean episode length: 221.28
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 24.2271
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3046
Episode_Termination/object_dropping 3.2917
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 0.12s
                      Time elapsed: 00:02:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 114/1 [0m                       

                       Computation: 733580 steps/s (collection: 0.049s, learning 0.086s)
                       Mean reward: 159.77
               Mean episode length: 224.67
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 31.8107
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3367
Episode_Termination/object_dropping 2.7500
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 0.13s
                      Time elapsed: 00:02:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 115/1 [0m                       

                       Computation: 735755 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 180.23
               Mean episode length: 243.29
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 26.8439
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3099
Episode_Termination/object_dropping 2.6667
       Episode_Termination/time_out 54.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 0.13s
                      Time elapsed: 00:02:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 116/1 [0m                       

                       Computation: 723882 steps/s (collection: 0.047s, learning 0.089s)
                       Mean reward: 161.15
               Mean episode length: 202.44
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 32.0856
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3058
Episode_Termination/object_dropping 2.6667
       Episode_Termination/time_out 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 0.14s
                      Time elapsed: 00:02:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 117/1 [0m                       

                       Computation: 761753 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 155.55
               Mean episode length: 217.60
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 30.5434
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3292
Episode_Termination/object_dropping 2.7500
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 0.13s
                      Time elapsed: 00:02:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 118/1 [0m                       

                       Computation: 693918 steps/s (collection: 0.054s, learning 0.088s)
                       Mean reward: 140.23
               Mean episode length: 213.44
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 28.0454
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3094
Episode_Termination/object_dropping 4.3333
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 0.14s
                      Time elapsed: 00:02:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 119/1 [0m                       

                       Computation: 616114 steps/s (collection: 0.053s, learning 0.107s)
                       Mean reward: 178.65
               Mean episode length: 229.72
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 34.6517
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3507
Episode_Termination/object_dropping 2.6667
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 0.16s
                      Time elapsed: 00:02:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 120/1 [0m                       

                       Computation: 554732 steps/s (collection: 0.057s, learning 0.120s)
                       Mean reward: 161.77
               Mean episode length: 216.88
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 30.8593
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3242
Episode_Termination/object_dropping 3.4167
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 0.18s
                      Time elapsed: 00:02:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 121/1 [0m                       

                       Computation: 583114 steps/s (collection: 0.053s, learning 0.116s)
                       Mean reward: 224.04
               Mean episode length: 224.65
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 43.8740
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.3670
Episode_Termination/object_dropping 2.8750
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 0.17s
                      Time elapsed: 00:02:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 122/1 [0m                       

                       Computation: 630087 steps/s (collection: 0.051s, learning 0.105s)
                       Mean reward: 190.80
               Mean episode length: 219.38
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 37.9107
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3505
Episode_Termination/object_dropping 3.0833
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 0.16s
                      Time elapsed: 00:02:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 123/1 [0m                       

                       Computation: 737526 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 200.14
               Mean episode length: 233.43
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 37.9985
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.3677
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 0.13s
                      Time elapsed: 00:02:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 124/1 [0m                       

                       Computation: 597447 steps/s (collection: 0.067s, learning 0.098s)
                       Mean reward: 200.90
               Mean episode length: 229.44
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 39.3460
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.3608
Episode_Termination/object_dropping 2.2500
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 0.16s
                      Time elapsed: 00:02:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 125/1 [0m                       

                       Computation: 593854 steps/s (collection: 0.057s, learning 0.109s)
                       Mean reward: 227.34
               Mean episode length: 244.29
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 35.5139
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3578
Episode_Termination/object_dropping 2.5000
       Episode_Termination/time_out 50.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 0.17s
                      Time elapsed: 00:02:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 126/1 [0m                       

                       Computation: 522747 steps/s (collection: 0.051s, learning 0.137s)
                       Mean reward: 143.36
               Mean episode length: 217.85
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 27.3972
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3258
Episode_Termination/object_dropping 2.1250
       Episode_Termination/time_out 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 0.19s
                      Time elapsed: 00:02:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 127/1 [0m                       

                       Computation: 597653 steps/s (collection: 0.054s, learning 0.111s)
                       Mean reward: 201.38
               Mean episode length: 219.11
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 38.9389
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3516
Episode_Termination/object_dropping 2.0417
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 0.16s
                      Time elapsed: 00:02:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 128/1 [0m                       

                       Computation: 577786 steps/s (collection: 0.052s, learning 0.118s)
                       Mean reward: 211.29
               Mean episode length: 224.09
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 41.2252
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.3658
Episode_Termination/object_dropping 3.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 0.17s
                      Time elapsed: 00:02:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 129/1 [0m                       

                       Computation: 597786 steps/s (collection: 0.054s, learning 0.111s)
                       Mean reward: 234.88
               Mean episode length: 227.49
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 46.3781
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.3853
Episode_Termination/object_dropping 2.9583
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 0.16s
                      Time elapsed: 00:02:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 130/1 [0m                       

                       Computation: 626342 steps/s (collection: 0.052s, learning 0.105s)
                       Mean reward: 232.30
               Mean episode length: 222.66
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 46.8335
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.3822
Episode_Termination/object_dropping 2.9583
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 0.16s
                      Time elapsed: 00:02:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 131/1 [0m                       

                       Computation: 604922 steps/s (collection: 0.046s, learning 0.117s)
                       Mean reward: 255.74
               Mean episode length: 222.93
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 51.4615
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4013
Episode_Termination/object_dropping 3.1667
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 0.16s
                      Time elapsed: 00:02:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 132/1 [0m                       

                       Computation: 618902 steps/s (collection: 0.045s, learning 0.114s)
                       Mean reward: 240.59
               Mean episode length: 226.44
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 47.8015
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.3922
Episode_Termination/object_dropping 2.6667
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 0.16s
                      Time elapsed: 00:02:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 133/1 [0m                       

                       Computation: 738864 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 229.96
               Mean episode length: 226.55
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 46.0053
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.3876
Episode_Termination/object_dropping 2.5000
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 0.13s
                      Time elapsed: 00:02:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 134/1 [0m                       

                       Computation: 734432 steps/s (collection: 0.053s, learning 0.080s)
                       Mean reward: 261.10
               Mean episode length: 226.42
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 51.0684
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4013
Episode_Termination/object_dropping 2.5000
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 0.13s
                      Time elapsed: 00:02:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 135/1 [0m                       

                       Computation: 727310 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 240.57
               Mean episode length: 225.01
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 47.7550
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.3890
Episode_Termination/object_dropping 2.3750
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 0.14s
                      Time elapsed: 00:02:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 136/1 [0m                       

                       Computation: 729482 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 292.07
               Mean episode length: 242.44
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 42.9308
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.3664
Episode_Termination/object_dropping 2.5417
       Episode_Termination/time_out 42.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 0.13s
                      Time elapsed: 00:02:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 137/1 [0m                       

                       Computation: 783166 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 245.93
               Mean episode length: 211.87
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 48.4359
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.3818
Episode_Termination/object_dropping 2.6250
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 0.13s
                      Time elapsed: 00:02:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 138/1 [0m                       

                       Computation: 716414 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 222.44
               Mean episode length: 214.51
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 46.8718
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.3749
Episode_Termination/object_dropping 3.5417
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 0.14s
                      Time elapsed: 00:02:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 139/1 [0m                       

                       Computation: 750230 steps/s (collection: 0.049s, learning 0.083s)
                       Mean reward: 253.48
               Mean episode length: 221.84
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 50.3148
       Episode_Reward/object_height 0.0040
     Episode_Reward/reaching_object 0.3970
Episode_Termination/object_dropping 3.6250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 0.13s
                      Time elapsed: 00:02:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 140/1 [0m                       

                       Computation: 738980 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 296.97
               Mean episode length: 225.12
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 57.9141
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4146
Episode_Termination/object_dropping 3.0417
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 0.13s
                      Time elapsed: 00:02:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 141/1 [0m                       

                       Computation: 822477 steps/s (collection: 0.044s, learning 0.076s)
                       Mean reward: 275.41
               Mean episode length: 223.26
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 53.3250
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.3963
Episode_Termination/object_dropping 3.2500
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 0.12s
                      Time elapsed: 00:02:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 142/1 [0m                       

                       Computation: 787615 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 333.81
               Mean episode length: 229.05
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 66.2855
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4412
Episode_Termination/object_dropping 2.3333
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 0.12s
                      Time elapsed: 00:02:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 143/1 [0m                       

                       Computation: 677925 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 271.50
               Mean episode length: 222.89
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 52.4588
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4044
Episode_Termination/object_dropping 2.9167
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 0.15s
                      Time elapsed: 00:02:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 144/1 [0m                       

                       Computation: 776933 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 349.24
               Mean episode length: 229.17
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 70.4750
       Episode_Reward/object_height 0.0049
     Episode_Reward/reaching_object 0.4555
Episode_Termination/object_dropping 2.2083
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 0.13s
                      Time elapsed: 00:02:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 145/1 [0m                       

                       Computation: 721821 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 312.09
               Mean episode length: 224.27
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 60.7029
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4221
Episode_Termination/object_dropping 2.5000
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 0.14s
                      Time elapsed: 00:02:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 146/1 [0m                       

                       Computation: 748339 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 354.20
               Mean episode length: 241.60
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 63.3544
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4302
Episode_Termination/object_dropping 2.3750
       Episode_Termination/time_out 38.9167
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 0.13s
                      Time elapsed: 00:02:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 147/1 [0m                       

                       Computation: 757029 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 282.14
               Mean episode length: 220.66
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 58.7577
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4032
Episode_Termination/object_dropping 2.0417
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 0.13s
                      Time elapsed: 00:02:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 148/1 [0m                       

                       Computation: 705132 steps/s (collection: 0.049s, learning 0.090s)
                       Mean reward: 358.45
               Mean episode length: 222.89
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 70.2594
       Episode_Reward/object_height 0.0052
     Episode_Reward/reaching_object 0.4481
Episode_Termination/object_dropping 2.4583
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 0.14s
                      Time elapsed: 00:02:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 149/1 [0m                       

                       Computation: 642414 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 342.45
               Mean episode length: 224.99
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 67.5985
       Episode_Reward/object_height 0.0050
     Episode_Reward/reaching_object 0.4449
Episode_Termination/object_dropping 2.7917
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 0.15s
                      Time elapsed: 00:02:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 150/1 [0m                       

                       Computation: 779287 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 377.36
               Mean episode length: 233.52
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 74.0724
       Episode_Reward/object_height 0.0055
     Episode_Reward/reaching_object 0.4755
Episode_Termination/object_dropping 2.2500
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 0.13s
                      Time elapsed: 00:02:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 151/1 [0m                       

                       Computation: 812366 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 377.89
               Mean episode length: 228.39
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 73.7148
       Episode_Reward/object_height 0.0054
     Episode_Reward/reaching_object 0.4640
Episode_Termination/object_dropping 2.5417
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 0.12s
                      Time elapsed: 00:02:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 152/1 [0m                       

                       Computation: 811353 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 375.12
               Mean episode length: 227.13
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 74.8264
       Episode_Reward/object_height 0.0055
     Episode_Reward/reaching_object 0.4644
Episode_Termination/object_dropping 2.4583
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 0.12s
                      Time elapsed: 00:02:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 153/1 [0m                       

                       Computation: 820211 steps/s (collection: 0.043s, learning 0.077s)
                       Mean reward: 420.95
               Mean episode length: 225.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 83.8272
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.4872
Episode_Termination/object_dropping 2.4583
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 0.12s
                      Time elapsed: 00:02:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 154/1 [0m                       

                       Computation: 817153 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 394.68
               Mean episode length: 229.34
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 78.4378
       Episode_Reward/object_height 0.0058
     Episode_Reward/reaching_object 0.4777
Episode_Termination/object_dropping 2.2500
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 0.12s
                      Time elapsed: 00:02:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 155/1 [0m                       

                       Computation: 649678 steps/s (collection: 0.056s, learning 0.095s)
                       Mean reward: 378.61
               Mean episode length: 225.96
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 75.3008
       Episode_Reward/object_height 0.0057
     Episode_Reward/reaching_object 0.4602
Episode_Termination/object_dropping 2.3750
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 0.15s
                      Time elapsed: 00:02:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 156/1 [0m                       

                       Computation: 728306 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 435.75
               Mean episode length: 227.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 88.3386
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.4989
Episode_Termination/object_dropping 2.0417
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 0.13s
                      Time elapsed: 00:02:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 157/1 [0m                       

                       Computation: 779956 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 447.35
               Mean episode length: 241.80
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 87.0465
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.5006
Episode_Termination/object_dropping 1.9167
       Episode_Termination/time_out 34.6667
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 0.13s
                      Time elapsed: 00:02:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 158/1 [0m                       

                       Computation: 723234 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 411.39
               Mean episode length: 224.49
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 81.0232
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.4698
Episode_Termination/object_dropping 2.1667
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 0.14s
                      Time elapsed: 00:02:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 159/1 [0m                       

                       Computation: 764301 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 451.20
               Mean episode length: 225.95
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 88.8531
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.5103
Episode_Termination/object_dropping 2.7083
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 0.13s
                      Time elapsed: 00:02:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 160/1 [0m                       

                       Computation: 784931 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 445.26
               Mean episode length: 229.17
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 88.5414
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.5033
Episode_Termination/object_dropping 2.4583
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 0.13s
                      Time elapsed: 00:03:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 161/1 [0m                       

                       Computation: 754284 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 514.73
               Mean episode length: 232.42
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 104.4040
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.5522
Episode_Termination/object_dropping 2.0417
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 0.13s
                      Time elapsed: 00:03:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 162/1 [0m                       

                       Computation: 794611 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 509.18
               Mean episode length: 236.96
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 100.7384
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.5407
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 0.12s
                      Time elapsed: 00:03:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 163/1 [0m                       

                       Computation: 738610 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 471.35
               Mean episode length: 231.19
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 95.1333
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.5226
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 0.13s
                      Time elapsed: 00:03:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 164/1 [0m                       

                       Computation: 810712 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 532.14
               Mean episode length: 234.42
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 107.5065
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.5674
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 0.12s
                      Time elapsed: 00:03:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 165/1 [0m                       

                       Computation: 809772 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 460.74
               Mean episode length: 231.51
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 91.0758
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.5189
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 0.12s
                      Time elapsed: 00:03:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 166/1 [0m                       

                       Computation: 775518 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 519.98
               Mean episode length: 231.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 103.2073
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.5514
Episode_Termination/object_dropping 1.9167
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 0.13s
                      Time elapsed: 00:03:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 167/1 [0m                       

                       Computation: 776511 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 522.41
               Mean episode length: 242.22
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 100.1008
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.5314
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 33.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 0.13s
                      Time elapsed: 00:03:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 168/1 [0m                       

                       Computation: 693231 steps/s (collection: 0.049s, learning 0.093s)
                       Mean reward: 522.65
               Mean episode length: 226.69
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 104.4338
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.5376
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 0.14s
                      Time elapsed: 00:03:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 169/1 [0m                       

                       Computation: 748696 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 538.42
               Mean episode length: 230.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 106.5407
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.5495
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 0.13s
                      Time elapsed: 00:03:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 170/1 [0m                       

                       Computation: 636160 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 550.58
               Mean episode length: 232.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 109.3633
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.5630
Episode_Termination/object_dropping 2.5000
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 0.15s
                      Time elapsed: 00:03:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 171/1 [0m                       

                       Computation: 836561 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 556.29
               Mean episode length: 237.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 109.6740
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.5672
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 0.12s
                      Time elapsed: 00:03:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 172/1 [0m                       

                       Computation: 826023 steps/s (collection: 0.042s, learning 0.077s)
                       Mean reward: 579.63
               Mean episode length: 234.69
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 114.8268
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.5837
Episode_Termination/object_dropping 1.9167
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 0.12s
                      Time elapsed: 00:03:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 173/1 [0m                       

                       Computation: 800986 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 547.48
               Mean episode length: 230.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 109.9486
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.5677
Episode_Termination/object_dropping 2.2917
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 0.12s
                      Time elapsed: 00:03:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 174/1 [0m                       

                       Computation: 829970 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 553.98
               Mean episode length: 227.51
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 110.8429
       Episode_Reward/object_height 0.0132
     Episode_Reward/reaching_object 0.5673
Episode_Termination/object_dropping 2.4167
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 0.12s
                      Time elapsed: 00:03:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 175/1 [0m                       

                       Computation: 856356 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 525.94
               Mean episode length: 224.50
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 105.1485
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.5463
Episode_Termination/object_dropping 2.6250
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 0.11s
                      Time elapsed: 00:03:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 176/1 [0m                       

                       Computation: 806486 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 528.24
               Mean episode length: 232.05
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 104.0457
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.5591
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 0.12s
                      Time elapsed: 00:03:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 177/1 [0m                       

                       Computation: 755646 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 571.29
               Mean episode length: 235.17
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 115.4662
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.5962
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 0.13s
                      Time elapsed: 00:03:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 178/1 [0m                       

                       Computation: 814292 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 592.23
               Mean episode length: 239.99
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 108.4584
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.5702
Episode_Termination/object_dropping 2.3750
       Episode_Termination/time_out 30.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 0.12s
                      Time elapsed: 00:03:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 179/1 [0m                       

                       Computation: 813843 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 600.73
               Mean episode length: 230.23
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 117.8374
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.5921
Episode_Termination/object_dropping 1.9167
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 0.12s
                      Time elapsed: 00:03:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 180/1 [0m                       

                       Computation: 676471 steps/s (collection: 0.047s, learning 0.099s)
                       Mean reward: 621.38
               Mean episode length: 231.08
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 123.6670
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.6093
Episode_Termination/object_dropping 2.1667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 0.15s
                      Time elapsed: 00:03:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 181/1 [0m                       

                       Computation: 770396 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 621.23
               Mean episode length: 234.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 123.2327
       Episode_Reward/object_height 0.0156
     Episode_Reward/reaching_object 0.6133
Episode_Termination/object_dropping 2.0417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 0.13s
                      Time elapsed: 00:03:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 182/1 [0m                       

                       Computation: 705284 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 626.79
               Mean episode length: 233.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 123.1717
       Episode_Reward/object_height 0.0148
     Episode_Reward/reaching_object 0.5984
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 0.14s
                      Time elapsed: 00:03:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 183/1 [0m                       

                       Computation: 820518 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 669.84
               Mean episode length: 237.05
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 133.9280
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.6422
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 0.12s
                      Time elapsed: 00:03:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 184/1 [0m                       

                       Computation: 771923 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 614.94
               Mean episode length: 227.63
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 121.3327
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.5874
Episode_Termination/object_dropping 2.3750
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 0.13s
                      Time elapsed: 00:03:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 185/1 [0m                       

                       Computation: 776425 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 646.03
               Mean episode length: 236.49
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 129.7449
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.6251
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 0.13s
                      Time elapsed: 00:03:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 186/1 [0m                       

                       Computation: 619533 steps/s (collection: 0.050s, learning 0.109s)
                       Mean reward: 684.37
               Mean episode length: 237.62
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 135.2828
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.6415
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 0.16s
                      Time elapsed: 00:03:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 187/1 [0m                       

                       Computation: 662473 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 679.61
               Mean episode length: 233.92
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 134.8651
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.6329
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 0.15s
                      Time elapsed: 00:03:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 188/1 [0m                       

                       Computation: 692035 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 705.37
               Mean episode length: 244.76
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 139.5554
       Episode_Reward/object_height 0.0120
     Episode_Reward/reaching_object 0.6610
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 29.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 0.14s
                      Time elapsed: 00:03:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 189/1 [0m                       

                       Computation: 752971 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 655.05
               Mean episode length: 237.28
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 131.9750
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.6235
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 0.13s
                      Time elapsed: 00:03:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 190/1 [0m                       

                       Computation: 786825 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 638.25
               Mean episode length: 228.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 128.6813
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.6185
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 0.12s
                      Time elapsed: 00:03:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 191/1 [0m                       

                       Computation: 794169 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 681.63
               Mean episode length: 237.57
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 135.6283
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.6364
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 0.12s
                      Time elapsed: 00:03:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 192/1 [0m                       

                       Computation: 792773 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 658.95
               Mean episode length: 234.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 130.8740
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.6178
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 0.12s
                      Time elapsed: 00:03:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 193/1 [0m                       

                       Computation: 789930 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 669.85
               Mean episode length: 234.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 133.2778
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.6297
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 0.12s
                      Time elapsed: 00:03:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 194/1 [0m                       

                       Computation: 692790 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 658.25
               Mean episode length: 230.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 130.7409
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.6168
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 0.14s
                      Time elapsed: 00:03:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 195/1 [0m                       

                       Computation: 708998 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 666.45
               Mean episode length: 233.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 133.7161
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.6295
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 0.14s
                      Time elapsed: 00:03:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 196/1 [0m                       

                       Computation: 761970 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 665.34
               Mean episode length: 233.08
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 133.3514
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.6342
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 0.13s
                      Time elapsed: 00:03:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 197/1 [0m                       

                       Computation: 722692 steps/s (collection: 0.047s, learning 0.089s)
                       Mean reward: 665.82
               Mean episode length: 236.08
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 131.9506
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.6216
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 0.14s
                      Time elapsed: 00:03:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 198/1 [0m                       

                       Computation: 708414 steps/s (collection: 0.050s, learning 0.089s)
                       Mean reward: 701.70
               Mean episode length: 241.51
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 135.8898
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.6356
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 29.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 0.14s
                      Time elapsed: 00:03:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 199/1 [0m                       

                       Computation: 775976 steps/s (collection: 0.047s, learning 0.080s)
                       Mean reward: 625.99
               Mean episode length: 234.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 124.5044
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.6038
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 0.13s
                      Time elapsed: 00:03:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 200/1 [0m                       

                       Computation: 729427 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 645.59
               Mean episode length: 230.77
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 128.5557
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.6118
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 0.13s
                      Time elapsed: 00:03:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 201/1 [0m                       

                       Computation: 779690 steps/s (collection: 0.046s, learning 0.081s)
                       Mean reward: 654.83
               Mean episode length: 231.99
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 130.1092
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.6265
Episode_Termination/object_dropping 2.2917
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 0.13s
                      Time elapsed: 00:03:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 202/1 [0m                       

                       Computation: 783193 steps/s (collection: 0.047s, learning 0.079s)
                       Mean reward: 696.45
               Mean episode length: 238.99
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 138.0719
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.6509
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 0.13s
                      Time elapsed: 00:03:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 203/1 [0m                       

                       Computation: 783924 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 705.96
               Mean episode length: 237.10
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 139.9967
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.6580
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 0.13s
                      Time elapsed: 00:03:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 204/1 [0m                       

                       Computation: 692046 steps/s (collection: 0.048s, learning 0.094s)
                       Mean reward: 695.02
               Mean episode length: 239.34
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 138.5879
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.6504
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 0.14s
                      Time elapsed: 00:03:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 205/1 [0m                       

                       Computation: 816889 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 676.41
               Mean episode length: 241.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 134.8609
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.6391
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 0.12s
                      Time elapsed: 00:03:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 206/1 [0m                       

                       Computation: 786109 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 650.46
               Mean episode length: 236.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 130.0531
       Episode_Reward/object_height 0.0129
     Episode_Reward/reaching_object 0.6225
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 0.13s
                      Time elapsed: 00:03:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 207/1 [0m                       

                       Computation: 805180 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 669.71
               Mean episode length: 238.97
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 133.7164
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.6291
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 0.12s
                      Time elapsed: 00:03:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 208/1 [0m                       

                       Computation: 750181 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 691.27
               Mean episode length: 235.96
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 137.3029
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.6492
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 0.13s
                      Time elapsed: 00:03:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 209/1 [0m                       

                       Computation: 759027 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 736.53
               Mean episode length: 244.92
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 148.4916
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.6794
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 27.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 0.13s
                      Time elapsed: 00:03:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 210/1 [0m                       

                       Computation: 616688 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 730.29
               Mean episode length: 239.77
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 142.8845
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.6627
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 0.16s
                      Time elapsed: 00:03:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 211/1 [0m                       

                       Computation: 638009 steps/s (collection: 0.042s, learning 0.113s)
                       Mean reward: 705.37
               Mean episode length: 238.54
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 141.1762
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.6568
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 0.15s
                      Time elapsed: 00:03:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 212/1 [0m                       

                       Computation: 608718 steps/s (collection: 0.041s, learning 0.120s)
                       Mean reward: 740.29
               Mean episode length: 240.53
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 147.6535
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.6778
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 0.16s
                      Time elapsed: 00:03:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 213/1 [0m                       

                       Computation: 684375 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 765.87
               Mean episode length: 241.93
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 153.3592
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7005
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 0.14s
                      Time elapsed: 00:03:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 214/1 [0m                       

                       Computation: 627784 steps/s (collection: 0.045s, learning 0.112s)
                       Mean reward: 710.26
               Mean episode length: 234.61
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 142.1555
       Episode_Reward/object_height 0.0127
     Episode_Reward/reaching_object 0.6522
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 0.16s
                      Time elapsed: 00:04:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 215/1 [0m                       

                       Computation: 622509 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 735.20
               Mean episode length: 239.74
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 147.6674
       Episode_Reward/object_height 0.0132
     Episode_Reward/reaching_object 0.6784
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 0.16s
                      Time elapsed: 00:04:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 216/1 [0m                       

                       Computation: 735767 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 749.87
               Mean episode length: 236.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 149.3612
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.6795
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 0.13s
                      Time elapsed: 00:04:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 217/1 [0m                       

                       Computation: 661697 steps/s (collection: 0.050s, learning 0.099s)
                       Mean reward: 749.15
               Mean episode length: 238.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 149.2533
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.6808
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 0.15s
                      Time elapsed: 00:04:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 218/1 [0m                       

                       Computation: 740656 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 748.32
               Mean episode length: 238.23
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 149.1745
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.6824
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 0.13s
                      Time elapsed: 00:04:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 219/1 [0m                       

                       Computation: 687272 steps/s (collection: 0.053s, learning 0.091s)
                       Mean reward: 763.89
               Mean episode length: 244.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 146.3385
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.6735
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 26.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 0.14s
                      Time elapsed: 00:04:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 220/1 [0m                       

                       Computation: 724499 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 709.95
               Mean episode length: 239.36
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 140.1253
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.6510
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 0.14s
                      Time elapsed: 00:04:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 221/1 [0m                       

                       Computation: 747199 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 732.59
               Mean episode length: 233.64
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 146.3518
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.6583
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 0.13s
                      Time elapsed: 00:04:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 222/1 [0m                       

                       Computation: 760687 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 717.06
               Mean episode length: 233.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 143.4768
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.6586
Episode_Termination/object_dropping 2.2083
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 0.13s
                      Time elapsed: 00:04:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 223/1 [0m                       

                       Computation: 735003 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 703.43
               Mean episode length: 231.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 138.7276
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.6391
Episode_Termination/object_dropping 2.2500
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 0.13s
                      Time elapsed: 00:04:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 224/1 [0m                       

                       Computation: 702070 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 697.40
               Mean episode length: 233.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 138.6666
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.6367
Episode_Termination/object_dropping 2.4167
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 0.14s
                      Time elapsed: 00:04:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 225/1 [0m                       

                       Computation: 639765 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 731.45
               Mean episode length: 234.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 146.1720
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.6620
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 0.15s
                      Time elapsed: 00:04:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 226/1 [0m                       

                       Computation: 717102 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 713.99
               Mean episode length: 234.68
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 140.9887
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.6429
Episode_Termination/object_dropping 1.9583
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 0.14s
                      Time elapsed: 00:04:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 227/1 [0m                       

                       Computation: 739002 steps/s (collection: 0.048s, learning 0.085s)
                       Mean reward: 739.01
               Mean episode length: 236.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 147.3896
       Episode_Reward/object_height 0.0127
     Episode_Reward/reaching_object 0.6705
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 0.13s
                      Time elapsed: 00:04:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 228/1 [0m                       

                       Computation: 700447 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 713.72
               Mean episode length: 233.72
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 142.2142
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.6494
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 0.14s
                      Time elapsed: 00:04:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 229/1 [0m                       

                       Computation: 743910 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 729.36
               Mean episode length: 239.32
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 145.3608
       Episode_Reward/object_height 0.0123
     Episode_Reward/reaching_object 0.6641
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 0.13s
                      Time elapsed: 00:04:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 230/1 [0m                       

                       Computation: 765929 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 731.93
               Mean episode length: 244.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 142.2671
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.6525
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 22.9583
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 0.13s
                      Time elapsed: 00:04:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 231/1 [0m                       

                       Computation: 737993 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 728.15
               Mean episode length: 239.50
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 144.8059
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.6661
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 0.13s
                      Time elapsed: 00:04:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 232/1 [0m                       

                       Computation: 768513 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 766.65
               Mean episode length: 242.81
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 152.4628
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.6975
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 0.13s
                      Time elapsed: 00:04:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 233/1 [0m                       

                       Computation: 672263 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 771.28
               Mean episode length: 244.02
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 152.0914
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.6940
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 0.15s
                      Time elapsed: 00:04:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 234/1 [0m                       

                       Computation: 707959 steps/s (collection: 0.050s, learning 0.089s)
                       Mean reward: 764.89
               Mean episode length: 243.58
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 152.6543
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.6948
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 0.14s
                      Time elapsed: 00:04:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 235/1 [0m                       

                       Computation: 776688 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 787.03
               Mean episode length: 244.10
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 156.9950
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7154
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 0.13s
                      Time elapsed: 00:04:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 236/1 [0m                       

                       Computation: 670954 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 761.41
               Mean episode length: 239.73
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.8917
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.6945
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 0.15s
                      Time elapsed: 00:04:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 237/1 [0m                       

                       Computation: 579713 steps/s (collection: 0.063s, learning 0.107s)
                       Mean reward: 803.42
               Mean episode length: 243.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 159.7897
       Episode_Reward/object_height 0.0143
     Episode_Reward/reaching_object 0.7256
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 0.17s
                      Time elapsed: 00:04:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 238/1 [0m                       

                       Computation: 717337 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 784.08
               Mean episode length: 242.71
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 155.2203
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7109
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 0.14s
                      Time elapsed: 00:04:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 239/1 [0m                       

                       Computation: 657470 steps/s (collection: 0.045s, learning 0.105s)
                       Mean reward: 786.82
               Mean episode length: 241.27
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 156.6775
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7141
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 0.15s
                      Time elapsed: 00:04:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 240/1 [0m                       

                       Computation: 737796 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 795.08
               Mean episode length: 243.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 153.3721
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7011
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 24.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 0.13s
                      Time elapsed: 00:04:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 241/1 [0m                       

                       Computation: 800817 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 776.39
               Mean episode length: 237.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 153.5825
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.6949
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 0.12s
                      Time elapsed: 00:04:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 242/1 [0m                       

                       Computation: 784545 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 800.04
               Mean episode length: 246.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 159.2890
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7222
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 0.13s
                      Time elapsed: 00:04:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 243/1 [0m                       

                       Computation: 776745 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 769.71
               Mean episode length: 238.37
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 154.1125
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.6943
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 0.13s
                      Time elapsed: 00:04:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 244/1 [0m                       

                       Computation: 713027 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 811.89
               Mean episode length: 243.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 161.9500
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7298
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 0.14s
                      Time elapsed: 00:04:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 245/1 [0m                       

                       Computation: 765440 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 818.87
               Mean episode length: 246.51
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.6378
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7416
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 0.13s
                      Time elapsed: 00:04:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 246/1 [0m                       

                       Computation: 713105 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 803.98
               Mean episode length: 242.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 160.6416
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7265
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 0.14s
                      Time elapsed: 00:04:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 247/1 [0m                       

                       Computation: 764834 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 788.79
               Mean episode length: 244.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 157.0562
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7211
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 0.13s
                      Time elapsed: 00:04:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 248/1 [0m                       

                       Computation: 757065 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 790.66
               Mean episode length: 245.14
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 157.9862
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7194
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 0.13s
                      Time elapsed: 00:04:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 249/1 [0m                       

                       Computation: 720112 steps/s (collection: 0.047s, learning 0.090s)
                       Mean reward: 798.48
               Mean episode length: 243.92
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 160.1763
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7270
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 0.14s
                      Time elapsed: 00:04:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 250/1 [0m                       

                       Computation: 728118 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 819.15
               Mean episode length: 246.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 160.9610
       Episode_Reward/object_height 0.0143
     Episode_Reward/reaching_object 0.7362
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 25.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 0.14s
                      Time elapsed: 00:04:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 251/1 [0m                       

                       Computation: 727332 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 799.90
               Mean episode length: 239.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 158.6628
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7197
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 0.14s
                      Time elapsed: 00:04:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 252/1 [0m                       

                       Computation: 687201 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 793.94
               Mean episode length: 239.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 158.8536
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7235
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 0.14s
                      Time elapsed: 00:04:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 253/1 [0m                       

                       Computation: 772700 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 793.88
               Mean episode length: 242.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 157.7512
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7229
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 18.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 0.13s
                      Time elapsed: 00:04:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 254/1 [0m                       

                       Computation: 716134 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 794.96
               Mean episode length: 241.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 157.8458
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7250
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 0.14s
                      Time elapsed: 00:04:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 255/1 [0m                       

                       Computation: 782365 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 815.69
               Mean episode length: 244.89
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 161.7764
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7381
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 0.13s
                      Time elapsed: 00:04:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 256/1 [0m                       

                       Computation: 731962 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 807.25
               Mean episode length: 244.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 160.8784
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7359
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 0.13s
                      Time elapsed: 00:04:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 257/1 [0m                       

                       Computation: 709064 steps/s (collection: 0.048s, learning 0.091s)
                       Mean reward: 786.91
               Mean episode length: 243.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 155.6208
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7255
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 0.14s
                      Time elapsed: 00:04:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 258/1 [0m                       

                       Computation: 744541 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 818.90
               Mean episode length: 246.26
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 162.5891
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7524
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 0.13s
                      Time elapsed: 00:04:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 259/1 [0m                       

                       Computation: 767420 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 802.59
               Mean episode length: 245.43
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 159.0588
       Episode_Reward/object_height 0.0143
     Episode_Reward/reaching_object 0.7371
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 0.13s
                      Time elapsed: 00:04:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 260/1 [0m                       

                       Computation: 707978 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 789.65
               Mean episode length: 244.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 156.4446
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7284
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 0.14s
                      Time elapsed: 00:04:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 261/1 [0m                       

                       Computation: 668476 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 806.69
               Mean episode length: 244.64
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 156.7108
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7235
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 23.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 0.15s
                      Time elapsed: 00:04:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 262/1 [0m                       

                       Computation: 736210 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 816.81
               Mean episode length: 243.55
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 162.9271
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7471
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 0.13s
                      Time elapsed: 00:04:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 263/1 [0m                       

                       Computation: 695676 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 809.03
               Mean episode length: 241.71
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 161.1789
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7384
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 0.14s
                      Time elapsed: 00:04:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 264/1 [0m                       

                       Computation: 766624 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 810.11
               Mean episode length: 241.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 161.2126
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7375
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 18.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 0.13s
                      Time elapsed: 00:04:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 265/1 [0m                       

                       Computation: 799708 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 807.10
               Mean episode length: 241.05
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 160.7640
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7377
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 0.12s
                      Time elapsed: 00:04:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 266/1 [0m                       

                       Computation: 801611 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 761.36
               Mean episode length: 240.75
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 151.0800
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7044
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 0.12s
                      Time elapsed: 00:04:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 267/1 [0m                       

                       Computation: 777108 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 724.51
               Mean episode length: 237.10
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 144.8041
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.6702
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 0.13s
                      Time elapsed: 00:04:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 268/1 [0m                       

                       Computation: 654819 steps/s (collection: 0.044s, learning 0.106s)
                       Mean reward: 732.85
               Mean episode length: 241.87
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 145.6803
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.6751
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 0.15s
                      Time elapsed: 00:05:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 269/1 [0m                       

                       Computation: 620343 steps/s (collection: 0.069s, learning 0.090s)
                       Mean reward: 684.46
               Mean episode length: 240.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 136.6386
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.6440
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 0.16s
                      Time elapsed: 00:05:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 270/1 [0m                       

                       Computation: 767892 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 664.67
               Mean episode length: 241.85
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 130.3123
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.6288
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 0.13s
                      Time elapsed: 00:05:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 271/1 [0m                       

                       Computation: 663728 steps/s (collection: 0.046s, learning 0.102s)
                       Mean reward: 702.86
               Mean episode length: 245.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 136.7571
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.6517
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 22.4583
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 0.15s
                      Time elapsed: 00:05:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 272/1 [0m                       

                       Computation: 751523 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 708.63
               Mean episode length: 245.12
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 141.4052
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.6669
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 0.13s
                      Time elapsed: 00:05:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 273/1 [0m                       

                       Computation: 797121 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 736.92
               Mean episode length: 246.09
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 146.1656
       Episode_Reward/object_height 0.0143
     Episode_Reward/reaching_object 0.6726
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 0.12s
                      Time elapsed: 00:05:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 274/1 [0m                       

                       Computation: 792173 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 753.81
               Mean episode length: 245.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 150.1013
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.6941
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 19.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 0.12s
                      Time elapsed: 00:05:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 275/1 [0m                       

                       Computation: 749491 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 792.34
               Mean episode length: 243.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 157.5935
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7150
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 0.13s
                      Time elapsed: 00:05:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 276/1 [0m                       

                       Computation: 751488 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 813.63
               Mean episode length: 245.66
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 161.4483
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7388
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 0.13s
                      Time elapsed: 00:05:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 277/1 [0m                       

                       Computation: 749457 steps/s (collection: 0.046s, learning 0.085s)
                       Mean reward: 817.97
               Mean episode length: 246.73
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 162.2562
       Episode_Reward/object_height 0.0155
     Episode_Reward/reaching_object 0.7372
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 0.13s
                      Time elapsed: 00:05:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 278/1 [0m                       

                       Computation: 716890 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 814.66
               Mean episode length: 243.14
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 162.0924
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7338
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 0.14s
                      Time elapsed: 00:05:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 279/1 [0m                       

                       Computation: 670676 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 805.19
               Mean episode length: 242.69
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 160.0125
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7253
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 0.15s
                      Time elapsed: 00:05:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 280/1 [0m                       

                       Computation: 776874 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 819.94
               Mean episode length: 244.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.3644
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7436
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 0.13s
                      Time elapsed: 00:05:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 281/1 [0m                       

                       Computation: 674883 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 837.02
               Mean episode length: 244.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.4243
       Episode_Reward/object_height 0.0157
     Episode_Reward/reaching_object 0.7539
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 0.15s
                      Time elapsed: 00:05:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 282/1 [0m                       

                       Computation: 736330 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 837.85
               Mean episode length: 246.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.0220
       Episode_Reward/object_height 0.0157
     Episode_Reward/reaching_object 0.7427
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 21.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 0.13s
                      Time elapsed: 00:05:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 283/1 [0m                       

                       Computation: 714499 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 818.77
               Mean episode length: 245.02
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 162.5825
       Episode_Reward/object_height 0.0156
     Episode_Reward/reaching_object 0.7342
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 0.14s
                      Time elapsed: 00:05:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 284/1 [0m                       

                       Computation: 759584 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 837.18
               Mean episode length: 245.64
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.1035
       Episode_Reward/object_height 0.0159
     Episode_Reward/reaching_object 0.7509
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 0.13s
                      Time elapsed: 00:05:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 285/1 [0m                       

                       Computation: 756020 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 834.68
               Mean episode length: 245.32
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.1730
       Episode_Reward/object_height 0.0160
     Episode_Reward/reaching_object 0.7566
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 0.13s
                      Time elapsed: 00:05:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 286/1 [0m                       

                       Computation: 713727 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 838.80
               Mean episode length: 246.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.7769
       Episode_Reward/object_height 0.0160
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 0.14s
                      Time elapsed: 00:05:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 287/1 [0m                       

                       Computation: 791279 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 840.29
               Mean episode length: 244.94
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.4151
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 0.12s
                      Time elapsed: 00:05:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 288/1 [0m                       

                       Computation: 789105 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 804.89
               Mean episode length: 239.91
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 159.4496
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7270
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 0.12s
                      Time elapsed: 00:05:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 289/1 [0m                       

                       Computation: 815267 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 826.25
               Mean episode length: 244.05
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.1718
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.7458
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 0.12s
                      Time elapsed: 00:05:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 290/1 [0m                       

                       Computation: 718626 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 821.73
               Mean episode length: 243.11
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.3496
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.7362
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 0.14s
                      Time elapsed: 00:05:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 291/1 [0m                       

                       Computation: 766623 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 842.96
               Mean episode length: 246.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.6852
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 0.13s
                      Time elapsed: 00:05:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 292/1 [0m                       

                       Computation: 761226 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 853.50
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9326
       Episode_Reward/object_height 0.0162
     Episode_Reward/reaching_object 0.7651
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 21.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 0.13s
                      Time elapsed: 00:05:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 293/1 [0m                       

                       Computation: 762692 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 843.25
               Mean episode length: 245.04
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.6038
       Episode_Reward/object_height 0.0160
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 0.13s
                      Time elapsed: 00:05:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 294/1 [0m                       

                       Computation: 779732 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 843.18
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.6520
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7668
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 0.13s
                      Time elapsed: 00:05:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 295/1 [0m                       

                       Computation: 831277 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 813.59
               Mean episode length: 243.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.0780
       Episode_Reward/object_height 0.0156
     Episode_Reward/reaching_object 0.7397
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 0.12s
                      Time elapsed: 00:05:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 296/1 [0m                       

                       Computation: 758763 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 827.96
               Mean episode length: 246.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.9146
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.7447
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 0.13s
                      Time elapsed: 00:05:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 297/1 [0m                       

                       Computation: 646559 steps/s (collection: 0.045s, learning 0.108s)
                       Mean reward: 821.80
               Mean episode length: 244.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.1944
       Episode_Reward/object_height 0.0157
     Episode_Reward/reaching_object 0.7363
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 0.15s
                      Time elapsed: 00:05:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 298/1 [0m                       

                       Computation: 682045 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 832.51
               Mean episode length: 244.37
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.8618
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7486
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 0.14s
                      Time elapsed: 00:05:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 299/1 [0m                       

                       Computation: 697637 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 817.90
               Mean episode length: 244.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.1392
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.7420
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 0.14s
                      Time elapsed: 00:05:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 300/1 [0m                       

                       Computation: 623020 steps/s (collection: 0.061s, learning 0.097s)
                       Mean reward: 824.31
               Mean episode length: 243.62
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.2157
       Episode_Reward/object_height 0.0162
     Episode_Reward/reaching_object 0.7387
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 0.16s
                      Time elapsed: 00:05:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 301/1 [0m                       

                       Computation: 677895 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 808.02
               Mean episode length: 242.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 160.1965
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7231
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 0.15s
                      Time elapsed: 00:05:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 302/1 [0m                       

                       Computation: 688299 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 790.62
               Mean episode length: 241.29
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 157.7590
       Episode_Reward/object_height 0.0160
     Episode_Reward/reaching_object 0.7221
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 0.14s
                      Time elapsed: 00:05:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 303/1 [0m                       

                       Computation: 662696 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 820.08
               Mean episode length: 245.29
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.4686
       Episode_Reward/object_height 0.0166
     Episode_Reward/reaching_object 0.7374
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 20.7500
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 0.15s
                      Time elapsed: 00:05:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 304/1 [0m                       

                       Computation: 747359 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 824.68
               Mean episode length: 240.77
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.4627
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7380
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 0.13s
                      Time elapsed: 00:05:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 305/1 [0m                       

                       Computation: 707000 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 832.79
               Mean episode length: 245.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.9364
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7459
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 18.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 0.14s
                      Time elapsed: 00:05:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 306/1 [0m                       

                       Computation: 752235 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 832.06
               Mean episode length: 243.64
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.5926
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7451
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 0.13s
                      Time elapsed: 00:05:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 307/1 [0m                       

                       Computation: 710004 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 827.47
               Mean episode length: 243.78
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.1065
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7422
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 0.14s
                      Time elapsed: 00:05:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 308/1 [0m                       

                       Computation: 724122 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 822.59
               Mean episode length: 243.87
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.2229
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7384
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 0.14s
                      Time elapsed: 00:05:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 309/1 [0m                       

                       Computation: 753231 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 830.30
               Mean episode length: 243.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.3896
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7319
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 0.13s
                      Time elapsed: 00:05:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 310/1 [0m                       

                       Computation: 680225 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 828.54
               Mean episode length: 244.30
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.3287
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7331
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 0.14s
                      Time elapsed: 00:05:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 311/1 [0m                       

                       Computation: 779621 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 803.64
               Mean episode length: 240.20
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 158.9077
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7164
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 0.13s
                      Time elapsed: 00:05:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 312/1 [0m                       

                       Computation: 677701 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 819.00
               Mean episode length: 239.75
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.2519
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7288
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 0.15s
                      Time elapsed: 00:05:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 313/1 [0m                       

                       Computation: 651351 steps/s (collection: 0.040s, learning 0.111s)
                       Mean reward: 829.60
               Mean episode length: 244.17
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.4085
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7308
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 20.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 0.15s
                      Time elapsed: 00:05:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 314/1 [0m                       

                       Computation: 741881 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 820.08
               Mean episode length: 240.19
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.0651
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7249
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 0.13s
                      Time elapsed: 00:05:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 315/1 [0m                       

                       Computation: 776535 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 820.87
               Mean episode length: 243.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.2809
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7409
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 0.13s
                      Time elapsed: 00:05:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 316/1 [0m                       

                       Computation: 748117 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 848.63
               Mean episode length: 244.41
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.0130
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7576
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 17.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 0.13s
                      Time elapsed: 00:05:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 317/1 [0m                       

                       Computation: 790656 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 842.10
               Mean episode length: 243.38
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.7362
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7478
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 0.12s
                      Time elapsed: 00:05:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 318/1 [0m                       

                       Computation: 689739 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 846.20
               Mean episode length: 244.62
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.3083
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7581
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 0.14s
                      Time elapsed: 00:05:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 319/1 [0m                       

                       Computation: 645519 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 842.92
               Mean episode length: 243.62
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.7906
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7536
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 0.15s
                      Time elapsed: 00:05:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 320/1 [0m                       

                       Computation: 644226 steps/s (collection: 0.047s, learning 0.106s)
                       Mean reward: 822.19
               Mean episode length: 241.74
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.8413
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7397
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 0.15s
                      Time elapsed: 00:05:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 321/1 [0m                       

                       Computation: 619682 steps/s (collection: 0.048s, learning 0.111s)
                       Mean reward: 830.35
               Mean episode length: 241.66
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.5043
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7416
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 0.16s
                      Time elapsed: 00:05:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 322/1 [0m                       

                       Computation: 630030 steps/s (collection: 0.047s, learning 0.110s)
                       Mean reward: 819.40
               Mean episode length: 239.23
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.3296
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7354
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 0.16s
                      Time elapsed: 00:06:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 323/1 [0m                       

                       Computation: 640614 steps/s (collection: 0.047s, learning 0.106s)
                       Mean reward: 839.12
               Mean episode length: 241.77
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.2021
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7448
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 19.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 0.15s
                      Time elapsed: 00:06:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 324/1 [0m                       

                       Computation: 597274 steps/s (collection: 0.047s, learning 0.118s)
                       Mean reward: 831.49
               Mean episode length: 242.52
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.7687
       Episode_Reward/object_height 0.0249
     Episode_Reward/reaching_object 0.7426
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 0.16s
                      Time elapsed: 00:06:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 325/1 [0m                       

                       Computation: 650728 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 828.54
               Mean episode length: 240.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.0721
       Episode_Reward/object_height 0.0255
     Episode_Reward/reaching_object 0.7456
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 0.15s
                      Time elapsed: 00:06:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 326/1 [0m                       

                       Computation: 608527 steps/s (collection: 0.050s, learning 0.112s)
                       Mean reward: 836.89
               Mean episode length: 241.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.6455
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7511
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 0.16s
                      Time elapsed: 00:06:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 327/1 [0m                       

                       Computation: 599292 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 836.76
               Mean episode length: 244.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.1004
       Episode_Reward/object_height 0.0261
     Episode_Reward/reaching_object 0.7491
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 0.16s
                      Time elapsed: 00:06:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 328/1 [0m                       

                       Computation: 719377 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 817.70
               Mean episode length: 240.04
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.2712
       Episode_Reward/object_height 0.0256
     Episode_Reward/reaching_object 0.7247
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 0.14s
                      Time elapsed: 00:06:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 329/1 [0m                       

                       Computation: 776542 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 820.80
               Mean episode length: 241.31
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.5674
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7322
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 0.13s
                      Time elapsed: 00:06:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 330/1 [0m                       

                       Computation: 733059 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 831.66
               Mean episode length: 240.79
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 165.8960
       Episode_Reward/object_height 0.0262
     Episode_Reward/reaching_object 0.7407
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 0.13s
                      Time elapsed: 00:06:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 331/1 [0m                       

                       Computation: 782407 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 800.47
               Mean episode length: 235.55
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 159.1646
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7191
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 0.13s
                      Time elapsed: 00:06:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 332/1 [0m                       

                       Computation: 694393 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 827.12
               Mean episode length: 239.76
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.3732
       Episode_Reward/object_height 0.0261
     Episode_Reward/reaching_object 0.7371
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 0.14s
                      Time elapsed: 00:06:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 333/1 [0m                       

                       Computation: 766817 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 829.23
               Mean episode length: 238.94
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.4856
       Episode_Reward/object_height 0.0263
     Episode_Reward/reaching_object 0.7341
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 0.13s
                      Time elapsed: 00:06:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 334/1 [0m                       

                       Computation: 684761 steps/s (collection: 0.043s, learning 0.101s)
                       Mean reward: 838.56
               Mean episode length: 241.88
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.5796
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7346
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 19.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 0.14s
                      Time elapsed: 00:06:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 335/1 [0m                       

                       Computation: 795568 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 821.19
               Mean episode length: 237.57
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.6233
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7331
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 0.12s
                      Time elapsed: 00:06:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 336/1 [0m                       

                       Computation: 689239 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 842.76
               Mean episode length: 242.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.0310
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7566
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 0.14s
                      Time elapsed: 00:06:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 337/1 [0m                       

                       Computation: 704107 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 834.51
               Mean episode length: 242.56
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.5237
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7499
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 0.14s
                      Time elapsed: 00:06:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 338/1 [0m                       

                       Computation: 785331 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 815.48
               Mean episode length: 239.41
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 162.9446
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7292
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 0.13s
                      Time elapsed: 00:06:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 339/1 [0m                       

                       Computation: 758906 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 826.74
               Mean episode length: 244.23
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.6447
       Episode_Reward/object_height 0.0275
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 0.13s
                      Time elapsed: 00:06:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 340/1 [0m                       

                       Computation: 625614 steps/s (collection: 0.041s, learning 0.117s)
                       Mean reward: 839.00
               Mean episode length: 245.12
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.5369
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 0.16s
                      Time elapsed: 00:06:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 341/1 [0m                       

                       Computation: 786151 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 833.19
               Mean episode length: 241.73
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.4851
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7473
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 0.13s
                      Time elapsed: 00:06:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 342/1 [0m                       

                       Computation: 786207 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 830.13
               Mean episode length: 242.47
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.5326
       Episode_Reward/object_height 0.0281
     Episode_Reward/reaching_object 0.7464
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 0.13s
                      Time elapsed: 00:06:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 343/1 [0m                       

                       Computation: 807413 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 823.61
               Mean episode length: 240.29
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.6227
       Episode_Reward/object_height 0.0281
     Episode_Reward/reaching_object 0.7412
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 0.12s
                      Time elapsed: 00:06:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 344/1 [0m                       

                       Computation: 747073 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 836.05
               Mean episode length: 245.02
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.9205
       Episode_Reward/object_height 0.0285
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 19.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 0.13s
                      Time elapsed: 00:06:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 345/1 [0m                       

                       Computation: 818392 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 814.32
               Mean episode length: 240.90
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 162.2022
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7465
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 0.12s
                      Time elapsed: 00:06:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 346/1 [0m                       

                       Computation: 854151 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 808.99
               Mean episode length: 239.97
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 161.4230
       Episode_Reward/object_height 0.0278
     Episode_Reward/reaching_object 0.7379
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 0.12s
                      Time elapsed: 00:06:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 347/1 [0m                       

                       Computation: 815924 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 823.35
               Mean episode length: 241.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 163.2360
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7457
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 18.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 0.12s
                      Time elapsed: 00:06:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 348/1 [0m                       

                       Computation: 743856 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 818.96
               Mean episode length: 243.74
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 162.7206
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7472
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 0.13s
                      Time elapsed: 00:06:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 349/1 [0m                       

                       Computation: 701222 steps/s (collection: 0.036s, learning 0.105s)
                       Mean reward: 827.83
               Mean episode length: 244.40
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.6816
       Episode_Reward/object_height 0.0278
     Episode_Reward/reaching_object 0.7444
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 0.14s
                      Time elapsed: 00:06:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 350/1 [0m                       

                       Computation: 811289 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 831.81
               Mean episode length: 244.08
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.2658
       Episode_Reward/object_height 0.0281
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 0.12s
                      Time elapsed: 00:06:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 351/1 [0m                       

                       Computation: 758474 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 838.38
               Mean episode length: 245.35
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.4077
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7517
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 0.13s
                      Time elapsed: 00:06:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 352/1 [0m                       

                       Computation: 693594 steps/s (collection: 0.038s, learning 0.104s)
                       Mean reward: 820.99
               Mean episode length: 245.02
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.9441
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7360
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 0.14s
                      Time elapsed: 00:06:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 353/1 [0m                       

                       Computation: 762494 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 821.27
               Mean episode length: 245.33
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.4636
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7377
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 0.13s
                      Time elapsed: 00:06:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 354/1 [0m                       

                       Computation: 723435 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 832.38
               Mean episode length: 242.09
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 166.4616
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7460
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 0.14s
                      Time elapsed: 00:06:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 355/1 [0m                       

                       Computation: 742354 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 846.84
               Mean episode length: 244.10
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 166.9578
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7491
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 20.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 0.13s
                      Time elapsed: 00:06:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 356/1 [0m                       

                       Computation: 757204 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 843.93
               Mean episode length: 243.75
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.3831
       Episode_Reward/object_height 0.0272
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 0.13s
                      Time elapsed: 00:06:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 357/1 [0m                       

                       Computation: 799517 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 858.28
               Mean episode length: 246.59
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.1766
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7773
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 18.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 0.12s
                      Time elapsed: 00:06:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 358/1 [0m                       

                       Computation: 730761 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 857.98
               Mean episode length: 246.08
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.1241
       Episode_Reward/object_height 0.0275
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 0.13s
                      Time elapsed: 00:06:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 359/1 [0m                       

                       Computation: 853345 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 839.84
               Mean episode length: 244.65
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.8109
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7616
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 0.12s
                      Time elapsed: 00:06:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 360/1 [0m                       

                       Computation: 758882 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 829.76
               Mean episode length: 242.73
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 165.4011
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7517
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 0.13s
                      Time elapsed: 00:06:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 361/1 [0m                       

                       Computation: 799728 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 837.52
               Mean episode length: 245.83
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.1740
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7541
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 0.12s
                      Time elapsed: 00:06:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 362/1 [0m                       

                       Computation: 780721 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 779.41
               Mean episode length: 242.27
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 155.6862
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7092
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 0.13s
                      Time elapsed: 00:06:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 363/1 [0m                       

                       Computation: 753295 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 801.20
               Mean episode length: 243.16
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 159.1076
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7251
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 0.13s
                      Time elapsed: 00:06:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 364/1 [0m                       

                       Computation: 754574 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 828.94
               Mean episode length: 245.45
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 165.2539
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7549
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 0.13s
                      Time elapsed: 00:06:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 365/1 [0m                       

                       Computation: 722523 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 815.19
               Mean episode length: 245.15
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 160.4950
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7346
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 18.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 0.14s
                      Time elapsed: 00:06:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 366/1 [0m                       

                       Computation: 759237 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 831.64
               Mean episode length: 244.14
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.2958
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 0.13s
                      Time elapsed: 00:06:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 367/1 [0m                       

                       Computation: 764901 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 828.41
               Mean episode length: 243.10
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 165.2742
       Episode_Reward/object_height 0.0263
     Episode_Reward/reaching_object 0.7535
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 0.13s
                      Time elapsed: 00:06:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 368/1 [0m                       

                       Computation: 761204 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 850.61
               Mean episode length: 245.94
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 169.1173
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 18.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 0.13s
                      Time elapsed: 00:06:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 369/1 [0m                       

                       Computation: 800073 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 849.71
               Mean episode length: 245.20
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 169.0866
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7705
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 0.12s
                      Time elapsed: 00:06:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 370/1 [0m                       

                       Computation: 827412 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 848.01
               Mean episode length: 246.23
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 169.2076
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 0.12s
                      Time elapsed: 00:06:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 371/1 [0m                       

                       Computation: 767512 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 846.57
               Mean episode length: 246.03
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.5647
       Episode_Reward/object_height 0.0262
     Episode_Reward/reaching_object 0.7703
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 0.13s
                      Time elapsed: 00:06:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 372/1 [0m                       

                       Computation: 676545 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 844.32
               Mean episode length: 244.35
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.0865
       Episode_Reward/object_height 0.0260
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 0.15s
                      Time elapsed: 00:06:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 373/1 [0m                       

                       Computation: 766167 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 852.76
               Mean episode length: 244.53
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 169.6813
       Episode_Reward/object_height 0.0261
     Episode_Reward/reaching_object 0.7644
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 0.13s
                      Time elapsed: 00:06:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 374/1 [0m                       

                       Computation: 835275 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 841.93
               Mean episode length: 242.67
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 167.7643
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 0.12s
                      Time elapsed: 00:06:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 375/1 [0m                       

                       Computation: 848870 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 847.60
               Mean episode length: 246.69
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.2350
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7624
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 19.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 0.12s
                      Time elapsed: 00:06:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 376/1 [0m                       

                       Computation: 835688 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 845.53
               Mean episode length: 244.86
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.1127
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 0.12s
                      Time elapsed: 00:06:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 377/1 [0m                       

                       Computation: 815563 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 858.04
               Mean episode length: 246.85
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.7730
       Episode_Reward/object_height 0.0260
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 0.12s
                      Time elapsed: 00:07:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 378/1 [0m                       

                       Computation: 843470 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 831.40
               Mean episode length: 244.41
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 165.9377
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 0.12s
                      Time elapsed: 00:07:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 379/1 [0m                       

                       Computation: 818774 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 825.41
               Mean episode length: 243.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 163.8205
       Episode_Reward/object_height 0.0248
     Episode_Reward/reaching_object 0.7433
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 0.12s
                      Time elapsed: 00:07:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 380/1 [0m                       

                       Computation: 797581 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 837.96
               Mean episode length: 243.25
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 166.1742
       Episode_Reward/object_height 0.0249
     Episode_Reward/reaching_object 0.7493
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 0.12s
                      Time elapsed: 00:07:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 381/1 [0m                       

                       Computation: 604856 steps/s (collection: 0.042s, learning 0.121s)
                       Mean reward: 820.12
               Mean episode length: 242.62
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 163.3467
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7440
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 0.16s
                      Time elapsed: 00:07:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 382/1 [0m                       

                       Computation: 722325 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 839.25
               Mean episode length: 245.80
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 167.6225
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7538
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 0.14s
                      Time elapsed: 00:07:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 383/1 [0m                       

                       Computation: 682618 steps/s (collection: 0.038s, learning 0.106s)
                       Mean reward: 844.42
               Mean episode length: 244.69
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.1014
       Episode_Reward/object_height 0.0248
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 0.14s
                      Time elapsed: 00:07:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 384/1 [0m                       

                       Computation: 777764 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 841.70
               Mean episode length: 245.80
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 167.8715
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 0.13s
                      Time elapsed: 00:07:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 385/1 [0m                       

                       Computation: 782456 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 825.66
               Mean episode length: 244.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 165.0906
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7364
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 0.13s
                      Time elapsed: 00:07:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 386/1 [0m                       

                       Computation: 737275 steps/s (collection: 0.036s, learning 0.097s)
                       Mean reward: 852.42
               Mean episode length: 246.75
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.4727
       Episode_Reward/object_height 0.0251
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 18.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 0.13s
                      Time elapsed: 00:07:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 387/1 [0m                       

                       Computation: 843192 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 843.00
               Mean episode length: 243.80
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 167.7243
       Episode_Reward/object_height 0.0246
     Episode_Reward/reaching_object 0.7541
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 0.12s
                      Time elapsed: 00:07:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 388/1 [0m                       

                       Computation: 762206 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 858.55
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.3108
       Episode_Reward/object_height 0.0251
     Episode_Reward/reaching_object 0.7733
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 0.13s
                      Time elapsed: 00:07:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 389/1 [0m                       

                       Computation: 779883 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 860.17
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.1399
       Episode_Reward/object_height 0.0249
     Episode_Reward/reaching_object 0.7690
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.6250
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 0.13s
                      Time elapsed: 00:07:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 390/1 [0m                       

                       Computation: 750175 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 852.97
               Mean episode length: 244.36
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.1758
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 0.13s
                      Time elapsed: 00:07:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 391/1 [0m                       

                       Computation: 764652 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 844.53
               Mean episode length: 243.88
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.3815
       Episode_Reward/object_height 0.0241
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 0.13s
                      Time elapsed: 00:07:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 392/1 [0m                       

                       Computation: 783357 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 857.09
               Mean episode length: 246.73
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.7339
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 0.13s
                      Time elapsed: 00:07:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 393/1 [0m                       

                       Computation: 715627 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 849.36
               Mean episode length: 244.83
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 169.1729
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 0.14s
                      Time elapsed: 00:07:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 394/1 [0m                       

                       Computation: 816035 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 843.83
               Mean episode length: 242.55
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.0706
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7516
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 0.12s
                      Time elapsed: 00:07:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 395/1 [0m                       

                       Computation: 798930 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 861.53
               Mean episode length: 246.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.2367
       Episode_Reward/object_height 0.0241
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 0.12s
                      Time elapsed: 00:07:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 396/1 [0m                       

                       Computation: 738404 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 855.83
               Mean episode length: 245.94
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.0102
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7635
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 0.13s
                      Time elapsed: 00:07:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 397/1 [0m                       

                       Computation: 780869 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 853.42
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.2442
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 0.13s
                      Time elapsed: 00:07:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 398/1 [0m                       

                       Computation: 704886 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 834.28
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 165.4407
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 0.14s
                      Time elapsed: 00:07:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 399/1 [0m                       

                       Computation: 810162 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 848.10
               Mean episode length: 246.49
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.9216
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 0.12s
                      Time elapsed: 00:07:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 400/1 [0m                       

                       Computation: 697038 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 864.07
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.5588
       Episode_Reward/object_height 0.0241
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 0.14s
                      Time elapsed: 00:07:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 401/1 [0m                       

                       Computation: 841404 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 860.37
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.4297
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 0.12s
                      Time elapsed: 00:07:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 402/1 [0m                       

                       Computation: 664160 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 857.61
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.8949
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 0.15s
                      Time elapsed: 00:07:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 403/1 [0m                       

                       Computation: 741419 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 861.09
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.8274
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 0.13s
                      Time elapsed: 00:07:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 404/1 [0m                       

                       Computation: 822534 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 867.87
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.9516
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7826
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 0.12s
                      Time elapsed: 00:07:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 405/1 [0m                       

                       Computation: 775071 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 861.28
               Mean episode length: 245.99
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.1252
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 0.13s
                      Time elapsed: 00:07:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 406/1 [0m                       

                       Computation: 773920 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 859.17
               Mean episode length: 245.74
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.8558
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 0.13s
                      Time elapsed: 00:07:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 407/1 [0m                       

                       Computation: 765211 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 853.57
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.5206
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 19.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 0.13s
                      Time elapsed: 00:07:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 408/1 [0m                       

                       Computation: 806189 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 858.43
               Mean episode length: 246.04
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.7394
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 0.12s
                      Time elapsed: 00:07:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 409/1 [0m                       

                       Computation: 785796 steps/s (collection: 0.035s, learning 0.090s)
                       Mean reward: 860.31
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.3324
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 0.13s
                      Time elapsed: 00:07:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 410/1 [0m                       

                       Computation: 779244 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 871.76
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 173.5579
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7878
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 0.13s
                      Time elapsed: 00:07:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 411/1 [0m                       

                       Computation: 683329 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 869.44
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 173.0555
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7874
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 0.14s
                      Time elapsed: 00:07:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 412/1 [0m                       

                       Computation: 871237 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 864.52
               Mean episode length: 246.87
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 172.1539
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7840
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 0.11s
                      Time elapsed: 00:07:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 413/1 [0m                       

                       Computation: 807043 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 868.18
               Mean episode length: 247.27
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.0013
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7834
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 0.12s
                      Time elapsed: 00:07:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 414/1 [0m                       

                       Computation: 657516 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 835.42
               Mean episode length: 242.10
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 166.2882
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 0.15s
                      Time elapsed: 00:07:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 415/1 [0m                       

                       Computation: 733452 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 845.25
               Mean episode length: 243.22
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.5122
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 0.13s
                      Time elapsed: 00:07:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 416/1 [0m                       

                       Computation: 709713 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 852.81
               Mean episode length: 245.31
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.1405
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7634
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 0.14s
                      Time elapsed: 00:07:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 417/1 [0m                       

                       Computation: 772714 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 849.22
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.3419
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 17.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 0.13s
                      Time elapsed: 00:07:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 418/1 [0m                       

                       Computation: 746235 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 860.24
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.7120
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 0.13s
                      Time elapsed: 00:07:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 419/1 [0m                       

                       Computation: 725944 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 855.48
               Mean episode length: 246.37
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.2878
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7602
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 0.14s
                      Time elapsed: 00:07:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 420/1 [0m                       

                       Computation: 722599 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 843.38
               Mean episode length: 245.81
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.5450
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7568
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 0.14s
                      Time elapsed: 00:07:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 421/1 [0m                       

                       Computation: 626283 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 844.78
               Mean episode length: 244.78
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.1162
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7505
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 0.16s
                      Time elapsed: 00:07:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 422/1 [0m                       

                       Computation: 612007 steps/s (collection: 0.055s, learning 0.106s)
                       Mean reward: 854.30
               Mean episode length: 245.72
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.8894
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7669
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 0.16s
                      Time elapsed: 00:07:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 423/1 [0m                       

                       Computation: 668509 steps/s (collection: 0.049s, learning 0.098s)
                       Mean reward: 855.63
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.8590
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 0.15s
                      Time elapsed: 00:07:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 424/1 [0m                       

                       Computation: 825832 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 854.65
               Mean episode length: 245.37
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.4864
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7675
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 0.12s
                      Time elapsed: 00:07:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 425/1 [0m                       

                       Computation: 802921 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 853.97
               Mean episode length: 246.07
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.3874
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 0.12s
                      Time elapsed: 00:07:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 426/1 [0m                       

                       Computation: 788890 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 871.26
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.4466
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7904
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 0.12s
                      Time elapsed: 00:07:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 427/1 [0m                       

                       Computation: 791782 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 870.38
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.1707
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 0.12s
                      Time elapsed: 00:07:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 428/1 [0m                       

                       Computation: 846158 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 866.90
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.0959
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 18.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 0.12s
                      Time elapsed: 00:07:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 429/1 [0m                       

                       Computation: 800354 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 855.51
               Mean episode length: 245.13
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.6314
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 0.12s
                      Time elapsed: 00:07:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 430/1 [0m                       

                       Computation: 863896 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 858.26
               Mean episode length: 246.19
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.6940
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 0.11s
                      Time elapsed: 00:07:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 431/1 [0m                       

                       Computation: 862726 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 861.94
               Mean episode length: 246.37
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.5908
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 0.11s
                      Time elapsed: 00:07:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 432/1 [0m                       

                       Computation: 763744 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 870.32
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.3757
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7942
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 0.13s
                      Time elapsed: 00:07:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 433/1 [0m                       

                       Computation: 778586 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 861.27
               Mean episode length: 246.82
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.2892
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 0.13s
                      Time elapsed: 00:08:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 434/1 [0m                       

                       Computation: 787295 steps/s (collection: 0.046s, learning 0.079s)
                       Mean reward: 856.62
               Mean episode length: 245.25
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.1763
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 0.12s
                      Time elapsed: 00:08:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 435/1 [0m                       

                       Computation: 809548 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 860.83
               Mean episode length: 246.15
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.4291
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7831
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 0.12s
                      Time elapsed: 00:08:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 436/1 [0m                       

                       Computation: 809148 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 858.90
               Mean episode length: 245.42
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.1846
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 0.12s
                      Time elapsed: 00:08:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 437/1 [0m                       

                       Computation: 779169 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 859.41
               Mean episode length: 246.17
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.1207
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7788
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 0.13s
                      Time elapsed: 00:08:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 438/1 [0m                       

                       Computation: 757075 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 864.24
               Mean episode length: 246.87
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.3343
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 0.13s
                      Time elapsed: 00:08:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 439/1 [0m                       

                       Computation: 677652 steps/s (collection: 0.038s, learning 0.108s)
                       Mean reward: 862.25
               Mean episode length: 246.93
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.9357
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7798
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 0.15s
                      Time elapsed: 00:08:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 440/1 [0m                       

                       Computation: 624224 steps/s (collection: 0.044s, learning 0.114s)
                       Mean reward: 860.63
               Mean episode length: 246.95
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.4052
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 0.16s
                      Time elapsed: 00:08:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 441/1 [0m                       

                       Computation: 640362 steps/s (collection: 0.039s, learning 0.115s)
                       Mean reward: 859.68
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.1327
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 0.15s
                      Time elapsed: 00:08:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 442/1 [0m                       

                       Computation: 674446 steps/s (collection: 0.037s, learning 0.109s)
                       Mean reward: 872.60
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.6281
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7861
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 0.15s
                      Time elapsed: 00:08:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 443/1 [0m                       

                       Computation: 655147 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 851.01
               Mean episode length: 246.77
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.6306
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 0.15s
                      Time elapsed: 00:08:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 444/1 [0m                       

                       Computation: 661717 steps/s (collection: 0.036s, learning 0.112s)
                       Mean reward: 839.51
               Mean episode length: 245.85
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.1534
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 0.15s
                      Time elapsed: 00:08:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 445/1 [0m                       

                       Computation: 862208 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 859.66
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.4703
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 0.11s
                      Time elapsed: 00:08:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 446/1 [0m                       

                       Computation: 842057 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 861.43
               Mean episode length: 247.02
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.3750
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 0.12s
                      Time elapsed: 00:08:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 447/1 [0m                       

                       Computation: 816396 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 868.73
               Mean episode length: 246.93
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 172.8161
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 0.12s
                      Time elapsed: 00:08:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 448/1 [0m                       

                       Computation: 757571 steps/s (collection: 0.035s, learning 0.094s)
                       Mean reward: 874.01
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 173.5186
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7875
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 0.13s
                      Time elapsed: 00:08:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 449/1 [0m                       

                       Computation: 790448 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 856.62
               Mean episode length: 244.58
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.7273
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 0.12s
                      Time elapsed: 00:08:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 450/1 [0m                       

                       Computation: 795482 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 868.73
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 173.0045
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7784
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 0.12s
                      Time elapsed: 00:08:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 451/1 [0m                       

                       Computation: 743929 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 861.22
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.9447
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 0.13s
                      Time elapsed: 00:08:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 452/1 [0m                       

                       Computation: 740668 steps/s (collection: 0.048s, learning 0.085s)
                       Mean reward: 858.41
               Mean episode length: 245.50
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.5448
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7699
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 0.13s
                      Time elapsed: 00:08:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 453/1 [0m                       

                       Computation: 784322 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 865.31
               Mean episode length: 246.64
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 172.0983
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7771
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 0.13s
                      Time elapsed: 00:08:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 454/1 [0m                       

                       Computation: 746884 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 857.79
               Mean episode length: 246.22
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.4826
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 0.13s
                      Time elapsed: 00:08:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 455/1 [0m                       

                       Computation: 733414 steps/s (collection: 0.052s, learning 0.083s)
                       Mean reward: 850.71
               Mean episode length: 243.75
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.8003
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 0.13s
                      Time elapsed: 00:08:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 456/1 [0m                       

                       Computation: 780075 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 861.62
               Mean episode length: 245.89
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.6896
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 0.13s
                      Time elapsed: 00:08:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 457/1 [0m                       

                       Computation: 835207 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 865.93
               Mean episode length: 246.53
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.7308
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 0.12s
                      Time elapsed: 00:08:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 458/1 [0m                       

                       Computation: 843715 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 847.04
               Mean episode length: 242.99
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.4574
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 0.12s
                      Time elapsed: 00:08:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 459/1 [0m                       

                       Computation: 809019 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 843.79
               Mean episode length: 242.52
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 166.4602
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7542
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 0.12s
                      Time elapsed: 00:08:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 460/1 [0m                       

                       Computation: 778941 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 833.46
               Mean episode length: 240.65
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 166.2687
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7552
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 0.13s
                      Time elapsed: 00:08:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 461/1 [0m                       

                       Computation: 795703 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 837.19
               Mean episode length: 242.16
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 166.8001
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 0.12s
                      Time elapsed: 00:08:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 462/1 [0m                       

                       Computation: 850653 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 844.54
               Mean episode length: 243.33
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.0508
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 0.12s
                      Time elapsed: 00:08:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 463/1 [0m                       

                       Computation: 781243 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 822.15
               Mean episode length: 240.16
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 162.5072
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7398
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 0.13s
                      Time elapsed: 00:08:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 464/1 [0m                       

                       Computation: 779814 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 831.00
               Mean episode length: 244.46
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 165.9533
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7510
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 0.13s
                      Time elapsed: 00:08:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 465/1 [0m                       

                       Computation: 752644 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 820.40
               Mean episode length: 245.97
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.7962
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7492
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 0.13s
                      Time elapsed: 00:08:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 466/1 [0m                       

                       Computation: 775879 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 797.86
               Mean episode length: 244.99
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 158.4238
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7286
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 0.13s
                      Time elapsed: 00:08:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 467/1 [0m                       

                       Computation: 712248 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 820.19
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.3576
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7507
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 0.14s
                      Time elapsed: 00:08:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 468/1 [0m                       

                       Computation: 781236 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 818.77
               Mean episode length: 246.60
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.6119
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7514
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 0.13s
                      Time elapsed: 00:08:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 469/1 [0m                       

                       Computation: 735786 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 829.03
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.7620
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 0.13s
                      Time elapsed: 00:08:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 470/1 [0m                       

                       Computation: 804227 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 845.07
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.2101
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 0.12s
                      Time elapsed: 00:08:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 471/1 [0m                       

                       Computation: 671022 steps/s (collection: 0.037s, learning 0.109s)
                       Mean reward: 849.46
               Mean episode length: 246.69
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.0164
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 0.15s
                      Time elapsed: 00:08:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 472/1 [0m                       

                       Computation: 784804 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 863.57
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1721
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 0.13s
                      Time elapsed: 00:08:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 473/1 [0m                       

                       Computation: 710446 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 865.27
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1852
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7838
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 0.14s
                      Time elapsed: 00:08:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 474/1 [0m                       

                       Computation: 762025 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 865.18
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.2561
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7756
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 0.13s
                      Time elapsed: 00:08:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 475/1 [0m                       

                       Computation: 766119 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 866.31
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1744
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7773
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 0.13s
                      Time elapsed: 00:08:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 476/1 [0m                       

                       Computation: 750674 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 868.92
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.2122
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 0.13s
                      Time elapsed: 00:08:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 477/1 [0m                       

                       Computation: 732047 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 874.87
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.2648
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7787
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 0.13s
                      Time elapsed: 00:08:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 478/1 [0m                       

                       Computation: 749860 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 865.72
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1209
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 0.13s
                      Time elapsed: 00:08:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 479/1 [0m                       

                       Computation: 848346 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 859.16
               Mean episode length: 246.50
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.0452
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 0.12s
                      Time elapsed: 00:08:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 480/1 [0m                       

                       Computation: 800214 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 860.29
               Mean episode length: 246.66
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.1376
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 18.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 0.12s
                      Time elapsed: 00:08:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 481/1 [0m                       

                       Computation: 821968 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 869.43
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.9266
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 0.12s
                      Time elapsed: 00:08:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 482/1 [0m                       

                       Computation: 826087 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 867.29
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.6589
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 0.12s
                      Time elapsed: 00:08:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 483/1 [0m                       

                       Computation: 769292 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 861.74
               Mean episode length: 247.01
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.6636
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 0.13s
                      Time elapsed: 00:08:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 484/1 [0m                       

                       Computation: 830067 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 865.49
               Mean episode length: 247.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.4477
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 0.12s
                      Time elapsed: 00:08:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 485/1 [0m                       

                       Computation: 829679 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 856.46
               Mean episode length: 247.51
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.6058
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7527
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 0.12s
                      Time elapsed: 00:08:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 486/1 [0m                       

                       Computation: 737874 steps/s (collection: 0.036s, learning 0.098s)
                       Mean reward: 860.51
               Mean episode length: 246.16
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.1618
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7598
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 0.13s
                      Time elapsed: 00:08:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 487/1 [0m                       

                       Computation: 781764 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 868.76
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.6860
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 0.13s
                      Time elapsed: 00:08:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 488/1 [0m                       

                       Computation: 720108 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 874.34
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.2294
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7908
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 0.14s
                      Time elapsed: 00:08:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 489/1 [0m                       

                       Computation: 734948 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 871.34
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.7561
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7850
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 0.13s
                      Time elapsed: 00:08:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 490/1 [0m                       

                       Computation: 717634 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 872.32
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.6280
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 0.14s
                      Time elapsed: 00:09:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 491/1 [0m                       

                       Computation: 710801 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 866.88
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.4111
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 0.14s
                      Time elapsed: 00:09:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 492/1 [0m                       

                       Computation: 789106 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 874.70
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.3210
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7920
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 0.12s
                      Time elapsed: 00:09:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 493/1 [0m                       

                       Computation: 753537 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 862.15
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.7868
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7813
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 18.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 0.13s
                      Time elapsed: 00:09:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 494/1 [0m                       

                       Computation: 818785 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 864.24
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.2641
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 0.12s
                      Time elapsed: 00:09:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 495/1 [0m                       

                       Computation: 818846 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 868.12
               Mean episode length: 247.12
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.8553
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7757
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 0.12s
                      Time elapsed: 00:09:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 496/1 [0m                       

                       Computation: 823502 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 858.95
               Mean episode length: 247.01
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.1096
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7635
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 0.12s
                      Time elapsed: 00:09:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 497/1 [0m                       

                       Computation: 758811 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 865.32
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1310
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 0.13s
                      Time elapsed: 00:09:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 498/1 [0m                       

                       Computation: 761804 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 858.36
               Mean episode length: 246.95
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.7219
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 0.13s
                      Time elapsed: 00:09:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 499/1 [0m                       

                       Computation: 686184 steps/s (collection: 0.038s, learning 0.105s)
                       Mean reward: 870.44
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.3939
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 0.14s
                      Time elapsed: 00:09:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 500/1 [0m                       

                       Computation: 721230 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 861.04
               Mean episode length: 246.85
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.6398
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7780
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 0.14s
                      Time elapsed: 00:09:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 501/1 [0m                       

                       Computation: 682404 steps/s (collection: 0.037s, learning 0.107s)
                       Mean reward: 866.71
               Mean episode length: 247.08
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1583
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7869
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 0.14s
                      Time elapsed: 00:09:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 502/1 [0m                       

                       Computation: 668457 steps/s (collection: 0.037s, learning 0.110s)
                       Mean reward: 861.45
               Mean episode length: 246.10
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.4869
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 0.15s
                      Time elapsed: 00:09:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 503/1 [0m                       

                       Computation: 679637 steps/s (collection: 0.038s, learning 0.106s)
                       Mean reward: 852.24
               Mean episode length: 245.15
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.7264
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7679
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 0.14s
                      Time elapsed: 00:09:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 504/1 [0m                       

                       Computation: 802388 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 864.12
               Mean episode length: 246.16
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.0650
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 0.12s
                      Time elapsed: 00:09:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 505/1 [0m                       

                       Computation: 801669 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 866.10
               Mean episode length: 246.58
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.4979
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 0.12s
                      Time elapsed: 00:09:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 506/1 [0m                       

                       Computation: 771688 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 851.33
               Mean episode length: 244.29
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.7241
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7699
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 0.13s
                      Time elapsed: 00:09:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 507/1 [0m                       

                       Computation: 792601 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 855.40
               Mean episode length: 245.07
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.1363
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 0.12s
                      Time elapsed: 00:09:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 508/1 [0m                       

                       Computation: 778063 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 846.46
               Mean episode length: 243.75
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.0600
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 0.13s
                      Time elapsed: 00:09:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 509/1 [0m                       

                       Computation: 813471 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 844.90
               Mean episode length: 242.66
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.9658
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 0.12s
                      Time elapsed: 00:09:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 510/1 [0m                       

                       Computation: 733945 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 853.76
               Mean episode length: 244.85
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.7648
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 0.13s
                      Time elapsed: 00:09:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 511/1 [0m                       

                       Computation: 749673 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 851.92
               Mean episode length: 244.97
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.5130
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 0.13s
                      Time elapsed: 00:09:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 512/1 [0m                       

                       Computation: 715254 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 857.70
               Mean episode length: 245.46
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.0036
       Episode_Reward/object_height 0.0241
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 0.14s
                      Time elapsed: 00:09:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 513/1 [0m                       

                       Computation: 714225 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 858.94
               Mean episode length: 246.09
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.4674
       Episode_Reward/object_height 0.0241
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 0.14s
                      Time elapsed: 00:09:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 514/1 [0m                       

                       Computation: 734230 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 861.11
               Mean episode length: 245.85
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.2175
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 0.13s
                      Time elapsed: 00:09:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 515/1 [0m                       

                       Computation: 572671 steps/s (collection: 0.042s, learning 0.130s)
                       Mean reward: 860.20
               Mean episode length: 245.93
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.3843
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 0.17s
                      Time elapsed: 00:09:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 516/1 [0m                       

                       Computation: 614227 steps/s (collection: 0.046s, learning 0.115s)
                       Mean reward: 856.86
               Mean episode length: 246.15
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.5743
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7755
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 0.16s
                      Time elapsed: 00:09:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 517/1 [0m                       

                       Computation: 652707 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 856.88
               Mean episode length: 245.50
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.7138
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 0.15s
                      Time elapsed: 00:09:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 518/1 [0m                       

                       Computation: 608823 steps/s (collection: 0.048s, learning 0.113s)
                       Mean reward: 851.43
               Mean episode length: 243.74
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.9834
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 0.16s
                      Time elapsed: 00:09:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 519/1 [0m                       

                       Computation: 604828 steps/s (collection: 0.052s, learning 0.111s)
                       Mean reward: 851.76
               Mean episode length: 244.71
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.3399
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 0.16s
                      Time elapsed: 00:09:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 520/1 [0m                       

                       Computation: 657696 steps/s (collection: 0.047s, learning 0.103s)
                       Mean reward: 850.37
               Mean episode length: 244.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.9116
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7651
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 0.15s
                      Time elapsed: 00:09:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 521/1 [0m                       

                       Computation: 642472 steps/s (collection: 0.047s, learning 0.106s)
                       Mean reward: 846.63
               Mean episode length: 244.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9876
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7544
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 0.15s
                      Time elapsed: 00:09:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 522/1 [0m                       

                       Computation: 578153 steps/s (collection: 0.049s, learning 0.121s)
                       Mean reward: 846.76
               Mean episode length: 245.10
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.2603
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7634
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 0.17s
                      Time elapsed: 00:09:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 523/1 [0m                       

                       Computation: 524327 steps/s (collection: 0.052s, learning 0.135s)
                       Mean reward: 847.83
               Mean episode length: 246.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.7271
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 0.19s
                      Time elapsed: 00:09:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 524/1 [0m                       

                       Computation: 613762 steps/s (collection: 0.049s, learning 0.111s)
                       Mean reward: 843.51
               Mean episode length: 245.48
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.1638
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 0.16s
                      Time elapsed: 00:09:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 525/1 [0m                       

                       Computation: 538483 steps/s (collection: 0.050s, learning 0.133s)
                       Mean reward: 843.16
               Mean episode length: 245.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.6013
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7756
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 0.18s
                      Time elapsed: 00:09:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 526/1 [0m                       

                       Computation: 648768 steps/s (collection: 0.045s, learning 0.107s)
                       Mean reward: 826.39
               Mean episode length: 243.01
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.5446
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 0.15s
                      Time elapsed: 00:09:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 527/1 [0m                       

                       Computation: 629687 steps/s (collection: 0.042s, learning 0.115s)
                       Mean reward: 828.48
               Mean episode length: 242.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.6479
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 0.16s
                      Time elapsed: 00:09:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 528/1 [0m                       

                       Computation: 661889 steps/s (collection: 0.049s, learning 0.100s)
                       Mean reward: 841.74
               Mean episode length: 245.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.2732
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7624
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 0.15s
                      Time elapsed: 00:09:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 529/1 [0m                       

                       Computation: 600887 steps/s (collection: 0.048s, learning 0.116s)
                       Mean reward: 821.82
               Mean episode length: 241.10
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.8940
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7504
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 0.16s
                      Time elapsed: 00:09:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 530/1 [0m                       

                       Computation: 623133 steps/s (collection: 0.046s, learning 0.112s)
                       Mean reward: 839.75
               Mean episode length: 244.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.0104
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 0.16s
                      Time elapsed: 00:09:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 531/1 [0m                       

                       Computation: 653987 steps/s (collection: 0.049s, learning 0.101s)
                       Mean reward: 836.13
               Mean episode length: 242.66
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.7394
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 0.15s
                      Time elapsed: 00:09:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 532/1 [0m                       

                       Computation: 616181 steps/s (collection: 0.051s, learning 0.109s)
                       Mean reward: 837.95
               Mean episode length: 243.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.2597
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7543
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 0.16s
                      Time elapsed: 00:09:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 533/1 [0m                       

                       Computation: 600996 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 829.24
               Mean episode length: 241.73
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.2213
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 0.16s
                      Time elapsed: 00:09:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 534/1 [0m                       

                       Computation: 616033 steps/s (collection: 0.046s, learning 0.114s)
                       Mean reward: 840.91
               Mean episode length: 243.61
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.3133
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 0.16s
                      Time elapsed: 00:09:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 535/1 [0m                       

                       Computation: 770766 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 856.06
               Mean episode length: 245.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.3132
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 0.13s
                      Time elapsed: 00:09:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 536/1 [0m                       

                       Computation: 613805 steps/s (collection: 0.052s, learning 0.108s)
                       Mean reward: 830.82
               Mean episode length: 243.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.5450
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7554
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 0.16s
                      Time elapsed: 00:09:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 537/1 [0m                       

                       Computation: 796207 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 849.23
               Mean episode length: 246.32
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2019
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 0.12s
                      Time elapsed: 00:09:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 538/1 [0m                       

                       Computation: 663950 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 835.61
               Mean episode length: 244.95
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.1882
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7648
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 0.15s
                      Time elapsed: 00:09:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 539/1 [0m                       

                       Computation: 799156 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 835.58
               Mean episode length: 245.43
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.2774
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7654
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 0.12s
                      Time elapsed: 00:09:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 540/1 [0m                       

                       Computation: 741690 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 818.30
               Mean episode length: 243.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.1834
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 0.13s
                      Time elapsed: 00:09:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 541/1 [0m                       

                       Computation: 844593 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 802.34
               Mean episode length: 241.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.7168
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7313
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 0.12s
                      Time elapsed: 00:09:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 542/1 [0m                       

                       Computation: 824576 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 827.98
               Mean episode length: 244.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.3684
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7508
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 0.12s
                      Time elapsed: 00:10:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 543/1 [0m                       

                       Computation: 822140 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 817.18
               Mean episode length: 241.85
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.8179
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7426
Episode_Termination/object_dropping 1.9583
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 0.12s
                      Time elapsed: 00:10:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 544/1 [0m                       

                       Computation: 755055 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 817.24
               Mean episode length: 242.97
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.1055
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 0.13s
                      Time elapsed: 00:10:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 545/1 [0m                       

                       Computation: 818761 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 840.32
               Mean episode length: 244.21
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.7232
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 0.12s
                      Time elapsed: 00:10:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 546/1 [0m                       

                       Computation: 776520 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 844.62
               Mean episode length: 243.04
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.7215
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 0.13s
                      Time elapsed: 00:10:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 547/1 [0m                       

                       Computation: 816071 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 843.29
               Mean episode length: 243.40
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.9641
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 0.12s
                      Time elapsed: 00:10:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 548/1 [0m                       

                       Computation: 779680 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 849.42
               Mean episode length: 243.18
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2149
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7756
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 0.13s
                      Time elapsed: 00:10:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 549/1 [0m                       

                       Computation: 754045 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 827.33
               Mean episode length: 238.91
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.7265
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7576
Episode_Termination/object_dropping 2.2500
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 0.13s
                      Time elapsed: 00:10:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 550/1 [0m                       

                       Computation: 789349 steps/s (collection: 0.047s, learning 0.078s)
                       Mean reward: 835.42
               Mean episode length: 242.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.8082
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 0.12s
                      Time elapsed: 00:10:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 551/1 [0m                       

                       Computation: 799156 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 842.55
               Mean episode length: 243.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.4429
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7703
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 0.12s
                      Time elapsed: 00:10:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 552/1 [0m                       

                       Computation: 795895 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 836.41
               Mean episode length: 243.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.0558
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7716
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 0.12s
                      Time elapsed: 00:10:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 553/1 [0m                       

                       Computation: 655263 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 848.54
               Mean episode length: 244.25
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.9276
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7730
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 0.15s
                      Time elapsed: 00:10:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 554/1 [0m                       

                       Computation: 595536 steps/s (collection: 0.037s, learning 0.128s)
                       Mean reward: 841.17
               Mean episode length: 243.38
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.9641
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7689
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 0.17s
                      Time elapsed: 00:10:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 555/1 [0m                       

                       Computation: 626034 steps/s (collection: 0.037s, learning 0.120s)
                       Mean reward: 839.49
               Mean episode length: 241.90
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.5739
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7654
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 0.16s
                      Time elapsed: 00:10:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 556/1 [0m                       

                       Computation: 702228 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 838.12
               Mean episode length: 244.93
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.7297
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7620
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 0.14s
                      Time elapsed: 00:10:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 557/1 [0m                       

                       Computation: 653712 steps/s (collection: 0.046s, learning 0.104s)
                       Mean reward: 831.26
               Mean episode length: 245.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.6481
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7600
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 0.15s
                      Time elapsed: 00:10:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 558/1 [0m                       

                       Computation: 680708 steps/s (collection: 0.038s, learning 0.106s)
                       Mean reward: 816.03
               Mean episode length: 244.78
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.7713
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 0.14s
                      Time elapsed: 00:10:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 559/1 [0m                       

                       Computation: 803590 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 790.96
               Mean episode length: 240.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.6964
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7291
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 0.12s
                      Time elapsed: 00:10:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 560/1 [0m                       

                       Computation: 767799 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 800.79
               Mean episode length: 243.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 159.7155
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7356
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 0.13s
                      Time elapsed: 00:10:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 561/1 [0m                       

                       Computation: 689581 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 808.34
               Mean episode length: 242.24
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 160.8462
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7398
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 0.14s
                      Time elapsed: 00:10:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 562/1 [0m                       

                       Computation: 799618 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 815.09
               Mean episode length: 239.26
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 161.6368
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7320
Episode_Termination/object_dropping 1.9167
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 0.12s
                      Time elapsed: 00:10:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 563/1 [0m                       

                       Computation: 812575 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 803.29
               Mean episode length: 238.17
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 159.0996
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7221
Episode_Termination/object_dropping 2.7917
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 0.12s
                      Time elapsed: 00:10:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 564/1 [0m                       

                       Computation: 762596 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 823.08
               Mean episode length: 241.02
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.7262
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7421
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 0.13s
                      Time elapsed: 00:10:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 565/1 [0m                       

                       Computation: 723512 steps/s (collection: 0.047s, learning 0.089s)
                       Mean reward: 824.07
               Mean episode length: 239.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.0512
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7368
Episode_Termination/object_dropping 2.6667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 0.14s
                      Time elapsed: 00:10:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 566/1 [0m                       

                       Computation: 756214 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 834.44
               Mean episode length: 241.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.5793
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7530
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 0.13s
                      Time elapsed: 00:10:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 567/1 [0m                       

                       Computation: 768485 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 830.27
               Mean episode length: 240.12
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.6063
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7492
Episode_Termination/object_dropping 2.1250
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 0.13s
                      Time elapsed: 00:10:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 568/1 [0m                       

                       Computation: 736826 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 844.56
               Mean episode length: 243.02
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.7098
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7688
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 0.13s
                      Time elapsed: 00:10:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 569/1 [0m                       

                       Computation: 799105 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 843.22
               Mean episode length: 241.62
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.0796
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7676
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 0.12s
                      Time elapsed: 00:10:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 570/1 [0m                       

                       Computation: 850955 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 826.06
               Mean episode length: 238.18
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.8821
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 2.7083
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 0.12s
                      Time elapsed: 00:10:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 571/1 [0m                       

                       Computation: 783105 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 834.38
               Mean episode length: 240.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.5738
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 2.4583
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 0.13s
                      Time elapsed: 00:10:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 572/1 [0m                       

                       Computation: 788404 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 832.66
               Mean episode length: 240.03
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.8698
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7490
Episode_Termination/object_dropping 2.3333
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 0.12s
                      Time elapsed: 00:10:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 573/1 [0m                       

                       Computation: 853635 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 839.87
               Mean episode length: 243.54
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.3391
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 0.12s
                      Time elapsed: 00:10:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 574/1 [0m                       

                       Computation: 785818 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 832.21
               Mean episode length: 240.63
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.7467
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7578
Episode_Termination/object_dropping 2.3333
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 0.13s
                      Time elapsed: 00:10:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 575/1 [0m                       

                       Computation: 843684 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 829.95
               Mean episode length: 240.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.9958
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7549
Episode_Termination/object_dropping 2.0417
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 0.12s
                      Time elapsed: 00:10:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 576/1 [0m                       

                       Computation: 710041 steps/s (collection: 0.049s, learning 0.089s)
                       Mean reward: 840.20
               Mean episode length: 242.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.8318
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 0.14s
                      Time elapsed: 00:10:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 577/1 [0m                       

                       Computation: 778147 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 841.94
               Mean episode length: 242.53
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.7030
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 0.13s
                      Time elapsed: 00:10:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 578/1 [0m                       

                       Computation: 744322 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 825.49
               Mean episode length: 239.63
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.7552
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7493
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 0.13s
                      Time elapsed: 00:10:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 579/1 [0m                       

                       Computation: 743760 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 842.34
               Mean episode length: 242.07
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.2122
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 0.13s
                      Time elapsed: 00:10:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 580/1 [0m                       

                       Computation: 779460 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 842.07
               Mean episode length: 242.25
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.2470
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 0.13s
                      Time elapsed: 00:10:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 581/1 [0m                       

                       Computation: 704739 steps/s (collection: 0.046s, learning 0.094s)
                       Mean reward: 852.18
               Mean episode length: 243.97
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7333
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 1.9583
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 0.14s
                      Time elapsed: 00:10:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 582/1 [0m                       

                       Computation: 707072 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 837.59
               Mean episode length: 242.54
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.4866
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 0.14s
                      Time elapsed: 00:10:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 583/1 [0m                       

                       Computation: 785875 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 851.44
               Mean episode length: 244.27
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.4932
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 0.13s
                      Time elapsed: 00:10:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 584/1 [0m                       

                       Computation: 661851 steps/s (collection: 0.039s, learning 0.110s)
                       Mean reward: 860.43
               Mean episode length: 245.58
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.2414
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 0.15s
                      Time elapsed: 00:10:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 585/1 [0m                       

                       Computation: 701396 steps/s (collection: 0.036s, learning 0.104s)
                       Mean reward: 854.48
               Mean episode length: 246.12
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9476
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 0.14s
                      Time elapsed: 00:10:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 586/1 [0m                       

                       Computation: 693115 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 848.58
               Mean episode length: 245.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.5374
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7624
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 0.14s
                      Time elapsed: 00:10:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 587/1 [0m                       

                       Computation: 634123 steps/s (collection: 0.039s, learning 0.117s)
                       Mean reward: 839.24
               Mean episode length: 243.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.5421
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7559
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 0.16s
                      Time elapsed: 00:10:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 588/1 [0m                       

                       Computation: 766851 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 868.68
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1173
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7897
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 0.13s
                      Time elapsed: 00:10:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 589/1 [0m                       

                       Computation: 737999 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 848.45
               Mean episode length: 245.79
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1160
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 0.13s
                      Time elapsed: 00:10:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 590/1 [0m                       

                       Computation: 736441 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 848.11
               Mean episode length: 244.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.8761
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 0.13s
                      Time elapsed: 00:10:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 591/1 [0m                       

                       Computation: 799244 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 854.24
               Mean episode length: 246.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.0038
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 0.12s
                      Time elapsed: 00:10:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 592/1 [0m                       

                       Computation: 822337 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 850.03
               Mean episode length: 244.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.1815
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 0.12s
                      Time elapsed: 00:10:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 593/1 [0m                       

                       Computation: 816572 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 838.11
               Mean episode length: 242.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.2968
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 0.12s
                      Time elapsed: 00:10:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 594/1 [0m                       

                       Computation: 799883 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 852.51
               Mean episode length: 245.12
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.5639
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 0.12s
                      Time elapsed: 00:10:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 595/1 [0m                       

                       Computation: 765203 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 853.19
               Mean episode length: 244.97
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.5424
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 0.13s
                      Time elapsed: 00:10:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 596/1 [0m                       

                       Computation: 778467 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 852.19
               Mean episode length: 244.65
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.8172
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 0.13s
                      Time elapsed: 00:10:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 597/1 [0m                       

                       Computation: 727636 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 853.67
               Mean episode length: 245.25
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.8298
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 0.14s
                      Time elapsed: 00:10:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 598/1 [0m                       

                       Computation: 704261 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 849.57
               Mean episode length: 245.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.5214
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 0.14s
                      Time elapsed: 00:11:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 599/1 [0m                       

                       Computation: 847298 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 859.83
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8950
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7827
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 0.12s
                      Time elapsed: 00:11:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 600/1 [0m                       

                       Computation: 709529 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 861.24
               Mean episode length: 246.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.2953
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7846
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 0.14s
                      Time elapsed: 00:11:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 601/1 [0m                       

                       Computation: 708789 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 856.54
               Mean episode length: 245.44
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8327
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 0.14s
                      Time elapsed: 00:11:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 602/1 [0m                       

                       Computation: 733513 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 858.94
               Mean episode length: 246.24
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.2266
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7870
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 0.13s
                      Time elapsed: 00:11:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 603/1 [0m                       

                       Computation: 715973 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 858.88
               Mean episode length: 246.49
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.1095
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7859
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 0.14s
                      Time elapsed: 00:11:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 604/1 [0m                       

                       Computation: 699329 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 863.40
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8308
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 0.14s
                      Time elapsed: 00:11:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 605/1 [0m                       

                       Computation: 862252 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 860.47
               Mean episode length: 247.03
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9289
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 0.11s
                      Time elapsed: 00:11:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 606/1 [0m                       

                       Computation: 783245 steps/s (collection: 0.047s, learning 0.079s)
                       Mean reward: 861.62
               Mean episode length: 247.07
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8445
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7859
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 0.13s
                      Time elapsed: 00:11:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 607/1 [0m                       

                       Computation: 767129 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 865.26
               Mean episode length: 246.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3919
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7846
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 0.13s
                      Time elapsed: 00:11:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 608/1 [0m                       

                       Computation: 815672 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 853.35
               Mean episode length: 245.04
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1876
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 0.12s
                      Time elapsed: 00:11:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 609/1 [0m                       

                       Computation: 808940 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 858.94
               Mean episode length: 245.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.3245
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 0.12s
                      Time elapsed: 00:11:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 610/1 [0m                       

                       Computation: 837494 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 856.94
               Mean episode length: 245.61
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.7589
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 0.12s
                      Time elapsed: 00:11:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 611/1 [0m                       

                       Computation: 739447 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 865.18
               Mean episode length: 247.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9629
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 0.13s
                      Time elapsed: 00:11:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 612/1 [0m                       

                       Computation: 754087 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 863.68
               Mean episode length: 246.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8533
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7812
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 0.13s
                      Time elapsed: 00:11:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 613/1 [0m                       

                       Computation: 731046 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 851.25
               Mean episode length: 244.36
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.2944
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 0.13s
                      Time elapsed: 00:11:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 614/1 [0m                       

                       Computation: 715171 steps/s (collection: 0.036s, learning 0.101s)
                       Mean reward: 838.40
               Mean episode length: 244.45
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.9989
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7563
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 0.14s
                      Time elapsed: 00:11:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 615/1 [0m                       

                       Computation: 739987 steps/s (collection: 0.035s, learning 0.098s)
                       Mean reward: 843.83
               Mean episode length: 243.55
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.2593
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 0.13s
                      Time elapsed: 00:11:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 616/1 [0m                       

                       Computation: 765788 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 831.22
               Mean episode length: 241.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.8480
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7560
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 0.13s
                      Time elapsed: 00:11:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 617/1 [0m                       

                       Computation: 759531 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 849.54
               Mean episode length: 243.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.8647
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 0.13s
                      Time elapsed: 00:11:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 618/1 [0m                       

                       Computation: 797072 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 852.79
               Mean episode length: 244.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.1429
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7783
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 0.12s
                      Time elapsed: 00:11:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 619/1 [0m                       

                       Computation: 840636 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 853.79
               Mean episode length: 244.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.0465
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 0.12s
                      Time elapsed: 00:11:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 620/1 [0m                       

                       Computation: 771792 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 840.26
               Mean episode length: 242.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.6516
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7411
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 0.13s
                      Time elapsed: 00:11:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 621/1 [0m                       

                       Computation: 779170 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 822.75
               Mean episode length: 239.24
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.3785
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7182
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 0.13s
                      Time elapsed: 00:11:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 622/1 [0m                       

                       Computation: 783732 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 836.56
               Mean episode length: 243.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.4788
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7394
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 0.13s
                      Time elapsed: 00:11:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 623/1 [0m                       

                       Computation: 724513 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 817.00
               Mean episode length: 240.55
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 162.6341
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7170
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 0.14s
                      Time elapsed: 00:11:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 624/1 [0m                       

                       Computation: 698826 steps/s (collection: 0.035s, learning 0.105s)
                       Mean reward: 815.38
               Mean episode length: 238.91
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 162.3896
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7056
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 0.14s
                      Time elapsed: 00:11:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 625/1 [0m                       

                       Computation: 691994 steps/s (collection: 0.037s, learning 0.106s)
                       Mean reward: 826.37
               Mean episode length: 242.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.7470
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7238
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 0.14s
                      Time elapsed: 00:11:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 626/1 [0m                       

                       Computation: 755175 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 853.08
               Mean episode length: 245.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.0323
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7461
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 0.13s
                      Time elapsed: 00:11:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 627/1 [0m                       

                       Computation: 740755 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 829.46
               Mean episode length: 241.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 164.9672
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7188
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 0.13s
                      Time elapsed: 00:11:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 628/1 [0m                       

                       Computation: 761828 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 831.57
               Mean episode length: 242.62
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 166.2849
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7144
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 0.13s
                      Time elapsed: 00:11:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 629/1 [0m                       

                       Computation: 776914 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 832.41
               Mean episode length: 242.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 165.2025
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7064
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 0.13s
                      Time elapsed: 00:11:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 630/1 [0m                       

                       Computation: 841689 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 820.60
               Mean episode length: 240.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 162.9085
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7049
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 0.12s
                      Time elapsed: 00:11:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 631/1 [0m                       

                       Computation: 835735 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 845.30
               Mean episode length: 245.34
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 167.8485
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7282
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 0.12s
                      Time elapsed: 00:11:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 632/1 [0m                       

                       Computation: 845948 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 851.01
               Mean episode length: 246.31
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 169.3259
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7425
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 0.12s
                      Time elapsed: 00:11:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 633/1 [0m                       

                       Computation: 830371 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 850.53
               Mean episode length: 246.86
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 169.6220
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7368
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 0.12s
                      Time elapsed: 00:11:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 634/1 [0m                       

                       Computation: 827787 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 860.36
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.2249
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7450
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 0.12s
                      Time elapsed: 00:11:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 635/1 [0m                       

                       Computation: 834879 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 862.18
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.2448
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7513
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 0.12s
                      Time elapsed: 00:11:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 636/1 [0m                       

                       Computation: 813871 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 863.06
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.6597
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7557
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 0.12s
                      Time elapsed: 00:11:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 637/1 [0m                       

                       Computation: 797893 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 873.60
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 174.0230
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7620
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 0.12s
                      Time elapsed: 00:11:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 638/1 [0m                       

                       Computation: 831547 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 874.07
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 174.2429
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 0.12s
                      Time elapsed: 00:11:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 639/1 [0m                       

                       Computation: 822083 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 874.60
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 174.1684
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 0.12s
                      Time elapsed: 00:11:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 640/1 [0m                       

                       Computation: 724570 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 876.43
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 174.6603
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 0.14s
                      Time elapsed: 00:11:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 641/1 [0m                       

                       Computation: 711477 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 866.13
               Mean episode length: 246.99
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 172.9558
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7736
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 0.14s
                      Time elapsed: 00:11:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 642/1 [0m                       

                       Computation: 699319 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 869.92
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 173.1336
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 0.14s
                      Time elapsed: 00:11:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 643/1 [0m                       

                       Computation: 725425 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 875.71
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 174.2427
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7961
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 0.14s
                      Time elapsed: 00:11:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 644/1 [0m                       

                       Computation: 697743 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 869.31
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 172.7048
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7796
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 0.14s
                      Time elapsed: 00:11:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 645/1 [0m                       

                       Computation: 739530 steps/s (collection: 0.036s, learning 0.097s)
                       Mean reward: 875.41
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 174.2292
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7905
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 0.13s
                      Time elapsed: 00:11:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 646/1 [0m                       

                       Computation: 630084 steps/s (collection: 0.047s, learning 0.110s)
                       Mean reward: 873.63
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 173.6876
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7834
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 0.16s
                      Time elapsed: 00:11:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 647/1 [0m                       

                       Computation: 770799 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 871.30
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 173.3070
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7821
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 0.13s
                      Time elapsed: 00:11:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 648/1 [0m                       

                       Computation: 738874 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 880.92
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 175.2302
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7937
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 0.13s
                      Time elapsed: 00:11:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 649/1 [0m                       

                       Computation: 784251 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 863.96
               Mean episode length: 247.09
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1916
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7894
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 0.13s
                      Time elapsed: 00:11:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 650/1 [0m                       

                       Computation: 783532 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 879.27
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 175.0301
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7977
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 0.13s
                      Time elapsed: 00:11:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 651/1 [0m                       

                       Computation: 746776 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 866.92
               Mean episode length: 246.07
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 172.9474
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7941
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 0.13s
                      Time elapsed: 00:11:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 652/1 [0m                       

                       Computation: 724315 steps/s (collection: 0.047s, learning 0.089s)
                       Mean reward: 869.57
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.4518
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7988
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 0.14s
                      Time elapsed: 00:11:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 653/1 [0m                       

                       Computation: 659037 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 872.62
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.6309
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7962
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 0.15s
                      Time elapsed: 00:11:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 654/1 [0m                       

                       Computation: 706822 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 863.90
               Mean episode length: 247.02
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1301
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 0.14s
                      Time elapsed: 00:11:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 655/1 [0m                       

                       Computation: 779122 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 880.23
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.9874
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7909
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 0.13s
                      Time elapsed: 00:12:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 656/1 [0m                       

                       Computation: 767765 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 874.25
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.0748
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7935
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 0.13s
                      Time elapsed: 00:12:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 657/1 [0m                       

                       Computation: 730024 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 871.01
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.2915
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7942
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 18.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 0.13s
                      Time elapsed: 00:12:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 658/1 [0m                       

                       Computation: 681019 steps/s (collection: 0.036s, learning 0.109s)
                       Mean reward: 872.69
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.1814
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 0.14s
                      Time elapsed: 00:12:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 659/1 [0m                       

                       Computation: 746773 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 879.64
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.8314
       Episode_Reward/object_height 0.0241
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 0.13s
                      Time elapsed: 00:12:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 660/1 [0m                       

                       Computation: 767009 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 869.62
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.0755
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7671
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 0.13s
                      Time elapsed: 00:12:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 661/1 [0m                       

                       Computation: 752916 steps/s (collection: 0.035s, learning 0.096s)
                       Mean reward: 869.10
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.8016
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 0.13s
                      Time elapsed: 00:12:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 662/1 [0m                       

                       Computation: 829197 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 873.70
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.0235
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7836
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 0.12s
                      Time elapsed: 00:12:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 663/1 [0m                       

                       Computation: 798850 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 873.98
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.8981
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7847
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 0.12s
                      Time elapsed: 00:12:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 664/1 [0m                       

                       Computation: 744164 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 863.81
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1144
       Episode_Reward/object_height 0.0241
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 0.13s
                      Time elapsed: 00:12:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 665/1 [0m                       

                       Computation: 888943 steps/s (collection: 0.037s, learning 0.074s)
                       Mean reward: 864.33
               Mean episode length: 246.62
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.3157
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7756
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 0.11s
                      Time elapsed: 00:12:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 666/1 [0m                       

                       Computation: 805438 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 873.42
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.4354
       Episode_Reward/object_height 0.0246
     Episode_Reward/reaching_object 0.7967
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 0.12s
                      Time elapsed: 00:12:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 667/1 [0m                       

                       Computation: 848516 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 873.06
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.0042
       Episode_Reward/object_height 0.0246
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 0.12s
                      Time elapsed: 00:12:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 668/1 [0m                       

                       Computation: 843290 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 870.38
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.4378
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7805
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 0.12s
                      Time elapsed: 00:12:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 669/1 [0m                       

                       Computation: 782585 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 867.28
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.9689
       Episode_Reward/object_height 0.0246
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 0.13s
                      Time elapsed: 00:12:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 670/1 [0m                       

                       Computation: 836245 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 865.56
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.9704
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 0.12s
                      Time elapsed: 00:12:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 671/1 [0m                       

                       Computation: 758670 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 864.28
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.8186
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7798
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 0.13s
                      Time elapsed: 00:12:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 672/1 [0m                       

                       Computation: 749916 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 856.36
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.7097
       Episode_Reward/object_height 0.0246
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 0.13s
                      Time elapsed: 00:12:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 673/1 [0m                       

                       Computation: 704090 steps/s (collection: 0.048s, learning 0.091s)
                       Mean reward: 855.61
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.6892
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 0.14s
                      Time elapsed: 00:12:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 674/1 [0m                       

                       Computation: 761403 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 860.44
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.9250
       Episode_Reward/object_height 0.0249
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 0.13s
                      Time elapsed: 00:12:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 675/1 [0m                       

                       Computation: 802338 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 875.20
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.1426
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7821
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 0.12s
                      Time elapsed: 00:12:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 676/1 [0m                       

                       Computation: 815358 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 873.30
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.6475
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7903
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 0.12s
                      Time elapsed: 00:12:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 677/1 [0m                       

                       Computation: 753003 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 871.13
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.3665
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7835
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 0.13s
                      Time elapsed: 00:12:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 678/1 [0m                       

                       Computation: 724569 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 866.66
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.6419
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 18.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 0.14s
                      Time elapsed: 00:12:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 679/1 [0m                       

                       Computation: 785480 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 861.03
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.3657
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7673
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 0.13s
                      Time elapsed: 00:12:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 680/1 [0m                       

                       Computation: 829142 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 850.26
               Mean episode length: 246.92
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.8067
       Episode_Reward/object_height 0.0249
     Episode_Reward/reaching_object 0.7581
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 0.12s
                      Time elapsed: 00:12:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 681/1 [0m                       

                       Computation: 795117 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 861.30
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.9462
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 0.12s
                      Time elapsed: 00:12:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 682/1 [0m                       

                       Computation: 711815 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 843.32
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.9030
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7491
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 0.14s
                      Time elapsed: 00:12:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 683/1 [0m                       

                       Computation: 798260 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 831.92
               Mean episode length: 245.38
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.9068
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7299
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 0.12s
                      Time elapsed: 00:12:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 684/1 [0m                       

                       Computation: 716971 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 836.14
               Mean episode length: 247.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.6765
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7441
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 0.14s
                      Time elapsed: 00:12:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 685/1 [0m                       

                       Computation: 708206 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 843.18
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.3986
       Episode_Reward/object_height 0.0246
     Episode_Reward/reaching_object 0.7506
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 0.14s
                      Time elapsed: 00:12:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 686/1 [0m                       

                       Computation: 725425 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 836.67
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.5111
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7548
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 0.14s
                      Time elapsed: 00:12:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 687/1 [0m                       

                       Computation: 641152 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 793.05
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 156.9548
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7367
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 0.15s
                      Time elapsed: 00:12:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 688/1 [0m                       

                       Computation: 765186 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 709.51
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 141.1216
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.6858
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 0.13s
                      Time elapsed: 00:12:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 689/1 [0m                       

                       Computation: 765126 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 709.35
               Mean episode length: 247.18
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 142.0541
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.6842
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 0.13s
                      Time elapsed: 00:12:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 690/1 [0m                       

                       Computation: 789497 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 789.38
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 155.8756
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7378
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 0.12s
                      Time elapsed: 00:12:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 691/1 [0m                       

                       Computation: 823028 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 816.92
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 162.0990
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7524
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 0.12s
                      Time elapsed: 00:12:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 692/1 [0m                       

                       Computation: 786352 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 809.14
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 161.9878
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 0.13s
                      Time elapsed: 00:12:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 693/1 [0m                       

                       Computation: 857580 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 812.27
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 160.9569
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7484
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 0.11s
                      Time elapsed: 00:12:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 694/1 [0m                       

                       Computation: 747281 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 836.35
               Mean episode length: 246.79
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.3627
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 0.13s
                      Time elapsed: 00:12:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 695/1 [0m                       

                       Computation: 747041 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 854.60
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.8606
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 0.13s
                      Time elapsed: 00:12:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 696/1 [0m                       

                       Computation: 822856 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 847.58
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.2176
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7737
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 0.12s
                      Time elapsed: 00:12:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 697/1 [0m                       

                       Computation: 851639 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 830.82
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 165.7445
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 0.12s
                      Time elapsed: 00:12:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 698/1 [0m                       

                       Computation: 757938 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 842.18
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.6901
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 0.13s
                      Time elapsed: 00:12:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 699/1 [0m                       

                       Computation: 781361 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 853.08
               Mean episode length: 246.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.1114
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 0.13s
                      Time elapsed: 00:12:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 700/1 [0m                       

                       Computation: 745627 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 851.41
               Mean episode length: 246.90
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.4591
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 0.13s
                      Time elapsed: 00:12:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 701/1 [0m                       

                       Computation: 742118 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 856.27
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.3944
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 0.13s
                      Time elapsed: 00:12:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 702/1 [0m                       

                       Computation: 735355 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 844.68
               Mean episode length: 245.99
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.3931
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7481
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 0.13s
                      Time elapsed: 00:12:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 703/1 [0m                       

                       Computation: 741698 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 857.40
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.2908
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7669
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 0.13s
                      Time elapsed: 00:12:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 704/1 [0m                       

                       Computation: 791363 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 862.02
               Mean episode length: 247.28
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.6605
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 0.12s
                      Time elapsed: 00:12:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 705/1 [0m                       

                       Computation: 664061 steps/s (collection: 0.037s, learning 0.111s)
                       Mean reward: 840.62
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.4180
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7414
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 0.15s
                      Time elapsed: 00:12:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 706/1 [0m                       

                       Computation: 805668 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 832.38
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.4580
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7332
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 18.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 0.12s
                      Time elapsed: 00:12:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 707/1 [0m                       

                       Computation: 683727 steps/s (collection: 0.039s, learning 0.105s)
                       Mean reward: 855.21
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.0161
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 0.14s
                      Time elapsed: 00:12:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 708/1 [0m                       

                       Computation: 822444 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 852.03
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0301
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7624
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 0.12s
                      Time elapsed: 00:12:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 709/1 [0m                       

                       Computation: 616243 steps/s (collection: 0.058s, learning 0.102s)
                       Mean reward: 864.12
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.0318
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7630
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 0.16s
                      Time elapsed: 00:12:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 710/1 [0m                       

                       Computation: 784334 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 868.81
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7825
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 0.13s
                      Time elapsed: 00:12:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 711/1 [0m                       

                       Computation: 805238 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 860.04
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5535
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 0.12s
                      Time elapsed: 00:13:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 712/1 [0m                       

                       Computation: 802202 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 860.58
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7527
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 0.12s
                      Time elapsed: 00:13:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 713/1 [0m                       

                       Computation: 787698 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 860.86
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4893
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7733
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 0.12s
                      Time elapsed: 00:13:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 714/1 [0m                       

                       Computation: 769211 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 853.36
               Mean episode length: 246.59
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.4610
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 0.13s
                      Time elapsed: 00:13:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 715/1 [0m                       

                       Computation: 858308 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 859.99
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.9493
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 0.11s
                      Time elapsed: 00:13:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 716/1 [0m                       

                       Computation: 816470 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 855.35
               Mean episode length: 246.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.2197
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 0.12s
                      Time elapsed: 00:13:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 717/1 [0m                       

                       Computation: 849577 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 849.97
               Mean episode length: 245.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.2808
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 0.12s
                      Time elapsed: 00:13:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 718/1 [0m                       

                       Computation: 780283 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 839.96
               Mean episode length: 244.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.1888
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 0.13s
                      Time elapsed: 00:13:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 719/1 [0m                       

                       Computation: 776950 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 854.88
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8131
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 0.13s
                      Time elapsed: 00:13:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 720/1 [0m                       

                       Computation: 734996 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 843.97
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.0819
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7456
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 0.13s
                      Time elapsed: 00:13:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 721/1 [0m                       

                       Computation: 776406 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 847.59
               Mean episode length: 246.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.3475
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7442
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 0.13s
                      Time elapsed: 00:13:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 722/1 [0m                       

                       Computation: 744477 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 849.03
               Mean episode length: 247.34
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.8057
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7526
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 0.13s
                      Time elapsed: 00:13:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 723/1 [0m                       

                       Computation: 799074 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 830.89
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.4967
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7469
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 0.12s
                      Time elapsed: 00:13:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 724/1 [0m                       

                       Computation: 845845 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 816.77
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.6205
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7190
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 0.12s
                      Time elapsed: 00:13:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 725/1 [0m                       

                       Computation: 806132 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 782.44
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 155.9294
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7031
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 0.12s
                      Time elapsed: 00:13:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 726/1 [0m                       

                       Computation: 824294 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 834.84
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.7353
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7360
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 0.12s
                      Time elapsed: 00:13:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 727/1 [0m                       

                       Computation: 862872 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 856.69
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5377
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7539
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 0.11s
                      Time elapsed: 00:13:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 728/1 [0m                       

                       Computation: 829366 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 854.69
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.4188
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 0.12s
                      Time elapsed: 00:13:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 729/1 [0m                       

                       Computation: 753719 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 857.37
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8814
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7596
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 0.13s
                      Time elapsed: 00:13:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 730/1 [0m                       

                       Computation: 712048 steps/s (collection: 0.036s, learning 0.102s)
                       Mean reward: 859.16
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8189
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 0.14s
                      Time elapsed: 00:13:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 731/1 [0m                       

                       Computation: 749615 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 861.40
               Mean episode length: 246.92
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4240
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 0.13s
                      Time elapsed: 00:13:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 732/1 [0m                       

                       Computation: 804155 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 867.80
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8998
       Episode_Reward/object_height 0.0255
     Episode_Reward/reaching_object 0.7909
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 0.12s
                      Time elapsed: 00:13:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 733/1 [0m                       

                       Computation: 742519 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 869.44
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.6668
       Episode_Reward/object_height 0.0255
     Episode_Reward/reaching_object 0.7851
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 0.13s
                      Time elapsed: 00:13:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 734/1 [0m                       

                       Computation: 716989 steps/s (collection: 0.048s, learning 0.089s)
                       Mean reward: 868.32
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.1753
       Episode_Reward/object_height 0.0256
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 0.14s
                      Time elapsed: 00:13:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 735/1 [0m                       

                       Computation: 693519 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 868.58
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7654
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7917
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 0.14s
                      Time elapsed: 00:13:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 736/1 [0m                       

                       Computation: 768188 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 864.71
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7610
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7842
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 0.13s
                      Time elapsed: 00:13:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 737/1 [0m                       

                       Computation: 800495 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 866.11
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7740
       Episode_Reward/object_height 0.0263
     Episode_Reward/reaching_object 0.7824
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 18.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 0.12s
                      Time elapsed: 00:13:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 738/1 [0m                       

                       Computation: 767416 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 870.23
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.9442
       Episode_Reward/object_height 0.0263
     Episode_Reward/reaching_object 0.7873
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 0.13s
                      Time elapsed: 00:13:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 739/1 [0m                       

                       Computation: 811027 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 866.41
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3722
       Episode_Reward/object_height 0.0264
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 0.12s
                      Time elapsed: 00:13:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 740/1 [0m                       

                       Computation: 784882 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 870.62
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3569
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 0.13s
                      Time elapsed: 00:13:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 741/1 [0m                       

                       Computation: 820007 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 863.94
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7655
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 0.12s
                      Time elapsed: 00:13:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 742/1 [0m                       

                       Computation: 763930 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 870.20
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4488
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7743
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 0.13s
                      Time elapsed: 00:13:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 743/1 [0m                       

                       Computation: 709715 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 876.89
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5798
       Episode_Reward/object_height 0.0272
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 0.14s
                      Time elapsed: 00:13:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 744/1 [0m                       

                       Computation: 758987 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 870.46
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.3030
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 0.13s
                      Time elapsed: 00:13:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 745/1 [0m                       

                       Computation: 742260 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 872.88
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.9753
       Episode_Reward/object_height 0.0272
     Episode_Reward/reaching_object 0.7875
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 0.13s
                      Time elapsed: 00:13:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 746/1 [0m                       

                       Computation: 855280 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 863.45
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1062
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7845
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 0.11s
                      Time elapsed: 00:13:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 747/1 [0m                       

                       Computation: 677866 steps/s (collection: 0.045s, learning 0.100s)
                       Mean reward: 874.41
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8426
       Episode_Reward/object_height 0.0273
     Episode_Reward/reaching_object 0.7933
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 0.15s
                      Time elapsed: 00:13:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 748/1 [0m                       

                       Computation: 837832 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 863.06
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.8368
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 0.12s
                      Time elapsed: 00:13:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 749/1 [0m                       

                       Computation: 818512 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 878.81
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.0189
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7898
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 0.12s
                      Time elapsed: 00:13:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 750/1 [0m                       

                       Computation: 835347 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 864.70
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4131
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7782
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 0.12s
                      Time elapsed: 00:13:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 751/1 [0m                       

                       Computation: 769190 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 866.23
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4630
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 0.13s
                      Time elapsed: 00:13:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 752/1 [0m                       

                       Computation: 734297 steps/s (collection: 0.035s, learning 0.099s)
                       Mean reward: 876.25
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.2943
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7895
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 0.13s
                      Time elapsed: 00:13:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 753/1 [0m                       

                       Computation: 797314 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 868.51
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0615
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 0.12s
                      Time elapsed: 00:13:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 754/1 [0m                       

                       Computation: 836366 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 862.77
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.0016
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7838
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 0.12s
                      Time elapsed: 00:13:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 755/1 [0m                       

                       Computation: 796719 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 873.87
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0289
       Episode_Reward/object_height 0.0273
     Episode_Reward/reaching_object 0.7953
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 0.12s
                      Time elapsed: 00:13:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 756/1 [0m                       

                       Computation: 799145 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 872.70
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1105
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7871
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 0.12s
                      Time elapsed: 00:13:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 757/1 [0m                       

                       Computation: 775781 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 872.53
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6812
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7912
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 0.13s
                      Time elapsed: 00:13:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 758/1 [0m                       

                       Computation: 761996 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 875.18
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0457
       Episode_Reward/object_height 0.0261
     Episode_Reward/reaching_object 0.7912
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 0.13s
                      Time elapsed: 00:13:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 759/1 [0m                       

                       Computation: 707595 steps/s (collection: 0.036s, learning 0.103s)
                       Mean reward: 870.33
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.4220
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7916
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 0.14s
                      Time elapsed: 00:13:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 760/1 [0m                       

                       Computation: 732359 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 872.29
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.8247
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 0.13s
                      Time elapsed: 00:13:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 761/1 [0m                       

                       Computation: 719333 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 873.99
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2370
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7924
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 0.14s
                      Time elapsed: 00:13:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 762/1 [0m                       

                       Computation: 774731 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 867.72
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.9829
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7863
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 0.13s
                      Time elapsed: 00:13:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 763/1 [0m                       

                       Computation: 756796 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 867.34
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5036
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7876
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 0.13s
                      Time elapsed: 00:13:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 764/1 [0m                       

                       Computation: 845344 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 865.28
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1045
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7869
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 0.12s
                      Time elapsed: 00:13:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 765/1 [0m                       

                       Computation: 781975 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 861.33
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4352
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7910
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 0.13s
                      Time elapsed: 00:13:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 766/1 [0m                       

                       Computation: 721999 steps/s (collection: 0.036s, learning 0.100s)
                       Mean reward: 856.11
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.2034
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7821
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 0.14s
                      Time elapsed: 00:13:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 767/1 [0m                       

                       Computation: 718378 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 836.10
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.7140
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 0.14s
                      Time elapsed: 00:13:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 768/1 [0m                       

                       Computation: 698548 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 856.08
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5912
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7908
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 0.14s
                      Time elapsed: 00:14:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 769/1 [0m                       

                       Computation: 733687 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 845.84
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.0649
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7870
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 0.13s
                      Time elapsed: 00:14:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 770/1 [0m                       

                       Computation: 701367 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 847.22
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0343
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7866
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 0.14s
                      Time elapsed: 00:14:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 771/1 [0m                       

                       Computation: 761998 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 848.38
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.7692
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7906
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 0.13s
                      Time elapsed: 00:14:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 772/1 [0m                       

                       Computation: 826768 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 851.53
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.5669
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7887
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 0.12s
                      Time elapsed: 00:14:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 773/1 [0m                       

                       Computation: 798018 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 844.61
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.4605
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7875
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 0.12s
                      Time elapsed: 00:14:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 774/1 [0m                       

                       Computation: 736080 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 857.87
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0589
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7905
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 0.13s
                      Time elapsed: 00:14:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 775/1 [0m                       

                       Computation: 792292 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 859.17
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.8604
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7933
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 0.12s
                      Time elapsed: 00:14:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 776/1 [0m                       

                       Computation: 789655 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 863.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.2520
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7897
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 0.12s
                      Time elapsed: 00:14:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 777/1 [0m                       

                       Computation: 852678 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 852.81
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.4370
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 0.12s
                      Time elapsed: 00:14:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 778/1 [0m                       

                       Computation: 675226 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 866.32
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4319
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7912
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 0.15s
                      Time elapsed: 00:14:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 779/1 [0m                       

                       Computation: 798648 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 868.11
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8880
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7894
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 0.12s
                      Time elapsed: 00:14:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 780/1 [0m                       

                       Computation: 773212 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 867.87
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.9261
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7935
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 0.13s
                      Time elapsed: 00:14:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 781/1 [0m                       

                       Computation: 870101 steps/s (collection: 0.036s, learning 0.077s)
                       Mean reward: 861.83
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.5851
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 0.11s
                      Time elapsed: 00:14:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 782/1 [0m                       

                       Computation: 756509 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 865.07
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1116
       Episode_Reward/object_height 0.0242
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 0.13s
                      Time elapsed: 00:14:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 783/1 [0m                       

                       Computation: 791539 steps/s (collection: 0.044s, learning 0.080s)
                       Mean reward: 870.29
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2584
       Episode_Reward/object_height 0.0246
     Episode_Reward/reaching_object 0.7893
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 0.12s
                      Time elapsed: 00:14:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 784/1 [0m                       

                       Computation: 755971 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 864.02
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.4769
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7852
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 0.13s
                      Time elapsed: 00:14:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 785/1 [0m                       

                       Computation: 810752 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 866.70
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7717
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7885
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 0.12s
                      Time elapsed: 00:14:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 786/1 [0m                       

                       Computation: 667042 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 865.05
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1993
       Episode_Reward/object_height 0.0251
     Episode_Reward/reaching_object 0.7845
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 0.15s
                      Time elapsed: 00:14:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 787/1 [0m                       

                       Computation: 783190 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 863.74
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.8237
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7845
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 0.13s
                      Time elapsed: 00:14:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 788/1 [0m                       

                       Computation: 552087 steps/s (collection: 0.053s, learning 0.126s)
                       Mean reward: 866.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2288
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 0.18s
                      Time elapsed: 00:14:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 789/1 [0m                       

                       Computation: 628281 steps/s (collection: 0.044s, learning 0.112s)
                       Mean reward: 863.51
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.7799
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 0.16s
                      Time elapsed: 00:14:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 790/1 [0m                       

                       Computation: 749498 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 863.31
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.8307
       Episode_Reward/object_height 0.0256
     Episode_Reward/reaching_object 0.7844
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 0.13s
                      Time elapsed: 00:14:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 791/1 [0m                       

                       Computation: 762894 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 852.89
               Mean episode length: 247.34
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.2756
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 0.13s
                      Time elapsed: 00:14:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 792/1 [0m                       

                       Computation: 785335 steps/s (collection: 0.044s, learning 0.082s)
                       Mean reward: 863.53
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1378
       Episode_Reward/object_height 0.0257
     Episode_Reward/reaching_object 0.7869
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 0.13s
                      Time elapsed: 00:14:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 793/1 [0m                       

                       Computation: 690979 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 856.62
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.6583
       Episode_Reward/object_height 0.0257
     Episode_Reward/reaching_object 0.7771
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 0.14s
                      Time elapsed: 00:14:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 794/1 [0m                       

                       Computation: 753778 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 858.57
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.6430
       Episode_Reward/object_height 0.0257
     Episode_Reward/reaching_object 0.7757
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 0.13s
                      Time elapsed: 00:14:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 795/1 [0m                       

                       Computation: 819363 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 868.04
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7437
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7884
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 0.12s
                      Time elapsed: 00:14:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 796/1 [0m                       

                       Computation: 804061 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 860.01
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1641
       Episode_Reward/object_height 0.0257
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 0.12s
                      Time elapsed: 00:14:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 797/1 [0m                       

                       Computation: 789597 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 863.18
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.5473
       Episode_Reward/object_height 0.0256
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 0.12s
                      Time elapsed: 00:14:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 798/1 [0m                       

                       Computation: 805361 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 852.83
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.6547
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 0.12s
                      Time elapsed: 00:14:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 799/1 [0m                       

                       Computation: 825946 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 853.19
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.1995
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 0.12s
                      Time elapsed: 00:14:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 800/1 [0m                       

                       Computation: 631861 steps/s (collection: 0.039s, learning 0.117s)
                       Mean reward: 859.69
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.9074
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7755
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 0.16s
                      Time elapsed: 00:14:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 801/1 [0m                       

                       Computation: 692284 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 844.85
               Mean episode length: 247.08
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.7680
       Episode_Reward/object_height 0.0251
     Episode_Reward/reaching_object 0.7648
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 0.14s
                      Time elapsed: 00:14:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 802/1 [0m                       

                       Computation: 788591 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 849.08
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0691
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 0.12s
                      Time elapsed: 00:14:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 803/1 [0m                       

                       Computation: 590104 steps/s (collection: 0.048s, learning 0.119s)
                       Mean reward: 845.23
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.9229
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 0.17s
                      Time elapsed: 00:14:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 804/1 [0m                       

                       Computation: 742049 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 849.84
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1377
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 0.13s
                      Time elapsed: 00:14:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 805/1 [0m                       

                       Computation: 706148 steps/s (collection: 0.045s, learning 0.095s)
                       Mean reward: 837.50
               Mean episode length: 247.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.6202
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 0.14s
                      Time elapsed: 00:14:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 806/1 [0m                       

                       Computation: 811161 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 821.28
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 162.6392
       Episode_Reward/object_height 0.0248
     Episode_Reward/reaching_object 0.7589
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 0.12s
                      Time elapsed: 00:14:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 807/1 [0m                       

                       Computation: 854618 steps/s (collection: 0.038s, learning 0.078s)
                       Mean reward: 825.22
               Mean episode length: 245.96
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 164.5372
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7630
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 0.12s
                      Time elapsed: 00:14:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 808/1 [0m                       

                       Computation: 854992 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 835.86
               Mean episode length: 247.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.5094
       Episode_Reward/object_height 0.0257
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 0.11s
                      Time elapsed: 00:14:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 809/1 [0m                       

                       Computation: 801332 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 837.09
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.0859
       Episode_Reward/object_height 0.0256
     Episode_Reward/reaching_object 0.7662
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 0.12s
                      Time elapsed: 00:14:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 810/1 [0m                       

                       Computation: 738815 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 845.53
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.2330
       Episode_Reward/object_height 0.0260
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 0.13s
                      Time elapsed: 00:14:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 811/1 [0m                       

                       Computation: 635939 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 842.43
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.5841
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 0.15s
                      Time elapsed: 00:14:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 812/1 [0m                       

                       Computation: 638143 steps/s (collection: 0.045s, learning 0.110s)
                       Mean reward: 851.28
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8249
       Episode_Reward/object_height 0.0260
     Episode_Reward/reaching_object 0.7778
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 0.15s
                      Time elapsed: 00:14:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 813/1 [0m                       

                       Computation: 648779 steps/s (collection: 0.048s, learning 0.104s)
                       Mean reward: 849.34
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.9234
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 0.15s
                      Time elapsed: 00:14:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 814/1 [0m                       

                       Computation: 634040 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 851.65
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.6316
       Episode_Reward/object_height 0.0260
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 0.16s
                      Time elapsed: 00:14:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 815/1 [0m                       

                       Computation: 621854 steps/s (collection: 0.046s, learning 0.112s)
                       Mean reward: 852.14
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3568
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 0.16s
                      Time elapsed: 00:14:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 816/1 [0m                       

                       Computation: 576264 steps/s (collection: 0.047s, learning 0.124s)
                       Mean reward: 837.20
               Mean episode length: 246.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.3479
       Episode_Reward/object_height 0.0257
     Episode_Reward/reaching_object 0.7583
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 0.17s
                      Time elapsed: 00:14:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 817/1 [0m                       

                       Computation: 634338 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 851.17
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.6054
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7754
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 0.15s
                      Time elapsed: 00:14:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 818/1 [0m                       

                       Computation: 724677 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 845.63
               Mean episode length: 246.95
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.5848
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7706
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 0.14s
                      Time elapsed: 00:14:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 819/1 [0m                       

                       Computation: 796438 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 854.49
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.1954
       Episode_Reward/object_height 0.0261
     Episode_Reward/reaching_object 0.7736
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 0.12s
                      Time elapsed: 00:14:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 820/1 [0m                       

                       Computation: 675175 steps/s (collection: 0.038s, learning 0.108s)
                       Mean reward: 836.43
               Mean episode length: 246.40
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.5656
       Episode_Reward/object_height 0.0256
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 0.15s
                      Time elapsed: 00:14:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 821/1 [0m                       

                       Computation: 599796 steps/s (collection: 0.039s, learning 0.125s)
                       Mean reward: 853.78
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7191
       Episode_Reward/object_height 0.0260
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 0.16s
                      Time elapsed: 00:14:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 822/1 [0m                       

                       Computation: 771004 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 849.97
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0613
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 0.13s
                      Time elapsed: 00:14:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 823/1 [0m                       

                       Computation: 659556 steps/s (collection: 0.045s, learning 0.105s)
                       Mean reward: 849.79
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.8881
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 0.15s
                      Time elapsed: 00:15:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 824/1 [0m                       

                       Computation: 776232 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 845.62
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.2506
       Episode_Reward/object_height 0.0255
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 0.13s
                      Time elapsed: 00:15:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 825/1 [0m                       

                       Computation: 710481 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 853.87
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7769
       Episode_Reward/object_height 0.0256
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 0.14s
                      Time elapsed: 00:15:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 826/1 [0m                       

                       Computation: 656432 steps/s (collection: 0.053s, learning 0.097s)
                       Mean reward: 843.81
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.9054
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 0.15s
                      Time elapsed: 00:15:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 827/1 [0m                       

                       Computation: 786178 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 846.66
               Mean episode length: 246.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.6713
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7730
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 0.13s
                      Time elapsed: 00:15:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 828/1 [0m                       

                       Computation: 702169 steps/s (collection: 0.048s, learning 0.092s)
                       Mean reward: 857.88
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.9100
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7811
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 0.14s
                      Time elapsed: 00:15:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 829/1 [0m                       

                       Computation: 832467 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 851.04
               Mean episode length: 247.74
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1777
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 0.12s
                      Time elapsed: 00:15:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 830/1 [0m                       

                       Computation: 778548 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 849.82
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3087
       Episode_Reward/object_height 0.0249
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 0.13s
                      Time elapsed: 00:15:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 831/1 [0m                       

                       Computation: 764460 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 848.71
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.9972
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 0.13s
                      Time elapsed: 00:15:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 832/1 [0m                       

                       Computation: 839031 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 848.69
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.4707
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 0.12s
                      Time elapsed: 00:15:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 833/1 [0m                       

                       Computation: 773917 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 831.85
               Mean episode length: 245.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.6328
       Episode_Reward/object_height 0.0242
     Episode_Reward/reaching_object 0.7582
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 0.13s
                      Time elapsed: 00:15:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 834/1 [0m                       

                       Computation: 750207 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 837.27
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.1184
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 0.13s
                      Time elapsed: 00:15:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 835/1 [0m                       

                       Computation: 744525 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 841.22
               Mean episode length: 246.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.6890
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 0.13s
                      Time elapsed: 00:15:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 836/1 [0m                       

                       Computation: 728561 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 838.02
               Mean episode length: 246.42
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.0103
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7668
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 0.13s
                      Time elapsed: 00:15:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 837/1 [0m                       

                       Computation: 716244 steps/s (collection: 0.048s, learning 0.089s)
                       Mean reward: 836.00
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.3356
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 0.14s
                      Time elapsed: 00:15:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 838/1 [0m                       

                       Computation: 757039 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 836.99
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.1440
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 0.13s
                      Time elapsed: 00:15:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 839/1 [0m                       

                       Computation: 786207 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 841.89
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.4176
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 0.13s
                      Time elapsed: 00:15:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 840/1 [0m                       

                       Computation: 795559 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 839.62
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.1722
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7687
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 0.12s
                      Time elapsed: 00:15:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 841/1 [0m                       

                       Computation: 789408 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 834.48
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.1037
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7634
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 0.12s
                      Time elapsed: 00:15:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 842/1 [0m                       

                       Computation: 794400 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 835.61
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.4091
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7592
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 0.12s
                      Time elapsed: 00:15:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 843/1 [0m                       

                       Computation: 792491 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 840.95
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.0115
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7561
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 0.12s
                      Time elapsed: 00:15:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 844/1 [0m                       

                       Computation: 802680 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 846.98
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.6708
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 0.12s
                      Time elapsed: 00:15:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 845/1 [0m                       

                       Computation: 744995 steps/s (collection: 0.048s, learning 0.084s)
                       Mean reward: 846.46
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.6082
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 0.13s
                      Time elapsed: 00:15:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 846/1 [0m                       

                       Computation: 700228 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 852.57
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.6152
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 0.14s
                      Time elapsed: 00:15:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 847/1 [0m                       

                       Computation: 800074 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 843.42
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.9765
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 0.12s
                      Time elapsed: 00:15:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 848/1 [0m                       

                       Computation: 774746 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 841.60
               Mean episode length: 246.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.3363
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 0.13s
                      Time elapsed: 00:15:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 849/1 [0m                       

                       Computation: 754936 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 848.85
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.5360
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7818
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 0.13s
                      Time elapsed: 00:15:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 850/1 [0m                       

                       Computation: 717920 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 837.99
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.5273
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 0.14s
                      Time elapsed: 00:15:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 851/1 [0m                       

                       Computation: 782959 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 847.37
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.5955
       Episode_Reward/object_height 0.0238
     Episode_Reward/reaching_object 0.7796
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 0.13s
                      Time elapsed: 00:15:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 852/1 [0m                       

                       Computation: 785313 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 845.71
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.4057
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 0.13s
                      Time elapsed: 00:15:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 853/1 [0m                       

                       Computation: 799080 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 847.75
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.7499
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 0.12s
                      Time elapsed: 00:15:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 854/1 [0m                       

                       Computation: 750506 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 846.19
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.9192
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 0.13s
                      Time elapsed: 00:15:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 855/1 [0m                       

                       Computation: 758045 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 846.93
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.3965
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 0.13s
                      Time elapsed: 00:15:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 856/1 [0m                       

                       Computation: 644563 steps/s (collection: 0.045s, learning 0.108s)
                       Mean reward: 841.64
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.5592
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7784
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 0.15s
                      Time elapsed: 00:15:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 857/1 [0m                       

                       Computation: 720001 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 843.47
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.5110
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 0.14s
                      Time elapsed: 00:15:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 858/1 [0m                       

                       Computation: 660947 steps/s (collection: 0.049s, learning 0.100s)
                       Mean reward: 852.86
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9510
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7855
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 0.15s
                      Time elapsed: 00:15:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 859/1 [0m                       

                       Computation: 756821 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 853.11
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9585
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 0.13s
                      Time elapsed: 00:15:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 860/1 [0m                       

                       Computation: 678604 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 854.01
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.2217
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 0.14s
                      Time elapsed: 00:15:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 861/1 [0m                       

                       Computation: 750074 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 845.48
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.1180
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 0.13s
                      Time elapsed: 00:15:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 862/1 [0m                       

                       Computation: 724193 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 857.06
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.6094
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7833
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 0.14s
                      Time elapsed: 00:15:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 863/1 [0m                       

                       Computation: 674149 steps/s (collection: 0.037s, learning 0.109s)
                       Mean reward: 851.41
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.5783
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7835
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 0.15s
                      Time elapsed: 00:15:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 864/1 [0m                       

                       Computation: 564870 steps/s (collection: 0.058s, learning 0.116s)
                       Mean reward: 846.30
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.3997
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 0.17s
                      Time elapsed: 00:15:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 865/1 [0m                       

                       Computation: 812282 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 848.75
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.7206
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7788
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 0.12s
                      Time elapsed: 00:15:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 866/1 [0m                       

                       Computation: 826173 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 853.31
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8431
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 0.12s
                      Time elapsed: 00:15:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 867/1 [0m                       

                       Computation: 836612 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 846.47
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.7802
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 0.12s
                      Time elapsed: 00:15:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 868/1 [0m                       

                       Computation: 748914 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 842.08
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.6674
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7589
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 0.13s
                      Time elapsed: 00:15:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 869/1 [0m                       

                       Computation: 785576 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 846.79
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.9407
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 0.13s
                      Time elapsed: 00:15:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 870/1 [0m                       

                       Computation: 799134 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 846.99
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.6921
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 0.12s
                      Time elapsed: 00:15:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 871/1 [0m                       

                       Computation: 791241 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 839.54
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.3418
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7516
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 0.12s
                      Time elapsed: 00:15:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 872/1 [0m                       

                       Computation: 863678 steps/s (collection: 0.036s, learning 0.077s)
                       Mean reward: 851.15
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.6569
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 0.11s
                      Time elapsed: 00:15:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 873/1 [0m                       

                       Computation: 760237 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 852.87
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8371
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 0.13s
                      Time elapsed: 00:15:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 874/1 [0m                       

                       Computation: 812635 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 855.16
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.1387
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 0.12s
                      Time elapsed: 00:15:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 875/1 [0m                       

                       Computation: 826534 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 846.26
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.6534
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 0.12s
                      Time elapsed: 00:15:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 876/1 [0m                       

                       Computation: 712669 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 850.06
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0447
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 0.14s
                      Time elapsed: 00:15:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 877/1 [0m                       

                       Computation: 837155 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 850.98
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3389
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 0.12s
                      Time elapsed: 00:15:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 878/1 [0m                       

                       Computation: 704570 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 851.93
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.2889
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 0.14s
                      Time elapsed: 00:15:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 879/1 [0m                       

                       Computation: 854907 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 843.87
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.0776
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 0.11s
                      Time elapsed: 00:16:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 880/1 [0m                       

                       Computation: 757695 steps/s (collection: 0.035s, learning 0.094s)
                       Mean reward: 857.98
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.8103
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7716
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 0.13s
                      Time elapsed: 00:16:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 881/1 [0m                       

                       Computation: 734807 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 846.56
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.0362
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 0.13s
                      Time elapsed: 00:16:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 882/1 [0m                       

                       Computation: 777274 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 837.27
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.2815
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 0.13s
                      Time elapsed: 00:16:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 883/1 [0m                       

                       Computation: 724885 steps/s (collection: 0.047s, learning 0.089s)
                       Mean reward: 848.14
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0995
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 0.14s
                      Time elapsed: 00:16:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 884/1 [0m                       

                       Computation: 718939 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 848.01
               Mean episode length: 247.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.6626
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 0.14s
                      Time elapsed: 00:16:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 885/1 [0m                       

                       Computation: 683359 steps/s (collection: 0.039s, learning 0.105s)
                       Mean reward: 842.61
               Mean episode length: 247.51
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.9818
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 0.14s
                      Time elapsed: 00:16:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 886/1 [0m                       

                       Computation: 797020 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 852.13
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9976
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 0.12s
                      Time elapsed: 00:16:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 887/1 [0m                       

                       Computation: 733351 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 849.95
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0998
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 0.13s
                      Time elapsed: 00:16:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 888/1 [0m                       

                       Computation: 722910 steps/s (collection: 0.036s, learning 0.100s)
                       Mean reward: 854.15
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.0466
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7669
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 0.14s
                      Time elapsed: 00:16:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 889/1 [0m                       

                       Computation: 823196 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 850.53
               Mean episode length: 247.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3522
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7651
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 0.12s
                      Time elapsed: 00:16:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 890/1 [0m                       

                       Computation: 719007 steps/s (collection: 0.053s, learning 0.084s)
                       Mean reward: 849.66
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1932
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 0.14s
                      Time elapsed: 00:16:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 891/1 [0m                       

                       Computation: 789742 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 843.36
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.0590
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 0.12s
                      Time elapsed: 00:16:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 892/1 [0m                       

                       Computation: 802791 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 858.97
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.9804
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 0.12s
                      Time elapsed: 00:16:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 893/1 [0m                       

                       Computation: 842374 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 852.70
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.5389
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 0.12s
                      Time elapsed: 00:16:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 894/1 [0m                       

                       Computation: 841914 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 853.56
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8816
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 0.12s
                      Time elapsed: 00:16:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 895/1 [0m                       

                       Computation: 826877 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 845.97
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.2520
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7609
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 0.12s
                      Time elapsed: 00:16:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 896/1 [0m                       

                       Computation: 827373 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 854.59
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.2784
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 0.12s
                      Time elapsed: 00:16:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 897/1 [0m                       

                       Computation: 834196 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 851.70
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7210
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 0.12s
                      Time elapsed: 00:16:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 898/1 [0m                       

                       Computation: 880832 steps/s (collection: 0.036s, learning 0.075s)
                       Mean reward: 842.98
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.4489
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 0.11s
                      Time elapsed: 00:16:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 899/1 [0m                       

                       Computation: 850874 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 855.03
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7084
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.6667
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 0.12s
                      Time elapsed: 00:16:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 900/1 [0m                       

                       Computation: 817730 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 851.71
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.6014
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 0.12s
                      Time elapsed: 00:16:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 901/1 [0m                       

                       Computation: 853601 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 850.28
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3921
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 0.12s
                      Time elapsed: 00:16:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 902/1 [0m                       

                       Computation: 762969 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 848.68
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0884
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 0.13s
                      Time elapsed: 00:16:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 903/1 [0m                       

                       Computation: 731847 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 850.61
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.4698
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 0.13s
                      Time elapsed: 00:16:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 904/1 [0m                       

                       Computation: 645646 steps/s (collection: 0.037s, learning 0.116s)
                       Mean reward: 855.81
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.4444
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 0.15s
                      Time elapsed: 00:16:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 905/1 [0m                       

                       Computation: 764016 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 855.12
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9971
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7743
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 0.13s
                      Time elapsed: 00:16:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 906/1 [0m                       

                       Computation: 711691 steps/s (collection: 0.037s, learning 0.102s)
                       Mean reward: 846.85
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.4639
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 0.14s
                      Time elapsed: 00:16:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 907/1 [0m                       

                       Computation: 820748 steps/s (collection: 0.035s, learning 0.085s)
                       Mean reward: 849.10
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0745
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 17.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 0.12s
                      Time elapsed: 00:16:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 908/1 [0m                       

                       Computation: 760422 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 858.48
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.7321
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7773
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 0.13s
                      Time elapsed: 00:16:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 909/1 [0m                       

                       Computation: 840113 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 854.20
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.2038
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 0.12s
                      Time elapsed: 00:16:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 910/1 [0m                       

                       Computation: 870285 steps/s (collection: 0.038s, learning 0.075s)
                       Mean reward: 846.11
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.7763
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 0.11s
                      Time elapsed: 00:16:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 911/1 [0m                       

                       Computation: 815939 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 848.43
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.2724
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 0.12s
                      Time elapsed: 00:16:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 912/1 [0m                       

                       Computation: 835197 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 843.98
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.5395
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7709
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 0.12s
                      Time elapsed: 00:16:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 913/1 [0m                       

                       Computation: 834006 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 849.16
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.6175
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7742
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 0.12s
                      Time elapsed: 00:16:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 914/1 [0m                       

                       Computation: 818831 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 843.46
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.2027
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 0.12s
                      Time elapsed: 00:16:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 915/1 [0m                       

                       Computation: 810726 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 844.71
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.7781
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7847
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 0.12s
                      Time elapsed: 00:16:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 916/1 [0m                       

                       Computation: 845249 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 849.26
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0933
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7844
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 0.12s
                      Time elapsed: 00:16:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 917/1 [0m                       

                       Computation: 869932 steps/s (collection: 0.036s, learning 0.077s)
                       Mean reward: 856.94
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5477
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7896
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 0.11s
                      Time elapsed: 00:16:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 918/1 [0m                       

                       Computation: 833714 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 853.50
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.0189
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7839
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 0.12s
                      Time elapsed: 00:16:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 919/1 [0m                       

                       Computation: 831470 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 851.16
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.2565
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 0.12s
                      Time elapsed: 00:16:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 920/1 [0m                       

                       Computation: 835315 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 856.97
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.8127
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7883
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 0.12s
                      Time elapsed: 00:16:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 921/1 [0m                       

                       Computation: 876540 steps/s (collection: 0.036s, learning 0.077s)
                       Mean reward: 860.55
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4643
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7858
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 0.11s
                      Time elapsed: 00:16:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 922/1 [0m                       

                       Computation: 835014 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 851.71
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7101
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7799
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 0.12s
                      Time elapsed: 00:16:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 923/1 [0m                       

                       Computation: 831993 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 852.09
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.4769
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 0.12s
                      Time elapsed: 00:16:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 924/1 [0m                       

                       Computation: 792290 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 849.60
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.4885
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7742
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 0.12s
                      Time elapsed: 00:16:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 925/1 [0m                       

                       Computation: 727911 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 862.51
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.5280
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 0.14s
                      Time elapsed: 00:16:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 926/1 [0m                       

                       Computation: 793643 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 850.04
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1475
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7743
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 0.12s
                      Time elapsed: 00:16:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 927/1 [0m                       

                       Computation: 783829 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 854.66
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.1423
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 0.13s
                      Time elapsed: 00:16:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 928/1 [0m                       

                       Computation: 788026 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 856.31
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5903
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 0.12s
                      Time elapsed: 00:16:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 929/1 [0m                       

                       Computation: 819036 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 860.68
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.3679
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 0.12s
                      Time elapsed: 00:16:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 930/1 [0m                       

                       Computation: 746466 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 853.50
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9774
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7689
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 18.0833
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 0.13s
                      Time elapsed: 00:16:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 931/1 [0m                       

                       Computation: 786277 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 850.85
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.6994
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7622
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 0.13s
                      Time elapsed: 00:16:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 932/1 [0m                       

                       Computation: 839944 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 844.60
               Mean episode length: 245.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.4792
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 0.12s
                      Time elapsed: 00:16:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 933/1 [0m                       

                       Computation: 750849 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 844.71
               Mean episode length: 245.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.7513
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 0.13s
                      Time elapsed: 00:16:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 934/1 [0m                       

                       Computation: 728006 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 844.99
               Mean episode length: 245.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.3209
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7549
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 0.14s
                      Time elapsed: 00:16:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 935/1 [0m                       

                       Computation: 768300 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 847.82
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.8236
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 0.13s
                      Time elapsed: 00:17:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 936/1 [0m                       

                       Computation: 743102 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 851.84
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.2150
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 0.13s
                      Time elapsed: 00:17:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 937/1 [0m                       

                       Computation: 709685 steps/s (collection: 0.037s, learning 0.102s)
                       Mean reward: 852.27
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3318
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7688
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 0.14s
                      Time elapsed: 00:17:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 938/1 [0m                       

                       Computation: 676320 steps/s (collection: 0.038s, learning 0.107s)
                       Mean reward: 844.27
               Mean episode length: 245.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.7105
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7526
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 0.15s
                      Time elapsed: 00:17:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 939/1 [0m                       

                       Computation: 783227 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 848.66
               Mean episode length: 246.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0970
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 0.13s
                      Time elapsed: 00:17:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 940/1 [0m                       

                       Computation: 750312 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 852.88
               Mean episode length: 246.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7811
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7465
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 0.13s
                      Time elapsed: 00:17:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 941/1 [0m                       

                       Computation: 747217 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 841.14
               Mean episode length: 245.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.5590
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7341
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 0.13s
                      Time elapsed: 00:17:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 942/1 [0m                       

                       Computation: 706340 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 845.83
               Mean episode length: 246.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.4392
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7462
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 0.14s
                      Time elapsed: 00:17:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 943/1 [0m                       

                       Computation: 737774 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 859.15
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.2033
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 0.13s
                      Time elapsed: 00:17:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 944/1 [0m                       

                       Computation: 783197 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 850.82
               Mean episode length: 245.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.3138
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 0.13s
                      Time elapsed: 00:17:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 945/1 [0m                       

                       Computation: 708745 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 851.88
               Mean episode length: 246.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.3495
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7510
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 0.14s
                      Time elapsed: 00:17:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 946/1 [0m                       

                       Computation: 808887 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 847.46
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.7616
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7552
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 0.12s
                      Time elapsed: 00:17:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 947/1 [0m                       

                       Computation: 850667 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 851.31
               Mean episode length: 245.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.6396
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 0.12s
                      Time elapsed: 00:17:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 948/1 [0m                       

                       Computation: 844567 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 850.11
               Mean episode length: 246.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.5342
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7510
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 0.12s
                      Time elapsed: 00:17:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 949/1 [0m                       

                       Computation: 860249 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 855.79
               Mean episode length: 247.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6228
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 0.11s
                      Time elapsed: 00:17:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 950/1 [0m                       

                       Computation: 767936 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 851.71
               Mean episode length: 246.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.5299
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 0.13s
                      Time elapsed: 00:17:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 951/1 [0m                       

                       Computation: 782108 steps/s (collection: 0.035s, learning 0.090s)
                       Mean reward: 855.22
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5950
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 0.13s
                      Time elapsed: 00:17:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 952/1 [0m                       

                       Computation: 806400 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 858.94
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.2609
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7524
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 0.12s
                      Time elapsed: 00:17:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 953/1 [0m                       

                       Computation: 772382 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 862.02
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8569
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7529
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 0.13s
                      Time elapsed: 00:17:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 954/1 [0m                       

                       Computation: 799829 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 855.78
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.4459
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7514
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 0.12s
                      Time elapsed: 00:17:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 955/1 [0m                       

                       Computation: 727031 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 853.08
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.1655
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7551
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 0.14s
                      Time elapsed: 00:17:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 956/1 [0m                       

                       Computation: 745919 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 852.35
               Mean episode length: 246.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.4547
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 0.13s
                      Time elapsed: 00:17:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 957/1 [0m                       

                       Computation: 780238 steps/s (collection: 0.035s, learning 0.091s)
                       Mean reward: 861.66
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8237
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 0.13s
                      Time elapsed: 00:17:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 958/1 [0m                       

                       Computation: 772755 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 856.24
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.9595
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 0.13s
                      Time elapsed: 00:17:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 959/1 [0m                       

                       Computation: 732365 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 860.80
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1998
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7812
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 0.13s
                      Time elapsed: 00:17:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 960/1 [0m                       

                       Computation: 745819 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 861.13
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.9858
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 0.13s
                      Time elapsed: 00:17:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 961/1 [0m                       

                       Computation: 786363 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 855.12
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5170
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 0.13s
                      Time elapsed: 00:17:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 962/1 [0m                       

                       Computation: 744605 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 846.04
               Mean episode length: 247.12
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.6136
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7803
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 0.13s
                      Time elapsed: 00:17:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 963/1 [0m                       

                       Computation: 728040 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 846.72
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.7900
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 0.14s
                      Time elapsed: 00:17:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 964/1 [0m                       

                       Computation: 790468 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 864.81
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4411
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7929
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 0.12s
                      Time elapsed: 00:17:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 965/1 [0m                       

                       Computation: 744087 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 862.46
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8938
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7844
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 0.13s
                      Time elapsed: 00:17:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 966/1 [0m                       

                       Computation: 827176 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 863.90
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8786
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7857
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 0.12s
                      Time elapsed: 00:17:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 967/1 [0m                       

                       Computation: 696267 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 858.49
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.8172
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 0.14s
                      Time elapsed: 00:17:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 968/1 [0m                       

                       Computation: 853426 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 847.77
               Mean episode length: 245.51
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.5215
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7679
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 0.12s
                      Time elapsed: 00:17:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 969/1 [0m                       

                       Computation: 869866 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 859.49
               Mean episode length: 246.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.8929
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 0.11s
                      Time elapsed: 00:17:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 970/1 [0m                       

                       Computation: 862178 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 857.33
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.8617
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 0.11s
                      Time elapsed: 00:17:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 971/1 [0m                       

                       Computation: 840310 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 868.30
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.9251
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7981
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 0.12s
                      Time elapsed: 00:17:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 972/1 [0m                       

                       Computation: 848669 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 861.55
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6382
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7833
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 0.12s
                      Time elapsed: 00:17:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 973/1 [0m                       

                       Computation: 842444 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 866.29
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4468
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 0.12s
                      Time elapsed: 00:17:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 974/1 [0m                       

                       Computation: 741498 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 864.43
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1301
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 0.13s
                      Time elapsed: 00:17:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 975/1 [0m                       

                       Computation: 772615 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 872.62
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.5373
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7705
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 0.13s
                      Time elapsed: 00:17:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 976/1 [0m                       

                       Computation: 725658 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 869.79
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.1792
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 0.14s
                      Time elapsed: 00:17:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 977/1 [0m                       

                       Computation: 764886 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 867.51
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.8500
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7827
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 0.13s
                      Time elapsed: 00:17:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 978/1 [0m                       

                       Computation: 792755 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 879.20
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.0868
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7852
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 0.12s
                      Time elapsed: 00:17:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 979/1 [0m                       

                       Computation: 788412 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 868.19
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.0636
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7881
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 0.12s
                      Time elapsed: 00:17:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 980/1 [0m                       

                       Computation: 776753 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 876.76
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.6622
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7962
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 0.13s
                      Time elapsed: 00:17:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 981/1 [0m                       

                       Computation: 825102 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 865.35
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.3915
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7921
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 0.12s
                      Time elapsed: 00:17:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 982/1 [0m                       

                       Computation: 761896 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 871.47
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.7086
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7934
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 0.13s
                      Time elapsed: 00:17:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 983/1 [0m                       

                       Computation: 793101 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 870.54
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.3493
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7940
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 0.12s
                      Time elapsed: 00:17:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 984/1 [0m                       

                       Computation: 755527 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 866.80
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7410
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7952
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 0.13s
                      Time elapsed: 00:17:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 985/1 [0m                       

                       Computation: 750196 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 875.47
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.5847
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7990
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 0.13s
                      Time elapsed: 00:17:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 986/1 [0m                       

                       Computation: 817660 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 864.78
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4041
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7883
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 0.12s
                      Time elapsed: 00:17:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 987/1 [0m                       

                       Computation: 828371 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 865.78
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.2856
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7965
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 0.12s
                      Time elapsed: 00:17:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 988/1 [0m                       

                       Computation: 783251 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 870.34
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.2883
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.8005
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 0.13s
                      Time elapsed: 00:17:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 989/1 [0m                       

                       Computation: 857567 steps/s (collection: 0.040s, learning 0.075s)
                       Mean reward: 865.36
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9807
       Episode_Reward/object_height 0.0182
     Episode_Reward/reaching_object 0.7961
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 0.11s
                      Time elapsed: 00:17:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 990/1 [0m                       

                       Computation: 854615 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 861.23
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4090
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7925
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 0.12s
                      Time elapsed: 00:17:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 991/1 [0m                       

                       Computation: 789485 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 864.30
               Mean episode length: 247.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1078
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7945
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 0.12s
                      Time elapsed: 00:17:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 992/1 [0m                       

                       Computation: 832990 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 853.62
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1721
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7882
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 0.12s
                      Time elapsed: 00:18:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 993/1 [0m                       

                       Computation: 802210 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 859.91
               Mean episode length: 247.50
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.6602
       Episode_Reward/object_height 0.0176
     Episode_Reward/reaching_object 0.7868
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 0.12s
                      Time elapsed: 00:18:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 994/1 [0m                       

                       Computation: 805649 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 862.08
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7474
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7954
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 0.12s
                      Time elapsed: 00:18:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 995/1 [0m                       

                       Computation: 812325 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 858.28
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.9387
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7855
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 0.12s
                      Time elapsed: 00:18:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 996/1 [0m                       

                       Computation: 815258 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 860.75
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1263
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7857
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 0.12s
                      Time elapsed: 00:18:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 997/1 [0m                       

                       Computation: 798964 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 853.97
               Mean episode length: 246.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8687
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7831
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 0.12s
                      Time elapsed: 00:18:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 998/1 [0m                       

                       Computation: 753175 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 860.16
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.0403
       Episode_Reward/object_height 0.0176
     Episode_Reward/reaching_object 0.7926
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 0.13s
                      Time elapsed: 00:18:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 999/1 [0m                       

                       Computation: 865579 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 855.64
               Mean episode length: 246.89
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0768
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 0.11s
                      Time elapsed: 00:18:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1000/1 [0m                       

                       Computation: 672769 steps/s (collection: 0.037s, learning 0.110s)
                       Mean reward: 845.66
               Mean episode length: 244.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.2700
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7715
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 0.15s
                      Time elapsed: 00:18:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1001/1 [0m                       

                       Computation: 758541 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 849.40
               Mean episode length: 245.42
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.2980
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7803
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 0.13s
                      Time elapsed: 00:18:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1002/1 [0m                       

                       Computation: 655290 steps/s (collection: 0.055s, learning 0.095s)
                       Mean reward: 854.39
               Mean episode length: 245.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.9144
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 0.15s
                      Time elapsed: 00:18:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1003/1 [0m                       

                       Computation: 798924 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 840.87
               Mean episode length: 242.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.0973
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7486
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 18.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 0.12s
                      Time elapsed: 00:18:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1004/1 [0m                       

                       Computation: 608655 steps/s (collection: 0.057s, learning 0.105s)
                       Mean reward: 860.50
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4495
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7730
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 0.16s
                      Time elapsed: 00:18:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1005/1 [0m                       

                       Computation: 722517 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 849.58
               Mean episode length: 244.28
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9844
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 0.14s
                      Time elapsed: 00:18:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1006/1 [0m                       

                       Computation: 719875 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 832.53
               Mean episode length: 240.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.3636
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7367
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 0.14s
                      Time elapsed: 00:18:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1007/1 [0m                       

                       Computation: 692099 steps/s (collection: 0.038s, learning 0.104s)
                       Mean reward: 837.82
               Mean episode length: 241.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.1068
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7476
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 0.14s
                      Time elapsed: 00:18:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1008/1 [0m                       

                       Computation: 699610 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 829.44
               Mean episode length: 242.48
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.6598
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7455
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 0.14s
                      Time elapsed: 00:18:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1009/1 [0m                       

                       Computation: 696862 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 829.95
               Mean episode length: 242.06
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.6526
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7267
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 0.14s
                      Time elapsed: 00:18:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1010/1 [0m                       

                       Computation: 799122 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 820.50
               Mean episode length: 241.12
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.3361
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7125
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 0.12s
                      Time elapsed: 00:18:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1011/1 [0m                       

                       Computation: 697073 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 828.53
               Mean episode length: 242.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.1454
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7356
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 0.14s
                      Time elapsed: 00:18:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1012/1 [0m                       

                       Computation: 764559 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 837.78
               Mean episode length: 245.02
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.8482
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7504
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 0.13s
                      Time elapsed: 00:18:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1013/1 [0m                       

                       Computation: 744259 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 829.37
               Mean episode length: 245.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.9112
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7309
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 0.13s
                      Time elapsed: 00:18:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1014/1 [0m                       

                       Computation: 717423 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 799.04
               Mean episode length: 246.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.8200
       Episode_Reward/object_height 0.0182
     Episode_Reward/reaching_object 0.6971
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 0.14s
                      Time elapsed: 00:18:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1015/1 [0m                       

                       Computation: 761721 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 743.25
               Mean episode length: 244.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 147.8890
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.6674
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 0.13s
                      Time elapsed: 00:18:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1016/1 [0m                       

                       Computation: 747389 steps/s (collection: 0.049s, learning 0.083s)
                       Mean reward: 723.00
               Mean episode length: 243.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 143.9670
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.6553
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 0.13s
                      Time elapsed: 00:18:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1017/1 [0m                       

                       Computation: 781612 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 766.75
               Mean episode length: 245.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 152.3035
       Episode_Reward/object_height 0.0183
     Episode_Reward/reaching_object 0.6927
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 0.13s
                      Time elapsed: 00:18:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1018/1 [0m                       

                       Computation: 835231 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 797.36
               Mean episode length: 246.11
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.9887
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7164
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 0.12s
                      Time elapsed: 00:18:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1019/1 [0m                       

                       Computation: 825712 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 820.12
               Mean episode length: 246.83
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.9033
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7406
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 0.12s
                      Time elapsed: 00:18:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1020/1 [0m                       

                       Computation: 791270 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 820.55
               Mean episode length: 246.28
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.1258
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7438
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 0.12s
                      Time elapsed: 00:18:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1021/1 [0m                       

                       Computation: 664032 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 840.60
               Mean episode length: 246.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.0330
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7558
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 0.15s
                      Time elapsed: 00:18:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1022/1 [0m                       

                       Computation: 736685 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 849.88
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.1567
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 0.13s
                      Time elapsed: 00:18:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1023/1 [0m                       

                       Computation: 691753 steps/s (collection: 0.039s, learning 0.104s)
                       Mean reward: 840.60
               Mean episode length: 247.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.4354
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 0.14s
                      Time elapsed: 00:18:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1024/1 [0m                       

                       Computation: 816158 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 858.61
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8618
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7673
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 0.12s
                      Time elapsed: 00:18:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1025/1 [0m                       

                       Computation: 636199 steps/s (collection: 0.041s, learning 0.114s)
                       Mean reward: 854.10
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.3917
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 0.15s
                      Time elapsed: 00:18:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1026/1 [0m                       

                       Computation: 702902 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 844.56
               Mean episode length: 246.07
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.7522
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7597
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 0.14s
                      Time elapsed: 00:18:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1027/1 [0m                       

                       Computation: 746647 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 842.77
               Mean episode length: 246.13
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.1262
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 0.13s
                      Time elapsed: 00:18:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1028/1 [0m                       

                       Computation: 748690 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 846.34
               Mean episode length: 246.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.3789
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 0.13s
                      Time elapsed: 00:18:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1029/1 [0m                       

                       Computation: 765652 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 844.40
               Mean episode length: 245.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.9327
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 0.13s
                      Time elapsed: 00:18:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1030/1 [0m                       

                       Computation: 696497 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 839.88
               Mean episode length: 245.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.9643
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 0.14s
                      Time elapsed: 00:18:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1031/1 [0m                       

                       Computation: 771722 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 841.79
               Mean episode length: 244.61
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.2930
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7620
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 0.13s
                      Time elapsed: 00:18:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1032/1 [0m                       

                       Computation: 850885 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 853.70
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.5632
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7688
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 18.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 0.12s
                      Time elapsed: 00:18:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1033/1 [0m                       

                       Computation: 743977 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 851.28
               Mean episode length: 246.30
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.6554
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 0.13s
                      Time elapsed: 00:18:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1034/1 [0m                       

                       Computation: 760622 steps/s (collection: 0.035s, learning 0.094s)
                       Mean reward: 851.33
               Mean episode length: 245.95
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2433
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7471
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 0.13s
                      Time elapsed: 00:18:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1035/1 [0m                       

                       Computation: 747561 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 833.97
               Mean episode length: 243.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.7018
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7364
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 0.13s
                      Time elapsed: 00:18:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1036/1 [0m                       

                       Computation: 702462 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 834.93
               Mean episode length: 244.30
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.6602
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7369
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 0.14s
                      Time elapsed: 00:18:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1037/1 [0m                       

                       Computation: 756131 steps/s (collection: 0.046s, learning 0.084s)
                       Mean reward: 839.32
               Mean episode length: 244.93
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.6688
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7458
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 0.13s
                      Time elapsed: 00:18:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1038/1 [0m                       

                       Computation: 749668 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 837.92
               Mean episode length: 245.50
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.5779
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7381
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 0.13s
                      Time elapsed: 00:18:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1039/1 [0m                       

                       Computation: 725534 steps/s (collection: 0.048s, learning 0.087s)
                       Mean reward: 844.61
               Mean episode length: 245.83
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.9358
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7454
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 0.14s
                      Time elapsed: 00:18:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1040/1 [0m                       

                       Computation: 794607 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 828.91
               Mean episode length: 242.63
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.1825
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7393
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 0.12s
                      Time elapsed: 00:18:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1041/1 [0m                       

                       Computation: 772439 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 837.61
               Mean episode length: 245.42
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.5844
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7436
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 0.13s
                      Time elapsed: 00:18:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1042/1 [0m                       

                       Computation: 830664 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 846.18
               Mean episode length: 245.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.2911
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7474
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 0.12s
                      Time elapsed: 00:18:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1043/1 [0m                       

                       Computation: 635187 steps/s (collection: 0.049s, learning 0.106s)
                       Mean reward: 825.97
               Mean episode length: 245.25
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.2774
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7283
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 0.15s
                      Time elapsed: 00:18:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1044/1 [0m                       

                       Computation: 628050 steps/s (collection: 0.043s, learning 0.113s)
                       Mean reward: 846.27
               Mean episode length: 246.83
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.5023
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7453
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 0.16s
                      Time elapsed: 00:18:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1045/1 [0m                       

                       Computation: 752416 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 847.62
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.7768
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7517
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 0.13s
                      Time elapsed: 00:18:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1046/1 [0m                       

                       Computation: 697042 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 849.57
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2589
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 0.14s
                      Time elapsed: 00:18:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1047/1 [0m                       

                       Computation: 713905 steps/s (collection: 0.051s, learning 0.087s)
                       Mean reward: 829.95
               Mean episode length: 244.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.3545
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7205
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 0.14s
                      Time elapsed: 00:18:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1048/1 [0m                       

                       Computation: 842212 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 840.29
               Mean episode length: 245.33
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.4375
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7271
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 0.12s
                      Time elapsed: 00:19:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1049/1 [0m                       

                       Computation: 629897 steps/s (collection: 0.050s, learning 0.106s)
                       Mean reward: 854.31
               Mean episode length: 246.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1416
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7352
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 0.16s
                      Time elapsed: 00:19:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1050/1 [0m                       

                       Computation: 616019 steps/s (collection: 0.045s, learning 0.115s)
                       Mean reward: 855.55
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.4642
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7488
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 0.16s
                      Time elapsed: 00:19:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1051/1 [0m                       

                       Computation: 549552 steps/s (collection: 0.058s, learning 0.121s)
                       Mean reward: 862.25
               Mean episode length: 246.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7320
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7544
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 0.18s
                      Time elapsed: 00:19:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1052/1 [0m                       

                       Computation: 608404 steps/s (collection: 0.046s, learning 0.116s)
                       Mean reward: 849.76
               Mean episode length: 246.66
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.3542
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7498
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 0.16s
                      Time elapsed: 00:19:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1053/1 [0m                       

                       Computation: 627621 steps/s (collection: 0.044s, learning 0.113s)
                       Mean reward: 864.01
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.9399
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 18.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 0.16s
                      Time elapsed: 00:19:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1054/1 [0m                       

                       Computation: 700077 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 864.06
               Mean episode length: 247.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9844
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7585
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 0.14s
                      Time elapsed: 00:19:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1055/1 [0m                       

                       Computation: 809574 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 858.37
               Mean episode length: 246.04
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.6468
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 0.12s
                      Time elapsed: 00:19:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1056/1 [0m                       

                       Computation: 804294 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 859.52
               Mean episode length: 246.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4772
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 0.12s
                      Time elapsed: 00:19:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1057/1 [0m                       

                       Computation: 723034 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 850.60
               Mean episode length: 244.74
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.8819
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7498
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 0.14s
                      Time elapsed: 00:19:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1058/1 [0m                       

                       Computation: 776971 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 855.32
               Mean episode length: 246.26
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.2741
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 0.13s
                      Time elapsed: 00:19:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1059/1 [0m                       

                       Computation: 680349 steps/s (collection: 0.036s, learning 0.108s)
                       Mean reward: 867.31
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8316
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 0.14s
                      Time elapsed: 00:19:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1060/1 [0m                       

                       Computation: 628038 steps/s (collection: 0.039s, learning 0.118s)
                       Mean reward: 855.28
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5970
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7523
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 0.16s
                      Time elapsed: 00:19:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1061/1 [0m                       

                       Computation: 758867 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 863.70
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0648
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7544
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 0.13s
                      Time elapsed: 00:19:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1062/1 [0m                       

                       Computation: 770950 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 865.86
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3143
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 0.13s
                      Time elapsed: 00:19:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1063/1 [0m                       

                       Computation: 717399 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 863.91
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.2659
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 0.14s
                      Time elapsed: 00:19:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1064/1 [0m                       

                       Computation: 555238 steps/s (collection: 0.053s, learning 0.125s)
                       Mean reward: 861.71
               Mean episode length: 246.85
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5878
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 0.18s
                      Time elapsed: 00:19:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1065/1 [0m                       

                       Computation: 644420 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 858.83
               Mean episode length: 245.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.8853
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 0.15s
                      Time elapsed: 00:19:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1066/1 [0m                       

                       Computation: 780100 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 860.26
               Mean episode length: 246.06
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1071
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7525
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 0.13s
                      Time elapsed: 00:19:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1067/1 [0m                       

                       Computation: 727432 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 864.36
               Mean episode length: 247.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1061
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 0.14s
                      Time elapsed: 00:19:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1068/1 [0m                       

                       Computation: 696687 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 854.20
               Mean episode length: 245.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8988
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7610
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 0.14s
                      Time elapsed: 00:19:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1069/1 [0m                       

                       Computation: 772074 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 850.01
               Mean episode length: 243.17
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.7489
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 0.13s
                      Time elapsed: 00:19:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1070/1 [0m                       

                       Computation: 808226 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 845.14
               Mean episode length: 243.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.0873
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7427
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 0.12s
                      Time elapsed: 00:19:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1071/1 [0m                       

                       Computation: 751972 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 852.54
               Mean episode length: 246.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5729
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7473
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 0.13s
                      Time elapsed: 00:19:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1072/1 [0m                       

                       Computation: 754526 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 837.61
               Mean episode length: 242.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.4569
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7296
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 0.13s
                      Time elapsed: 00:19:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1073/1 [0m                       

                       Computation: 765368 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 841.73
               Mean episode length: 246.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.8335
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7292
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 0.13s
                      Time elapsed: 00:19:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1074/1 [0m                       

                       Computation: 728925 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 841.86
               Mean episode length: 247.11
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.1121
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7213
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 0.13s
                      Time elapsed: 00:19:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1075/1 [0m                       

                       Computation: 854583 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 837.42
               Mean episode length: 247.03
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.6176
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7166
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 0.12s
                      Time elapsed: 00:19:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1076/1 [0m                       

                       Computation: 732476 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 847.72
               Mean episode length: 246.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.6601
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7273
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 0.13s
                      Time elapsed: 00:19:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1077/1 [0m                       

                       Computation: 776476 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 837.16
               Mean episode length: 244.50
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.7177
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7216
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 0.13s
                      Time elapsed: 00:19:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1078/1 [0m                       

                       Computation: 762286 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 829.60
               Mean episode length: 245.72
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.9900
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7197
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 0.13s
                      Time elapsed: 00:19:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1079/1 [0m                       

                       Computation: 675566 steps/s (collection: 0.043s, learning 0.103s)
                       Mean reward: 846.08
               Mean episode length: 246.14
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.8373
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7254
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 0.15s
                      Time elapsed: 00:19:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1080/1 [0m                       

                       Computation: 576897 steps/s (collection: 0.047s, learning 0.123s)
                       Mean reward: 848.97
               Mean episode length: 246.96
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5244
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7338
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 0.17s
                      Time elapsed: 00:19:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1081/1 [0m                       

                       Computation: 654418 steps/s (collection: 0.044s, learning 0.106s)
                       Mean reward: 851.80
               Mean episode length: 246.77
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1737
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7326
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 0.15s
                      Time elapsed: 00:19:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1082/1 [0m                       

                       Computation: 608631 steps/s (collection: 0.046s, learning 0.115s)
                       Mean reward: 858.04
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.4519
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7409
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 0.16s
                      Time elapsed: 00:19:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1083/1 [0m                       

                       Computation: 621943 steps/s (collection: 0.043s, learning 0.115s)
                       Mean reward: 848.80
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.9328
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7303
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 0.16s
                      Time elapsed: 00:19:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1084/1 [0m                       

                       Computation: 553568 steps/s (collection: 0.057s, learning 0.121s)
                       Mean reward: 847.97
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.7047
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7348
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 0.18s
                      Time elapsed: 00:19:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1085/1 [0m                       

                       Computation: 675475 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 864.83
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.1236
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 0.15s
                      Time elapsed: 00:19:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1086/1 [0m                       

                       Computation: 734135 steps/s (collection: 0.047s, learning 0.087s)
                       Mean reward: 863.13
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0394
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7557
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 0.13s
                      Time elapsed: 00:19:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1087/1 [0m                       

                       Computation: 797087 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 870.44
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.0750
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 0.12s
                      Time elapsed: 00:19:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1088/1 [0m                       

                       Computation: 741593 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 857.14
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0931
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7569
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 0.13s
                      Time elapsed: 00:19:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1089/1 [0m                       

                       Computation: 546588 steps/s (collection: 0.055s, learning 0.125s)
                       Mean reward: 876.03
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3903
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7804
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 0.18s
                      Time elapsed: 00:19:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1090/1 [0m                       

                       Computation: 645442 steps/s (collection: 0.049s, learning 0.104s)
                       Mean reward: 881.23
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.4254
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7918
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 0.15s
                      Time elapsed: 00:19:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1091/1 [0m                       

                       Computation: 675450 steps/s (collection: 0.048s, learning 0.098s)
                       Mean reward: 867.17
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3120
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 0.15s
                      Time elapsed: 00:19:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1092/1 [0m                       

                       Computation: 601077 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 872.69
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.4127
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 0.16s
                      Time elapsed: 00:19:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1093/1 [0m                       

                       Computation: 605761 steps/s (collection: 0.047s, learning 0.115s)
                       Mean reward: 874.86
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8633
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 0.16s
                      Time elapsed: 00:19:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1094/1 [0m                       

                       Computation: 694317 steps/s (collection: 0.045s, learning 0.097s)
                       Mean reward: 878.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8202
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 0.14s
                      Time elapsed: 00:19:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1095/1 [0m                       

                       Computation: 720701 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 874.17
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.1351
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 0.14s
                      Time elapsed: 00:19:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1096/1 [0m                       

                       Computation: 723190 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 873.07
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7745
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7859
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 0.14s
                      Time elapsed: 00:19:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1097/1 [0m                       

                       Computation: 581267 steps/s (collection: 0.050s, learning 0.120s)
                       Mean reward: 866.88
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7911
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7827
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 0.17s
                      Time elapsed: 00:19:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1098/1 [0m                       

                       Computation: 598200 steps/s (collection: 0.052s, learning 0.113s)
                       Mean reward: 872.27
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6161
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7825
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 0.16s
                      Time elapsed: 00:19:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1099/1 [0m                       

                       Computation: 659633 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 858.30
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5496
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 0.15s
                      Time elapsed: 00:20:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1100/1 [0m                       

                       Computation: 583244 steps/s (collection: 0.048s, learning 0.121s)
                       Mean reward: 865.95
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0788
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7811
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 0.17s
                      Time elapsed: 00:20:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1101/1 [0m                       

                       Computation: 579763 steps/s (collection: 0.049s, learning 0.121s)
                       Mean reward: 865.50
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.6852
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7840
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 0.17s
                      Time elapsed: 00:20:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1102/1 [0m                       

                       Computation: 585785 steps/s (collection: 0.053s, learning 0.115s)
                       Mean reward: 863.32
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.9684
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7844
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 0.17s
                      Time elapsed: 00:20:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1103/1 [0m                       

                       Computation: 680105 steps/s (collection: 0.050s, learning 0.095s)
                       Mean reward: 863.36
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7641
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 0.14s
                      Time elapsed: 00:20:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1104/1 [0m                       

                       Computation: 630797 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 859.08
               Mean episode length: 247.07
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.2623
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 0.16s
                      Time elapsed: 00:20:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1105/1 [0m                       

                       Computation: 550629 steps/s (collection: 0.054s, learning 0.125s)
                       Mean reward: 866.43
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.5909
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7846
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 0.18s
                      Time elapsed: 00:20:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1106/1 [0m                       

                       Computation: 839694 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 866.75
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7204
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 0.12s
                      Time elapsed: 00:20:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1107/1 [0m                       

                       Computation: 756060 steps/s (collection: 0.035s, learning 0.095s)
                       Mean reward: 868.25
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7914
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 0.13s
                      Time elapsed: 00:20:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1108/1 [0m                       

                       Computation: 718297 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 873.16
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7812
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7908
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 0.14s
                      Time elapsed: 00:20:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1109/1 [0m                       

                       Computation: 702046 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 871.31
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.1279
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 0.14s
                      Time elapsed: 00:20:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1110/1 [0m                       

                       Computation: 692041 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 874.67
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8202
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 0.14s
                      Time elapsed: 00:20:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1111/1 [0m                       

                       Computation: 731171 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 873.70
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7801
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7780
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 0.13s
                      Time elapsed: 00:20:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1112/1 [0m                       

                       Computation: 746680 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 863.95
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.9621
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 0.13s
                      Time elapsed: 00:20:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1113/1 [0m                       

                       Computation: 647648 steps/s (collection: 0.046s, learning 0.106s)
                       Mean reward: 866.46
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7522
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 0.15s
                      Time elapsed: 00:20:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1114/1 [0m                       

                       Computation: 715809 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 875.54
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2253
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 0.14s
                      Time elapsed: 00:20:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1115/1 [0m                       

                       Computation: 802322 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 873.45
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3385
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7850
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 0.12s
                      Time elapsed: 00:20:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1116/1 [0m                       

                       Computation: 792432 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 881.77
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.5499
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 0.12s
                      Time elapsed: 00:20:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1117/1 [0m                       

                       Computation: 738687 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 875.85
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4158
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7778
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 0.13s
                      Time elapsed: 00:20:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1118/1 [0m                       

                       Computation: 771821 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 872.12
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6276
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 0.13s
                      Time elapsed: 00:20:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1119/1 [0m                       

                       Computation: 802402 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 869.78
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7471
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 0.12s
                      Time elapsed: 00:20:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1120/1 [0m                       

                       Computation: 746095 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 876.19
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.6529
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 0.13s
                      Time elapsed: 00:20:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1121/1 [0m                       

                       Computation: 841954 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 871.38
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2697
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 0.12s
                      Time elapsed: 00:20:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1122/1 [0m                       

                       Computation: 849892 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 872.21
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8545
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 0.12s
                      Time elapsed: 00:20:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1123/1 [0m                       

                       Computation: 807587 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 875.81
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5352
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 0.12s
                      Time elapsed: 00:20:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1124/1 [0m                       

                       Computation: 797299 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 871.43
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7654
       Episode_Reward/object_height 0.0233
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 0.12s
                      Time elapsed: 00:20:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1125/1 [0m                       

                       Computation: 786303 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 872.86
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8536
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 0.13s
                      Time elapsed: 00:20:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1126/1 [0m                       

                       Computation: 790254 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 862.57
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6797
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7519
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 0.12s
                      Time elapsed: 00:20:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1127/1 [0m                       

                       Computation: 749232 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 874.66
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9065
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7541
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 0.13s
                      Time elapsed: 00:20:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1128/1 [0m                       

                       Computation: 812266 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 870.33
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0902
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7527
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 0.12s
                      Time elapsed: 00:20:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1129/1 [0m                       

                       Computation: 806524 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 873.69
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9594
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 0.12s
                      Time elapsed: 00:20:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1130/1 [0m                       

                       Computation: 840752 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 872.26
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3111
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7620
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 0.12s
                      Time elapsed: 00:20:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1131/1 [0m                       

                       Computation: 757922 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 872.46
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6918
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 0.13s
                      Time elapsed: 00:20:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1132/1 [0m                       

                       Computation: 725246 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 870.31
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9999
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7706
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 0.14s
                      Time elapsed: 00:20:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1133/1 [0m                       

                       Computation: 764668 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 871.64
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3439
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 0.13s
                      Time elapsed: 00:20:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1134/1 [0m                       

                       Computation: 620118 steps/s (collection: 0.038s, learning 0.121s)
                       Mean reward: 877.71
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5929
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 0.16s
                      Time elapsed: 00:20:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1135/1 [0m                       

                       Computation: 616409 steps/s (collection: 0.048s, learning 0.111s)
                       Mean reward: 873.57
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0649
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7824
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 0.16s
                      Time elapsed: 00:20:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1136/1 [0m                       

                       Computation: 654226 steps/s (collection: 0.040s, learning 0.111s)
                       Mean reward: 876.19
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3933
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7813
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 0.15s
                      Time elapsed: 00:20:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1137/1 [0m                       

                       Computation: 578153 steps/s (collection: 0.047s, learning 0.123s)
                       Mean reward: 880.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.2942
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 0.17s
                      Time elapsed: 00:20:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1138/1 [0m                       

                       Computation: 638589 steps/s (collection: 0.053s, learning 0.101s)
                       Mean reward: 871.26
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6245
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7878
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 0.15s
                      Time elapsed: 00:20:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1139/1 [0m                       

                       Computation: 619924 steps/s (collection: 0.053s, learning 0.106s)
                       Mean reward: 878.13
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8188
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7923
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 0.16s
                      Time elapsed: 00:20:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1140/1 [0m                       

                       Computation: 586761 steps/s (collection: 0.050s, learning 0.118s)
                       Mean reward: 873.09
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2527
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 0.17s
                      Time elapsed: 00:20:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1141/1 [0m                       

                       Computation: 740082 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 875.13
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3482
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7838
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 0.13s
                      Time elapsed: 00:20:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1142/1 [0m                       

                       Computation: 588438 steps/s (collection: 0.050s, learning 0.117s)
                       Mean reward: 875.25
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3237
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7834
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 0.17s
                      Time elapsed: 00:20:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1143/1 [0m                       

                       Computation: 726412 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 876.17
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3237
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7805
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 0.14s
                      Time elapsed: 00:20:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1144/1 [0m                       

                       Computation: 707117 steps/s (collection: 0.046s, learning 0.094s)
                       Mean reward: 873.03
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9018
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 0.14s
                      Time elapsed: 00:20:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1145/1 [0m                       

                       Computation: 716602 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 877.33
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9406
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7922
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 0.14s
                      Time elapsed: 00:20:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1146/1 [0m                       

                       Computation: 601208 steps/s (collection: 0.047s, learning 0.117s)
                       Mean reward: 872.86
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8405
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 0.16s
                      Time elapsed: 00:20:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1147/1 [0m                       

                       Computation: 729809 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 873.93
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9275
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7844
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 0.13s
                      Time elapsed: 00:20:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1148/1 [0m                       

                       Computation: 625981 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 871.08
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5306
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 0.16s
                      Time elapsed: 00:20:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1149/1 [0m                       

                       Computation: 758916 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 875.76
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4243
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7845
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 0.13s
                      Time elapsed: 00:20:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1150/1 [0m                       

                       Computation: 826988 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 868.09
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.5498
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 0.12s
                      Time elapsed: 00:20:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1151/1 [0m                       

                       Computation: 560953 steps/s (collection: 0.057s, learning 0.118s)
                       Mean reward: 871.94
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6750
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 0.18s
                      Time elapsed: 00:20:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1152/1 [0m                       

                       Computation: 667650 steps/s (collection: 0.053s, learning 0.094s)
                       Mean reward: 874.34
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8502
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 0.15s
                      Time elapsed: 00:21:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1153/1 [0m                       

                       Computation: 619723 steps/s (collection: 0.049s, learning 0.109s)
                       Mean reward: 872.53
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5768
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 0.16s
                      Time elapsed: 00:21:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1154/1 [0m                       

                       Computation: 597509 steps/s (collection: 0.052s, learning 0.113s)
                       Mean reward: 866.42
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8839
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7709
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 0.16s
                      Time elapsed: 00:21:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1155/1 [0m                       

                       Computation: 644435 steps/s (collection: 0.041s, learning 0.112s)
                       Mean reward: 873.39
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9693
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7844
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 0.15s
                      Time elapsed: 00:21:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1156/1 [0m                       

                       Computation: 692581 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 873.85
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7156
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 0.14s
                      Time elapsed: 00:21:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1157/1 [0m                       

                       Computation: 865826 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 870.78
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2309
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 0.11s
                      Time elapsed: 00:21:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1158/1 [0m                       

                       Computation: 773978 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 876.58
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.1807
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7873
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 0.13s
                      Time elapsed: 00:21:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1159/1 [0m                       

                       Computation: 603016 steps/s (collection: 0.056s, learning 0.107s)
                       Mean reward: 873.71
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0929
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7925
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 0.16s
                      Time elapsed: 00:21:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1160/1 [0m                       

                       Computation: 725115 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 873.18
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8146
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7838
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 0.14s
                      Time elapsed: 00:21:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1161/1 [0m                       

                       Computation: 593938 steps/s (collection: 0.043s, learning 0.122s)
                       Mean reward: 877.55
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.7417
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7870
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 0.17s
                      Time elapsed: 00:21:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1162/1 [0m                       

                       Computation: 714739 steps/s (collection: 0.037s, learning 0.101s)
                       Mean reward: 874.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.1655
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 0.14s
                      Time elapsed: 00:21:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1163/1 [0m                       

                       Computation: 648632 steps/s (collection: 0.042s, learning 0.109s)
                       Mean reward: 869.29
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.1929
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7810
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 0.15s
                      Time elapsed: 00:21:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1164/1 [0m                       

                       Computation: 743548 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 861.53
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4970
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 0.13s
                      Time elapsed: 00:21:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1165/1 [0m                       

                       Computation: 676083 steps/s (collection: 0.046s, learning 0.099s)
                       Mean reward: 871.16
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5303
       Episode_Reward/object_height 0.0231
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 0.15s
                      Time elapsed: 00:21:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1166/1 [0m                       

                       Computation: 772176 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 874.06
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9973
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 0.13s
                      Time elapsed: 00:21:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1167/1 [0m                       

                       Computation: 798123 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 876.05
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0992
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 0.12s
                      Time elapsed: 00:21:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1168/1 [0m                       

                       Computation: 794547 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 870.11
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.0252
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 0.12s
                      Time elapsed: 00:21:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1169/1 [0m                       

                       Computation: 712869 steps/s (collection: 0.037s, learning 0.101s)
                       Mean reward: 872.35
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8517
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 0.14s
                      Time elapsed: 00:21:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1170/1 [0m                       

                       Computation: 805293 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 877.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.7716
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 0.12s
                      Time elapsed: 00:21:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1171/1 [0m                       

                       Computation: 774322 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 873.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5427
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 0.13s
                      Time elapsed: 00:21:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1172/1 [0m                       

                       Computation: 820330 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 875.81
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.4771
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7792
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 0.12s
                      Time elapsed: 00:21:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1173/1 [0m                       

                       Computation: 788818 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 879.43
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.0084
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7919
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 0.12s
                      Time elapsed: 00:21:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1174/1 [0m                       

                       Computation: 838139 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 873.86
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8693
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7839
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 0.12s
                      Time elapsed: 00:21:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1175/1 [0m                       

                       Computation: 789325 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 871.10
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5457
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7805
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 0.12s
                      Time elapsed: 00:21:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1176/1 [0m                       

                       Computation: 812186 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 878.10
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6088
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7801
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 0.12s
                      Time elapsed: 00:21:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1177/1 [0m                       

                       Computation: 753161 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 874.95
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3809
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 0.13s
                      Time elapsed: 00:21:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1178/1 [0m                       

                       Computation: 690825 steps/s (collection: 0.038s, learning 0.105s)
                       Mean reward: 878.23
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.8497
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7914
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 0.14s
                      Time elapsed: 00:21:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1179/1 [0m                       

                       Computation: 708766 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 876.80
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2319
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7878
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 0.14s
                      Time elapsed: 00:21:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1180/1 [0m                       

                       Computation: 669784 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 877.54
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.7232
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7902
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 0.15s
                      Time elapsed: 00:21:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1181/1 [0m                       

                       Computation: 695386 steps/s (collection: 0.036s, learning 0.105s)
                       Mean reward: 878.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.7018
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7910
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 0.14s
                      Time elapsed: 00:21:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1182/1 [0m                       

                       Computation: 768064 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 867.74
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6965
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 0.13s
                      Time elapsed: 00:21:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1183/1 [0m                       

                       Computation: 773883 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 880.73
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.1052
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7907
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 0.13s
                      Time elapsed: 00:21:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1184/1 [0m                       

                       Computation: 702862 steps/s (collection: 0.036s, learning 0.103s)
                       Mean reward: 865.07
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.4726
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 0.14s
                      Time elapsed: 00:21:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1185/1 [0m                       

                       Computation: 764786 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 872.23
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.6480
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7866
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 0.13s
                      Time elapsed: 00:21:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1186/1 [0m                       

                       Computation: 854418 steps/s (collection: 0.043s, learning 0.073s)
                       Mean reward: 862.83
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1856
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7803
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 0.12s
                      Time elapsed: 00:21:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1187/1 [0m                       

                       Computation: 657451 steps/s (collection: 0.045s, learning 0.105s)
                       Mean reward: 875.62
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0934
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7836
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 0.15s
                      Time elapsed: 00:21:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1188/1 [0m                       

                       Computation: 779668 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 876.92
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5733
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7899
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.7083
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 0.13s
                      Time elapsed: 00:21:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1189/1 [0m                       

                       Computation: 747543 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 871.77
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5127
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 0.13s
                      Time elapsed: 00:21:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1190/1 [0m                       

                       Computation: 699509 steps/s (collection: 0.037s, learning 0.104s)
                       Mean reward: 878.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.0179
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7912
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 0.14s
                      Time elapsed: 00:21:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1191/1 [0m                       

                       Computation: 722509 steps/s (collection: 0.036s, learning 0.100s)
                       Mean reward: 876.38
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.4780
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7885
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 0.14s
                      Time elapsed: 00:21:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1192/1 [0m                       

                       Computation: 633108 steps/s (collection: 0.039s, learning 0.116s)
                       Mean reward: 872.30
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7714
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 0.16s
                      Time elapsed: 00:21:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1193/1 [0m                       

                       Computation: 717384 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 873.03
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.6480
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 0.14s
                      Time elapsed: 00:21:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1194/1 [0m                       

                       Computation: 719549 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 873.39
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.9523
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 0.14s
                      Time elapsed: 00:21:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1195/1 [0m                       

                       Computation: 756930 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 878.65
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.9049
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7890
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 0.13s
                      Time elapsed: 00:21:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1196/1 [0m                       

                       Computation: 683818 steps/s (collection: 0.036s, learning 0.108s)
                       Mean reward: 871.05
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.3525
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7861
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 0.14s
                      Time elapsed: 00:21:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1197/1 [0m                       

                       Computation: 799175 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 878.12
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8023
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7924
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 0.12s
                      Time elapsed: 00:21:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1198/1 [0m                       

                       Computation: 740970 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 867.96
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1693
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7886
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 0.13s
                      Time elapsed: 00:21:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1199/1 [0m                       

                       Computation: 829764 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 871.45
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5555
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7919
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 0.12s
                      Time elapsed: 00:21:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1200/1 [0m                       

                       Computation: 647816 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 870.93
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7764
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7894
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 0.15s
                      Time elapsed: 00:21:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1201/1 [0m                       

                       Computation: 773516 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 875.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.4497
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7896
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 0.13s
                      Time elapsed: 00:21:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1202/1 [0m                       

                       Computation: 759945 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 874.10
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0546
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7932
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 0.13s
                      Time elapsed: 00:21:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1203/1 [0m                       

                       Computation: 715672 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 873.99
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.1128
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7874
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 0.14s
                      Time elapsed: 00:21:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1204/1 [0m                       

                       Computation: 688450 steps/s (collection: 0.038s, learning 0.105s)
                       Mean reward: 871.88
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5361
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7871
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 0.14s
                      Time elapsed: 00:21:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1205/1 [0m                       

                       Computation: 720892 steps/s (collection: 0.035s, learning 0.101s)
                       Mean reward: 873.90
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.1403
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7924
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 0.14s
                      Time elapsed: 00:21:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1206/1 [0m                       

                       Computation: 734540 steps/s (collection: 0.036s, learning 0.098s)
                       Mean reward: 871.84
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6993
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7881
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 0.13s
                      Time elapsed: 00:21:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1207/1 [0m                       

                       Computation: 727870 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 878.89
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8506
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7922
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 0.14s
                      Time elapsed: 00:22:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1208/1 [0m                       

                       Computation: 825978 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 873.78
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0313
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 0.12s
                      Time elapsed: 00:22:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1209/1 [0m                       

                       Computation: 826614 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 873.32
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.9174
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7831
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 0.12s
                      Time elapsed: 00:22:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1210/1 [0m                       

                       Computation: 799274 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 870.96
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3874
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7918
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 0.12s
                      Time elapsed: 00:22:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1211/1 [0m                       

                       Computation: 799165 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 871.26
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.4408
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 0.12s
                      Time elapsed: 00:22:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1212/1 [0m                       

                       Computation: 862556 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 875.09
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.3124
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7888
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 0.11s
                      Time elapsed: 00:22:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1213/1 [0m                       

                       Computation: 822496 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 871.29
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3441
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7881
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 0.12s
                      Time elapsed: 00:22:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1214/1 [0m                       

                       Computation: 753164 steps/s (collection: 0.047s, learning 0.084s)
                       Mean reward: 872.29
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7813
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7877
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 0.13s
                      Time elapsed: 00:22:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1215/1 [0m                       

                       Computation: 842668 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 870.21
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.4791
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 0.12s
                      Time elapsed: 00:22:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1216/1 [0m                       

                       Computation: 765373 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 869.86
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2190
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7880
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 0.13s
                      Time elapsed: 00:22:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1217/1 [0m                       

                       Computation: 800382 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 872.93
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7972
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7904
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 0.12s
                      Time elapsed: 00:22:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1218/1 [0m                       

                       Computation: 825970 steps/s (collection: 0.044s, learning 0.075s)
                       Mean reward: 875.92
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.6252
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7935
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 0.12s
                      Time elapsed: 00:22:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1219/1 [0m                       

                       Computation: 726165 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 872.25
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.8436
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7924
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 0.14s
                      Time elapsed: 00:22:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1220/1 [0m                       

                       Computation: 773330 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 868.43
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7584
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7894
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 0.13s
                      Time elapsed: 00:22:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1221/1 [0m                       

                       Computation: 800993 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 868.67
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0765
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7884
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 0.12s
                      Time elapsed: 00:22:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1222/1 [0m                       

                       Computation: 727749 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 870.38
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3416
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7917
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 0.14s
                      Time elapsed: 00:22:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1223/1 [0m                       

                       Computation: 696157 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 860.50
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1978
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 0.14s
                      Time elapsed: 00:22:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1224/1 [0m                       

                       Computation: 747045 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 868.80
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1295
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7842
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 0.13s
                      Time elapsed: 00:22:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1225/1 [0m                       

                       Computation: 802641 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 868.96
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.9534
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7852
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 0.12s
                      Time elapsed: 00:22:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1226/1 [0m                       

                       Computation: 744677 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 865.24
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.3836
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7859
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 0.13s
                      Time elapsed: 00:22:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1227/1 [0m                       

                       Computation: 809561 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 865.40
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.0083
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7838
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 0.12s
                      Time elapsed: 00:22:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1228/1 [0m                       

                       Computation: 706607 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 870.35
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0442
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 0.14s
                      Time elapsed: 00:22:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1229/1 [0m                       

                       Computation: 736268 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 868.04
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6515
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 0.13s
                      Time elapsed: 00:22:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1230/1 [0m                       

                       Computation: 725414 steps/s (collection: 0.048s, learning 0.088s)
                       Mean reward: 866.59
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.3261
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 0.14s
                      Time elapsed: 00:22:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1231/1 [0m                       

                       Computation: 805312 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 865.29
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0107
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7757
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 0.12s
                      Time elapsed: 00:22:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1232/1 [0m                       

                       Computation: 792038 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 862.13
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.5640
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 0.12s
                      Time elapsed: 00:22:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1233/1 [0m                       

                       Computation: 813180 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 855.21
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.6496
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7653
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 0.12s
                      Time elapsed: 00:22:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1234/1 [0m                       

                       Computation: 783022 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 871.26
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6881
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 0.13s
                      Time elapsed: 00:22:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1235/1 [0m                       

                       Computation: 757418 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 864.11
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1123
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7812
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 0.13s
                      Time elapsed: 00:22:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1236/1 [0m                       

                       Computation: 801232 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 862.66
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6270
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7770
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 0.12s
                      Time elapsed: 00:22:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1237/1 [0m                       

                       Computation: 794787 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 869.02
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2652
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7790
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 0.12s
                      Time elapsed: 00:22:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1238/1 [0m                       

                       Computation: 743898 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 856.18
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.1928
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 0.13s
                      Time elapsed: 00:22:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1239/1 [0m                       

                       Computation: 840031 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 861.75
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.5876
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7653
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 0.12s
                      Time elapsed: 00:22:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1240/1 [0m                       

                       Computation: 736272 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 852.86
               Mean episode length: 246.21
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.2530
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 0.13s
                      Time elapsed: 00:22:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1241/1 [0m                       

                       Computation: 787426 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 862.69
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4343
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 0.12s
                      Time elapsed: 00:22:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1242/1 [0m                       

                       Computation: 774119 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 858.57
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2025
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 0.13s
                      Time elapsed: 00:22:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1243/1 [0m                       

                       Computation: 858358 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 866.46
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0303
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 0.11s
                      Time elapsed: 00:22:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1244/1 [0m                       

                       Computation: 628372 steps/s (collection: 0.051s, learning 0.106s)
                       Mean reward: 873.34
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8450
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 0.16s
                      Time elapsed: 00:22:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1245/1 [0m                       

                       Computation: 847248 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 860.43
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1088
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7653
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 0.12s
                      Time elapsed: 00:22:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1246/1 [0m                       

                       Computation: 858315 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 857.97
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6755
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 0.11s
                      Time elapsed: 00:22:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1247/1 [0m                       

                       Computation: 763715 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 866.42
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7532
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 0.13s
                      Time elapsed: 00:22:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1248/1 [0m                       

                       Computation: 581600 steps/s (collection: 0.046s, learning 0.123s)
                       Mean reward: 866.11
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6634
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 0.17s
                      Time elapsed: 00:22:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1249/1 [0m                       

                       Computation: 628043 steps/s (collection: 0.041s, learning 0.116s)
                       Mean reward: 863.66
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5109
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 0.16s
                      Time elapsed: 00:22:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1250/1 [0m                       

                       Computation: 666614 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 874.58
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2671
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 0.15s
                      Time elapsed: 00:22:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1251/1 [0m                       

                       Computation: 781126 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 871.49
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6737
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 0.13s
                      Time elapsed: 00:22:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1252/1 [0m                       

                       Computation: 597698 steps/s (collection: 0.041s, learning 0.124s)
                       Mean reward: 863.92
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1533
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 0.16s
                      Time elapsed: 00:22:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1253/1 [0m                       

                       Computation: 559951 steps/s (collection: 0.045s, learning 0.131s)
                       Mean reward: 873.63
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.1203
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7825
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 0.18s
                      Time elapsed: 00:22:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1254/1 [0m                       

                       Computation: 661924 steps/s (collection: 0.052s, learning 0.097s)
                       Mean reward: 861.06
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3142
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 0.15s
                      Time elapsed: 00:22:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1255/1 [0m                       

                       Computation: 796923 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 867.00
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6447
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7726
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 0.12s
                      Time elapsed: 00:22:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1256/1 [0m                       

                       Computation: 818389 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 872.34
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2055
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 0.12s
                      Time elapsed: 00:22:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1257/1 [0m                       

                       Computation: 776966 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 867.16
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3305
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 0.13s
                      Time elapsed: 00:22:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1258/1 [0m                       

                       Computation: 831483 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 866.97
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3458
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 0.12s
                      Time elapsed: 00:22:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1259/1 [0m                       

                       Computation: 770811 steps/s (collection: 0.045s, learning 0.083s)
                       Mean reward: 869.84
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5863
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7726
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 0.13s
                      Time elapsed: 00:22:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1260/1 [0m                       

                       Computation: 802777 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 875.14
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4023
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 0.12s
                      Time elapsed: 00:22:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1261/1 [0m                       

                       Computation: 807084 steps/s (collection: 0.035s, learning 0.087s)
                       Mean reward: 869.26
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8418
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7751
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 0.12s
                      Time elapsed: 00:22:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1262/1 [0m                       

                       Computation: 701160 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 867.96
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8061
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 0.14s
                      Time elapsed: 00:22:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1263/1 [0m                       

                       Computation: 689918 steps/s (collection: 0.037s, learning 0.106s)
                       Mean reward: 872.53
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8324
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 0.14s
                      Time elapsed: 00:23:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1264/1 [0m                       

                       Computation: 724687 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 873.29
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0538
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 0.14s
                      Time elapsed: 00:23:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1265/1 [0m                       

                       Computation: 794261 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 871.56
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3187
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7705
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 0.12s
                      Time elapsed: 00:23:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1266/1 [0m                       

                       Computation: 801963 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 871.02
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2127
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 0.12s
                      Time elapsed: 00:23:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1267/1 [0m                       

                       Computation: 736223 steps/s (collection: 0.047s, learning 0.087s)
                       Mean reward: 872.85
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8194
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 0.13s
                      Time elapsed: 00:23:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1268/1 [0m                       

                       Computation: 758005 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 869.42
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7754
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 0.13s
                      Time elapsed: 00:23:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1269/1 [0m                       

                       Computation: 719554 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 867.34
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4384
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7859
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 0.14s
                      Time elapsed: 00:23:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1270/1 [0m                       

                       Computation: 764928 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 865.61
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3728
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 0.13s
                      Time elapsed: 00:23:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1271/1 [0m                       

                       Computation: 753508 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 875.82
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3090
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 0.13s
                      Time elapsed: 00:23:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1272/1 [0m                       

                       Computation: 657678 steps/s (collection: 0.048s, learning 0.102s)
                       Mean reward: 878.63
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0079
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7807
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 0.15s
                      Time elapsed: 00:23:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1273/1 [0m                       

                       Computation: 679440 steps/s (collection: 0.044s, learning 0.101s)
                       Mean reward: 867.83
               Mean episode length: 247.50
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6445
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 0.14s
                      Time elapsed: 00:23:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1274/1 [0m                       

                       Computation: 723850 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 862.68
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9336
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7696
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 0.14s
                      Time elapsed: 00:23:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1275/1 [0m                       

                       Computation: 719644 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 873.42
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7581
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 0.14s
                      Time elapsed: 00:23:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1276/1 [0m                       

                       Computation: 728010 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 869.04
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1416
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7749
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 0.14s
                      Time elapsed: 00:23:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1277/1 [0m                       

                       Computation: 684940 steps/s (collection: 0.042s, learning 0.102s)
                       Mean reward: 871.43
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2278
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7756
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 0.14s
                      Time elapsed: 00:23:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1278/1 [0m                       

                       Computation: 655242 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 868.39
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0915
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 0.15s
                      Time elapsed: 00:23:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1279/1 [0m                       

                       Computation: 646575 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 870.28
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2704
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 0.15s
                      Time elapsed: 00:23:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1280/1 [0m                       

                       Computation: 618051 steps/s (collection: 0.044s, learning 0.115s)
                       Mean reward: 863.01
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2572
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7707
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 0.16s
                      Time elapsed: 00:23:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1281/1 [0m                       

                       Computation: 627969 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 860.61
               Mean episode length: 247.18
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9611
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 0.16s
                      Time elapsed: 00:23:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1282/1 [0m                       

                       Computation: 550608 steps/s (collection: 0.051s, learning 0.128s)
                       Mean reward: 867.68
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4040
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 0.18s
                      Time elapsed: 00:23:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1283/1 [0m                       

                       Computation: 764437 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 859.64
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4227
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 0.13s
                      Time elapsed: 00:23:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1284/1 [0m                       

                       Computation: 751571 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 857.74
               Mean episode length: 247.01
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6902
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 0.13s
                      Time elapsed: 00:23:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1285/1 [0m                       

                       Computation: 764155 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 861.75
               Mean episode length: 247.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1029
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 0.13s
                      Time elapsed: 00:23:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1286/1 [0m                       

                       Computation: 751203 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 859.30
               Mean episode length: 246.02
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9773
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 0.13s
                      Time elapsed: 00:23:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1287/1 [0m                       

                       Computation: 759490 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 855.59
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.7939
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 0.13s
                      Time elapsed: 00:23:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1288/1 [0m                       

                       Computation: 789333 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 865.60
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9623
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7600
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 0.12s
                      Time elapsed: 00:23:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1289/1 [0m                       

                       Computation: 774859 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 860.07
               Mean episode length: 247.10
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0705
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7498
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 0.13s
                      Time elapsed: 00:23:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1290/1 [0m                       

                       Computation: 667913 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 860.87
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8902
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 0.15s
                      Time elapsed: 00:23:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1291/1 [0m                       

                       Computation: 822541 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 853.14
               Mean episode length: 246.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.0184
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7536
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 0.12s
                      Time elapsed: 00:23:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1292/1 [0m                       

                       Computation: 805588 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 864.75
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1801
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 0.12s
                      Time elapsed: 00:23:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1293/1 [0m                       

                       Computation: 619911 steps/s (collection: 0.050s, learning 0.109s)
                       Mean reward: 859.16
               Mean episode length: 247.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4748
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7644
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 0.16s
                      Time elapsed: 00:23:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1294/1 [0m                       

                       Computation: 739043 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 862.28
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5849
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 0.13s
                      Time elapsed: 00:23:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1295/1 [0m                       

                       Computation: 668995 steps/s (collection: 0.047s, learning 0.100s)
                       Mean reward: 862.32
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8729
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7576
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 0.15s
                      Time elapsed: 00:23:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1296/1 [0m                       

                       Computation: 773897 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 859.97
               Mean episode length: 246.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4027
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7496
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 0.13s
                      Time elapsed: 00:23:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1297/1 [0m                       

                       Computation: 726824 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 871.10
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3914
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 0.14s
                      Time elapsed: 00:23:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1298/1 [0m                       

                       Computation: 772029 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 872.80
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0874
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 0.13s
                      Time elapsed: 00:23:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1299/1 [0m                       

                       Computation: 788996 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 866.83
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7480
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7703
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 0.12s
                      Time elapsed: 00:23:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1300/1 [0m                       

                       Computation: 760859 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 868.00
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7759
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 0.13s
                      Time elapsed: 00:23:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1301/1 [0m                       

                       Computation: 776453 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 869.47
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8635
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 0.13s
                      Time elapsed: 00:23:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1302/1 [0m                       

                       Computation: 689355 steps/s (collection: 0.055s, learning 0.088s)
                       Mean reward: 868.55
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8821
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 0.14s
                      Time elapsed: 00:23:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1303/1 [0m                       

                       Computation: 709918 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 870.54
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9988
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7715
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 0.14s
                      Time elapsed: 00:23:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1304/1 [0m                       

                       Computation: 558482 steps/s (collection: 0.053s, learning 0.123s)
                       Mean reward: 861.59
               Mean episode length: 246.62
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3639
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 0.18s
                      Time elapsed: 00:23:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1305/1 [0m                       

                       Computation: 620057 steps/s (collection: 0.040s, learning 0.118s)
                       Mean reward: 874.46
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2067
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 0.16s
                      Time elapsed: 00:23:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1306/1 [0m                       

                       Computation: 635747 steps/s (collection: 0.040s, learning 0.115s)
                       Mean reward: 866.22
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6164
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 0.15s
                      Time elapsed: 00:23:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1307/1 [0m                       

                       Computation: 713179 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 870.84
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4057
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 0.14s
                      Time elapsed: 00:23:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1308/1 [0m                       

                       Computation: 718253 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 871.34
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5301
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7900
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 0.14s
                      Time elapsed: 00:23:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1309/1 [0m                       

                       Computation: 659663 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 867.33
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8007
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 0.15s
                      Time elapsed: 00:23:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1310/1 [0m                       

                       Computation: 781030 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 864.79
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2942
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7857
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 0.13s
                      Time elapsed: 00:23:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1311/1 [0m                       

                       Computation: 814721 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 861.55
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4746
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7839
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 0.12s
                      Time elapsed: 00:23:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1312/1 [0m                       

                       Computation: 724100 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 867.89
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5799
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 0.14s
                      Time elapsed: 00:23:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1313/1 [0m                       

                       Computation: 802855 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 871.80
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6116
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7898
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 0.12s
                      Time elapsed: 00:23:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1314/1 [0m                       

                       Computation: 832934 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 865.40
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2996
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7863
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 0.12s
                      Time elapsed: 00:23:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1315/1 [0m                       

                       Computation: 783538 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 871.15
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4985
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 0.13s
                      Time elapsed: 00:23:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1316/1 [0m                       

                       Computation: 783132 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 870.48
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5552
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7923
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 0.13s
                      Time elapsed: 00:23:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1317/1 [0m                       

                       Computation: 613846 steps/s (collection: 0.039s, learning 0.122s)
                       Mean reward: 860.66
               Mean episode length: 247.08
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4622
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7834
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 0.16s
                      Time elapsed: 00:23:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1318/1 [0m                       

                       Computation: 652724 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 870.17
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5346
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 0.15s
                      Time elapsed: 00:24:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1319/1 [0m                       

                       Computation: 648348 steps/s (collection: 0.054s, learning 0.098s)
                       Mean reward: 873.51
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8269
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 0.15s
                      Time elapsed: 00:24:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1320/1 [0m                       

                       Computation: 773750 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 870.01
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2773
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7839
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 0.13s
                      Time elapsed: 00:24:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1321/1 [0m                       

                       Computation: 677464 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 870.44
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3865
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7873
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 0.15s
                      Time elapsed: 00:24:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1322/1 [0m                       

                       Computation: 738069 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 866.74
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7138
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7845
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 0.13s
                      Time elapsed: 00:24:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1323/1 [0m                       

                       Computation: 675273 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 873.44
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9707
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7909
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 0.15s
                      Time elapsed: 00:24:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1324/1 [0m                       

                       Computation: 743934 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 874.90
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.1461
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7943
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 0.13s
                      Time elapsed: 00:24:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1325/1 [0m                       

                       Computation: 733115 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 867.79
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9683
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7932
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 0.13s
                      Time elapsed: 00:24:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1326/1 [0m                       

                       Computation: 764864 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 865.88
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6460
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 0.13s
                      Time elapsed: 00:24:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1327/1 [0m                       

                       Computation: 753098 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 875.78
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4216
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7911
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 0.13s
                      Time elapsed: 00:24:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1328/1 [0m                       

                       Computation: 755510 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 870.93
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4500
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7861
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 0.13s
                      Time elapsed: 00:24:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1329/1 [0m                       

                       Computation: 779524 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 870.55
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2202
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 0.13s
                      Time elapsed: 00:24:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1330/1 [0m                       

                       Computation: 672672 steps/s (collection: 0.056s, learning 0.091s)
                       Mean reward: 871.31
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5505
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7891
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 0.15s
                      Time elapsed: 00:24:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1331/1 [0m                       

                       Computation: 741453 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 875.06
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2601
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7898
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 0.13s
                      Time elapsed: 00:24:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1332/1 [0m                       

                       Computation: 801588 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 870.04
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1618
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 0.12s
                      Time elapsed: 00:24:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1333/1 [0m                       

                       Computation: 752703 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 862.50
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5035
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 0.13s
                      Time elapsed: 00:24:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1334/1 [0m                       

                       Computation: 767185 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 869.49
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0086
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 0.13s
                      Time elapsed: 00:24:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1335/1 [0m                       

                       Computation: 738994 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 867.18
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5430
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 0.13s
                      Time elapsed: 00:24:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1336/1 [0m                       

                       Computation: 714805 steps/s (collection: 0.052s, learning 0.086s)
                       Mean reward: 874.95
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0136
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7881
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 0.14s
                      Time elapsed: 00:24:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1337/1 [0m                       

                       Computation: 711494 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 865.93
               Mean episode length: 247.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5335
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 0.14s
                      Time elapsed: 00:24:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1338/1 [0m                       

                       Computation: 764104 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 876.15
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2504
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7876
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 0.13s
                      Time elapsed: 00:24:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1339/1 [0m                       

                       Computation: 694299 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 867.53
               Mean episode length: 247.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6987
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 0.14s
                      Time elapsed: 00:24:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1340/1 [0m                       

                       Computation: 679918 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 872.06
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7975
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 0.14s
                      Time elapsed: 00:24:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1341/1 [0m                       

                       Computation: 677217 steps/s (collection: 0.048s, learning 0.098s)
                       Mean reward: 870.45
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0806
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 0.15s
                      Time elapsed: 00:24:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1342/1 [0m                       

                       Computation: 707024 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 868.27
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9370
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 0.14s
                      Time elapsed: 00:24:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1343/1 [0m                       

                       Computation: 692131 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 869.62
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2517
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7804
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 0.14s
                      Time elapsed: 00:24:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1344/1 [0m                       

                       Computation: 732949 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 865.21
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4394
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 0.13s
                      Time elapsed: 00:24:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1345/1 [0m                       

                       Computation: 728060 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 871.59
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7964
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7895
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 0.14s
                      Time elapsed: 00:24:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1346/1 [0m                       

                       Computation: 701499 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 869.63
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2224
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7917
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 0.14s
                      Time elapsed: 00:24:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1347/1 [0m                       

                       Computation: 697054 steps/s (collection: 0.037s, learning 0.104s)
                       Mean reward: 870.54
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1066
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 0.14s
                      Time elapsed: 00:24:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1348/1 [0m                       

                       Computation: 672312 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 866.41
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5537
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7871
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 0.15s
                      Time elapsed: 00:24:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1349/1 [0m                       

                       Computation: 785552 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 872.77
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7479
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7896
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 0.13s
                      Time elapsed: 00:24:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1350/1 [0m                       

                       Computation: 835471 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 869.46
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0044
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7865
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 0.12s
                      Time elapsed: 00:24:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1351/1 [0m                       

                       Computation: 807982 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 874.42
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9287
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7867
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 0.12s
                      Time elapsed: 00:24:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1352/1 [0m                       

                       Computation: 751619 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 868.32
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9202
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 0.13s
                      Time elapsed: 00:24:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1353/1 [0m                       

                       Computation: 740370 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 871.73
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4114
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 0.13s
                      Time elapsed: 00:24:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1354/1 [0m                       

                       Computation: 800458 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 873.89
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8743
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 0.12s
                      Time elapsed: 00:24:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1355/1 [0m                       

                       Computation: 780016 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 876.39
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5764
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7799
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 0.13s
                      Time elapsed: 00:24:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1356/1 [0m                       

                       Computation: 689517 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 863.54
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8184
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 0.14s
                      Time elapsed: 00:24:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1357/1 [0m                       

                       Computation: 738674 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 874.42
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.1746
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 0.13s
                      Time elapsed: 00:24:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1358/1 [0m                       

                       Computation: 622056 steps/s (collection: 0.058s, learning 0.100s)
                       Mean reward: 857.89
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6626
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 0.16s
                      Time elapsed: 00:24:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1359/1 [0m                       

                       Computation: 712481 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 873.39
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3708
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 0.14s
                      Time elapsed: 00:24:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1360/1 [0m                       

                       Computation: 778617 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 863.14
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8761
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 0.13s
                      Time elapsed: 00:24:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1361/1 [0m                       

                       Computation: 753585 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 873.11
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7252
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 0.13s
                      Time elapsed: 00:24:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1362/1 [0m                       

                       Computation: 783090 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 869.44
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3682
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 0.13s
                      Time elapsed: 00:24:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1363/1 [0m                       

                       Computation: 702175 steps/s (collection: 0.045s, learning 0.095s)
                       Mean reward: 862.71
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6920
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 0.14s
                      Time elapsed: 00:24:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1364/1 [0m                       

                       Computation: 767315 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 874.06
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3712
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 0.13s
                      Time elapsed: 00:24:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1365/1 [0m                       

                       Computation: 763341 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 879.72
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0917
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 0.13s
                      Time elapsed: 00:24:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1366/1 [0m                       

                       Computation: 754323 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 876.66
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5523
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 0.13s
                      Time elapsed: 00:24:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1367/1 [0m                       

                       Computation: 579905 steps/s (collection: 0.044s, learning 0.125s)
                       Mean reward: 873.59
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9175
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7831
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 0.17s
                      Time elapsed: 00:24:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1368/1 [0m                       

                       Computation: 625824 steps/s (collection: 0.044s, learning 0.113s)
                       Mean reward: 877.24
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6186
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 0.16s
                      Time elapsed: 00:24:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1369/1 [0m                       

                       Computation: 780040 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 864.33
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2200
       Episode_Reward/object_height 0.0183
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 0.13s
                      Time elapsed: 00:24:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1370/1 [0m                       

                       Computation: 739044 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 871.91
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6614
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 0.13s
                      Time elapsed: 00:24:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1371/1 [0m                       

                       Computation: 812314 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 869.76
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3244
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 0.12s
                      Time elapsed: 00:24:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1372/1 [0m                       

                       Computation: 722755 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 872.62
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4791
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 0.14s
                      Time elapsed: 00:24:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1373/1 [0m                       

                       Computation: 784845 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 871.86
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6231
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 0.13s
                      Time elapsed: 00:25:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1374/1 [0m                       

                       Computation: 591175 steps/s (collection: 0.047s, learning 0.119s)
                       Mean reward: 870.42
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0692
       Episode_Reward/object_height 0.0183
     Episode_Reward/reaching_object 0.7716
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 0.17s
                      Time elapsed: 00:25:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1375/1 [0m                       

                       Computation: 620099 steps/s (collection: 0.054s, learning 0.105s)
                       Mean reward: 864.15
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8548
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 0.16s
                      Time elapsed: 00:25:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1376/1 [0m                       

                       Computation: 593924 steps/s (collection: 0.050s, learning 0.116s)
                       Mean reward: 873.28
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9563
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 0.17s
                      Time elapsed: 00:25:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1377/1 [0m                       

                       Computation: 632027 steps/s (collection: 0.049s, learning 0.107s)
                       Mean reward: 871.50
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3146
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 0.16s
                      Time elapsed: 00:25:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1378/1 [0m                       

                       Computation: 687145 steps/s (collection: 0.047s, learning 0.096s)
                       Mean reward: 871.03
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6315
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 0.14s
                      Time elapsed: 00:25:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1379/1 [0m                       

                       Computation: 778945 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 859.64
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3327
       Episode_Reward/object_height 0.0176
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 0.13s
                      Time elapsed: 00:25:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1380/1 [0m                       

                       Computation: 625920 steps/s (collection: 0.046s, learning 0.112s)
                       Mean reward: 858.79
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4111
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 0.16s
                      Time elapsed: 00:25:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1381/1 [0m                       

                       Computation: 614090 steps/s (collection: 0.048s, learning 0.112s)
                       Mean reward: 864.28
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0431
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7687
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 0.16s
                      Time elapsed: 00:25:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1382/1 [0m                       

                       Computation: 729934 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 854.37
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2912
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7517
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 0.13s
                      Time elapsed: 00:25:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1383/1 [0m                       

                       Computation: 752209 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 856.76
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8973
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 0.13s
                      Time elapsed: 00:25:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1384/1 [0m                       

                       Computation: 574538 steps/s (collection: 0.050s, learning 0.121s)
                       Mean reward: 857.69
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4279
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7566
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 0.17s
                      Time elapsed: 00:25:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1385/1 [0m                       

                       Computation: 604889 steps/s (collection: 0.048s, learning 0.115s)
                       Mean reward: 857.62
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6481
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 0.16s
                      Time elapsed: 00:25:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1386/1 [0m                       

                       Computation: 580929 steps/s (collection: 0.055s, learning 0.114s)
                       Mean reward: 862.27
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6260
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7730
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 0.17s
                      Time elapsed: 00:25:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1387/1 [0m                       

                       Computation: 564013 steps/s (collection: 0.048s, learning 0.126s)
                       Mean reward: 856.77
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3219
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7690
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 0.17s
                      Time elapsed: 00:25:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1388/1 [0m                       

                       Computation: 585048 steps/s (collection: 0.051s, learning 0.118s)
                       Mean reward: 871.59
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.7646
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7799
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 0.17s
                      Time elapsed: 00:25:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1389/1 [0m                       

                       Computation: 590136 steps/s (collection: 0.046s, learning 0.121s)
                       Mean reward: 853.22
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 169.7131
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 0.17s
                      Time elapsed: 00:25:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1390/1 [0m                       

                       Computation: 677740 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 854.43
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.7899
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 0.15s
                      Time elapsed: 00:25:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1391/1 [0m                       

                       Computation: 748882 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 845.88
               Mean episode length: 246.32
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7576
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 0.13s
                      Time elapsed: 00:25:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1392/1 [0m                       

                       Computation: 726596 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 858.09
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.4795
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 0.14s
                      Time elapsed: 00:25:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1393/1 [0m                       

                       Computation: 717650 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 859.03
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.8259
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 0.14s
                      Time elapsed: 00:25:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1394/1 [0m                       

                       Computation: 648827 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 845.68
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.1276
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7521
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 0.15s
                      Time elapsed: 00:25:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1395/1 [0m                       

                       Computation: 799105 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 847.63
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 168.6834
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7432
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 0.12s
                      Time elapsed: 00:25:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1396/1 [0m                       

                       Computation: 750009 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 852.61
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 169.9552
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7414
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 0.13s
                      Time elapsed: 00:25:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1397/1 [0m                       

                       Computation: 725552 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 845.82
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 168.6205
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7468
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 0.14s
                      Time elapsed: 00:25:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1398/1 [0m                       

                       Computation: 684915 steps/s (collection: 0.039s, learning 0.105s)
                       Mean reward: 864.16
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.3938
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7574
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 0.14s
                      Time elapsed: 00:25:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1399/1 [0m                       

                       Computation: 747094 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 857.13
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.6918
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7545
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 0.13s
                      Time elapsed: 00:25:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1400/1 [0m                       

                       Computation: 694528 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 850.13
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 169.5201
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 0.14s
                      Time elapsed: 00:25:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1401/1 [0m                       

                       Computation: 779580 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 866.48
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.4155
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7600
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 0.13s
                      Time elapsed: 00:25:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1402/1 [0m                       

                       Computation: 751570 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 868.05
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.8267
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 0.13s
                      Time elapsed: 00:25:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1403/1 [0m                       

                       Computation: 761711 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 866.23
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.2292
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 0.13s
                      Time elapsed: 00:25:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1404/1 [0m                       

                       Computation: 726230 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 871.95
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.4600
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 0.14s
                      Time elapsed: 00:25:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1405/1 [0m                       

                       Computation: 616146 steps/s (collection: 0.053s, learning 0.107s)
                       Mean reward: 873.23
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.8280
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7803
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 0.16s
                      Time elapsed: 00:25:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1406/1 [0m                       

                       Computation: 803835 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 871.07
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.5215
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7813
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 0.12s
                      Time elapsed: 00:25:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1407/1 [0m                       

                       Computation: 781480 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 870.15
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.2107
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7773
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 0.13s
                      Time elapsed: 00:25:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1408/1 [0m                       

                       Computation: 634530 steps/s (collection: 0.046s, learning 0.109s)
                       Mean reward: 879.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.1126
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7885
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 0.15s
                      Time elapsed: 00:25:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1409/1 [0m                       

                       Computation: 739023 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 877.57
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.7494
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7878
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 0.13s
                      Time elapsed: 00:25:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1410/1 [0m                       

                       Computation: 623034 steps/s (collection: 0.042s, learning 0.115s)
                       Mean reward: 874.53
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.1947
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7855
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 0.16s
                      Time elapsed: 00:25:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1411/1 [0m                       

                       Computation: 750672 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 876.46
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.7492
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7861
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 0.13s
                      Time elapsed: 00:25:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1412/1 [0m                       

                       Computation: 790189 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 871.08
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.6025
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 0.12s
                      Time elapsed: 00:25:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1413/1 [0m                       

                       Computation: 709170 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 877.95
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.9463
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7871
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 0.14s
                      Time elapsed: 00:25:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1414/1 [0m                       

                       Computation: 745759 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 876.97
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.4923
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 0.13s
                      Time elapsed: 00:25:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1415/1 [0m                       

                       Computation: 766962 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 870.78
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.2990
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 0.13s
                      Time elapsed: 00:25:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1416/1 [0m                       

                       Computation: 728704 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 868.68
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.8995
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 0.13s
                      Time elapsed: 00:25:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1417/1 [0m                       

                       Computation: 749923 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 869.28
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.0909
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 0.13s
                      Time elapsed: 00:25:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1418/1 [0m                       

                       Computation: 670526 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 868.50
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.2199
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 0.15s
                      Time elapsed: 00:25:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1419/1 [0m                       

                       Computation: 695093 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 863.20
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.1084
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 0.14s
                      Time elapsed: 00:25:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1420/1 [0m                       

                       Computation: 563242 steps/s (collection: 0.044s, learning 0.131s)
                       Mean reward: 863.09
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.0889
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 0.17s
                      Time elapsed: 00:25:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1421/1 [0m                       

                       Computation: 694527 steps/s (collection: 0.036s, learning 0.106s)
                       Mean reward: 868.17
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0253
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7807
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 0.14s
                      Time elapsed: 00:25:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1422/1 [0m                       

                       Computation: 698704 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 872.49
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.3033
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 0.14s
                      Time elapsed: 00:25:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1423/1 [0m                       

                       Computation: 677774 steps/s (collection: 0.045s, learning 0.100s)
                       Mean reward: 873.48
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.1331
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7787
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 0.15s
                      Time elapsed: 00:25:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1424/1 [0m                       

                       Computation: 770029 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 869.67
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.4202
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7799
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 0.13s
                      Time elapsed: 00:25:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1425/1 [0m                       

                       Computation: 657465 steps/s (collection: 0.051s, learning 0.099s)
                       Mean reward: 856.84
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8250
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 0.15s
                      Time elapsed: 00:25:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1426/1 [0m                       

                       Computation: 745538 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 860.86
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.3542
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7654
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 0.13s
                      Time elapsed: 00:26:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1427/1 [0m                       

                       Computation: 786232 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 855.78
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.6707
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 0.13s
                      Time elapsed: 00:26:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1428/1 [0m                       

                       Computation: 777107 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 861.65
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.2888
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 0.13s
                      Time elapsed: 00:26:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1429/1 [0m                       

                       Computation: 769619 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 866.76
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.5445
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 0.13s
                      Time elapsed: 00:26:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1430/1 [0m                       

                       Computation: 666309 steps/s (collection: 0.052s, learning 0.096s)
                       Mean reward: 849.72
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.3378
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 0.15s
                      Time elapsed: 00:26:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1431/1 [0m                       

                       Computation: 658746 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 851.10
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.8600
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7561
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 0.15s
                      Time elapsed: 00:26:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1432/1 [0m                       

                       Computation: 569751 steps/s (collection: 0.062s, learning 0.111s)
                       Mean reward: 861.63
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3993
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 0.17s
                      Time elapsed: 00:26:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1433/1 [0m                       

                       Computation: 588474 steps/s (collection: 0.049s, learning 0.119s)
                       Mean reward: 855.74
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5646
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7615
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 0.17s
                      Time elapsed: 00:26:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1434/1 [0m                       

                       Computation: 761873 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 863.98
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.3886
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 0.13s
                      Time elapsed: 00:26:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1435/1 [0m                       

                       Computation: 761991 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 864.92
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0284
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 0.13s
                      Time elapsed: 00:26:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1436/1 [0m                       

                       Computation: 764922 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 857.58
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8430
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 0.13s
                      Time elapsed: 00:26:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1437/1 [0m                       

                       Computation: 762414 steps/s (collection: 0.047s, learning 0.082s)
                       Mean reward: 866.46
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.8201
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7616
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 0.13s
                      Time elapsed: 00:26:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1438/1 [0m                       

                       Computation: 818920 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 860.18
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.4018
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 0.12s
                      Time elapsed: 00:26:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1439/1 [0m                       

                       Computation: 745350 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 870.44
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.4608
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7668
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 0.13s
                      Time elapsed: 00:26:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1440/1 [0m                       

                       Computation: 769713 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 869.49
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.9489
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 0.13s
                      Time elapsed: 00:26:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1441/1 [0m                       

                       Computation: 795586 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 860.67
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3245
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 0.12s
                      Time elapsed: 00:26:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1442/1 [0m                       

                       Computation: 744505 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 877.59
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0110
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7821
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 0.13s
                      Time elapsed: 00:26:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1443/1 [0m                       

                       Computation: 590003 steps/s (collection: 0.047s, learning 0.120s)
                       Mean reward: 873.26
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0213
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 0.17s
                      Time elapsed: 00:26:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1444/1 [0m                       

                       Computation: 655136 steps/s (collection: 0.045s, learning 0.105s)
                       Mean reward: 871.74
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0706
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7859
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 0.15s
                      Time elapsed: 00:26:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1445/1 [0m                       

                       Computation: 608574 steps/s (collection: 0.054s, learning 0.108s)
                       Mean reward: 869.66
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8378
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 0.16s
                      Time elapsed: 00:26:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1446/1 [0m                       

                       Computation: 599220 steps/s (collection: 0.050s, learning 0.115s)
                       Mean reward: 870.51
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3334
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7803
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 0.16s
                      Time elapsed: 00:26:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1447/1 [0m                       

                       Computation: 574463 steps/s (collection: 0.046s, learning 0.126s)
                       Mean reward: 871.76
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3620
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 0.17s
                      Time elapsed: 00:26:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1448/1 [0m                       

                       Computation: 597471 steps/s (collection: 0.048s, learning 0.117s)
                       Mean reward: 869.72
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.1790
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7781
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 0.16s
                      Time elapsed: 00:26:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1449/1 [0m                       

                       Computation: 568114 steps/s (collection: 0.049s, learning 0.124s)
                       Mean reward: 865.40
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2362
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 0.17s
                      Time elapsed: 00:26:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1450/1 [0m                       

                       Computation: 701971 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 868.03
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0001
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7727
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 0.14s
                      Time elapsed: 00:26:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1451/1 [0m                       

                       Computation: 606569 steps/s (collection: 0.044s, learning 0.118s)
                       Mean reward: 860.44
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1943
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 0.16s
                      Time elapsed: 00:26:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1452/1 [0m                       

                       Computation: 712090 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 869.05
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.9508
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 0.14s
                      Time elapsed: 00:26:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1453/1 [0m                       

                       Computation: 725202 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 859.44
               Mean episode length: 247.89
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6031
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7561
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 0.14s
                      Time elapsed: 00:26:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1454/1 [0m                       

                       Computation: 725237 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 874.49
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.1962
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 0.14s
                      Time elapsed: 00:26:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1455/1 [0m                       

                       Computation: 725294 steps/s (collection: 0.036s, learning 0.100s)
                       Mean reward: 871.77
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.6835
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7569
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 0.14s
                      Time elapsed: 00:26:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1456/1 [0m                       

                       Computation: 681462 steps/s (collection: 0.037s, learning 0.108s)
                       Mean reward: 864.51
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.1755
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7489
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 0.14s
                      Time elapsed: 00:26:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1457/1 [0m                       

                       Computation: 815661 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 859.63
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9059
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7454
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 0.12s
                      Time elapsed: 00:26:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1458/1 [0m                       

                       Computation: 733533 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 869.69
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3296
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 0.13s
                      Time elapsed: 00:26:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1459/1 [0m                       

                       Computation: 705022 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 861.33
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3245
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7622
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 0.14s
                      Time elapsed: 00:26:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1460/1 [0m                       

                       Computation: 738221 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 867.27
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7987
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 0.13s
                      Time elapsed: 00:26:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1461/1 [0m                       

                       Computation: 774645 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 865.31
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9893
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 0.13s
                      Time elapsed: 00:26:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1462/1 [0m                       

                       Computation: 788858 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 867.80
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7952
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 0.12s
                      Time elapsed: 00:26:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1463/1 [0m                       

                       Computation: 757772 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 858.87
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1957
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7637
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 0.13s
                      Time elapsed: 00:26:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1464/1 [0m                       

                       Computation: 586457 steps/s (collection: 0.050s, learning 0.118s)
                       Mean reward: 862.25
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5775
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 0.17s
                      Time elapsed: 00:26:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1465/1 [0m                       

                       Computation: 623991 steps/s (collection: 0.050s, learning 0.108s)
                       Mean reward: 857.04
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.8262
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7548
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 0.16s
                      Time elapsed: 00:26:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1466/1 [0m                       

                       Computation: 640263 steps/s (collection: 0.049s, learning 0.105s)
                       Mean reward: 853.88
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.8255
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7500
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 0.15s
                      Time elapsed: 00:26:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1467/1 [0m                       

                       Computation: 637704 steps/s (collection: 0.049s, learning 0.105s)
                       Mean reward: 855.69
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6130
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 0.15s
                      Time elapsed: 00:26:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1468/1 [0m                       

                       Computation: 597412 steps/s (collection: 0.046s, learning 0.119s)
                       Mean reward: 856.99
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4524
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 0.16s
                      Time elapsed: 00:26:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1469/1 [0m                       

                       Computation: 661914 steps/s (collection: 0.047s, learning 0.102s)
                       Mean reward: 851.89
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.3387
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 0.15s
                      Time elapsed: 00:26:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1470/1 [0m                       

                       Computation: 620002 steps/s (collection: 0.052s, learning 0.107s)
                       Mean reward: 869.53
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9625
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7751
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 0.16s
                      Time elapsed: 00:26:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1471/1 [0m                       

                       Computation: 698794 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 869.26
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2056
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 0.14s
                      Time elapsed: 00:26:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1472/1 [0m                       

                       Computation: 753763 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 866.41
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7916
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7836
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 0.13s
                      Time elapsed: 00:26:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1473/1 [0m                       

                       Computation: 640495 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 858.01
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8369
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 0.15s
                      Time elapsed: 00:26:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1474/1 [0m                       

                       Computation: 661217 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 855.70
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.9661
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7703
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 0.15s
                      Time elapsed: 00:26:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1475/1 [0m                       

                       Computation: 670760 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 859.23
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1293
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 0.15s
                      Time elapsed: 00:26:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1476/1 [0m                       

                       Computation: 708634 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 864.43
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0749
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 0.14s
                      Time elapsed: 00:26:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1477/1 [0m                       

                       Computation: 747160 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 858.07
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8650
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 0.13s
                      Time elapsed: 00:26:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1478/1 [0m                       

                       Computation: 731830 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 861.52
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4206
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 0.13s
                      Time elapsed: 00:27:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1479/1 [0m                       

                       Computation: 767906 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 856.05
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6396
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 0.13s
                      Time elapsed: 00:27:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1480/1 [0m                       

                       Computation: 786699 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 863.71
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0705
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 0.12s
                      Time elapsed: 00:27:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1481/1 [0m                       

                       Computation: 794861 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 847.55
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.5166
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7541
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 0.12s
                      Time elapsed: 00:27:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1482/1 [0m                       

                       Computation: 740161 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 857.53
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7543
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 0.13s
                      Time elapsed: 00:27:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1483/1 [0m                       

                       Computation: 756444 steps/s (collection: 0.047s, learning 0.083s)
                       Mean reward: 854.46
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3221
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7687
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 0.13s
                      Time elapsed: 00:27:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1484/1 [0m                       

                       Computation: 770543 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 857.53
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4551
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 0.13s
                      Time elapsed: 00:27:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1485/1 [0m                       

                       Computation: 739742 steps/s (collection: 0.047s, learning 0.086s)
                       Mean reward: 861.66
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0133
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7771
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 0.13s
                      Time elapsed: 00:27:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1486/1 [0m                       

                       Computation: 747436 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 850.11
               Mean episode length: 247.03
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.3734
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 0.13s
                      Time elapsed: 00:27:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1487/1 [0m                       

                       Computation: 701017 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 859.12
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8871
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7736
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 0.14s
                      Time elapsed: 00:27:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1488/1 [0m                       

                       Computation: 698788 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 859.77
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2461
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 0.14s
                      Time elapsed: 00:27:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1489/1 [0m                       

                       Computation: 758447 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 854.17
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.0006
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 0.13s
                      Time elapsed: 00:27:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1490/1 [0m                       

                       Computation: 672450 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 865.02
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9856
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7737
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 0.15s
                      Time elapsed: 00:27:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1491/1 [0m                       

                       Computation: 759368 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 864.57
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8934
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 0.13s
                      Time elapsed: 00:27:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1492/1 [0m                       

                       Computation: 600672 steps/s (collection: 0.044s, learning 0.120s)
                       Mean reward: 859.57
               Mean episode length: 247.03
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3668
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 0.16s
                      Time elapsed: 00:27:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1493/1 [0m                       

                       Computation: 761893 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 863.12
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1691
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 0.13s
                      Time elapsed: 00:27:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1494/1 [0m                       

                       Computation: 815634 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 867.36
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4989
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7643
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 0.12s
                      Time elapsed: 00:27:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1495/1 [0m                       

                       Computation: 779198 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 861.15
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1598
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 0.13s
                      Time elapsed: 00:27:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1496/1 [0m                       

                       Computation: 761942 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 857.79
               Mean episode length: 247.10
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9624
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 0.13s
                      Time elapsed: 00:27:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1497/1 [0m                       

                       Computation: 593829 steps/s (collection: 0.050s, learning 0.116s)
                       Mean reward: 863.51
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6786
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7730
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 0.17s
                      Time elapsed: 00:27:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1498/1 [0m                       

                       Computation: 568725 steps/s (collection: 0.046s, learning 0.127s)
                       Mean reward: 862.44
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0519
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7730
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.6250
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 0.17s
                      Time elapsed: 00:27:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1499/1 [0m                       

                       Computation: 559962 steps/s (collection: 0.057s, learning 0.119s)
                       Mean reward: 855.34
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.1747
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7599
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 0.18s
                      Time elapsed: 00:27:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1500/1 [0m                       

                       Computation: 714778 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 856.69
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7863
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 0.14s
                      Time elapsed: 00:27:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1501/1 [0m                       

                       Computation: 805045 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 861.11
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3906
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147554304
                    Iteration time: 0.12s
                      Time elapsed: 00:27:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1502/1 [0m                       

                       Computation: 696516 steps/s (collection: 0.037s, learning 0.104s)
                       Mean reward: 860.72
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4538
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7556
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 147652608
                    Iteration time: 0.14s
                      Time elapsed: 00:27:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1503/1 [0m                       

                       Computation: 791626 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 845.83
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.4654
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7509
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147750912
                    Iteration time: 0.12s
                      Time elapsed: 00:27:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1504/1 [0m                       

                       Computation: 633968 steps/s (collection: 0.038s, learning 0.118s)
                       Mean reward: 844.03
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.0983
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7453
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 147849216
                    Iteration time: 0.16s
                      Time elapsed: 00:27:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1505/1 [0m                       

                       Computation: 646196 steps/s (collection: 0.048s, learning 0.105s)
                       Mean reward: 856.22
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4051
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7530
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 147947520
                    Iteration time: 0.15s
                      Time elapsed: 00:27:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1506/1 [0m                       

                       Computation: 584964 steps/s (collection: 0.046s, learning 0.123s)
                       Mean reward: 827.55
               Mean episode length: 246.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 164.4055
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7334
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 148045824
                    Iteration time: 0.17s
                      Time elapsed: 00:27:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1507/1 [0m                       

                       Computation: 597520 steps/s (collection: 0.047s, learning 0.117s)
                       Mean reward: 866.53
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3486
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7653
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 148144128
                    Iteration time: 0.16s
                      Time elapsed: 00:27:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1508/1 [0m                       

                       Computation: 621954 steps/s (collection: 0.050s, learning 0.109s)
                       Mean reward: 839.29
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.6049
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 148242432
                    Iteration time: 0.16s
                      Time elapsed: 00:27:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1509/1 [0m                       

                       Computation: 759057 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 859.04
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9987
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 148340736
                    Iteration time: 0.13s
                      Time elapsed: 00:27:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1510/1 [0m                       

                       Computation: 693920 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 853.20
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.1905
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7571
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 148439040
                    Iteration time: 0.14s
                      Time elapsed: 00:27:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1511/1 [0m                       

                       Computation: 760068 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 859.82
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2158
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 148537344
                    Iteration time: 0.13s
                      Time elapsed: 00:27:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1512/1 [0m                       

                       Computation: 629941 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 848.25
               Mean episode length: 245.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7631
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 148635648
                    Iteration time: 0.16s
                      Time elapsed: 00:27:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1513/1 [0m                       

                       Computation: 620455 steps/s (collection: 0.047s, learning 0.111s)
                       Mean reward: 839.81
               Mean episode length: 245.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.1585
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7365
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 148733952
                    Iteration time: 0.16s
                      Time elapsed: 00:27:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1514/1 [0m                       

                       Computation: 599278 steps/s (collection: 0.055s, learning 0.109s)
                       Mean reward: 837.00
               Mean episode length: 246.14
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.0799
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7334
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 148832256
                    Iteration time: 0.16s
                      Time elapsed: 00:27:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1515/1 [0m                       

                       Computation: 682421 steps/s (collection: 0.048s, learning 0.096s)
                       Mean reward: 848.09
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.2671
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7364
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 148930560
                    Iteration time: 0.14s
                      Time elapsed: 00:27:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1516/1 [0m                       

                       Computation: 682562 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 849.42
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7517
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7380
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 149028864
                    Iteration time: 0.14s
                      Time elapsed: 00:27:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1517/1 [0m                       

                       Computation: 814324 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 836.30
               Mean episode length: 246.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.9247
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7346
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 149127168
                    Iteration time: 0.12s
                      Time elapsed: 00:27:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1518/1 [0m                       

                       Computation: 761865 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 840.03
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.4100
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7356
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 149225472
                    Iteration time: 0.13s
                      Time elapsed: 00:27:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1519/1 [0m                       

                       Computation: 759013 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 817.29
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 162.2620
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7187
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.7083
--------------------------------------------------------------------------------
                   Total timesteps: 149323776
                    Iteration time: 0.13s
                      Time elapsed: 00:27:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1520/1 [0m                       

                       Computation: 755233 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 786.16
               Mean episode length: 247.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 155.7190
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7010
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 149422080
                    Iteration time: 0.13s
                      Time elapsed: 00:27:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1521/1 [0m                       

                       Computation: 620042 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 796.35
               Mean episode length: 246.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 158.5644
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7010
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 149520384
                    Iteration time: 0.16s
                      Time elapsed: 00:27:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1522/1 [0m                       

                       Computation: 633942 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 810.90
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 161.2539
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7172
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 149618688
                    Iteration time: 0.16s
                      Time elapsed: 00:27:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1523/1 [0m                       

                       Computation: 561679 steps/s (collection: 0.048s, learning 0.127s)
                       Mean reward: 830.98
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.2305
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7275
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 149716992
                    Iteration time: 0.18s
                      Time elapsed: 00:27:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1524/1 [0m                       

                       Computation: 799018 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 808.52
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 160.8764
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7170
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 149815296
                    Iteration time: 0.12s
                      Time elapsed: 00:27:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1525/1 [0m                       

                       Computation: 825966 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 817.40
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 161.8568
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7106
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 149913600
                    Iteration time: 0.12s
                      Time elapsed: 00:27:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1526/1 [0m                       

                       Computation: 847386 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 823.32
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 163.1451
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7171
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 150011904
                    Iteration time: 0.12s
                      Time elapsed: 00:27:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1527/1 [0m                       

                       Computation: 776622 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 831.36
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 163.7024
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7227
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 150110208
                    Iteration time: 0.13s
                      Time elapsed: 00:27:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1528/1 [0m                       

                       Computation: 813655 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 840.07
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.6941
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7397
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 150208512
                    Iteration time: 0.12s
                      Time elapsed: 00:27:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1529/1 [0m                       

                       Computation: 784857 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 860.04
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0271
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7485
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 150306816
                    Iteration time: 0.13s
                      Time elapsed: 00:27:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1530/1 [0m                       

                       Computation: 736520 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 850.52
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.5291
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7529
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 150405120
                    Iteration time: 0.13s
                      Time elapsed: 00:27:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1531/1 [0m                       

                       Computation: 709655 steps/s (collection: 0.047s, learning 0.092s)
                       Mean reward: 852.68
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.0569
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7549
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 150503424
                    Iteration time: 0.14s
                      Time elapsed: 00:28:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1532/1 [0m                       

                       Computation: 648488 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 864.54
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3325
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7709
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 150601728
                    Iteration time: 0.15s
                      Time elapsed: 00:28:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1533/1 [0m                       

                       Computation: 647241 steps/s (collection: 0.046s, learning 0.106s)
                       Mean reward: 870.79
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5834
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7758
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 150700032
                    Iteration time: 0.15s
                      Time elapsed: 00:28:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1534/1 [0m                       

                       Computation: 740703 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 872.54
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7193
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7811
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 150798336
                    Iteration time: 0.13s
                      Time elapsed: 00:28:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1535/1 [0m                       

                       Computation: 832700 steps/s (collection: 0.043s, learning 0.075s)
                       Mean reward: 860.37
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1258
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7706
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 150896640
                    Iteration time: 0.12s
                      Time elapsed: 00:28:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1536/1 [0m                       

                       Computation: 733468 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 859.56
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.4495
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7620
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 150994944
                    Iteration time: 0.13s
                      Time elapsed: 00:28:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1537/1 [0m                       

                       Computation: 745930 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 869.82
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3950
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 151093248
                    Iteration time: 0.13s
                      Time elapsed: 00:28:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1538/1 [0m                       

                       Computation: 822812 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 860.06
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1845
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 151191552
                    Iteration time: 0.12s
                      Time elapsed: 00:28:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1539/1 [0m                       

                       Computation: 767895 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 861.83
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0774
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7592
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 151289856
                    Iteration time: 0.13s
                      Time elapsed: 00:28:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1540/1 [0m                       

                       Computation: 578041 steps/s (collection: 0.053s, learning 0.118s)
                       Mean reward: 857.57
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4925
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 151388160
                    Iteration time: 0.17s
                      Time elapsed: 00:28:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1541/1 [0m                       

                       Computation: 570340 steps/s (collection: 0.061s, learning 0.111s)
                       Mean reward: 854.94
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5429
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 151486464
                    Iteration time: 0.17s
                      Time elapsed: 00:28:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1542/1 [0m                       

                       Computation: 541501 steps/s (collection: 0.048s, learning 0.134s)
                       Mean reward: 848.46
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.9177
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7392
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 151584768
                    Iteration time: 0.18s
                      Time elapsed: 00:28:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1543/1 [0m                       

                       Computation: 624001 steps/s (collection: 0.045s, learning 0.113s)
                       Mean reward: 857.18
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9639
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 151683072
                    Iteration time: 0.16s
                      Time elapsed: 00:28:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1544/1 [0m                       

                       Computation: 634100 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 861.05
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5215
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7559
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 151781376
                    Iteration time: 0.16s
                      Time elapsed: 00:28:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1545/1 [0m                       

                       Computation: 561614 steps/s (collection: 0.059s, learning 0.116s)
                       Mean reward: 855.24
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.7653
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 151879680
                    Iteration time: 0.18s
                      Time elapsed: 00:28:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1546/1 [0m                       

                       Computation: 616254 steps/s (collection: 0.050s, learning 0.110s)
                       Mean reward: 858.09
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.8252
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 151977984
                    Iteration time: 0.16s
                      Time elapsed: 00:28:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1547/1 [0m                       

                       Computation: 560032 steps/s (collection: 0.053s, learning 0.123s)
                       Mean reward: 865.39
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.3472
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152076288
                    Iteration time: 0.18s
                      Time elapsed: 00:28:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1548/1 [0m                       

                       Computation: 797598 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 862.41
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5430
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 152174592
                    Iteration time: 0.12s
                      Time elapsed: 00:28:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1549/1 [0m                       

                       Computation: 743835 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 861.16
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6362
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 152272896
                    Iteration time: 0.13s
                      Time elapsed: 00:28:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1550/1 [0m                       

                       Computation: 623500 steps/s (collection: 0.038s, learning 0.120s)
                       Mean reward: 864.79
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.0483
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7595
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 152371200
                    Iteration time: 0.16s
                      Time elapsed: 00:28:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1551/1 [0m                       

                       Computation: 558416 steps/s (collection: 0.048s, learning 0.128s)
                       Mean reward: 862.22
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7056
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152469504
                    Iteration time: 0.18s
                      Time elapsed: 00:28:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1552/1 [0m                       

                       Computation: 624013 steps/s (collection: 0.044s, learning 0.114s)
                       Mean reward: 871.92
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.5388
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7733
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 152567808
                    Iteration time: 0.16s
                      Time elapsed: 00:28:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1553/1 [0m                       

                       Computation: 805477 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 862.04
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6911
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7688
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 152666112
                    Iteration time: 0.12s
                      Time elapsed: 00:28:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1554/1 [0m                       

                       Computation: 716950 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 863.87
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.7559
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7637
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 152764416
                    Iteration time: 0.14s
                      Time elapsed: 00:28:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1555/1 [0m                       

                       Computation: 618131 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 855.75
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.0701
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7568
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 152862720
                    Iteration time: 0.16s
                      Time elapsed: 00:28:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1556/1 [0m                       

                       Computation: 571003 steps/s (collection: 0.055s, learning 0.118s)
                       Mean reward: 852.38
               Mean episode length: 247.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.5833
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 152961024
                    Iteration time: 0.17s
                      Time elapsed: 00:28:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1557/1 [0m                       

                       Computation: 703290 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 851.96
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 169.8839
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7518
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 153059328
                    Iteration time: 0.14s
                      Time elapsed: 00:28:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1558/1 [0m                       

                       Computation: 689368 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 853.99
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.5151
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7423
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 153157632
                    Iteration time: 0.14s
                      Time elapsed: 00:28:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1559/1 [0m                       

                       Computation: 714349 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 849.96
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.2175
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7427
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 153255936
                    Iteration time: 0.14s
                      Time elapsed: 00:28:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1560/1 [0m                       

                       Computation: 700773 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 855.68
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.5169
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7450
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 153354240
                    Iteration time: 0.14s
                      Time elapsed: 00:28:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1561/1 [0m                       

                       Computation: 717731 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 843.89
               Mean episode length: 248.02
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.9715
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7332
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 153452544
                    Iteration time: 0.14s
                      Time elapsed: 00:28:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1562/1 [0m                       

                       Computation: 655188 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 854.85
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.0551
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7407
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 153550848
                    Iteration time: 0.15s
                      Time elapsed: 00:28:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1563/1 [0m                       

                       Computation: 741850 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 849.04
               Mean episode length: 246.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.9299
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7398
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 153649152
                    Iteration time: 0.13s
                      Time elapsed: 00:28:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1564/1 [0m                       

                       Computation: 773329 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 857.86
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.1532
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7498
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 153747456
                    Iteration time: 0.13s
                      Time elapsed: 00:28:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1565/1 [0m                       

                       Computation: 770039 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 856.40
               Mean episode length: 246.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6519
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7465
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 153845760
                    Iteration time: 0.13s
                      Time elapsed: 00:28:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1566/1 [0m                       

                       Computation: 610430 steps/s (collection: 0.043s, learning 0.118s)
                       Mean reward: 851.17
               Mean episode length: 245.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.5897
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7471
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 153944064
                    Iteration time: 0.16s
                      Time elapsed: 00:28:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1567/1 [0m                       

                       Computation: 860511 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 854.75
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7980
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7358
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 154042368
                    Iteration time: 0.11s
                      Time elapsed: 00:28:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1568/1 [0m                       

                       Computation: 524154 steps/s (collection: 0.055s, learning 0.133s)
                       Mean reward: 861.51
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.5186
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7551
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 154140672
                    Iteration time: 0.19s
                      Time elapsed: 00:28:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1569/1 [0m                       

                       Computation: 558459 steps/s (collection: 0.049s, learning 0.128s)
                       Mean reward: 854.75
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.0051
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7510
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 154238976
                    Iteration time: 0.18s
                      Time elapsed: 00:28:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1570/1 [0m                       

                       Computation: 558416 steps/s (collection: 0.054s, learning 0.122s)
                       Mean reward: 859.21
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.3498
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7448
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.8750
--------------------------------------------------------------------------------
                   Total timesteps: 154337280
                    Iteration time: 0.18s
                      Time elapsed: 00:28:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1571/1 [0m                       

                       Computation: 545848 steps/s (collection: 0.054s, learning 0.127s)
                       Mean reward: 854.73
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.1334
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7288
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 154435584
                    Iteration time: 0.18s
                      Time elapsed: 00:28:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1572/1 [0m                       

                       Computation: 699216 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 840.93
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.7369
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7196
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 154533888
                    Iteration time: 0.14s
                      Time elapsed: 00:28:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1573/1 [0m                       

                       Computation: 776584 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 845.15
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.3001
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7217
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 154632192
                    Iteration time: 0.13s
                      Time elapsed: 00:28:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1574/1 [0m                       

                       Computation: 806087 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 852.61
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.0422
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7263
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 154730496
                    Iteration time: 0.12s
                      Time elapsed: 00:28:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1575/1 [0m                       

                       Computation: 800686 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 843.69
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 167.9266
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7258
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 154828800
                    Iteration time: 0.12s
                      Time elapsed: 00:28:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1576/1 [0m                       

                       Computation: 794238 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 856.69
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.5631
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7353
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 154927104
                    Iteration time: 0.12s
                      Time elapsed: 00:28:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1577/1 [0m                       

                       Computation: 758730 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 854.43
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 169.8955
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7325
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 155025408
                    Iteration time: 0.13s
                      Time elapsed: 00:28:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1578/1 [0m                       

                       Computation: 823278 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 867.06
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.7210
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7447
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 155123712
                    Iteration time: 0.12s
                      Time elapsed: 00:28:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1579/1 [0m                       

                       Computation: 805669 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 860.31
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.1130
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7483
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 155222016
                    Iteration time: 0.12s
                      Time elapsed: 00:28:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1580/1 [0m                       

                       Computation: 753125 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 866.34
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.3866
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7504
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 155320320
                    Iteration time: 0.13s
                      Time elapsed: 00:28:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1581/1 [0m                       

                       Computation: 758892 steps/s (collection: 0.046s, learning 0.084s)
                       Mean reward: 867.16
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.6978
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 155418624
                    Iteration time: 0.13s
                      Time elapsed: 00:28:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1582/1 [0m                       

                       Computation: 652996 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 865.62
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.3949
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7582
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 155516928
                    Iteration time: 0.15s
                      Time elapsed: 00:28:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1583/1 [0m                       

                       Computation: 557742 steps/s (collection: 0.056s, learning 0.121s)
                       Mean reward: 866.78
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.3494
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 155615232
                    Iteration time: 0.18s
                      Time elapsed: 00:29:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1584/1 [0m                       

                       Computation: 555279 steps/s (collection: 0.055s, learning 0.122s)
                       Mean reward: 862.23
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.1281
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 155713536
                    Iteration time: 0.18s
                      Time elapsed: 00:29:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1585/1 [0m                       

                       Computation: 545947 steps/s (collection: 0.051s, learning 0.130s)
                       Mean reward: 869.16
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.0886
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7597
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 155811840
                    Iteration time: 0.18s
                      Time elapsed: 00:29:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1586/1 [0m                       

                       Computation: 629827 steps/s (collection: 0.047s, learning 0.109s)
                       Mean reward: 869.78
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.2165
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 155910144
                    Iteration time: 0.16s
                      Time elapsed: 00:29:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1587/1 [0m                       

                       Computation: 576408 steps/s (collection: 0.047s, learning 0.124s)
                       Mean reward: 867.54
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.8383
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7582
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 156008448
                    Iteration time: 0.17s
                      Time elapsed: 00:29:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1588/1 [0m                       

                       Computation: 636052 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 868.66
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.1224
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7548
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 156106752
                    Iteration time: 0.15s
                      Time elapsed: 00:29:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1589/1 [0m                       

                       Computation: 608388 steps/s (collection: 0.051s, learning 0.111s)
                       Mean reward: 857.75
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.6709
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7526
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 156205056
                    Iteration time: 0.16s
                      Time elapsed: 00:29:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1590/1 [0m                       

                       Computation: 612063 steps/s (collection: 0.046s, learning 0.115s)
                       Mean reward: 869.16
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.0353
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 156303360
                    Iteration time: 0.16s
                      Time elapsed: 00:29:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1591/1 [0m                       

                       Computation: 638189 steps/s (collection: 0.049s, learning 0.105s)
                       Mean reward: 863.15
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.8721
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 156401664
                    Iteration time: 0.15s
                      Time elapsed: 00:29:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1592/1 [0m                       

                       Computation: 699530 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 870.63
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.4309
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7706
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 156499968
                    Iteration time: 0.14s
                      Time elapsed: 00:29:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1593/1 [0m                       

                       Computation: 802402 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 863.64
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0496
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7563
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 156598272
                    Iteration time: 0.12s
                      Time elapsed: 00:29:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1594/1 [0m                       

                       Computation: 781353 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 862.79
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.0881
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7447
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 156696576
                    Iteration time: 0.13s
                      Time elapsed: 00:29:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1595/1 [0m                       

                       Computation: 805668 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 855.46
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.5069
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7542
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 156794880
                    Iteration time: 0.12s
                      Time elapsed: 00:29:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1596/1 [0m                       

                       Computation: 754573 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 859.46
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.2245
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 156893184
                    Iteration time: 0.13s
                      Time elapsed: 00:29:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1597/1 [0m                       

                       Computation: 787348 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 863.73
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.7350
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7525
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 156991488
                    Iteration time: 0.12s
                      Time elapsed: 00:29:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1598/1 [0m                       

                       Computation: 787499 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 871.24
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.4904
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 157089792
                    Iteration time: 0.12s
                      Time elapsed: 00:29:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1599/1 [0m                       

                       Computation: 768323 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 865.42
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.2925
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7610
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 157188096
                    Iteration time: 0.13s
                      Time elapsed: 00:29:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1600/1 [0m                       

                       Computation: 741793 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 861.88
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.8571
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 157286400
                    Iteration time: 0.13s
                      Time elapsed: 00:29:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1601/1 [0m                       

                       Computation: 747194 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 869.32
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.9365
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7476
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 157384704
                    Iteration time: 0.13s
                      Time elapsed: 00:29:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1602/1 [0m                       

                       Computation: 736889 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 858.50
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3616
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7531
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 157483008
                    Iteration time: 0.13s
                      Time elapsed: 00:29:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1603/1 [0m                       

                       Computation: 761979 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 856.86
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6737
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7458
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 157581312
                    Iteration time: 0.13s
                      Time elapsed: 00:29:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1604/1 [0m                       

                       Computation: 805632 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 858.78
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.0777
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 157679616
                    Iteration time: 0.12s
                      Time elapsed: 00:29:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1605/1 [0m                       

                       Computation: 617861 steps/s (collection: 0.045s, learning 0.115s)
                       Mean reward: 867.57
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.9427
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 157777920
                    Iteration time: 0.16s
                      Time elapsed: 00:29:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1606/1 [0m                       

                       Computation: 600982 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 849.62
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.0152
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7449
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 157876224
                    Iteration time: 0.16s
                      Time elapsed: 00:29:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1607/1 [0m                       

                       Computation: 631697 steps/s (collection: 0.048s, learning 0.108s)
                       Mean reward: 863.58
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.7466
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7519
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 157974528
                    Iteration time: 0.16s
                      Time elapsed: 00:29:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1608/1 [0m                       

                       Computation: 606735 steps/s (collection: 0.050s, learning 0.112s)
                       Mean reward: 864.31
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.0077
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7498
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 158072832
                    Iteration time: 0.16s
                      Time elapsed: 00:29:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1609/1 [0m                       

                       Computation: 597468 steps/s (collection: 0.046s, learning 0.119s)
                       Mean reward: 855.39
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8814
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7450
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 158171136
                    Iteration time: 0.16s
                      Time elapsed: 00:29:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1610/1 [0m                       

                       Computation: 586186 steps/s (collection: 0.047s, learning 0.120s)
                       Mean reward: 861.25
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5603
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 158269440
                    Iteration time: 0.17s
                      Time elapsed: 00:29:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1611/1 [0m                       

                       Computation: 680086 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 867.29
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.6889
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7466
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 158367744
                    Iteration time: 0.14s
                      Time elapsed: 00:29:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1612/1 [0m                       

                       Computation: 684541 steps/s (collection: 0.039s, learning 0.105s)
                       Mean reward: 856.31
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2653
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7404
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 158466048
                    Iteration time: 0.14s
                      Time elapsed: 00:29:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1613/1 [0m                       

                       Computation: 661876 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 873.21
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.9828
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7585
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 158564352
                    Iteration time: 0.15s
                      Time elapsed: 00:29:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1614/1 [0m                       

                       Computation: 711106 steps/s (collection: 0.036s, learning 0.102s)
                       Mean reward: 874.12
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0569
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 158662656
                    Iteration time: 0.14s
                      Time elapsed: 00:29:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1615/1 [0m                       

                       Computation: 754546 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 864.25
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3588
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 158760960
                    Iteration time: 0.13s
                      Time elapsed: 00:29:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1616/1 [0m                       

                       Computation: 766369 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 855.41
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3921
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7588
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 158859264
                    Iteration time: 0.13s
                      Time elapsed: 00:29:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1617/1 [0m                       

                       Computation: 739510 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 861.70
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6988
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7576
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 158957568
                    Iteration time: 0.13s
                      Time elapsed: 00:29:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1618/1 [0m                       

                       Computation: 754393 steps/s (collection: 0.046s, learning 0.084s)
                       Mean reward: 855.42
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5899
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 159055872
                    Iteration time: 0.13s
                      Time elapsed: 00:29:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1619/1 [0m                       

                       Computation: 791533 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 858.95
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7604
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7552
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 159154176
                    Iteration time: 0.12s
                      Time elapsed: 00:29:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1620/1 [0m                       

                       Computation: 704310 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 858.31
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1286
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7588
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 159252480
                    Iteration time: 0.14s
                      Time elapsed: 00:29:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1621/1 [0m                       

                       Computation: 776046 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 858.73
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7944
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7585
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 159350784
                    Iteration time: 0.13s
                      Time elapsed: 00:29:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1622/1 [0m                       

                       Computation: 581536 steps/s (collection: 0.047s, learning 0.123s)
                       Mean reward: 848.66
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.5757
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7484
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 159449088
                    Iteration time: 0.17s
                      Time elapsed: 00:29:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1623/1 [0m                       

                       Computation: 612325 steps/s (collection: 0.049s, learning 0.112s)
                       Mean reward: 863.06
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6999
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7585
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 18.0833
--------------------------------------------------------------------------------
                   Total timesteps: 159547392
                    Iteration time: 0.16s
                      Time elapsed: 00:29:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1624/1 [0m                       

                       Computation: 601844 steps/s (collection: 0.049s, learning 0.114s)
                       Mean reward: 866.54
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4666
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 159645696
                    Iteration time: 0.16s
                      Time elapsed: 00:29:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1625/1 [0m                       

                       Computation: 782321 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 862.79
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9022
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7596
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 159744000
                    Iteration time: 0.13s
                      Time elapsed: 00:29:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1626/1 [0m                       

                       Computation: 694644 steps/s (collection: 0.050s, learning 0.092s)
                       Mean reward: 874.71
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9837
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 159842304
                    Iteration time: 0.14s
                      Time elapsed: 00:29:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1627/1 [0m                       

                       Computation: 725619 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 870.45
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2948
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7706
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 159940608
                    Iteration time: 0.14s
                      Time elapsed: 00:29:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1628/1 [0m                       

                       Computation: 777032 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 865.56
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2863
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7627
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 160038912
                    Iteration time: 0.13s
                      Time elapsed: 00:29:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1629/1 [0m                       

                       Computation: 692131 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 862.73
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3620
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 160137216
                    Iteration time: 0.14s
                      Time elapsed: 00:29:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1630/1 [0m                       

                       Computation: 711788 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 863.49
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0928
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 160235520
                    Iteration time: 0.14s
                      Time elapsed: 00:29:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1631/1 [0m                       

                       Computation: 704143 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 860.84
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5341
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 160333824
                    Iteration time: 0.14s
                      Time elapsed: 00:29:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1632/1 [0m                       

                       Computation: 755680 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 866.60
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5551
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7634
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 160432128
                    Iteration time: 0.13s
                      Time elapsed: 00:29:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1633/1 [0m                       

                       Computation: 673255 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 861.00
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3317
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.1667
--------------------------------------------------------------------------------
                   Total timesteps: 160530432
                    Iteration time: 0.15s
                      Time elapsed: 00:29:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1634/1 [0m                       

                       Computation: 746689 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 864.50
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6895
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7564
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 160628736
                    Iteration time: 0.13s
                      Time elapsed: 00:30:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1635/1 [0m                       

                       Computation: 733261 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 866.08
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4423
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 160727040
                    Iteration time: 0.13s
                      Time elapsed: 00:30:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1636/1 [0m                       

                       Computation: 722402 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 861.06
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6852
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7635
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 160825344
                    Iteration time: 0.14s
                      Time elapsed: 00:30:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1637/1 [0m                       

                       Computation: 698511 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 860.85
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1269
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 160923648
                    Iteration time: 0.14s
                      Time elapsed: 00:30:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1638/1 [0m                       

                       Computation: 670945 steps/s (collection: 0.048s, learning 0.099s)
                       Mean reward: 870.88
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5711
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7683
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 161021952
                    Iteration time: 0.15s
                      Time elapsed: 00:30:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1639/1 [0m                       

                       Computation: 776996 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 862.33
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0873
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7634
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 161120256
                    Iteration time: 0.13s
                      Time elapsed: 00:30:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1640/1 [0m                       

                       Computation: 753172 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 852.13
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.4251
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 161218560
                    Iteration time: 0.13s
                      Time elapsed: 00:30:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1641/1 [0m                       

                       Computation: 789083 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 863.96
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9378
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7651
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 161316864
                    Iteration time: 0.12s
                      Time elapsed: 00:30:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1642/1 [0m                       

                       Computation: 736312 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 864.92
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1075
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 161415168
                    Iteration time: 0.13s
                      Time elapsed: 00:30:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1643/1 [0m                       

                       Computation: 746814 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 859.73
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2897
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.7917
--------------------------------------------------------------------------------
                   Total timesteps: 161513472
                    Iteration time: 0.13s
                      Time elapsed: 00:30:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1644/1 [0m                       

                       Computation: 749911 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 865.66
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4194
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 161611776
                    Iteration time: 0.13s
                      Time elapsed: 00:30:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1645/1 [0m                       

                       Computation: 725418 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 871.03
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4589
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 161710080
                    Iteration time: 0.14s
                      Time elapsed: 00:30:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1646/1 [0m                       

                       Computation: 680067 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 868.49
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0247
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 161808384
                    Iteration time: 0.14s
                      Time elapsed: 00:30:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1647/1 [0m                       

                       Computation: 770818 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 868.00
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6607
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 161906688
                    Iteration time: 0.13s
                      Time elapsed: 00:30:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1648/1 [0m                       

                       Computation: 764630 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 865.22
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0824
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 162004992
                    Iteration time: 0.13s
                      Time elapsed: 00:30:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1649/1 [0m                       

                       Computation: 776703 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 868.96
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8008
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7654
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 162103296
                    Iteration time: 0.13s
                      Time elapsed: 00:30:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1650/1 [0m                       

                       Computation: 770314 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 866.74
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4945
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7630
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 162201600
                    Iteration time: 0.13s
                      Time elapsed: 00:30:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1651/1 [0m                       

                       Computation: 694151 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 863.10
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6300
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 162299904
                    Iteration time: 0.14s
                      Time elapsed: 00:30:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1652/1 [0m                       

                       Computation: 663805 steps/s (collection: 0.058s, learning 0.091s)
                       Mean reward: 862.82
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4704
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 162398208
                    Iteration time: 0.15s
                      Time elapsed: 00:30:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1653/1 [0m                       

                       Computation: 785916 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 864.09
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1564
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7615
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 162496512
                    Iteration time: 0.13s
                      Time elapsed: 00:30:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1654/1 [0m                       

                       Computation: 724608 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 866.90
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3723
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 162594816
                    Iteration time: 0.14s
                      Time elapsed: 00:30:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1655/1 [0m                       

                       Computation: 736244 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 862.73
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8955
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 162693120
                    Iteration time: 0.13s
                      Time elapsed: 00:30:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1656/1 [0m                       

                       Computation: 682348 steps/s (collection: 0.046s, learning 0.098s)
                       Mean reward: 862.57
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5205
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7549
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 162791424
                    Iteration time: 0.14s
                      Time elapsed: 00:30:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1657/1 [0m                       

                       Computation: 792583 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 863.83
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7492
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 162889728
                    Iteration time: 0.12s
                      Time elapsed: 00:30:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1658/1 [0m                       

                       Computation: 719979 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 868.17
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8538
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7615
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 162988032
                    Iteration time: 0.14s
                      Time elapsed: 00:30:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1659/1 [0m                       

                       Computation: 725191 steps/s (collection: 0.047s, learning 0.089s)
                       Mean reward: 867.51
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0573
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7602
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 163086336
                    Iteration time: 0.14s
                      Time elapsed: 00:30:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1660/1 [0m                       

                       Computation: 787317 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 869.93
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3350
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 163184640
                    Iteration time: 0.12s
                      Time elapsed: 00:30:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1661/1 [0m                       

                       Computation: 670825 steps/s (collection: 0.053s, learning 0.094s)
                       Mean reward: 863.97
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1687
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7548
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 163282944
                    Iteration time: 0.15s
                      Time elapsed: 00:30:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1662/1 [0m                       

                       Computation: 747128 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 860.38
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7922
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 163381248
                    Iteration time: 0.13s
                      Time elapsed: 00:30:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1663/1 [0m                       

                       Computation: 737995 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 855.93
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4244
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7507
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 163479552
                    Iteration time: 0.13s
                      Time elapsed: 00:30:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1664/1 [0m                       

                       Computation: 569366 steps/s (collection: 0.050s, learning 0.123s)
                       Mean reward: 865.71
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3056
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 18.4167
--------------------------------------------------------------------------------
                   Total timesteps: 163577856
                    Iteration time: 0.17s
                      Time elapsed: 00:30:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1665/1 [0m                       

                       Computation: 646618 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 854.96
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4393
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7539
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 163676160
                    Iteration time: 0.15s
                      Time elapsed: 00:30:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1666/1 [0m                       

                       Computation: 588423 steps/s (collection: 0.047s, learning 0.121s)
                       Mean reward: 854.84
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2732
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 163774464
                    Iteration time: 0.17s
                      Time elapsed: 00:30:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1667/1 [0m                       

                       Computation: 776561 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 867.01
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6962
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 163872768
                    Iteration time: 0.13s
                      Time elapsed: 00:30:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1668/1 [0m                       

                       Computation: 786705 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 859.32
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8676
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7542
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 163971072
                    Iteration time: 0.12s
                      Time elapsed: 00:30:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1669/1 [0m                       

                       Computation: 779586 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 853.70
               Mean episode length: 247.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.0181
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7506
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 164069376
                    Iteration time: 0.13s
                      Time elapsed: 00:30:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1670/1 [0m                       

                       Computation: 725390 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 864.05
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7580
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7529
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 164167680
                    Iteration time: 0.14s
                      Time elapsed: 00:30:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1671/1 [0m                       

                       Computation: 764858 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 855.33
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.0835
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7531
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 164265984
                    Iteration time: 0.13s
                      Time elapsed: 00:30:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1672/1 [0m                       

                       Computation: 680374 steps/s (collection: 0.052s, learning 0.093s)
                       Mean reward: 864.43
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1572
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7563
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 164364288
                    Iteration time: 0.14s
                      Time elapsed: 00:30:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1673/1 [0m                       

                       Computation: 706963 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 863.23
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2206
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 164462592
                    Iteration time: 0.14s
                      Time elapsed: 00:30:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1674/1 [0m                       

                       Computation: 829299 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 859.81
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1538
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 164560896
                    Iteration time: 0.12s
                      Time elapsed: 00:30:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1675/1 [0m                       

                       Computation: 673975 steps/s (collection: 0.043s, learning 0.103s)
                       Mean reward: 866.60
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4598
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7600
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.2917
--------------------------------------------------------------------------------
                   Total timesteps: 164659200
                    Iteration time: 0.15s
                      Time elapsed: 00:30:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1676/1 [0m                       

                       Computation: 770917 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 855.34
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5865
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7512
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 164757504
                    Iteration time: 0.13s
                      Time elapsed: 00:30:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1677/1 [0m                       

                       Computation: 822446 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 853.24
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.8933
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 164855808
                    Iteration time: 0.12s
                      Time elapsed: 00:30:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1678/1 [0m                       

                       Computation: 765467 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 863.87
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2420
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 164954112
                    Iteration time: 0.13s
                      Time elapsed: 00:30:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1679/1 [0m                       

                       Computation: 786796 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 863.23
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6161
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7552
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 165052416
                    Iteration time: 0.12s
                      Time elapsed: 00:30:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1680/1 [0m                       

                       Computation: 680633 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 863.16
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0556
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 165150720
                    Iteration time: 0.14s
                      Time elapsed: 00:30:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1681/1 [0m                       

                       Computation: 773416 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 858.98
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3015
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7506
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 165249024
                    Iteration time: 0.13s
                      Time elapsed: 00:30:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1682/1 [0m                       

                       Computation: 765767 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 860.40
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2080
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7483
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 165347328
                    Iteration time: 0.13s
                      Time elapsed: 00:30:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1683/1 [0m                       

                       Computation: 665368 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 855.76
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.8767
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7387
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 165445632
                    Iteration time: 0.15s
                      Time elapsed: 00:30:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1684/1 [0m                       

                       Computation: 767938 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 859.12
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3083
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7471
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 165543936
                    Iteration time: 0.13s
                      Time elapsed: 00:30:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1685/1 [0m                       

                       Computation: 793964 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 865.30
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1691
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7521
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 165642240
                    Iteration time: 0.12s
                      Time elapsed: 00:30:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1686/1 [0m                       

                       Computation: 761074 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 854.54
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.0087
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7444
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 165740544
                    Iteration time: 0.13s
                      Time elapsed: 00:30:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1687/1 [0m                       

                       Computation: 741719 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 849.62
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.1940
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7444
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 165838848
                    Iteration time: 0.13s
                      Time elapsed: 00:30:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1688/1 [0m                       

                       Computation: 696859 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 853.12
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.4219
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7367
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 165937152
                    Iteration time: 0.14s
                      Time elapsed: 00:31:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1689/1 [0m                       

                       Computation: 635995 steps/s (collection: 0.047s, learning 0.108s)
                       Mean reward: 855.01
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3472
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 166035456
                    Iteration time: 0.15s
                      Time elapsed: 00:31:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1690/1 [0m                       

                       Computation: 738917 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 861.32
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8426
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7622
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 166133760
                    Iteration time: 0.13s
                      Time elapsed: 00:31:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1691/1 [0m                       

                       Computation: 756061 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 845.92
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.9264
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7523
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 166232064
                    Iteration time: 0.13s
                      Time elapsed: 00:31:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1692/1 [0m                       

                       Computation: 792699 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 864.69
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0164
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 166330368
                    Iteration time: 0.12s
                      Time elapsed: 00:31:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1693/1 [0m                       

                       Computation: 694564 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 866.12
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3864
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 166428672
                    Iteration time: 0.14s
                      Time elapsed: 00:31:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1694/1 [0m                       

                       Computation: 712257 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 857.05
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4377
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 166526976
                    Iteration time: 0.14s
                      Time elapsed: 00:31:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1695/1 [0m                       

                       Computation: 744399 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 867.30
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8408
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7544
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 166625280
                    Iteration time: 0.13s
                      Time elapsed: 00:31:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1696/1 [0m                       

                       Computation: 696492 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 858.28
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9508
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7489
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 166723584
                    Iteration time: 0.14s
                      Time elapsed: 00:31:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1697/1 [0m                       

                       Computation: 584864 steps/s (collection: 0.047s, learning 0.122s)
                       Mean reward: 854.92
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6377
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 166821888
                    Iteration time: 0.17s
                      Time elapsed: 00:31:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1698/1 [0m                       

                       Computation: 661865 steps/s (collection: 0.038s, learning 0.111s)
                       Mean reward: 865.47
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3214
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7484
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 166920192
                    Iteration time: 0.15s
                      Time elapsed: 00:31:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1699/1 [0m                       

                       Computation: 604610 steps/s (collection: 0.040s, learning 0.123s)
                       Mean reward: 854.98
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2690
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7415
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 167018496
                    Iteration time: 0.16s
                      Time elapsed: 00:31:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1700/1 [0m                       

                       Computation: 521241 steps/s (collection: 0.066s, learning 0.123s)
                       Mean reward: 854.24
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.1284
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7417
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 167116800
                    Iteration time: 0.19s
                      Time elapsed: 00:31:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1701/1 [0m                       

                       Computation: 596166 steps/s (collection: 0.050s, learning 0.114s)
                       Mean reward: 860.19
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3253
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7460
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 167215104
                    Iteration time: 0.16s
                      Time elapsed: 00:31:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1702/1 [0m                       

                       Computation: 597399 steps/s (collection: 0.048s, learning 0.117s)
                       Mean reward: 841.18
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.2578
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7368
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 167313408
                    Iteration time: 0.16s
                      Time elapsed: 00:31:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1703/1 [0m                       

                       Computation: 783151 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 849.79
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.8686
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7436
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 167411712
                    Iteration time: 0.13s
                      Time elapsed: 00:31:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1704/1 [0m                       

                       Computation: 677143 steps/s (collection: 0.038s, learning 0.108s)
                       Mean reward: 850.91
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.1389
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7491
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 167510016
                    Iteration time: 0.15s
                      Time elapsed: 00:31:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1705/1 [0m                       

                       Computation: 767952 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 840.38
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.1602
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7403
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 167608320
                    Iteration time: 0.13s
                      Time elapsed: 00:31:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1706/1 [0m                       

                       Computation: 812019 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 849.72
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.1342
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7492
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 167706624
                    Iteration time: 0.12s
                      Time elapsed: 00:31:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1707/1 [0m                       

                       Computation: 746926 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 855.55
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.9788
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7454
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 167804928
                    Iteration time: 0.13s
                      Time elapsed: 00:31:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1708/1 [0m                       

                       Computation: 804246 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 855.67
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6627
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7432
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 167903232
                    Iteration time: 0.12s
                      Time elapsed: 00:31:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1709/1 [0m                       

                       Computation: 779204 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 840.74
               Mean episode length: 247.50
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.6985
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7363
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 168001536
                    Iteration time: 0.13s
                      Time elapsed: 00:31:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1710/1 [0m                       

                       Computation: 801686 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 848.73
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.9725
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7328
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 168099840
                    Iteration time: 0.12s
                      Time elapsed: 00:31:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1711/1 [0m                       

                       Computation: 734007 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 843.53
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.8773
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7394
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 168198144
                    Iteration time: 0.13s
                      Time elapsed: 00:31:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1712/1 [0m                       

                       Computation: 745408 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 852.76
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3253
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7367
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 168296448
                    Iteration time: 0.13s
                      Time elapsed: 00:31:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1713/1 [0m                       

                       Computation: 750201 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 845.44
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.4763
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7273
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 168394752
                    Iteration time: 0.13s
                      Time elapsed: 00:31:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1714/1 [0m                       

                       Computation: 719525 steps/s (collection: 0.048s, learning 0.089s)
                       Mean reward: 846.89
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.3064
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7394
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 168493056
                    Iteration time: 0.14s
                      Time elapsed: 00:31:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1715/1 [0m                       

                       Computation: 768118 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 856.68
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0771
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7436
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 168591360
                    Iteration time: 0.13s
                      Time elapsed: 00:31:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1716/1 [0m                       

                       Computation: 778868 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 843.44
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.7387
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7307
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 168689664
                    Iteration time: 0.13s
                      Time elapsed: 00:31:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1717/1 [0m                       

                       Computation: 762502 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 848.06
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7149
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7379
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 168787968
                    Iteration time: 0.13s
                      Time elapsed: 00:31:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1718/1 [0m                       

                       Computation: 789748 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 849.69
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.6244
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7373
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 168886272
                    Iteration time: 0.12s
                      Time elapsed: 00:31:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1719/1 [0m                       

                       Computation: 750856 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 847.62
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.8405
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7321
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 168984576
                    Iteration time: 0.13s
                      Time elapsed: 00:31:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1720/1 [0m                       

                       Computation: 703822 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 844.56
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.4051
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7353
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 169082880
                    Iteration time: 0.14s
                      Time elapsed: 00:31:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1721/1 [0m                       

                       Computation: 741286 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 846.92
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7482
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7432
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 169181184
                    Iteration time: 0.13s
                      Time elapsed: 00:31:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1722/1 [0m                       

                       Computation: 707117 steps/s (collection: 0.037s, learning 0.102s)
                       Mean reward: 856.69
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0355
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7443
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 169279488
                    Iteration time: 0.14s
                      Time elapsed: 00:31:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1723/1 [0m                       

                       Computation: 737564 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 837.20
               Mean episode length: 246.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.0855
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7336
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 169377792
                    Iteration time: 0.13s
                      Time elapsed: 00:31:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1724/1 [0m                       

                       Computation: 752672 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 849.29
               Mean episode length: 247.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.9132
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7442
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 169476096
                    Iteration time: 0.13s
                      Time elapsed: 00:31:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1725/1 [0m                       

                       Computation: 682082 steps/s (collection: 0.039s, learning 0.105s)
                       Mean reward: 849.38
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7790
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7378
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 169574400
                    Iteration time: 0.14s
                      Time elapsed: 00:31:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1726/1 [0m                       

                       Computation: 679859 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 854.74
               Mean episode length: 247.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6111
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7372
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.3750
--------------------------------------------------------------------------------
                   Total timesteps: 169672704
                    Iteration time: 0.14s
                      Time elapsed: 00:31:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1727/1 [0m                       

                       Computation: 657687 steps/s (collection: 0.037s, learning 0.112s)
                       Mean reward: 862.47
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5753
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7463
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.3333
--------------------------------------------------------------------------------
                   Total timesteps: 169771008
                    Iteration time: 0.15s
                      Time elapsed: 00:31:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1728/1 [0m                       

                       Computation: 636102 steps/s (collection: 0.040s, learning 0.115s)
                       Mean reward: 840.09
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.7158
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7334
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 169869312
                    Iteration time: 0.15s
                      Time elapsed: 00:31:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1729/1 [0m                       

                       Computation: 691921 steps/s (collection: 0.042s, learning 0.100s)
                       Mean reward: 846.65
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.2560
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7356
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 169967616
                    Iteration time: 0.14s
                      Time elapsed: 00:31:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1730/1 [0m                       

                       Computation: 715380 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 863.74
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0876
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7444
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 170065920
                    Iteration time: 0.14s
                      Time elapsed: 00:31:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1731/1 [0m                       

                       Computation: 764580 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 850.87
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.6272
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7428
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 170164224
                    Iteration time: 0.13s
                      Time elapsed: 00:31:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1732/1 [0m                       

                       Computation: 808900 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 849.54
               Mean episode length: 246.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.4572
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7328
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 170262528
                    Iteration time: 0.12s
                      Time elapsed: 00:31:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1733/1 [0m                       

                       Computation: 754682 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 835.11
               Mean episode length: 246.69
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.9818
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7294
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 170360832
                    Iteration time: 0.13s
                      Time elapsed: 00:31:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1734/1 [0m                       

                       Computation: 697299 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 839.46
               Mean episode length: 246.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.2924
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7313
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 170459136
                    Iteration time: 0.14s
                      Time elapsed: 00:31:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1735/1 [0m                       

                       Computation: 756073 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 845.74
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.0553
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7364
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 170557440
                    Iteration time: 0.13s
                      Time elapsed: 00:31:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1736/1 [0m                       

                       Computation: 804559 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 848.47
               Mean episode length: 246.17
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.0285
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7403
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 170655744
                    Iteration time: 0.12s
                      Time elapsed: 00:31:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1737/1 [0m                       

                       Computation: 763558 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 846.43
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.1499
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7372
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 170754048
                    Iteration time: 0.13s
                      Time elapsed: 00:31:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1738/1 [0m                       

                       Computation: 809564 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 839.31
               Mean episode length: 246.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.2582
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7279
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 170852352
                    Iteration time: 0.12s
                      Time elapsed: 00:31:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1739/1 [0m                       

                       Computation: 764881 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 847.96
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.6289
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7283
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 170950656
                    Iteration time: 0.13s
                      Time elapsed: 00:31:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1740/1 [0m                       

                       Computation: 682554 steps/s (collection: 0.040s, learning 0.104s)
                       Mean reward: 835.90
               Mean episode length: 245.70
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.7627
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7313
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 171048960
                    Iteration time: 0.14s
                      Time elapsed: 00:31:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1741/1 [0m                       

                       Computation: 750320 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 832.78
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.9967
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7344
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 171147264
                    Iteration time: 0.13s
                      Time elapsed: 00:31:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1742/1 [0m                       

                       Computation: 666322 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 816.45
               Mean episode length: 242.62
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.7893
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7218
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 171245568
                    Iteration time: 0.15s
                      Time elapsed: 00:31:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1743/1 [0m                       

                       Computation: 789466 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 822.71
               Mean episode length: 245.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 163.5348
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7338
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 171343872
                    Iteration time: 0.12s
                      Time elapsed: 00:32:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1744/1 [0m                       

                       Computation: 692477 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 831.83
               Mean episode length: 245.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.9086
       Episode_Reward/object_height 0.0206
     Episode_Reward/reaching_object 0.7254
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 171442176
                    Iteration time: 0.14s
                      Time elapsed: 00:32:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1745/1 [0m                       

                       Computation: 763483 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 830.31
               Mean episode length: 244.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.7149
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7228
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 171540480
                    Iteration time: 0.13s
                      Time elapsed: 00:32:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1746/1 [0m                       

                       Computation: 825951 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 845.30
               Mean episode length: 246.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.8687
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7328
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 171638784
                    Iteration time: 0.12s
                      Time elapsed: 00:32:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1747/1 [0m                       

                       Computation: 844442 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 816.97
               Mean episode length: 243.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.4230
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7172
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 171737088
                    Iteration time: 0.12s
                      Time elapsed: 00:32:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1748/1 [0m                       

                       Computation: 802347 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 828.53
               Mean episode length: 244.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.1512
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7230
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 18.1667
--------------------------------------------------------------------------------
                   Total timesteps: 171835392
                    Iteration time: 0.12s
                      Time elapsed: 00:32:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1749/1 [0m                       

                       Computation: 817466 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 817.87
               Mean episode length: 245.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.5336
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7201
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 171933696
                    Iteration time: 0.12s
                      Time elapsed: 00:32:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1750/1 [0m                       

                       Computation: 812884 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 822.81
               Mean episode length: 244.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.5296
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7150
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 172032000
                    Iteration time: 0.12s
                      Time elapsed: 00:32:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1751/1 [0m                       

                       Computation: 807402 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 822.05
               Mean episode length: 245.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 163.6705
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7190
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 172130304
                    Iteration time: 0.12s
                      Time elapsed: 00:32:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1752/1 [0m                       

                       Computation: 736670 steps/s (collection: 0.036s, learning 0.097s)
                       Mean reward: 818.42
               Mean episode length: 244.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.2284
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7170
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 172228608
                    Iteration time: 0.13s
                      Time elapsed: 00:32:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1753/1 [0m                       

                       Computation: 615999 steps/s (collection: 0.047s, learning 0.113s)
                       Mean reward: 830.56
               Mean episode length: 245.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.3593
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7203
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 172326912
                    Iteration time: 0.16s
                      Time elapsed: 00:32:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1754/1 [0m                       

                       Computation: 724098 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 819.60
               Mean episode length: 245.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.0075
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7149
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 172425216
                    Iteration time: 0.14s
                      Time elapsed: 00:32:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1755/1 [0m                       

                       Computation: 667831 steps/s (collection: 0.048s, learning 0.099s)
                       Mean reward: 820.13
               Mean episode length: 244.69
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.2983
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7084
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 172523520
                    Iteration time: 0.15s
                      Time elapsed: 00:32:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1756/1 [0m                       

                       Computation: 728842 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 825.70
               Mean episode length: 244.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.1758
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7126
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 172621824
                    Iteration time: 0.13s
                      Time elapsed: 00:32:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1757/1 [0m                       

                       Computation: 772237 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 827.12
               Mean episode length: 244.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.3410
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7194
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 172720128
                    Iteration time: 0.13s
                      Time elapsed: 00:32:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1758/1 [0m                       

                       Computation: 837916 steps/s (collection: 0.037s, learning 0.080s)
                       Mean reward: 817.30
               Mean episode length: 242.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.1993
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7041
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 18.0833
--------------------------------------------------------------------------------
                   Total timesteps: 172818432
                    Iteration time: 0.12s
                      Time elapsed: 00:32:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1759/1 [0m                       

                       Computation: 815792 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 813.71
               Mean episode length: 244.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.4811
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7124
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 172916736
                    Iteration time: 0.12s
                      Time elapsed: 00:32:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1760/1 [0m                       

                       Computation: 750313 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 817.79
               Mean episode length: 242.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.2051
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7016
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 173015040
                    Iteration time: 0.13s
                      Time elapsed: 00:32:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1761/1 [0m                       

                       Computation: 782991 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 822.91
               Mean episode length: 245.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.4747
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7127
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 173113344
                    Iteration time: 0.13s
                      Time elapsed: 00:32:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1762/1 [0m                       

                       Computation: 763907 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 818.06
               Mean episode length: 242.12
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.2801
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7063
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 173211648
                    Iteration time: 0.13s
                      Time elapsed: 00:32:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1763/1 [0m                       

                       Computation: 675350 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 805.65
               Mean episode length: 241.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.1076
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7080
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 173309952
                    Iteration time: 0.15s
                      Time elapsed: 00:32:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1764/1 [0m                       

                       Computation: 688174 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 814.37
               Mean episode length: 241.81
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.3045
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7101
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 173408256
                    Iteration time: 0.14s
                      Time elapsed: 00:32:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1765/1 [0m                       

                       Computation: 704458 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 795.36
               Mean episode length: 239.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 158.0008
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.6893
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 173506560
                    Iteration time: 0.14s
                      Time elapsed: 00:32:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1766/1 [0m                       

                       Computation: 808927 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 826.50
               Mean episode length: 245.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.9126
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7110
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 173604864
                    Iteration time: 0.12s
                      Time elapsed: 00:32:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1767/1 [0m                       

                       Computation: 694630 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 812.98
               Mean episode length: 244.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.1794
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7065
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 173703168
                    Iteration time: 0.14s
                      Time elapsed: 00:32:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1768/1 [0m                       

                       Computation: 724486 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 819.89
               Mean episode length: 246.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.1820
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7192
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 173801472
                    Iteration time: 0.14s
                      Time elapsed: 00:32:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1769/1 [0m                       

                       Computation: 696983 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 831.59
               Mean episode length: 245.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.5631
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7173
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 173899776
                    Iteration time: 0.14s
                      Time elapsed: 00:32:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1770/1 [0m                       

                       Computation: 770865 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 810.40
               Mean episode length: 242.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.1034
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.6948
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 173998080
                    Iteration time: 0.13s
                      Time elapsed: 00:32:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1771/1 [0m                       

                       Computation: 826324 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 808.07
               Mean episode length: 244.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.9388
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7122
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 174096384
                    Iteration time: 0.12s
                      Time elapsed: 00:32:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1772/1 [0m                       

                       Computation: 794092 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 797.88
               Mean episode length: 240.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 159.2800
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.6922
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 174194688
                    Iteration time: 0.12s
                      Time elapsed: 00:32:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1773/1 [0m                       

                       Computation: 808090 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 820.00
               Mean episode length: 243.56
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.1128
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7125
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 174292992
                    Iteration time: 0.12s
                      Time elapsed: 00:32:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1774/1 [0m                       

                       Computation: 769110 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 810.60
               Mean episode length: 241.10
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.7817
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7015
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 174391296
                    Iteration time: 0.13s
                      Time elapsed: 00:32:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1775/1 [0m                       

                       Computation: 830609 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 825.96
               Mean episode length: 243.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.7662
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7143
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 174489600
                    Iteration time: 0.12s
                      Time elapsed: 00:32:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1776/1 [0m                       

                       Computation: 833851 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 822.69
               Mean episode length: 241.92
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.5675
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7118
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 174587904
                    Iteration time: 0.12s
                      Time elapsed: 00:32:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1777/1 [0m                       

                       Computation: 768588 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 811.41
               Mean episode length: 241.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.3505
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7071
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 174686208
                    Iteration time: 0.13s
                      Time elapsed: 00:32:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1778/1 [0m                       

                       Computation: 795370 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 804.24
               Mean episode length: 241.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 159.9177
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7001
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 174784512
                    Iteration time: 0.12s
                      Time elapsed: 00:32:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1779/1 [0m                       

                       Computation: 805688 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 823.17
               Mean episode length: 243.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.7966
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7058
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 18.6667
--------------------------------------------------------------------------------
                   Total timesteps: 174882816
                    Iteration time: 0.12s
                      Time elapsed: 00:32:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1780/1 [0m                       

                       Computation: 750349 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 800.59
               Mean episode length: 240.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.1353
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.6970
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 174981120
                    Iteration time: 0.13s
                      Time elapsed: 00:32:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1781/1 [0m                       

                       Computation: 758900 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 786.96
               Mean episode length: 238.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 157.1036
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.6878
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 175079424
                    Iteration time: 0.13s
                      Time elapsed: 00:32:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1782/1 [0m                       

                       Computation: 730793 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 787.66
               Mean episode length: 239.93
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 157.0995
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.6840
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 175177728
                    Iteration time: 0.13s
                      Time elapsed: 00:32:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1783/1 [0m                       

                       Computation: 735910 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 810.18
               Mean episode length: 242.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.6312
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.6959
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 175276032
                    Iteration time: 0.13s
                      Time elapsed: 00:32:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1784/1 [0m                       

                       Computation: 717400 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 796.64
               Mean episode length: 238.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 158.7547
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.6883
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 175374336
                    Iteration time: 0.14s
                      Time elapsed: 00:32:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1785/1 [0m                       

                       Computation: 746342 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 800.11
               Mean episode length: 240.03
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 159.5764
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.6887
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 175472640
                    Iteration time: 0.13s
                      Time elapsed: 00:32:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1786/1 [0m                       

                       Computation: 730731 steps/s (collection: 0.036s, learning 0.098s)
                       Mean reward: 789.77
               Mean episode length: 239.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 156.8370
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.6843
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 175570944
                    Iteration time: 0.13s
                      Time elapsed: 00:32:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1787/1 [0m                       

                       Computation: 689701 steps/s (collection: 0.039s, learning 0.104s)
                       Mean reward: 799.23
               Mean episode length: 240.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 158.8286
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.6885
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 175669248
                    Iteration time: 0.14s
                      Time elapsed: 00:32:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1788/1 [0m                       

                       Computation: 692167 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 794.62
               Mean episode length: 244.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 157.2582
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.6922
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 175767552
                    Iteration time: 0.14s
                      Time elapsed: 00:32:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1789/1 [0m                       

                       Computation: 630311 steps/s (collection: 0.043s, learning 0.113s)
                       Mean reward: 805.86
               Mean episode length: 244.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.1572
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.6927
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 175865856
                    Iteration time: 0.16s
                      Time elapsed: 00:32:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1790/1 [0m                       

                       Computation: 778596 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 786.88
               Mean episode length: 240.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 157.0308
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.6788
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 175964160
                    Iteration time: 0.13s
                      Time elapsed: 00:32:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1791/1 [0m                       

                       Computation: 699141 steps/s (collection: 0.037s, learning 0.104s)
                       Mean reward: 798.72
               Mean episode length: 242.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 158.9805
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.6906
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 176062464
                    Iteration time: 0.14s
                      Time elapsed: 00:32:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1792/1 [0m                       

                       Computation: 713809 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 806.03
               Mean episode length: 243.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.3370
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7020
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 176160768
                    Iteration time: 0.14s
                      Time elapsed: 00:32:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1793/1 [0m                       

                       Computation: 777797 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 823.01
               Mean episode length: 245.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.5519
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7076
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 176259072
                    Iteration time: 0.13s
                      Time elapsed: 00:32:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1794/1 [0m                       

                       Computation: 753566 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 823.38
               Mean episode length: 243.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.6369
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7120
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 176357376
                    Iteration time: 0.13s
                      Time elapsed: 00:32:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1795/1 [0m                       

                       Computation: 762321 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 820.86
               Mean episode length: 244.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.0540
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7094
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 176455680
                    Iteration time: 0.13s
                      Time elapsed: 00:32:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1796/1 [0m                       

                       Computation: 790637 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 800.33
               Mean episode length: 241.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 159.5481
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.6957
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 176553984
                    Iteration time: 0.12s
                      Time elapsed: 00:32:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1797/1 [0m                       

                       Computation: 750327 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 812.74
               Mean episode length: 241.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.7548
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7009
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 176652288
                    Iteration time: 0.13s
                      Time elapsed: 00:32:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1798/1 [0m                       

                       Computation: 758825 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 828.36
               Mean episode length: 245.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.8390
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7185
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 176750592
                    Iteration time: 0.13s
                      Time elapsed: 00:32:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1799/1 [0m                       

                       Computation: 799983 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 825.23
               Mean episode length: 244.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.8344
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7133
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 176848896
                    Iteration time: 0.12s
                      Time elapsed: 00:32:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1800/1 [0m                       

                       Computation: 796555 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 823.26
               Mean episode length: 242.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.1303
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7113
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 176947200
                    Iteration time: 0.12s
                      Time elapsed: 00:33:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1801/1 [0m                       

                       Computation: 728930 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 815.03
               Mean episode length: 240.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.7879
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7049
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 177045504
                    Iteration time: 0.13s
                      Time elapsed: 00:33:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1802/1 [0m                       

                       Computation: 827652 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 803.27
               Mean episode length: 239.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.7593
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.6997
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 177143808
                    Iteration time: 0.12s
                      Time elapsed: 00:33:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1803/1 [0m                       

                       Computation: 831196 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 827.00
               Mean episode length: 241.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.7859
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7081
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 177242112
                    Iteration time: 0.12s
                      Time elapsed: 00:33:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1804/1 [0m                       

                       Computation: 829262 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 831.71
               Mean episode length: 245.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.5619
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7209
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 177340416
                    Iteration time: 0.12s
                      Time elapsed: 00:33:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1805/1 [0m                       

                       Computation: 818764 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 848.78
               Mean episode length: 246.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.4812
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7230
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 177438720
                    Iteration time: 0.12s
                      Time elapsed: 00:33:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1806/1 [0m                       

                       Computation: 838867 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 834.88
               Mean episode length: 246.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.4008
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7142
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 177537024
                    Iteration time: 0.12s
                      Time elapsed: 00:33:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1807/1 [0m                       

                       Computation: 802496 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 816.44
               Mean episode length: 243.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.4417
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7073
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 177635328
                    Iteration time: 0.12s
                      Time elapsed: 00:33:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1808/1 [0m                       

                       Computation: 797015 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 833.55
               Mean episode length: 245.76
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.7300
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7234
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 177733632
                    Iteration time: 0.12s
                      Time elapsed: 00:33:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1809/1 [0m                       

                       Computation: 815737 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 821.37
               Mean episode length: 242.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.6471
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7092
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 177831936
                    Iteration time: 0.12s
                      Time elapsed: 00:33:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1810/1 [0m                       

                       Computation: 801018 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 830.17
               Mean episode length: 242.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.6184
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7054
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 18.4583
--------------------------------------------------------------------------------
                   Total timesteps: 177930240
                    Iteration time: 0.12s
                      Time elapsed: 00:33:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1811/1 [0m                       

                       Computation: 796296 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 840.92
               Mean episode length: 244.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.0523
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7165
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 178028544
                    Iteration time: 0.12s
                      Time elapsed: 00:33:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1812/1 [0m                       

                       Computation: 646642 steps/s (collection: 0.037s, learning 0.115s)
                       Mean reward: 843.21
               Mean episode length: 245.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.0830
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7176
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 178126848
                    Iteration time: 0.15s
                      Time elapsed: 00:33:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1813/1 [0m                       

                       Computation: 642319 steps/s (collection: 0.037s, learning 0.116s)
                       Mean reward: 829.54
               Mean episode length: 243.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.3370
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7147
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 178225152
                    Iteration time: 0.15s
                      Time elapsed: 00:33:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1814/1 [0m                       

                       Computation: 700059 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 843.86
               Mean episode length: 245.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.3047
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7162
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 178323456
                    Iteration time: 0.14s
                      Time elapsed: 00:33:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1815/1 [0m                       

                       Computation: 717392 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 834.92
               Mean episode length: 244.10
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.9127
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7106
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 178421760
                    Iteration time: 0.14s
                      Time elapsed: 00:33:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1816/1 [0m                       

                       Computation: 697080 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 831.95
               Mean episode length: 244.03
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.5392
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7080
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 178520064
                    Iteration time: 0.14s
                      Time elapsed: 00:33:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1817/1 [0m                       

                       Computation: 710555 steps/s (collection: 0.036s, learning 0.102s)
                       Mean reward: 833.88
               Mean episode length: 244.02
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.3985
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7123
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 178618368
                    Iteration time: 0.14s
                      Time elapsed: 00:33:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1818/1 [0m                       

                       Computation: 839521 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 830.42
               Mean episode length: 244.17
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.4818
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7129
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 178716672
                    Iteration time: 0.12s
                      Time elapsed: 00:33:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1819/1 [0m                       

                       Computation: 720833 steps/s (collection: 0.047s, learning 0.089s)
                       Mean reward: 826.26
               Mean episode length: 241.80
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.2292
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7077
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 178814976
                    Iteration time: 0.14s
                      Time elapsed: 00:33:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1820/1 [0m                       

                       Computation: 753059 steps/s (collection: 0.045s, learning 0.086s)
                       Mean reward: 838.75
               Mean episode length: 243.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.4352
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7171
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 178913280
                    Iteration time: 0.13s
                      Time elapsed: 00:33:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1821/1 [0m                       

                       Computation: 805633 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 837.96
               Mean episode length: 245.12
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.3717
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7152
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 179011584
                    Iteration time: 0.12s
                      Time elapsed: 00:33:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1822/1 [0m                       

                       Computation: 751403 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 832.10
               Mean episode length: 243.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.7273
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7060
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 179109888
                    Iteration time: 0.13s
                      Time elapsed: 00:33:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1823/1 [0m                       

                       Computation: 770263 steps/s (collection: 0.035s, learning 0.092s)
                       Mean reward: 830.48
               Mean episode length: 242.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.3348
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.6954
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 179208192
                    Iteration time: 0.13s
                      Time elapsed: 00:33:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1824/1 [0m                       

                       Computation: 720002 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 827.53
               Mean episode length: 244.25
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.6313
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7033
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 179306496
                    Iteration time: 0.14s
                      Time elapsed: 00:33:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1825/1 [0m                       

                       Computation: 789621 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 831.36
               Mean episode length: 246.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.0289
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7073
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 179404800
                    Iteration time: 0.12s
                      Time elapsed: 00:33:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1826/1 [0m                       

                       Computation: 738957 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 828.96
               Mean episode length: 245.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.5788
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7041
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 179503104
                    Iteration time: 0.13s
                      Time elapsed: 00:33:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1827/1 [0m                       

                       Computation: 799176 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 839.01
               Mean episode length: 243.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.0495
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7089
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 179601408
                    Iteration time: 0.12s
                      Time elapsed: 00:33:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1828/1 [0m                       

                       Computation: 838944 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 838.43
               Mean episode length: 245.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.7705
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7071
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 179699712
                    Iteration time: 0.12s
                      Time elapsed: 00:33:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1829/1 [0m                       

                       Computation: 764969 steps/s (collection: 0.035s, learning 0.093s)
                       Mean reward: 837.13
               Mean episode length: 243.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.6724
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7096
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 179798016
                    Iteration time: 0.13s
                      Time elapsed: 00:33:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1830/1 [0m                       

                       Computation: 802741 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 839.12
               Mean episode length: 244.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.4609
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7035
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 179896320
                    Iteration time: 0.12s
                      Time elapsed: 00:33:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1831/1 [0m                       

                       Computation: 795758 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 855.73
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4378
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7210
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 18.3333
--------------------------------------------------------------------------------
                   Total timesteps: 179994624
                    Iteration time: 0.12s
                      Time elapsed: 00:33:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1832/1 [0m                       

                       Computation: 800952 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 848.23
               Mean episode length: 245.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.5012
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7240
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 180092928
                    Iteration time: 0.12s
                      Time elapsed: 00:33:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1833/1 [0m                       

                       Computation: 810369 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 848.38
               Mean episode length: 245.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.7984
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7115
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 180191232
                    Iteration time: 0.12s
                      Time elapsed: 00:33:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1834/1 [0m                       

                       Computation: 807707 steps/s (collection: 0.035s, learning 0.087s)
                       Mean reward: 841.03
               Mean episode length: 244.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.3360
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7169
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 180289536
                    Iteration time: 0.12s
                      Time elapsed: 00:33:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1835/1 [0m                       

                       Computation: 827908 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 857.34
               Mean episode length: 246.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5530
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7283
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 180387840
                    Iteration time: 0.12s
                      Time elapsed: 00:33:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1836/1 [0m                       

                       Computation: 740435 steps/s (collection: 0.036s, learning 0.097s)
                       Mean reward: 838.47
               Mean episode length: 245.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.0553
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7150
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 180486144
                    Iteration time: 0.13s
                      Time elapsed: 00:33:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1837/1 [0m                       

                       Computation: 758938 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 838.39
               Mean episode length: 245.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.9150
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7194
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 180584448
                    Iteration time: 0.13s
                      Time elapsed: 00:33:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1838/1 [0m                       

                       Computation: 703924 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 855.26
               Mean episode length: 247.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5025
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7300
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 180682752
                    Iteration time: 0.14s
                      Time elapsed: 00:33:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1839/1 [0m                       

                       Computation: 722708 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 849.65
               Mean episode length: 247.01
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.1775
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7269
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 180781056
                    Iteration time: 0.14s
                      Time elapsed: 00:33:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1840/1 [0m                       

                       Computation: 757510 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 855.53
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8309
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7310
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 180879360
                    Iteration time: 0.13s
                      Time elapsed: 00:33:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1841/1 [0m                       

                       Computation: 805543 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 856.57
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8632
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7304
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 18.5417
--------------------------------------------------------------------------------
                   Total timesteps: 180977664
                    Iteration time: 0.12s
                      Time elapsed: 00:33:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1842/1 [0m                       

                       Computation: 686315 steps/s (collection: 0.038s, learning 0.106s)
                       Mean reward: 844.95
               Mean episode length: 246.02
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.9657
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7223
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 181075968
                    Iteration time: 0.14s
                      Time elapsed: 00:33:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1843/1 [0m                       

                       Computation: 712010 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 842.21
               Mean episode length: 246.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.6520
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7195
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 181174272
                    Iteration time: 0.14s
                      Time elapsed: 00:33:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1844/1 [0m                       

                       Computation: 725434 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 842.95
               Mean episode length: 246.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.7873
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7214
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 181272576
                    Iteration time: 0.14s
                      Time elapsed: 00:33:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1845/1 [0m                       

                       Computation: 695412 steps/s (collection: 0.037s, learning 0.104s)
                       Mean reward: 848.44
               Mean episode length: 244.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.2012
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7307
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 181370880
                    Iteration time: 0.14s
                      Time elapsed: 00:33:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1846/1 [0m                       

                       Computation: 719476 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 857.79
               Mean episode length: 246.93
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7857
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7374
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 181469184
                    Iteration time: 0.14s
                      Time elapsed: 00:33:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1847/1 [0m                       

                       Computation: 678231 steps/s (collection: 0.037s, learning 0.108s)
                       Mean reward: 846.55
               Mean episode length: 245.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.6581
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7271
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 181567488
                    Iteration time: 0.14s
                      Time elapsed: 00:33:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1848/1 [0m                       

                       Computation: 776568 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 852.18
               Mean episode length: 245.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.5784
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7294
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 181665792
                    Iteration time: 0.13s
                      Time elapsed: 00:33:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1849/1 [0m                       

                       Computation: 854668 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 844.30
               Mean episode length: 245.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.0379
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7209
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 181764096
                    Iteration time: 0.12s
                      Time elapsed: 00:33:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1850/1 [0m                       

                       Computation: 826382 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 855.32
               Mean episode length: 246.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3851
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7309
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 181862400
                    Iteration time: 0.12s
                      Time elapsed: 00:33:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1851/1 [0m                       

                       Computation: 760220 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 852.25
               Mean episode length: 246.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.5990
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7336
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 181960704
                    Iteration time: 0.13s
                      Time elapsed: 00:33:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1852/1 [0m                       

                       Computation: 795832 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 853.70
               Mean episode length: 246.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.1559
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7358
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 18.5833
--------------------------------------------------------------------------------
                   Total timesteps: 182059008
                    Iteration time: 0.12s
                      Time elapsed: 00:33:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1853/1 [0m                       

                       Computation: 836546 steps/s (collection: 0.035s, learning 0.083s)
                       Mean reward: 839.83
               Mean episode length: 244.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.5415
       Episode_Reward/object_height 0.0183
     Episode_Reward/reaching_object 0.7258
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 182157312
                    Iteration time: 0.12s
                      Time elapsed: 00:33:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1854/1 [0m                       

                       Computation: 821654 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 846.43
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.8772
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7340
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 182255616
                    Iteration time: 0.12s
                      Time elapsed: 00:33:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1855/1 [0m                       

                       Computation: 829257 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 852.24
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.7043
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7325
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 182353920
                    Iteration time: 0.12s
                      Time elapsed: 00:33:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1856/1 [0m                       

                       Computation: 808930 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 855.45
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2887
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7447
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 182452224
                    Iteration time: 0.12s
                      Time elapsed: 00:33:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1857/1 [0m                       

                       Computation: 799358 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 844.05
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.7475
       Episode_Reward/object_height 0.0183
     Episode_Reward/reaching_object 0.7371
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 182550528
                    Iteration time: 0.12s
                      Time elapsed: 00:33:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1858/1 [0m                       

                       Computation: 753307 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 847.38
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.1164
       Episode_Reward/object_height 0.0182
     Episode_Reward/reaching_object 0.7395
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 182648832
                    Iteration time: 0.13s
                      Time elapsed: 00:34:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1859/1 [0m                       

                       Computation: 768814 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 849.89
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.2498
       Episode_Reward/object_height 0.0182
     Episode_Reward/reaching_object 0.7348
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 182747136
                    Iteration time: 0.13s
                      Time elapsed: 00:34:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1860/1 [0m                       

                       Computation: 739056 steps/s (collection: 0.035s, learning 0.098s)
                       Mean reward: 854.19
               Mean episode length: 246.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2054
       Episode_Reward/object_height 0.0183
     Episode_Reward/reaching_object 0.7300
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 182845440
                    Iteration time: 0.13s
                      Time elapsed: 00:34:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1861/1 [0m                       

                       Computation: 770913 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 853.91
               Mean episode length: 247.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.1504
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7306
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 182943744
                    Iteration time: 0.13s
                      Time elapsed: 00:34:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1862/1 [0m                       

                       Computation: 692741 steps/s (collection: 0.038s, learning 0.104s)
                       Mean reward: 854.07
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.9382
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7400
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 183042048
                    Iteration time: 0.14s
                      Time elapsed: 00:34:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1863/1 [0m                       

                       Computation: 772783 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 856.49
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5482
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7369
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 183140352
                    Iteration time: 0.13s
                      Time elapsed: 00:34:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1864/1 [0m                       

                       Computation: 768966 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 850.19
               Mean episode length: 246.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.6795
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7265
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 183238656
                    Iteration time: 0.13s
                      Time elapsed: 00:34:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1865/1 [0m                       

                       Computation: 837569 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 858.58
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1189
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7380
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 183336960
                    Iteration time: 0.12s
                      Time elapsed: 00:34:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1866/1 [0m                       

                       Computation: 769713 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 859.09
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0804
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7369
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 183435264
                    Iteration time: 0.13s
                      Time elapsed: 00:34:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1867/1 [0m                       

                       Computation: 770896 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 859.40
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3837
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7369
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 183533568
                    Iteration time: 0.13s
                      Time elapsed: 00:34:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1868/1 [0m                       

                       Computation: 745249 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 860.53
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4682
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7364
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 183631872
                    Iteration time: 0.13s
                      Time elapsed: 00:34:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1869/1 [0m                       

                       Computation: 828954 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 861.99
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7351
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7348
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 183730176
                    Iteration time: 0.12s
                      Time elapsed: 00:34:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1870/1 [0m                       

                       Computation: 806992 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 858.20
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1596
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7340
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 183828480
                    Iteration time: 0.12s
                      Time elapsed: 00:34:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1871/1 [0m                       

                       Computation: 780090 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 864.77
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2337
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7455
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 183926784
                    Iteration time: 0.13s
                      Time elapsed: 00:34:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1872/1 [0m                       

                       Computation: 712574 steps/s (collection: 0.036s, learning 0.102s)
                       Mean reward: 863.94
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9732
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7365
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.6250
--------------------------------------------------------------------------------
                   Total timesteps: 184025088
                    Iteration time: 0.14s
                      Time elapsed: 00:34:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1873/1 [0m                       

                       Computation: 782867 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 867.82
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5881
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7449
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 19.2917
--------------------------------------------------------------------------------
                   Total timesteps: 184123392
                    Iteration time: 0.13s
                      Time elapsed: 00:34:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1874/1 [0m                       

                       Computation: 736081 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 859.45
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0002
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7396
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 184221696
                    Iteration time: 0.13s
                      Time elapsed: 00:34:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1875/1 [0m                       

                       Computation: 706352 steps/s (collection: 0.037s, learning 0.102s)
                       Mean reward: 861.73
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4294
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7372
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 184320000
                    Iteration time: 0.14s
                      Time elapsed: 00:34:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1876/1 [0m                       

                       Computation: 815429 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 860.46
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5874
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7380
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 184418304
                    Iteration time: 0.12s
                      Time elapsed: 00:34:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1877/1 [0m                       

                       Computation: 746031 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 867.54
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6883
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7435
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 184516608
                    Iteration time: 0.13s
                      Time elapsed: 00:34:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1878/1 [0m                       

                       Computation: 707868 steps/s (collection: 0.035s, learning 0.104s)
                       Mean reward: 857.29
               Mean episode length: 246.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1106
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7394
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 184614912
                    Iteration time: 0.14s
                      Time elapsed: 00:34:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1879/1 [0m                       

                       Computation: 805720 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 862.77
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3228
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7442
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 184713216
                    Iteration time: 0.12s
                      Time elapsed: 00:34:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1880/1 [0m                       

                       Computation: 748952 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 862.12
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7962
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7423
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 184811520
                    Iteration time: 0.13s
                      Time elapsed: 00:34:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1881/1 [0m                       

                       Computation: 795812 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 863.88
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6891
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7457
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 184909824
                    Iteration time: 0.12s
                      Time elapsed: 00:34:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1882/1 [0m                       

                       Computation: 799685 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 860.85
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3197
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7428
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 185008128
                    Iteration time: 0.12s
                      Time elapsed: 00:34:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1883/1 [0m                       

                       Computation: 776949 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 866.81
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3522
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7506
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.7500
--------------------------------------------------------------------------------
                   Total timesteps: 185106432
                    Iteration time: 0.13s
                      Time elapsed: 00:34:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1884/1 [0m                       

                       Computation: 725429 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 854.89
               Mean episode length: 247.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6092
       Episode_Reward/object_height 0.0165
     Episode_Reward/reaching_object 0.7382
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 185204736
                    Iteration time: 0.14s
                      Time elapsed: 00:34:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1885/1 [0m                       

                       Computation: 819135 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 856.91
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7396
       Episode_Reward/object_height 0.0164
     Episode_Reward/reaching_object 0.7360
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 185303040
                    Iteration time: 0.12s
                      Time elapsed: 00:34:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1886/1 [0m                       

                       Computation: 753058 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 860.88
               Mean episode length: 247.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3119
       Episode_Reward/object_height 0.0164
     Episode_Reward/reaching_object 0.7312
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 185401344
                    Iteration time: 0.13s
                      Time elapsed: 00:34:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1887/1 [0m                       

                       Computation: 795094 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 862.22
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4682
       Episode_Reward/object_height 0.0165
     Episode_Reward/reaching_object 0.7353
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 185499648
                    Iteration time: 0.12s
                      Time elapsed: 00:34:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1888/1 [0m                       

                       Computation: 768690 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 868.38
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8828
       Episode_Reward/object_height 0.0165
     Episode_Reward/reaching_object 0.7398
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 185597952
                    Iteration time: 0.13s
                      Time elapsed: 00:34:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1889/1 [0m                       

                       Computation: 802335 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 848.62
               Mean episode length: 244.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7748
       Episode_Reward/object_height 0.0160
     Episode_Reward/reaching_object 0.7241
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 185696256
                    Iteration time: 0.12s
                      Time elapsed: 00:34:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1890/1 [0m                       

                       Computation: 840139 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 859.43
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1956
       Episode_Reward/object_height 0.0163
     Episode_Reward/reaching_object 0.7322
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 185794560
                    Iteration time: 0.12s
                      Time elapsed: 00:34:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1891/1 [0m                       

                       Computation: 829437 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 864.36
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3287
       Episode_Reward/object_height 0.0162
     Episode_Reward/reaching_object 0.7413
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 185892864
                    Iteration time: 0.12s
                      Time elapsed: 00:34:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1892/1 [0m                       

                       Computation: 779990 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 869.35
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3171
       Episode_Reward/object_height 0.0163
     Episode_Reward/reaching_object 0.7381
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 185991168
                    Iteration time: 0.13s
                      Time elapsed: 00:34:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1893/1 [0m                       

                       Computation: 811417 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 866.72
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3131
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7379
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 18.3333
--------------------------------------------------------------------------------
                   Total timesteps: 186089472
                    Iteration time: 0.12s
                      Time elapsed: 00:34:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1894/1 [0m                       

                       Computation: 822375 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 854.35
               Mean episode length: 247.28
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.0329
       Episode_Reward/object_height 0.0159
     Episode_Reward/reaching_object 0.7333
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 18.2083
--------------------------------------------------------------------------------
                   Total timesteps: 186187776
                    Iteration time: 0.12s
                      Time elapsed: 00:34:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1895/1 [0m                       

                       Computation: 777453 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 845.76
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.9923
       Episode_Reward/object_height 0.0157
     Episode_Reward/reaching_object 0.7269
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 186286080
                    Iteration time: 0.13s
                      Time elapsed: 00:34:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1896/1 [0m                       

                       Computation: 783235 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 860.06
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4017
       Episode_Reward/object_height 0.0160
     Episode_Reward/reaching_object 0.7392
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 186384384
                    Iteration time: 0.13s
                      Time elapsed: 00:34:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1897/1 [0m                       

                       Computation: 770960 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 841.46
               Mean episode length: 246.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.2072
       Episode_Reward/object_height 0.0155
     Episode_Reward/reaching_object 0.7190
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 186482688
                    Iteration time: 0.13s
                      Time elapsed: 00:34:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1898/1 [0m                       

                       Computation: 780869 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 845.14
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.2313
       Episode_Reward/object_height 0.0156
     Episode_Reward/reaching_object 0.7206
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 186580992
                    Iteration time: 0.13s
                      Time elapsed: 00:34:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1899/1 [0m                       

                       Computation: 846156 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 840.42
               Mean episode length: 247.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.9192
       Episode_Reward/object_height 0.0155
     Episode_Reward/reaching_object 0.7129
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 186679296
                    Iteration time: 0.12s
                      Time elapsed: 00:34:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1900/1 [0m                       

                       Computation: 671320 steps/s (collection: 0.044s, learning 0.103s)
                       Mean reward: 827.69
               Mean episode length: 246.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.3509
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.7089
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 186777600
                    Iteration time: 0.15s
                      Time elapsed: 00:34:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1901/1 [0m                       

                       Computation: 753105 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 836.35
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.6035
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7135
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 186875904
                    Iteration time: 0.13s
                      Time elapsed: 00:34:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1902/1 [0m                       

                       Computation: 818920 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 836.07
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.5295
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.7096
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 186974208
                    Iteration time: 0.12s
                      Time elapsed: 00:34:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1903/1 [0m                       

                       Computation: 809718 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 826.87
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 164.2346
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7098
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 17.7500
--------------------------------------------------------------------------------
                   Total timesteps: 187072512
                    Iteration time: 0.12s
                      Time elapsed: 00:34:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1904/1 [0m                       

                       Computation: 747203 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 843.23
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.2687
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.7211
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 18.9167
--------------------------------------------------------------------------------
                   Total timesteps: 187170816
                    Iteration time: 0.13s
                      Time elapsed: 00:34:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1905/1 [0m                       

                       Computation: 793101 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 843.30
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.0260
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.7218
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 187269120
                    Iteration time: 0.12s
                      Time elapsed: 00:34:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1906/1 [0m                       

                       Computation: 620482 steps/s (collection: 0.040s, learning 0.119s)
                       Mean reward: 839.22
               Mean episode length: 246.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.9347
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7213
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 187367424
                    Iteration time: 0.16s
                      Time elapsed: 00:34:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1907/1 [0m                       

                       Computation: 805564 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 848.49
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.1188
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7304
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 187465728
                    Iteration time: 0.12s
                      Time elapsed: 00:34:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1908/1 [0m                       

                       Computation: 645085 steps/s (collection: 0.045s, learning 0.107s)
                       Mean reward: 847.45
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.5012
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7284
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 187564032
                    Iteration time: 0.15s
                      Time elapsed: 00:34:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1909/1 [0m                       

                       Computation: 769038 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 851.43
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.4011
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.7272
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 187662336
                    Iteration time: 0.13s
                      Time elapsed: 00:34:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1910/1 [0m                       

                       Computation: 773886 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 833.31
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.7997
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7180
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 187760640
                    Iteration time: 0.13s
                      Time elapsed: 00:34:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1911/1 [0m                       

                       Computation: 768341 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 830.67
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.0045
       Episode_Reward/object_height 0.0149
     Episode_Reward/reaching_object 0.7125
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 187858944
                    Iteration time: 0.13s
                      Time elapsed: 00:34:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1912/1 [0m                       

                       Computation: 784936 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 837.05
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.7924
       Episode_Reward/object_height 0.0149
     Episode_Reward/reaching_object 0.7216
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 187957248
                    Iteration time: 0.13s
                      Time elapsed: 00:34:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1913/1 [0m                       

                       Computation: 819254 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 838.48
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.4778
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7205
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 188055552
                    Iteration time: 0.12s
                      Time elapsed: 00:34:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1914/1 [0m                       

                       Computation: 779182 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 848.70
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.9019
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7266
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.5000
--------------------------------------------------------------------------------
                   Total timesteps: 188153856
                    Iteration time: 0.13s
                      Time elapsed: 00:34:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1915/1 [0m                       

                       Computation: 752408 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 839.55
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.4197
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7254
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 188252160
                    Iteration time: 0.13s
                      Time elapsed: 00:34:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1916/1 [0m                       

                       Computation: 759325 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 852.01
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.8307
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7327
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 188350464
                    Iteration time: 0.13s
                      Time elapsed: 00:35:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1917/1 [0m                       

                       Computation: 736031 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 863.75
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2419
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7459
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 188448768
                    Iteration time: 0.13s
                      Time elapsed: 00:35:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1918/1 [0m                       

                       Computation: 760455 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 860.53
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6751
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7387
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 188547072
                    Iteration time: 0.13s
                      Time elapsed: 00:35:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1919/1 [0m                       

                       Computation: 737040 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 857.65
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1228
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7414
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 188645376
                    Iteration time: 0.13s
                      Time elapsed: 00:35:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1920/1 [0m                       

                       Computation: 765614 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 847.71
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.8737
       Episode_Reward/object_height 0.0148
     Episode_Reward/reaching_object 0.7332
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 188743680
                    Iteration time: 0.13s
                      Time elapsed: 00:35:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1921/1 [0m                       

                       Computation: 755283 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 860.46
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1431
       Episode_Reward/object_height 0.0149
     Episode_Reward/reaching_object 0.7350
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 188841984
                    Iteration time: 0.13s
                      Time elapsed: 00:35:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1922/1 [0m                       

                       Computation: 834725 steps/s (collection: 0.035s, learning 0.083s)
                       Mean reward: 867.85
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8265
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7434
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 188940288
                    Iteration time: 0.12s
                      Time elapsed: 00:35:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1923/1 [0m                       

                       Computation: 865946 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 862.59
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6596
       Episode_Reward/object_height 0.0149
     Episode_Reward/reaching_object 0.7455
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 189038592
                    Iteration time: 0.11s
                      Time elapsed: 00:35:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1924/1 [0m                       

                       Computation: 872362 steps/s (collection: 0.036s, learning 0.077s)
                       Mean reward: 868.67
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0219
       Episode_Reward/object_height 0.0149
     Episode_Reward/reaching_object 0.7498
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 189136896
                    Iteration time: 0.11s
                      Time elapsed: 00:35:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1925/1 [0m                       

                       Computation: 818681 steps/s (collection: 0.035s, learning 0.085s)
                       Mean reward: 861.23
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2694
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7462
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 189235200
                    Iteration time: 0.12s
                      Time elapsed: 00:35:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1926/1 [0m                       

                       Computation: 837518 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 861.88
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9438
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7334
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 189333504
                    Iteration time: 0.12s
                      Time elapsed: 00:35:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1927/1 [0m                       

                       Computation: 825961 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 860.51
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1991
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7373
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 189431808
                    Iteration time: 0.12s
                      Time elapsed: 00:35:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1928/1 [0m                       

                       Computation: 789398 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 846.72
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.4261
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7201
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 189530112
                    Iteration time: 0.12s
                      Time elapsed: 00:35:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1929/1 [0m                       

                       Computation: 795904 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 853.46
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.8848
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7309
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 189628416
                    Iteration time: 0.12s
                      Time elapsed: 00:35:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1930/1 [0m                       

                       Computation: 815627 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 847.34
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.1229
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7274
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 189726720
                    Iteration time: 0.12s
                      Time elapsed: 00:35:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1931/1 [0m                       

                       Computation: 823763 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 861.01
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2081
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7306
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 189825024
                    Iteration time: 0.12s
                      Time elapsed: 00:35:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1932/1 [0m                       

                       Computation: 683524 steps/s (collection: 0.037s, learning 0.107s)
                       Mean reward: 850.88
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.5011
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7290
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 189923328
                    Iteration time: 0.14s
                      Time elapsed: 00:35:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1933/1 [0m                       

                       Computation: 655490 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 860.17
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8505
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7303
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 190021632
                    Iteration time: 0.15s
                      Time elapsed: 00:35:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1934/1 [0m                       

                       Computation: 657349 steps/s (collection: 0.044s, learning 0.106s)
                       Mean reward: 866.69
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6281
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7413
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 190119936
                    Iteration time: 0.15s
                      Time elapsed: 00:35:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1935/1 [0m                       

                       Computation: 620100 steps/s (collection: 0.036s, learning 0.123s)
                       Mean reward: 851.22
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.8675
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7379
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 18.2500
--------------------------------------------------------------------------------
                   Total timesteps: 190218240
                    Iteration time: 0.16s
                      Time elapsed: 00:35:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1936/1 [0m                       

                       Computation: 646768 steps/s (collection: 0.036s, learning 0.116s)
                       Mean reward: 840.44
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.6940
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7369
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 190316544
                    Iteration time: 0.15s
                      Time elapsed: 00:35:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1937/1 [0m                       

                       Computation: 659682 steps/s (collection: 0.037s, learning 0.112s)
                       Mean reward: 851.58
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2137
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7353
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 190414848
                    Iteration time: 0.15s
                      Time elapsed: 00:35:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1938/1 [0m                       

                       Computation: 704960 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 845.22
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.1324
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7307
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 190513152
                    Iteration time: 0.14s
                      Time elapsed: 00:35:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1939/1 [0m                       

                       Computation: 746278 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 849.96
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.2529
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7302
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 190611456
                    Iteration time: 0.13s
                      Time elapsed: 00:35:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1940/1 [0m                       

                       Computation: 725947 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 849.89
               Mean episode length: 246.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.3055
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7306
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 190709760
                    Iteration time: 0.14s
                      Time elapsed: 00:35:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1941/1 [0m                       

                       Computation: 661735 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 850.51
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.5895
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7352
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 190808064
                    Iteration time: 0.15s
                      Time elapsed: 00:35:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1942/1 [0m                       

                       Computation: 741525 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 858.22
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8989
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7389
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 190906368
                    Iteration time: 0.13s
                      Time elapsed: 00:35:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1943/1 [0m                       

                       Computation: 743506 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 859.05
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1592
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7449
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 191004672
                    Iteration time: 0.13s
                      Time elapsed: 00:35:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1944/1 [0m                       

                       Computation: 726881 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 852.09
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.6696
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7378
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 191102976
                    Iteration time: 0.14s
                      Time elapsed: 00:35:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1945/1 [0m                       

                       Computation: 665330 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 857.09
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6157
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7476
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 191201280
                    Iteration time: 0.15s
                      Time elapsed: 00:35:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1946/1 [0m                       

                       Computation: 801301 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 863.10
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2449
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.6250
--------------------------------------------------------------------------------
                   Total timesteps: 191299584
                    Iteration time: 0.12s
                      Time elapsed: 00:35:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1947/1 [0m                       

                       Computation: 639818 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 852.84
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5794
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7510
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 191397888
                    Iteration time: 0.15s
                      Time elapsed: 00:35:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1948/1 [0m                       

                       Computation: 805340 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 856.63
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4457
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7502
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 191496192
                    Iteration time: 0.12s
                      Time elapsed: 00:35:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1949/1 [0m                       

                       Computation: 770272 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 851.08
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.2950
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7509
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 191594496
                    Iteration time: 0.13s
                      Time elapsed: 00:35:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1950/1 [0m                       

                       Computation: 815421 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 858.53
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4524
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7517
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 191692800
                    Iteration time: 0.12s
                      Time elapsed: 00:35:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1951/1 [0m                       

                       Computation: 793545 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 856.30
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6835
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7475
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 191791104
                    Iteration time: 0.12s
                      Time elapsed: 00:35:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1952/1 [0m                       

                       Computation: 822542 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 861.92
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7537
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7517
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 191889408
                    Iteration time: 0.12s
                      Time elapsed: 00:35:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1953/1 [0m                       

                       Computation: 799141 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 870.70
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2898
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7589
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 191987712
                    Iteration time: 0.12s
                      Time elapsed: 00:35:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1954/1 [0m                       

                       Computation: 822505 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 866.66
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7881
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7578
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 192086016
                    Iteration time: 0.12s
                      Time elapsed: 00:35:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1955/1 [0m                       

                       Computation: 818735 steps/s (collection: 0.035s, learning 0.085s)
                       Mean reward: 859.67
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9907
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7493
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 192184320
                    Iteration time: 0.12s
                      Time elapsed: 00:35:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1956/1 [0m                       

                       Computation: 711278 steps/s (collection: 0.035s, learning 0.103s)
                       Mean reward: 862.03
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8321
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 192282624
                    Iteration time: 0.14s
                      Time elapsed: 00:35:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1957/1 [0m                       

                       Computation: 808845 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 863.11
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5199
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7442
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 192380928
                    Iteration time: 0.12s
                      Time elapsed: 00:35:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1958/1 [0m                       

                       Computation: 748499 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 862.60
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5515
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7455
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 192479232
                    Iteration time: 0.13s
                      Time elapsed: 00:35:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1959/1 [0m                       

                       Computation: 658891 steps/s (collection: 0.044s, learning 0.105s)
                       Mean reward: 870.27
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0164
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7508
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 192577536
                    Iteration time: 0.15s
                      Time elapsed: 00:35:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1960/1 [0m                       

                       Computation: 739779 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 856.66
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9121
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7410
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 192675840
                    Iteration time: 0.13s
                      Time elapsed: 00:35:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1961/1 [0m                       

                       Computation: 773840 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 866.20
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5904
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7475
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 18.5000
--------------------------------------------------------------------------------
                   Total timesteps: 192774144
                    Iteration time: 0.13s
                      Time elapsed: 00:35:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1962/1 [0m                       

                       Computation: 582927 steps/s (collection: 0.049s, learning 0.120s)
                       Mean reward: 861.25
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9623
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7390
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 192872448
                    Iteration time: 0.17s
                      Time elapsed: 00:35:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1963/1 [0m                       

                       Computation: 611664 steps/s (collection: 0.051s, learning 0.110s)
                       Mean reward: 852.10
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.8823
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7332
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 192970752
                    Iteration time: 0.16s
                      Time elapsed: 00:35:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1964/1 [0m                       

                       Computation: 581603 steps/s (collection: 0.053s, learning 0.117s)
                       Mean reward: 862.08
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0500
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7393
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 193069056
                    Iteration time: 0.17s
                      Time elapsed: 00:35:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1965/1 [0m                       

                       Computation: 610436 steps/s (collection: 0.046s, learning 0.115s)
                       Mean reward: 853.57
               Mean episode length: 247.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2015
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7379
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 193167360
                    Iteration time: 0.16s
                      Time elapsed: 00:35:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1966/1 [0m                       

                       Computation: 604626 steps/s (collection: 0.053s, learning 0.110s)
                       Mean reward: 864.27
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6513
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7416
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 193265664
                    Iteration time: 0.16s
                      Time elapsed: 00:35:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1967/1 [0m                       

                       Computation: 599237 steps/s (collection: 0.049s, learning 0.116s)
                       Mean reward: 858.46
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9824
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7413
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 193363968
                    Iteration time: 0.16s
                      Time elapsed: 00:35:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1968/1 [0m                       

                       Computation: 620027 steps/s (collection: 0.045s, learning 0.114s)
                       Mean reward: 862.13
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3579
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7420
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 193462272
                    Iteration time: 0.16s
                      Time elapsed: 00:35:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1969/1 [0m                       

                       Computation: 630952 steps/s (collection: 0.052s, learning 0.104s)
                       Mean reward: 862.51
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1621
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7422
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 193560576
                    Iteration time: 0.16s
                      Time elapsed: 00:35:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1970/1 [0m                       

                       Computation: 654689 steps/s (collection: 0.047s, learning 0.103s)
                       Mean reward: 863.07
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9251
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7335
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 193658880
                    Iteration time: 0.15s
                      Time elapsed: 00:35:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1971/1 [0m                       

                       Computation: 782275 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 866.63
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7775
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7350
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 193757184
                    Iteration time: 0.13s
                      Time elapsed: 00:35:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1972/1 [0m                       

                       Computation: 687286 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 863.34
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5452
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7350
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 193855488
                    Iteration time: 0.14s
                      Time elapsed: 00:36:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1973/1 [0m                       

                       Computation: 633964 steps/s (collection: 0.050s, learning 0.106s)
                       Mean reward: 863.51
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1379
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7381
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 193953792
                    Iteration time: 0.16s
                      Time elapsed: 00:36:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1974/1 [0m                       

                       Computation: 550487 steps/s (collection: 0.059s, learning 0.120s)
                       Mean reward: 860.80
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4860
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7325
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 194052096
                    Iteration time: 0.18s
                      Time elapsed: 00:36:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1975/1 [0m                       

                       Computation: 621629 steps/s (collection: 0.044s, learning 0.115s)
                       Mean reward: 847.91
               Mean episode length: 246.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.0187
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7169
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 194150400
                    Iteration time: 0.16s
                      Time elapsed: 00:36:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1976/1 [0m                       

                       Computation: 634053 steps/s (collection: 0.042s, learning 0.114s)
                       Mean reward: 873.41
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0543
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7373
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 194248704
                    Iteration time: 0.16s
                      Time elapsed: 00:36:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1977/1 [0m                       

                       Computation: 717437 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 857.80
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1807
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7375
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 194347008
                    Iteration time: 0.14s
                      Time elapsed: 00:36:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1978/1 [0m                       

                       Computation: 767853 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 869.23
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4310
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7443
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 194445312
                    Iteration time: 0.13s
                      Time elapsed: 00:36:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1979/1 [0m                       

                       Computation: 758694 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 857.57
               Mean episode length: 247.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6047
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7460
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 194543616
                    Iteration time: 0.13s
                      Time elapsed: 00:36:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1980/1 [0m                       

                       Computation: 601089 steps/s (collection: 0.048s, learning 0.116s)
                       Mean reward: 856.68
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9904
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7411
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 194641920
                    Iteration time: 0.16s
                      Time elapsed: 00:36:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1981/1 [0m                       

                       Computation: 625611 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 854.73
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.3551
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7460
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 194740224
                    Iteration time: 0.16s
                      Time elapsed: 00:36:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1982/1 [0m                       

                       Computation: 600841 steps/s (collection: 0.047s, learning 0.116s)
                       Mean reward: 860.48
               Mean episode length: 247.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3954
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7418
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 194838528
                    Iteration time: 0.16s
                      Time elapsed: 00:36:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1983/1 [0m                       

                       Computation: 722264 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 861.05
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4899
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 194936832
                    Iteration time: 0.14s
                      Time elapsed: 00:36:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1984/1 [0m                       

                       Computation: 743793 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 861.69
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3699
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7381
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 195035136
                    Iteration time: 0.13s
                      Time elapsed: 00:36:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1985/1 [0m                       

                       Computation: 788976 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 860.87
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3482
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7404
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 195133440
                    Iteration time: 0.12s
                      Time elapsed: 00:36:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1986/1 [0m                       

                       Computation: 782952 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 857.38
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0351
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7353
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 195231744
                    Iteration time: 0.13s
                      Time elapsed: 00:36:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1987/1 [0m                       

                       Computation: 725231 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 857.35
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4988
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7366
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.7083
--------------------------------------------------------------------------------
                   Total timesteps: 195330048
                    Iteration time: 0.14s
                      Time elapsed: 00:36:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1988/1 [0m                       

                       Computation: 579420 steps/s (collection: 0.049s, learning 0.121s)
                       Mean reward: 854.68
               Mean episode length: 247.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3286
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7308
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 195428352
                    Iteration time: 0.17s
                      Time elapsed: 00:36:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1989/1 [0m                       

                       Computation: 621967 steps/s (collection: 0.049s, learning 0.109s)
                       Mean reward: 857.80
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6542
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7357
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 195526656
                    Iteration time: 0.16s
                      Time elapsed: 00:36:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1990/1 [0m                       

                       Computation: 577947 steps/s (collection: 0.048s, learning 0.122s)
                       Mean reward: 851.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.1099
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7374
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 195624960
                    Iteration time: 0.17s
                      Time elapsed: 00:36:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1991/1 [0m                       

                       Computation: 588252 steps/s (collection: 0.048s, learning 0.119s)
                       Mean reward: 849.56
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.9442
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7260
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 195723264
                    Iteration time: 0.17s
                      Time elapsed: 00:36:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1992/1 [0m                       

                       Computation: 736168 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 842.96
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.5670
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7269
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 195821568
                    Iteration time: 0.13s
                      Time elapsed: 00:36:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1993/1 [0m                       

                       Computation: 750018 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 858.92
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0056
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7388
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 195919872
                    Iteration time: 0.13s
                      Time elapsed: 00:36:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1994/1 [0m                       

                       Computation: 735569 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 847.66
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.9050
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7314
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 196018176
                    Iteration time: 0.13s
                      Time elapsed: 00:36:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1995/1 [0m                       

                       Computation: 730700 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 842.13
               Mean episode length: 245.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.5793
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7216
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 196116480
                    Iteration time: 0.13s
                      Time elapsed: 00:36:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1996/1 [0m                       

                       Computation: 747290 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 855.54
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2375
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7335
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 196214784
                    Iteration time: 0.13s
                      Time elapsed: 00:36:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1997/1 [0m                       

                       Computation: 826581 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 844.76
               Mean episode length: 246.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.0123
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7230
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 196313088
                    Iteration time: 0.12s
                      Time elapsed: 00:36:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1998/1 [0m                       

                       Computation: 753168 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 841.56
               Mean episode length: 245.70
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.8957
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7169
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 196411392
                    Iteration time: 0.13s
                      Time elapsed: 00:36:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1999/1 [0m                       

                       Computation: 728985 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 830.88
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.1162
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7069
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 196509696
                    Iteration time: 0.13s
                      Time elapsed: 00:36:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 2000/1 [0m                       

                       Computation: 666371 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 814.61
               Mean episode length: 246.05
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.2409
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7007
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 196608000
                    Iteration time: 0.15s
                      Time elapsed: 00:36:32
                               ETA: 00:00:00

