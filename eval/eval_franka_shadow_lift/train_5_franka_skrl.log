################################################################################
                        [1m Learning iteration 1/1 [0m                        

                       Computation: 482399 steps/s (collection: 0.024s, learning 0.180s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 0.20s
                      Time elapsed: 00:00:01
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 2/1 [0m                        

                       Computation: 979495 steps/s (collection: 0.022s, learning 0.078s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 0.10s
                      Time elapsed: 00:00:02
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 3/1 [0m                        

                       Computation: 817495 steps/s (collection: 0.023s, learning 0.097s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 0.12s
                      Time elapsed: 00:00:03
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 4/1 [0m                        

                       Computation: 923878 steps/s (collection: 0.023s, learning 0.084s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 0.11s
                      Time elapsed: 00:00:03
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 5/1 [0m                        

                       Computation: 655093 steps/s (collection: 0.028s, learning 0.122s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 0.15s
                      Time elapsed: 00:00:04
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 6/1 [0m                        

                       Computation: 1010890 steps/s (collection: 0.024s, learning 0.073s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 0.10s
                      Time elapsed: 00:00:05
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 7/1 [0m                        

                       Computation: 999362 steps/s (collection: 0.025s, learning 0.073s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 0.10s
                      Time elapsed: 00:00:05
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 8/1 [0m                        

                       Computation: 995883 steps/s (collection: 0.024s, learning 0.075s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 0.10s
                      Time elapsed: 00:00:06
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 9/1 [0m                        

                       Computation: 974048 steps/s (collection: 0.029s, learning 0.072s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 0.10s
                      Time elapsed: 00:00:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 10/1 [0m                        

                       Computation: 1008664 steps/s (collection: 0.026s, learning 0.072s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 0.10s
                      Time elapsed: 00:00:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 11/1 [0m                        

                       Computation: 954022 steps/s (collection: 0.027s, learning 0.077s)
                       Mean reward: 0.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 0.0112
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.0367
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2560.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 0.10s
                      Time elapsed: 00:00:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 12/1 [0m                        

                       Computation: 780993 steps/s (collection: 0.032s, learning 0.094s)
                       Mean reward: 0.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0180
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0588
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 0.13s
                      Time elapsed: 00:00:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 13/1 [0m                        

                       Computation: 820030 steps/s (collection: 0.028s, learning 0.092s)
                       Mean reward: 0.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0180
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0588
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 0.12s
                      Time elapsed: 00:00:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 14/1 [0m                        

                       Computation: 958856 steps/s (collection: 0.031s, learning 0.072s)
                       Mean reward: 0.17
               Mean episode length: 67.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0010
      Episode_Reward/lifting_object 0.0030
       Episode_Reward/object_height 0.0008
     Episode_Reward/reaching_object 0.0379
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 682.6667
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 0.10s
                      Time elapsed: 00:00:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 15/1 [0m                        

                       Computation: 819078 steps/s (collection: 0.032s, learning 0.088s)
                       Mean reward: 4.87
               Mean episode length: 100.71
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0009
      Episode_Reward/lifting_object 0.2500
       Episode_Reward/object_height 0.0008
     Episode_Reward/reaching_object 0.0575
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 0.12s
                      Time elapsed: 00:00:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 16/1 [0m                        

                       Computation: 783077 steps/s (collection: 0.032s, learning 0.094s)
                       Mean reward: 1.12
               Mean episode length: 122.17
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0012
      Episode_Reward/lifting_object 0.3667
       Episode_Reward/object_height 0.0011
     Episode_Reward/reaching_object 0.0864
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 0.13s
                      Time elapsed: 00:00:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 17/1 [0m                        

                       Computation: 799934 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 0.53
               Mean episode length: 146.83
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0014
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0012
     Episode_Reward/reaching_object 0.1021
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 0.12s
                      Time elapsed: 00:00:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 18/1 [0m                        

                       Computation: 561084 steps/s (collection: 0.036s, learning 0.140s)
                       Mean reward: 12.14
               Mean episode length: 167.62
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 0.9500
       Episode_Reward/object_height 0.0015
     Episode_Reward/reaching_object 0.1148
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 0.18s
                      Time elapsed: 00:00:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 19/1 [0m                        

                       Computation: 705444 steps/s (collection: 0.037s, learning 0.102s)
                       Mean reward: 7.54
               Mean episode length: 193.42
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 1.5333
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1691
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 0.14s
                      Time elapsed: 00:00:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 20/1 [0m                        

                       Computation: 925170 steps/s (collection: 0.028s, learning 0.079s)
                       Mean reward: 3.76
               Mean episode length: 218.90
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 0.5889
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.1844
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 0.11s
                      Time elapsed: 00:00:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 21/1 [0m                        

                       Computation: 873595 steps/s (collection: 0.030s, learning 0.083s)
                       Mean reward: 3.76
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 0.6088
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2207
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 838.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 0.11s
                      Time elapsed: 00:00:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 22/1 [0m                        

                       Computation: 853587 steps/s (collection: 0.031s, learning 0.084s)
                       Mean reward: 0.62
               Mean episode length: 125.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 0.1958
       Episode_Reward/object_height 0.0015
     Episode_Reward/reaching_object 0.1646
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 1509.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 0.12s
                      Time elapsed: 00:00:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 23/1 [0m                        

                       Computation: 770730 steps/s (collection: 0.031s, learning 0.096s)
                       Mean reward: 0.15
               Mean episode length: 58.25
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0009
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0008
     Episode_Reward/reaching_object 0.0723
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 0.13s
                      Time elapsed: 00:00:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 24/1 [0m                        

                       Computation: 868468 steps/s (collection: 0.035s, learning 0.078s)
                       Mean reward: 5.43
               Mean episode length: 85.21
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0008
      Episode_Reward/lifting_object 0.9000
       Episode_Reward/object_height 0.0007
     Episode_Reward/reaching_object 0.0780
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 0.11s
                      Time elapsed: 00:00:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 25/1 [0m                        

                       Computation: 854751 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 3.68
               Mean episode length: 117.22
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0012
      Episode_Reward/lifting_object 0.6667
       Episode_Reward/object_height 0.0010
     Episode_Reward/reaching_object 0.1182
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 0.12s
                      Time elapsed: 00:00:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 26/1 [0m                        

                       Computation: 476506 steps/s (collection: 0.045s, learning 0.161s)
                       Mean reward: 5.31
               Mean episode length: 136.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0013
      Episode_Reward/lifting_object 0.9300
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.1308
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 0.21s
                      Time elapsed: 00:00:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 27/1 [0m                        

                       Computation: 903898 steps/s (collection: 0.037s, learning 0.072s)
                       Mean reward: 3.63
               Mean episode length: 160.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 0.3167
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1696
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 0.11s
                      Time elapsed: 00:00:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 28/1 [0m                        

                       Computation: 857792 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 3.34
               Mean episode length: 181.79
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 0.4611
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1905
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 0.11s
                      Time elapsed: 00:00:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 29/1 [0m                        

                       Computation: 873697 steps/s (collection: 0.040s, learning 0.073s)
                       Mean reward: 2.82
               Mean episode length: 200.03
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 0.3278
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.1991
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 0.11s
                      Time elapsed: 00:00:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 30/1 [0m                        

                       Computation: 789454 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 5.33
               Mean episode length: 217.30
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 0.9151
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2388
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 0.12s
                      Time elapsed: 00:00:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 31/1 [0m                        

                       Computation: 374377 steps/s (collection: 0.051s, learning 0.212s)
                       Mean reward: 8.09
               Mean episode length: 236.27
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 1.4722
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2518
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 0.26s
                      Time elapsed: 00:00:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 32/1 [0m                        

                       Computation: 743656 steps/s (collection: 0.036s, learning 0.097s)
                       Mean reward: 7.24
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 0.5324
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1616
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 159.8750
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 0.13s
                      Time elapsed: 00:00:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 33/1 [0m                        

                       Computation: 678371 steps/s (collection: 0.049s, learning 0.096s)
                       Mean reward: 1.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2959
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 0.14s
                      Time elapsed: 00:00:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 34/1 [0m                        

                       Computation: 842604 steps/s (collection: 0.029s, learning 0.088s)
                       Mean reward: 5.07
               Mean episode length: 123.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0014
      Episode_Reward/lifting_object 0.6556
       Episode_Reward/object_height 0.0012
     Episode_Reward/reaching_object 0.1364
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 0.12s
                      Time elapsed: 00:00:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 35/1 [0m                        

                       Computation: 900546 steps/s (collection: 0.030s, learning 0.079s)
                       Mean reward: 6.56
               Mean episode length: 151.46
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0016
      Episode_Reward/lifting_object 1.1622
       Episode_Reward/object_height 0.0014
     Episode_Reward/reaching_object 0.1674
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 0.11s
                      Time elapsed: 00:00:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 36/1 [0m                        

                       Computation: 851517 steps/s (collection: 0.034s, learning 0.081s)
                       Mean reward: 5.15
               Mean episode length: 172.56
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 0.6456
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1721
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 0.12s
                      Time elapsed: 00:00:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 37/1 [0m                        

                       Computation: 765881 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 8.63
               Mean episode length: 181.76
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 1.4303
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1999
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 0.13s
                      Time elapsed: 00:00:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 38/1 [0m                        

                       Computation: 526882 steps/s (collection: 0.036s, learning 0.151s)
                       Mean reward: 8.39
               Mean episode length: 185.59
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 1.3127
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.2080
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 0.19s
                      Time elapsed: 00:00:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 39/1 [0m                        

                       Computation: 578983 steps/s (collection: 0.044s, learning 0.126s)
                       Mean reward: 9.14
               Mean episode length: 215.11
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 1.6111
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2281
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 0.17s
                      Time elapsed: 00:00:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 40/1 [0m                        

                       Computation: 638368 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 13.79
               Mean episode length: 218.09
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 2.4234
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2487
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 0.15s
                      Time elapsed: 00:00:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 41/1 [0m                        

                       Computation: 788204 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 11.35
               Mean episode length: 233.06
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 1.9560
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2531
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 0.12s
                      Time elapsed: 00:00:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 42/1 [0m                        

                       Computation: 787155 steps/s (collection: 0.026s, learning 0.099s)
                       Mean reward: 13.59
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 4.1260
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2986
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 149.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 0.12s
                      Time elapsed: 00:00:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 43/1 [0m                        

                       Computation: 785750 steps/s (collection: 0.035s, learning 0.090s)
                       Mean reward: 1.24
               Mean episode length: 179.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.2419
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 0.13s
                      Time elapsed: 00:00:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 44/1 [0m                        

                       Computation: 498013 steps/s (collection: 0.038s, learning 0.159s)
                       Mean reward: 7.88
               Mean episode length: 203.40
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 0.4667
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.2148
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 0.20s
                      Time elapsed: 00:00:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 45/1 [0m                        

                       Computation: 786115 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 13.93
               Mean episode length: 191.67
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 2.8756
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.2301
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 0.13s
                      Time elapsed: 00:00:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 46/1 [0m                        

                       Computation: 593825 steps/s (collection: 0.042s, learning 0.124s)
                       Mean reward: 10.83
               Mean episode length: 179.90
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 2.1131
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.2186
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 0.17s
                      Time elapsed: 00:00:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 47/1 [0m                        

                       Computation: 566328 steps/s (collection: 0.053s, learning 0.121s)
                       Mean reward: 16.89
               Mean episode length: 200.30
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 3.0075
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2511
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 0.17s
                      Time elapsed: 00:00:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 48/1 [0m                        

                       Computation: 625282 steps/s (collection: 0.047s, learning 0.111s)
                       Mean reward: 15.83
               Mean episode length: 205.82
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 2.4808
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2623
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 0.16s
                      Time elapsed: 00:00:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 49/1 [0m                        

                       Computation: 693602 steps/s (collection: 0.049s, learning 0.093s)
                       Mean reward: 18.98
               Mean episode length: 222.62
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 3.5367
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2822
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 0.14s
                      Time elapsed: 00:00:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 50/1 [0m                        

                       Computation: 574857 steps/s (collection: 0.049s, learning 0.122s)
                       Mean reward: 20.77
               Mean episode length: 230.02
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 4.1133
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2867
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 0.17s
                      Time elapsed: 00:00:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 51/1 [0m                        

                       Computation: 528417 steps/s (collection: 0.065s, learning 0.122s)
                       Mean reward: 20.68
               Mean episode length: 232.09
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 3.8586
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2833
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 0.19s
                      Time elapsed: 00:00:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 52/1 [0m                        

                       Computation: 650539 steps/s (collection: 0.048s, learning 0.104s)
                       Mean reward: 17.38
               Mean episode length: 245.09
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 3.1950
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.3016
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 0.15s
                      Time elapsed: 00:00:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 53/1 [0m                        

                       Computation: 792677 steps/s (collection: 0.034s, learning 0.091s)
                       Mean reward: 28.83
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 4.6135
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2502
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 139.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 0.12s
                      Time elapsed: 00:00:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 54/1 [0m                        

                       Computation: 738977 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 32.95
               Mean episode length: 189.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 5.0778
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2353
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 0.13s
                      Time elapsed: 00:00:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 55/1 [0m                        

                       Computation: 684916 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 30.43
               Mean episode length: 192.40
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 6.3228
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.2381
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 0.14s
                      Time elapsed: 00:00:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 56/1 [0m                        

                       Computation: 516187 steps/s (collection: 0.060s, learning 0.131s)
                       Mean reward: 37.46
               Mean episode length: 209.07
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 6.9797
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2783
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 0.19s
                      Time elapsed: 00:00:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 57/1 [0m                        

                       Computation: 569802 steps/s (collection: 0.047s, learning 0.126s)
                       Mean reward: 34.88
               Mean episode length: 220.56
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 6.8394
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2906
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 0.17s
                      Time elapsed: 00:00:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 58/1 [0m                        

                       Computation: 680111 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 37.56
               Mean episode length: 216.62
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 7.2188
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2766
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 0.14s
                      Time elapsed: 00:00:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 59/1 [0m                        

                       Computation: 682367 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 61.98
               Mean episode length: 218.42
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 12.8323
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2843
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 0.14s
                      Time elapsed: 00:01:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 60/1 [0m                        

                       Computation: 621783 steps/s (collection: 0.047s, learning 0.111s)
                       Mean reward: 44.26
               Mean episode length: 234.50
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 8.4627
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3173
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 0.16s
                      Time elapsed: 00:01:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 61/1 [0m                        

                       Computation: 714776 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 61.47
               Mean episode length: 233.90
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 11.4160
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3085
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 0.14s
                      Time elapsed: 00:01:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 62/1 [0m                        

                       Computation: 391447 steps/s (collection: 0.071s, learning 0.181s)
                       Mean reward: 58.87
               Mean episode length: 242.56
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 10.8527
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3218
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 0.25s
                      Time elapsed: 00:01:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 63/1 [0m                        

                       Computation: 769272 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 60.67
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 11.3396
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2724
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 132.0833
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 0.13s
                      Time elapsed: 00:01:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 64/1 [0m                        

                       Computation: 669754 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 49.05
               Mean episode length: 178.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 11.8722
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2624
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 0.15s
                      Time elapsed: 00:01:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 65/1 [0m                        

                       Computation: 566573 steps/s (collection: 0.043s, learning 0.131s)
                       Mean reward: 43.90
               Mean episode length: 192.14
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 8.3570
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2474
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 0.17s
                      Time elapsed: 00:01:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 66/1 [0m                        

                       Computation: 672505 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 50.65
               Mean episode length: 196.40
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 9.7737
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2662
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 0.15s
                      Time elapsed: 00:01:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 67/1 [0m                        

                       Computation: 691795 steps/s (collection: 0.050s, learning 0.092s)
                       Mean reward: 71.66
               Mean episode length: 211.01
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 13.6462
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3003
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 0.14s
                      Time elapsed: 00:01:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 68/1 [0m                        

                       Computation: 736870 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 89.64
               Mean episode length: 218.11
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 17.5943
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3297
Episode_Termination/object_dropping 1.9583
       Episode_Termination/time_out 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 0.13s
                      Time elapsed: 00:01:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 69/1 [0m                        

                       Computation: 770898 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 84.04
               Mean episode length: 221.90
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 16.7405
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3230
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 0.13s
                      Time elapsed: 00:01:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 70/1 [0m                        

                       Computation: 818883 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 73.82
               Mean episode length: 235.64
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 14.6136
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3504
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 0.12s
                      Time elapsed: 00:01:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 71/1 [0m                        

                       Computation: 503470 steps/s (collection: 0.051s, learning 0.145s)
                       Mean reward: 92.82
               Mean episode length: 230.29
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 18.2815
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3354
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 0.20s
                      Time elapsed: 00:01:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 72/1 [0m                        

                       Computation: 657047 steps/s (collection: 0.046s, learning 0.104s)
                       Mean reward: 123.62
               Mean episode length: 239.89
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 24.6695
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.3705
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 0.15s
                      Time elapsed: 00:01:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 73/1 [0m                        

                       Computation: 714264 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 139.50
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 25.0041
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3661
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 123.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 0.14s
                      Time elapsed: 00:01:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 74/1 [0m                        

                       Computation: 635416 steps/s (collection: 0.045s, learning 0.110s)
                       Mean reward: 65.40
               Mean episode length: 209.27
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 14.9528
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2692
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 0.15s
                      Time elapsed: 00:01:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 75/1 [0m                        

                       Computation: 632595 steps/s (collection: 0.044s, learning 0.111s)
                       Mean reward: 112.06
               Mean episode length: 206.29
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 21.0794
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3087
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 0.16s
                      Time elapsed: 00:01:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 76/1 [0m                        

                       Computation: 505166 steps/s (collection: 0.052s, learning 0.142s)
                       Mean reward: 140.46
               Mean episode length: 207.29
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 27.9522
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3202
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 0.19s
                      Time elapsed: 00:01:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 77/1 [0m                        

                       Computation: 669636 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 208.90
               Mean episode length: 228.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 42.0284
       Episode_Reward/object_height 0.0048
     Episode_Reward/reaching_object 0.3993
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 0.15s
                      Time elapsed: 00:01:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 78/1 [0m                        

                       Computation: 733909 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 198.42
               Mean episode length: 232.03
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 37.0285
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.3840
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 0.13s
                      Time elapsed: 00:01:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 79/1 [0m                        

                       Computation: 835728 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 224.11
               Mean episode length: 237.60
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 43.3974
       Episode_Reward/object_height 0.0048
     Episode_Reward/reaching_object 0.4035
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 0.12s
                      Time elapsed: 00:01:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 80/1 [0m                        

                       Computation: 856650 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 230.81
               Mean episode length: 243.17
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 48.1919
       Episode_Reward/object_height 0.0052
     Episode_Reward/reaching_object 0.4231
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 0.11s
                      Time elapsed: 00:01:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 81/1 [0m                        

                       Computation: 717688 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 200.19
               Mean episode length: 240.22
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 41.1744
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.4005
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 0.14s
                      Time elapsed: 00:01:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 82/1 [0m                        

                       Computation: 825879 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 203.07
               Mean episode length: 242.46
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 40.2303
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4063
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 0.12s
                      Time elapsed: 00:01:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 83/1 [0m                        

                       Computation: 559456 steps/s (collection: 0.041s, learning 0.134s)
                       Mean reward: 224.17
               Mean episode length: 244.56
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 42.9899
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4092
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 0.18s
                      Time elapsed: 00:01:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 84/1 [0m                        

                       Computation: 722566 steps/s (collection: 0.033s, learning 0.103s)
                       Mean reward: 250.81
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 63.0452
       Episode_Reward/object_height 0.0055
     Episode_Reward/reaching_object 0.4684
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 116.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 0.14s
                      Time elapsed: 00:01:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 85/1 [0m                        

                       Computation: 608204 steps/s (collection: 0.045s, learning 0.117s)
                       Mean reward: 212.22
               Mean episode length: 226.31
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 43.8222
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4006
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 0.16s
                      Time elapsed: 00:01:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 86/1 [0m                        

                       Computation: 443712 steps/s (collection: 0.047s, learning 0.175s)
                       Mean reward: 230.54
               Mean episode length: 231.62
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 46.2392
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4176
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 0.22s
                      Time elapsed: 00:01:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 87/1 [0m                        

                       Computation: 702013 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 261.83
               Mean episode length: 227.67
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 52.5880
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4167
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 0.14s
                      Time elapsed: 00:01:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 88/1 [0m                        

                       Computation: 668508 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 289.60
               Mean episode length: 240.51
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 59.4564
       Episode_Reward/object_height 0.0049
     Episode_Reward/reaching_object 0.4532
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 0.15s
                      Time elapsed: 00:01:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 89/1 [0m                        

                       Computation: 514118 steps/s (collection: 0.059s, learning 0.132s)
                       Mean reward: 319.63
               Mean episode length: 239.68
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 63.5179
       Episode_Reward/object_height 0.0050
     Episode_Reward/reaching_object 0.4643
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 0.19s
                      Time elapsed: 00:01:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 90/1 [0m                        

                       Computation: 695514 steps/s (collection: 0.057s, learning 0.085s)
                       Mean reward: 298.84
               Mean episode length: 237.69
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 63.0513
       Episode_Reward/object_height 0.0050
     Episode_Reward/reaching_object 0.4634
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 0.14s
                      Time elapsed: 00:01:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 91/1 [0m                        

                       Computation: 736219 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 268.47
               Mean episode length: 237.47
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 53.1243
       Episode_Reward/object_height 0.0046
     Episode_Reward/reaching_object 0.4281
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 0.13s
                      Time elapsed: 00:01:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 92/1 [0m                        

                       Computation: 877210 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 302.26
               Mean episode length: 244.25
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 63.4985
       Episode_Reward/object_height 0.0054
     Episode_Reward/reaching_object 0.4761
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 0.11s
                      Time elapsed: 00:01:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 93/1 [0m                        

                       Computation: 675636 steps/s (collection: 0.036s, learning 0.109s)
                       Mean reward: 355.45
               Mean episode length: 243.06
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 72.1056
       Episode_Reward/object_height 0.0056
     Episode_Reward/reaching_object 0.4923
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 0.15s
                      Time elapsed: 00:01:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 94/1 [0m                        

                       Computation: 553761 steps/s (collection: 0.044s, learning 0.134s)
                       Mean reward: 402.57
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 70.6981
       Episode_Reward/object_height 0.0055
     Episode_Reward/reaching_object 0.4806
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 113.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 0.18s
                      Time elapsed: 00:01:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 95/1 [0m                        

                       Computation: 507669 steps/s (collection: 0.054s, learning 0.140s)
                       Mean reward: 403.68
               Mean episode length: 233.81
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 84.7433
       Episode_Reward/object_height 0.0061
     Episode_Reward/reaching_object 0.5209
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 0.19s
                      Time elapsed: 00:01:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 96/1 [0m                        

                       Computation: 741421 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 348.71
               Mean episode length: 227.29
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 70.0939
       Episode_Reward/object_height 0.0057
     Episode_Reward/reaching_object 0.4778
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 0.13s
                      Time elapsed: 00:01:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 97/1 [0m                        

                       Computation: 527248 steps/s (collection: 0.068s, learning 0.118s)
                       Mean reward: 376.20
               Mean episode length: 225.96
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 72.8633
       Episode_Reward/object_height 0.0057
     Episode_Reward/reaching_object 0.4603
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 0.19s
                      Time elapsed: 00:01:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 98/1 [0m                        

                       Computation: 563301 steps/s (collection: 0.055s, learning 0.120s)
                       Mean reward: 405.80
               Mean episode length: 241.63
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 81.8031
       Episode_Reward/object_height 0.0061
     Episode_Reward/reaching_object 0.5151
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 0.17s
                      Time elapsed: 00:01:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 99/1 [0m                        

                       Computation: 536216 steps/s (collection: 0.058s, learning 0.126s)
                       Mean reward: 453.93
               Mean episode length: 243.45
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 90.0158
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.5422
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 0.18s
                      Time elapsed: 00:01:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 100/1 [0m                       

                       Computation: 811840 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 500.38
               Mean episode length: 244.61
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 98.1427
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.5692
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 0.12s
                      Time elapsed: 00:01:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 101/1 [0m                       

                       Computation: 593339 steps/s (collection: 0.046s, learning 0.120s)
                       Mean reward: 486.54
               Mean episode length: 242.16
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 99.2838
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.5761
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 0.17s
                      Time elapsed: 00:01:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 102/1 [0m                       

                       Computation: 523155 steps/s (collection: 0.062s, learning 0.126s)
                       Mean reward: 493.35
               Mean episode length: 240.72
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 102.4348
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.5699
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 0.19s
                      Time elapsed: 00:01:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 103/1 [0m                       

                       Computation: 432897 steps/s (collection: 0.049s, learning 0.178s)
                       Mean reward: 481.62
               Mean episode length: 245.27
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 95.0529
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.5552
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 0.23s
                      Time elapsed: 00:01:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 104/1 [0m                       

                       Computation: 752841 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 547.35
               Mean episode length: 246.25
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 108.1883
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.5891
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 0.13s
                      Time elapsed: 00:01:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 105/1 [0m                       

                       Computation: 537053 steps/s (collection: 0.049s, learning 0.134s)
                       Mean reward: 555.63
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 92.1428
       Episode_Reward/object_height 0.0056
     Episode_Reward/reaching_object 0.5186
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 109.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 0.18s
                      Time elapsed: 00:01:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 106/1 [0m                       

                       Computation: 498899 steps/s (collection: 0.067s, learning 0.131s)
                       Mean reward: 529.10
               Mean episode length: 229.10
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 107.6072
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.5678
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 0.20s
                      Time elapsed: 00:01:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 107/1 [0m                       

                       Computation: 553520 steps/s (collection: 0.052s, learning 0.125s)
                       Mean reward: 462.73
               Mean episode length: 221.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 89.8822
       Episode_Reward/object_height 0.0055
     Episode_Reward/reaching_object 0.4901
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 0.18s
                      Time elapsed: 00:01:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 108/1 [0m                       

                       Computation: 604807 steps/s (collection: 0.045s, learning 0.118s)
                       Mean reward: 538.88
               Mean episode length: 236.54
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 108.3071
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.5707
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 0.16s
                      Time elapsed: 00:02:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 109/1 [0m                       

                       Computation: 783017 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 561.53
               Mean episode length: 246.35
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 111.8172
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.5965
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 0.13s
                      Time elapsed: 00:02:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 110/1 [0m                       

                       Computation: 837928 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 592.12
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 117.2044
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.6059
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 0.12s
                      Time elapsed: 00:02:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 111/1 [0m                       

                       Computation: 641662 steps/s (collection: 0.051s, learning 0.102s)
                       Mean reward: 569.11
               Mean episode length: 244.60
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 112.6836
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.5885
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 0.15s
                      Time elapsed: 00:02:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 112/1 [0m                       

                       Computation: 716610 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 615.06
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 116.8301
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.6010
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 0.14s
                      Time elapsed: 00:02:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 113/1 [0m                       

                       Computation: 855363 steps/s (collection: 0.040s, learning 0.075s)
                       Mean reward: 603.01
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 117.7461
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.5949
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 0.11s
                      Time elapsed: 00:02:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 114/1 [0m                       

                       Computation: 733392 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 622.65
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 122.8340
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.6207
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 0.13s
                      Time elapsed: 00:02:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 115/1 [0m                       

                       Computation: 688508 steps/s (collection: 0.038s, learning 0.105s)
                       Mean reward: 624.86
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 125.9433
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.6137
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 108.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 0.14s
                      Time elapsed: 00:02:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 116/1 [0m                       

                       Computation: 696123 steps/s (collection: 0.048s, learning 0.093s)
                       Mean reward: 621.26
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 126.5044
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.6398
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 0.14s
                      Time elapsed: 00:02:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 117/1 [0m                       

                       Computation: 715447 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 606.73
               Mean episode length: 229.91
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 127.8579
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.6353
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 0.14s
                      Time elapsed: 00:02:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 118/1 [0m                       

                       Computation: 812688 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 623.83
               Mean episode length: 244.63
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 124.3060
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.6224
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 0.12s
                      Time elapsed: 00:02:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 119/1 [0m                       

                       Computation: 862154 steps/s (collection: 0.039s, learning 0.075s)
                       Mean reward: 679.78
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 136.0108
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.6713
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 0.11s
                      Time elapsed: 00:02:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 120/1 [0m                       

                       Computation: 792528 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 679.15
               Mean episode length: 245.82
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 135.3922
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.6622
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 0.12s
                      Time elapsed: 00:02:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 121/1 [0m                       

                       Computation: 841624 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 679.52
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 135.8069
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.6564
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 0.12s
                      Time elapsed: 00:02:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 122/1 [0m                       

                       Computation: 865114 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 681.56
               Mean episode length: 245.77
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 137.2204
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.6592
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 0.11s
                      Time elapsed: 00:02:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 123/1 [0m                       

                       Computation: 864974 steps/s (collection: 0.039s, learning 0.075s)
                       Mean reward: 687.65
               Mean episode length: 246.95
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 137.1006
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.6613
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 0.11s
                      Time elapsed: 00:02:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 124/1 [0m                       

                       Computation: 701163 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 674.10
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 135.5084
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.6599
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 0.14s
                      Time elapsed: 00:02:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 125/1 [0m                       

                       Computation: 655312 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 715.22
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 141.4044
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.6599
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 109.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 0.15s
                      Time elapsed: 00:02:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 126/1 [0m                       

                       Computation: 634047 steps/s (collection: 0.047s, learning 0.109s)
                       Mean reward: 723.61
               Mean episode length: 244.95
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 142.8917
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7023
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 0.16s
                      Time elapsed: 00:02:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 127/1 [0m                       

                       Computation: 578136 steps/s (collection: 0.055s, learning 0.116s)
                       Mean reward: 660.61
               Mean episode length: 230.06
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 128.8664
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.6280
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 0.17s
                      Time elapsed: 00:02:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 128/1 [0m                       

                       Computation: 769591 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 702.36
               Mean episode length: 242.05
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 140.7981
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.6705
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 0.13s
                      Time elapsed: 00:02:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 129/1 [0m                       

                       Computation: 547338 steps/s (collection: 0.062s, learning 0.118s)
                       Mean reward: 703.96
               Mean episode length: 245.05
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 139.9023
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.6666
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 0.18s
                      Time elapsed: 00:02:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 130/1 [0m                       

                       Computation: 788341 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 724.15
               Mean episode length: 244.21
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 142.4091
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.6760
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 0.12s
                      Time elapsed: 00:02:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 131/1 [0m                       

                       Computation: 648775 steps/s (collection: 0.048s, learning 0.104s)
                       Mean reward: 761.69
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 151.2576
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7016
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 0.15s
                      Time elapsed: 00:02:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 132/1 [0m                       

                       Computation: 522777 steps/s (collection: 0.048s, learning 0.140s)
                       Mean reward: 757.85
               Mean episode length: 245.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 154.0445
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7071
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 0.19s
                      Time elapsed: 00:02:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 133/1 [0m                       

                       Computation: 591754 steps/s (collection: 0.037s, learning 0.129s)
                       Mean reward: 752.42
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 150.2766
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7042
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 0.17s
                      Time elapsed: 00:02:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 134/1 [0m                       

                       Computation: 658314 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 751.05
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.4990
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7023
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 0.15s
                      Time elapsed: 00:02:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 135/1 [0m                       

                       Computation: 737130 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 710.48
               Mean episode length: 245.64
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 142.2158
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.6780
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 0.13s
                      Time elapsed: 00:02:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 136/1 [0m                       

                       Computation: 848064 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 759.12
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 136.2783
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.6484
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 106.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 0.12s
                      Time elapsed: 00:02:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 137/1 [0m                       

                       Computation: 583068 steps/s (collection: 0.040s, learning 0.128s)
                       Mean reward: 801.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 161.6900
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7340
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 0.17s
                      Time elapsed: 00:02:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 138/1 [0m                       

                       Computation: 466420 steps/s (collection: 0.053s, learning 0.158s)
                       Mean reward: 710.35
               Mean episode length: 238.22
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 143.9389
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.6763
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 0.21s
                      Time elapsed: 00:02:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 139/1 [0m                       

                       Computation: 455140 steps/s (collection: 0.049s, learning 0.167s)
                       Mean reward: 725.16
               Mean episode length: 241.59
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 141.9252
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.6652
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 0.22s
                      Time elapsed: 00:02:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 140/1 [0m                       

                       Computation: 461181 steps/s (collection: 0.049s, learning 0.164s)
                       Mean reward: 782.32
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 155.2017
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7153
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 0.21s
                      Time elapsed: 00:02:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 141/1 [0m                       

                       Computation: 598254 steps/s (collection: 0.046s, learning 0.118s)
                       Mean reward: 745.95
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 148.9098
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7007
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 0.16s
                      Time elapsed: 00:02:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 142/1 [0m                       

                       Computation: 682571 steps/s (collection: 0.056s, learning 0.088s)
                       Mean reward: 743.10
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 147.7678
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.6885
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 0.14s
                      Time elapsed: 00:02:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 143/1 [0m                       

                       Computation: 838773 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 742.20
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 151.0916
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.6958
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 0.12s
                      Time elapsed: 00:02:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 144/1 [0m                       

                       Computation: 802813 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 740.83
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 147.7051
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.6919
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 0.12s
                      Time elapsed: 00:02:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 145/1 [0m                       

                       Computation: 835898 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 754.05
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 151.5097
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.6999
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 0.12s
                      Time elapsed: 00:02:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 146/1 [0m                       

                       Computation: 712916 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 755.13
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 150.8421
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.6982
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 106.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 0.14s
                      Time elapsed: 00:02:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 147/1 [0m                       

                       Computation: 760126 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 755.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 148.7956
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.6879
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 0.13s
                      Time elapsed: 00:02:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 148/1 [0m                       

                       Computation: 560283 steps/s (collection: 0.054s, learning 0.122s)
                       Mean reward: 787.25
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 151.1866
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7159
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 0.18s
                      Time elapsed: 00:02:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 149/1 [0m                       

                       Computation: 608994 steps/s (collection: 0.056s, learning 0.106s)
                       Mean reward: 785.81
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 157.6574
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7115
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 0.16s
                      Time elapsed: 00:02:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 150/1 [0m                       

                       Computation: 706367 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 779.07
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 153.8254
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7005
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 0.14s
                      Time elapsed: 00:02:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 151/1 [0m                       

                       Computation: 624547 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 778.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 154.6089
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7049
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 0.16s
                      Time elapsed: 00:02:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 152/1 [0m                       

                       Computation: 668548 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 805.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.1295
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7205
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 0.15s
                      Time elapsed: 00:02:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 153/1 [0m                       

                       Computation: 647408 steps/s (collection: 0.047s, learning 0.105s)
                       Mean reward: 824.99
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.5121
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7243
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 0.15s
                      Time elapsed: 00:02:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 154/1 [0m                       

                       Computation: 723480 steps/s (collection: 0.045s, learning 0.091s)
                       Mean reward: 821.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.1496
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7301
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 0.14s
                      Time elapsed: 00:02:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 155/1 [0m                       

                       Computation: 536794 steps/s (collection: 0.042s, learning 0.141s)
                       Mean reward: 811.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 160.9847
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7210
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 0.18s
                      Time elapsed: 00:02:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 156/1 [0m                       

                       Computation: 523795 steps/s (collection: 0.046s, learning 0.141s)
                       Mean reward: 778.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 155.2602
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7132
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 0.19s
                      Time elapsed: 00:02:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 157/1 [0m                       

                       Computation: 583298 steps/s (collection: 0.042s, learning 0.127s)
                       Mean reward: 801.12
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 151.5999
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.6823
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 104.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 0.17s
                      Time elapsed: 00:02:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 158/1 [0m                       

                       Computation: 403367 steps/s (collection: 0.080s, learning 0.164s)
                       Mean reward: 758.03
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 145.4778
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.6874
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 0.24s
                      Time elapsed: 00:02:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 159/1 [0m                       

                       Computation: 711392 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 755.12
               Mean episode length: 240.68
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 151.5947
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.6989
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 0.14s
                      Time elapsed: 00:03:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 160/1 [0m                       

                       Computation: 681429 steps/s (collection: 0.037s, learning 0.107s)
                       Mean reward: 757.44
               Mean episode length: 246.65
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 153.1831
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7162
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 0.14s
                      Time elapsed: 00:03:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 161/1 [0m                       

                       Computation: 663226 steps/s (collection: 0.038s, learning 0.110s)
                       Mean reward: 796.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 158.2404
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7259
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 0.15s
                      Time elapsed: 00:03:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 162/1 [0m                       

                       Computation: 577942 steps/s (collection: 0.045s, learning 0.125s)
                       Mean reward: 819.27
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.8437
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7433
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 0.17s
                      Time elapsed: 00:03:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 163/1 [0m                       

                       Computation: 606781 steps/s (collection: 0.038s, learning 0.124s)
                       Mean reward: 816.22
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.3913
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7393
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 0.16s
                      Time elapsed: 00:03:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 164/1 [0m                       

                       Computation: 462050 steps/s (collection: 0.072s, learning 0.141s)
                       Mean reward: 817.50
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.2773
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7390
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 0.21s
                      Time elapsed: 00:03:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 165/1 [0m                       

                       Computation: 748431 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 815.43
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.4142
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7315
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 0.13s
                      Time elapsed: 00:03:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 166/1 [0m                       

                       Computation: 601145 steps/s (collection: 0.044s, learning 0.120s)
                       Mean reward: 812.55
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.0642
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7358
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 0.16s
                      Time elapsed: 00:03:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 167/1 [0m                       

                       Computation: 684987 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 812.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 160.5841
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 105.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 0.14s
                      Time elapsed: 00:03:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 168/1 [0m                       

                       Computation: 716287 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 822.41
               Mean episode length: 243.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 159.7639
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7226
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 0.14s
                      Time elapsed: 00:03:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 169/1 [0m                       

                       Computation: 710269 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 809.99
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.4560
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 0.14s
                      Time elapsed: 00:03:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 170/1 [0m                       

                       Computation: 528336 steps/s (collection: 0.048s, learning 0.138s)
                       Mean reward: 809.89
               Mean episode length: 247.28
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 160.8001
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7283
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 0.19s
                      Time elapsed: 00:03:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 171/1 [0m                       

                       Computation: 600143 steps/s (collection: 0.042s, learning 0.121s)
                       Mean reward: 827.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.6696
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7434
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 0.16s
                      Time elapsed: 00:03:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 172/1 [0m                       

                       Computation: 678588 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 821.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.0446
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7430
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 0.14s
                      Time elapsed: 00:03:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 173/1 [0m                       

                       Computation: 542628 steps/s (collection: 0.074s, learning 0.107s)
                       Mean reward: 813.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.8043
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7379
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 0.18s
                      Time elapsed: 00:03:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 174/1 [0m                       

                       Computation: 720981 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 825.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.1190
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7424
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 0.14s
                      Time elapsed: 00:03:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 175/1 [0m                       

                       Computation: 557003 steps/s (collection: 0.039s, learning 0.137s)
                       Mean reward: 830.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.2028
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7525
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 0.18s
                      Time elapsed: 00:03:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 176/1 [0m                       

                       Computation: 531672 steps/s (collection: 0.044s, learning 0.141s)
                       Mean reward: 820.76
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.1972
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7379
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 0.18s
                      Time elapsed: 00:03:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 177/1 [0m                       

                       Computation: 680206 steps/s (collection: 0.053s, learning 0.092s)
                       Mean reward: 820.62
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.0131
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7356
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 0.14s
                      Time elapsed: 00:03:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 178/1 [0m                       

                       Computation: 664174 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 830.63
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 155.4111
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7238
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 102.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 0.15s
                      Time elapsed: 00:03:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 179/1 [0m                       

                       Computation: 619406 steps/s (collection: 0.042s, learning 0.117s)
                       Mean reward: 841.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.3093
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7513
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 0.16s
                      Time elapsed: 00:03:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 180/1 [0m                       

                       Computation: 668192 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 814.51
               Mean episode length: 245.83
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 162.4256
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7266
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 0.15s
                      Time elapsed: 00:03:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 181/1 [0m                       

                       Computation: 718769 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 824.15
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.9598
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7219
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 0.14s
                      Time elapsed: 00:03:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 182/1 [0m                       

                       Computation: 818896 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 811.67
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.5415
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7202
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 0.12s
                      Time elapsed: 00:03:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 183/1 [0m                       

                       Computation: 611571 steps/s (collection: 0.041s, learning 0.120s)
                       Mean reward: 830.69
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.4866
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7309
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 0.16s
                      Time elapsed: 00:03:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 184/1 [0m                       

                       Computation: 591882 steps/s (collection: 0.052s, learning 0.114s)
                       Mean reward: 837.21
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.9065
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7350
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 0.17s
                      Time elapsed: 00:03:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 185/1 [0m                       

                       Computation: 633485 steps/s (collection: 0.046s, learning 0.109s)
                       Mean reward: 818.46
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.1389
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7289
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 0.16s
                      Time elapsed: 00:03:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 186/1 [0m                       

                       Computation: 578092 steps/s (collection: 0.041s, learning 0.129s)
                       Mean reward: 824.14
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.9181
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7386
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 0.17s
                      Time elapsed: 00:03:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 187/1 [0m                       

                       Computation: 718893 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 833.45
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.8884
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7446
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 0.14s
                      Time elapsed: 00:03:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 188/1 [0m                       

                       Computation: 621239 steps/s (collection: 0.042s, learning 0.116s)
                       Mean reward: 818.76
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 152.9377
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.6945
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 103.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 0.16s
                      Time elapsed: 00:03:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 189/1 [0m                       

                       Computation: 665987 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 827.99
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.5389
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7317
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 0.15s
                      Time elapsed: 00:03:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 190/1 [0m                       

                       Computation: 711981 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 806.16
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.6322
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7340
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 0.14s
                      Time elapsed: 00:03:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 191/1 [0m                       

                       Computation: 488491 steps/s (collection: 0.040s, learning 0.161s)
                       Mean reward: 823.70
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.0062
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7326
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 0.20s
                      Time elapsed: 00:03:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 192/1 [0m                       

                       Computation: 579594 steps/s (collection: 0.043s, learning 0.127s)
                       Mean reward: 844.73
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.6679
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7504
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 0.17s
                      Time elapsed: 00:03:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 193/1 [0m                       

                       Computation: 546673 steps/s (collection: 0.040s, learning 0.140s)
                       Mean reward: 824.88
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.3953
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7380
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 0.18s
                      Time elapsed: 00:03:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 194/1 [0m                       

                       Computation: 582945 steps/s (collection: 0.042s, learning 0.127s)
                       Mean reward: 827.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.3357
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7412
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 0.17s
                      Time elapsed: 00:03:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 195/1 [0m                       

                       Computation: 455031 steps/s (collection: 0.050s, learning 0.167s)
                       Mean reward: 846.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.7758
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7505
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 0.22s
                      Time elapsed: 00:03:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 196/1 [0m                       

                       Computation: 740578 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 835.04
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.8562
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7405
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 0.13s
                      Time elapsed: 00:03:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 197/1 [0m                       

                       Computation: 668475 steps/s (collection: 0.041s, learning 0.106s)
                       Mean reward: 837.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.3935
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7346
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 0.15s
                      Time elapsed: 00:03:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 198/1 [0m                       

                       Computation: 657115 steps/s (collection: 0.037s, learning 0.113s)
                       Mean reward: 835.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.8902
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7364
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 105.6667
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 0.15s
                      Time elapsed: 00:03:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 199/1 [0m                       

                       Computation: 539713 steps/s (collection: 0.049s, learning 0.133s)
                       Mean reward: 835.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.0672
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7371
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 0.18s
                      Time elapsed: 00:03:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 200/1 [0m                       

                       Computation: 635561 steps/s (collection: 0.039s, learning 0.116s)
                       Mean reward: 836.54
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.2905
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7523
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 0.15s
                      Time elapsed: 00:03:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 201/1 [0m                       

                       Computation: 444193 steps/s (collection: 0.042s, learning 0.179s)
                       Mean reward: 831.85
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.9567
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7373
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 0.22s
                      Time elapsed: 00:03:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 202/1 [0m                       

                       Computation: 474601 steps/s (collection: 0.049s, learning 0.158s)
                       Mean reward: 829.19
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.7669
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7333
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 0.21s
                      Time elapsed: 00:03:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 203/1 [0m                       

                       Computation: 508268 steps/s (collection: 0.048s, learning 0.145s)
                       Mean reward: 839.48
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.5534
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7436
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 0.19s
                      Time elapsed: 00:03:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 204/1 [0m                       

                       Computation: 542542 steps/s (collection: 0.048s, learning 0.134s)
                       Mean reward: 835.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.6421
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7469
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 0.18s
                      Time elapsed: 00:03:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 205/1 [0m                       

                       Computation: 665626 steps/s (collection: 0.039s, learning 0.109s)
                       Mean reward: 847.29
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.2977
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7500
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 0.15s
                      Time elapsed: 00:03:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 206/1 [0m                       

                       Computation: 519710 steps/s (collection: 0.061s, learning 0.128s)
                       Mean reward: 855.29
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.4595
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7538
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 0.19s
                      Time elapsed: 00:03:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 207/1 [0m                       

                       Computation: 704382 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 830.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.9152
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7288
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 0.14s
                      Time elapsed: 00:03:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 208/1 [0m                       

                       Computation: 716819 steps/s (collection: 0.037s, learning 0.101s)
                       Mean reward: 832.06
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.4936
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7454
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 0.14s
                      Time elapsed: 00:03:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 209/1 [0m                       

                       Computation: 650600 steps/s (collection: 0.042s, learning 0.109s)
                       Mean reward: 842.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.5104
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7490
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 102.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 0.15s
                      Time elapsed: 00:03:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 210/1 [0m                       

                       Computation: 663249 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 840.93
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.6978
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7585
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 0.15s
                      Time elapsed: 00:04:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 211/1 [0m                       

                       Computation: 686238 steps/s (collection: 0.035s, learning 0.108s)
                       Mean reward: 848.11
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.3496
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7585
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 0.14s
                      Time elapsed: 00:04:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 212/1 [0m                       

                       Computation: 672918 steps/s (collection: 0.037s, learning 0.109s)
                       Mean reward: 832.41
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.8256
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7469
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 0.15s
                      Time elapsed: 00:04:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 213/1 [0m                       

                       Computation: 677039 steps/s (collection: 0.046s, learning 0.099s)
                       Mean reward: 843.74
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.8106
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7558
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 0.15s
                      Time elapsed: 00:04:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 214/1 [0m                       

                       Computation: 779094 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 853.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1871
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7597
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 0.13s
                      Time elapsed: 00:04:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 215/1 [0m                       

                       Computation: 617767 steps/s (collection: 0.043s, learning 0.116s)
                       Mean reward: 851.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0573
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 0.16s
                      Time elapsed: 00:04:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 216/1 [0m                       

                       Computation: 653431 steps/s (collection: 0.040s, learning 0.110s)
                       Mean reward: 847.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5259
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7536
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 0.15s
                      Time elapsed: 00:04:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 217/1 [0m                       

                       Computation: 760040 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 836.49
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.4156
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7514
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 0.13s
                      Time elapsed: 00:04:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 218/1 [0m                       

                       Computation: 782855 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 840.00
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.3193
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 0.13s
                      Time elapsed: 00:04:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 219/1 [0m                       

                       Computation: 714600 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 843.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.3980
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7504
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 104.2500
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 0.14s
                      Time elapsed: 00:04:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 220/1 [0m                       

                       Computation: 663913 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 836.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.4639
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7520
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 0.15s
                      Time elapsed: 00:04:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 221/1 [0m                       

                       Computation: 649626 steps/s (collection: 0.043s, learning 0.109s)
                       Mean reward: 851.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.7922
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 0.15s
                      Time elapsed: 00:04:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 222/1 [0m                       

                       Computation: 695675 steps/s (collection: 0.038s, learning 0.104s)
                       Mean reward: 840.12
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.2969
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7496
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 0.14s
                      Time elapsed: 00:04:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 223/1 [0m                       

                       Computation: 713502 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 852.77
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.4187
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 0.14s
                      Time elapsed: 00:04:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 224/1 [0m                       

                       Computation: 733041 steps/s (collection: 0.035s, learning 0.099s)
                       Mean reward: 859.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.0840
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 0.13s
                      Time elapsed: 00:04:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 225/1 [0m                       

                       Computation: 641376 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 837.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.0373
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7502
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 0.15s
                      Time elapsed: 00:04:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 226/1 [0m                       

                       Computation: 647549 steps/s (collection: 0.044s, learning 0.108s)
                       Mean reward: 848.84
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.2478
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7471
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 0.15s
                      Time elapsed: 00:04:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 227/1 [0m                       

                       Computation: 669742 steps/s (collection: 0.036s, learning 0.110s)
                       Mean reward: 844.66
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.2995
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7516
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 0.15s
                      Time elapsed: 00:04:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 228/1 [0m                       

                       Computation: 733454 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 842.85
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.4189
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7556
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 0.13s
                      Time elapsed: 00:04:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 229/1 [0m                       

                       Computation: 590938 steps/s (collection: 0.036s, learning 0.131s)
                       Mean reward: 853.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1689
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 0.17s
                      Time elapsed: 00:04:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 230/1 [0m                       

                       Computation: 747872 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 848.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.7220
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7307
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 101.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 0.13s
                      Time elapsed: 00:04:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 231/1 [0m                       

                       Computation: 553878 steps/s (collection: 0.043s, learning 0.135s)
                       Mean reward: 846.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.0117
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 0.18s
                      Time elapsed: 00:04:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 232/1 [0m                       

                       Computation: 611443 steps/s (collection: 0.040s, learning 0.121s)
                       Mean reward: 850.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8085
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 0.16s
                      Time elapsed: 00:04:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 233/1 [0m                       

                       Computation: 519328 steps/s (collection: 0.046s, learning 0.144s)
                       Mean reward: 835.92
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.7762
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7564
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 0.19s
                      Time elapsed: 00:04:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 234/1 [0m                       

                       Computation: 431776 steps/s (collection: 0.059s, learning 0.169s)
                       Mean reward: 846.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.3645
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7500
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 0.23s
                      Time elapsed: 00:04:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 235/1 [0m                       

                       Computation: 580022 steps/s (collection: 0.048s, learning 0.122s)
                       Mean reward: 855.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8545
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7589
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 0.17s
                      Time elapsed: 00:04:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 236/1 [0m                       

                       Computation: 543992 steps/s (collection: 0.054s, learning 0.127s)
                       Mean reward: 847.26
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.5180
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7487
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 0.18s
                      Time elapsed: 00:04:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 237/1 [0m                       

                       Computation: 507687 steps/s (collection: 0.052s, learning 0.142s)
                       Mean reward: 841.88
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.4682
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7604
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 0.19s
                      Time elapsed: 00:04:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 238/1 [0m                       

                       Computation: 608751 steps/s (collection: 0.045s, learning 0.116s)
                       Mean reward: 865.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.5938
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 0.16s
                      Time elapsed: 00:04:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 239/1 [0m                       

                       Computation: 608417 steps/s (collection: 0.037s, learning 0.125s)
                       Mean reward: 849.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9000
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7574
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 0.16s
                      Time elapsed: 00:04:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 240/1 [0m                       

                       Computation: 485333 steps/s (collection: 0.043s, learning 0.160s)
                       Mean reward: 826.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.8378
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7238
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 103.1667
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 0.20s
                      Time elapsed: 00:04:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 241/1 [0m                       

                       Computation: 648803 steps/s (collection: 0.046s, learning 0.106s)
                       Mean reward: 826.24
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.2856
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7404
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 0.15s
                      Time elapsed: 00:04:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 242/1 [0m                       

                       Computation: 792500 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 847.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0011
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7412
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 0.12s
                      Time elapsed: 00:04:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 243/1 [0m                       

                       Computation: 660849 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 828.22
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.6570
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7447
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 0.15s
                      Time elapsed: 00:04:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 244/1 [0m                       

                       Computation: 791070 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 840.40
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.8734
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7460
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 0.12s
                      Time elapsed: 00:04:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 245/1 [0m                       

                       Computation: 708914 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 833.22
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.9773
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7595
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 0.14s
                      Time elapsed: 00:04:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 246/1 [0m                       

                       Computation: 653058 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 838.01
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.3799
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7494
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 0.15s
                      Time elapsed: 00:04:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 247/1 [0m                       

                       Computation: 635043 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 813.12
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.9905
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7287
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 0.15s
                      Time elapsed: 00:04:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 248/1 [0m                       

                       Computation: 572838 steps/s (collection: 0.042s, learning 0.129s)
                       Mean reward: 833.63
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.3460
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7357
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 0.17s
                      Time elapsed: 00:04:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 249/1 [0m                       

                       Computation: 661731 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 834.06
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.4993
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7538
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 0.15s
                      Time elapsed: 00:04:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 250/1 [0m                       

                       Computation: 556620 steps/s (collection: 0.046s, learning 0.130s)
                       Mean reward: 827.07
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.3632
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7413
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 105.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 0.18s
                      Time elapsed: 00:04:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 251/1 [0m                       

                       Computation: 741342 steps/s (collection: 0.033s, learning 0.100s)
                       Mean reward: 823.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.1022
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7359
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 0.13s
                      Time elapsed: 00:04:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 252/1 [0m                       

                       Computation: 708907 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 847.84
               Mean episode length: 247.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.1057
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 0.14s
                      Time elapsed: 00:04:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 253/1 [0m                       

                       Computation: 675428 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 833.53
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.4574
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7380
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 0.15s
                      Time elapsed: 00:04:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 254/1 [0m                       

                       Computation: 688632 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 831.11
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.4311
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7430
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 0.14s
                      Time elapsed: 00:04:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 255/1 [0m                       

                       Computation: 567220 steps/s (collection: 0.040s, learning 0.133s)
                       Mean reward: 850.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.0926
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 0.17s
                      Time elapsed: 00:04:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 256/1 [0m                       

                       Computation: 568100 steps/s (collection: 0.049s, learning 0.124s)
                       Mean reward: 844.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.3100
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 0.17s
                      Time elapsed: 00:04:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 257/1 [0m                       

                       Computation: 643121 steps/s (collection: 0.049s, learning 0.104s)
                       Mean reward: 846.72
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.2852
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 0.15s
                      Time elapsed: 00:04:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 258/1 [0m                       

                       Computation: 756811 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 849.27
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.6073
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 0.13s
                      Time elapsed: 00:04:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 259/1 [0m                       

                       Computation: 833721 steps/s (collection: 0.035s, learning 0.083s)
                       Mean reward: 850.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.4395
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 0.12s
                      Time elapsed: 00:04:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 260/1 [0m                       

                       Computation: 741457 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 867.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.8881
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7941
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 0.13s
                      Time elapsed: 00:04:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 261/1 [0m                       

                       Computation: 748885 steps/s (collection: 0.035s, learning 0.097s)
                       Mean reward: 859.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.0276
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 102.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 0.13s
                      Time elapsed: 00:04:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 262/1 [0m                       

                       Computation: 674255 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 851.25
               Mean episode length: 246.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.3006
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7568
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 0.15s
                      Time elapsed: 00:05:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 263/1 [0m                       

                       Computation: 786561 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 848.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.5994
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 0.12s
                      Time elapsed: 00:05:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 264/1 [0m                       

                       Computation: 423457 steps/s (collection: 0.042s, learning 0.190s)
                       Mean reward: 866.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.6094
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 0.23s
                      Time elapsed: 00:05:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 265/1 [0m                       

                       Computation: 655252 steps/s (collection: 0.047s, learning 0.103s)
                       Mean reward: 856.44
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.8576
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7635
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 0.15s
                      Time elapsed: 00:05:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 266/1 [0m                       

                       Computation: 587542 steps/s (collection: 0.045s, learning 0.123s)
                       Mean reward: 854.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.2172
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7804
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 0.17s
                      Time elapsed: 00:05:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 267/1 [0m                       

                       Computation: 574293 steps/s (collection: 0.047s, learning 0.125s)
                       Mean reward: 855.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.5001
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7706
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 0.17s
                      Time elapsed: 00:05:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 268/1 [0m                       

                       Computation: 464550 steps/s (collection: 0.058s, learning 0.154s)
                       Mean reward: 846.95
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.9699
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 0.21s
                      Time elapsed: 00:05:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 269/1 [0m                       

                       Computation: 509182 steps/s (collection: 0.046s, learning 0.148s)
                       Mean reward: 853.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.4499
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 0.19s
                      Time elapsed: 00:05:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 270/1 [0m                       

                       Computation: 331521 steps/s (collection: 0.073s, learning 0.224s)
                       Mean reward: 854.13
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.4999
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 0.30s
                      Time elapsed: 00:05:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 271/1 [0m                       

                       Computation: 593376 steps/s (collection: 0.042s, learning 0.124s)
                       Mean reward: 839.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.6596
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 103.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 0.17s
                      Time elapsed: 00:05:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 272/1 [0m                       

                       Computation: 682472 steps/s (collection: 0.047s, learning 0.098s)
                       Mean reward: 837.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.7889
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 0.14s
                      Time elapsed: 00:05:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 273/1 [0m                       

                       Computation: 809021 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 817.35
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.6676
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 0.12s
                      Time elapsed: 00:05:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 274/1 [0m                       

                       Computation: 617573 steps/s (collection: 0.040s, learning 0.120s)
                       Mean reward: 847.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.6833
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 0.16s
                      Time elapsed: 00:05:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 275/1 [0m                       

                       Computation: 744203 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 853.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.4875
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 0.13s
                      Time elapsed: 00:05:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 276/1 [0m                       

                       Computation: 435697 steps/s (collection: 0.046s, learning 0.180s)
                       Mean reward: 841.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.7763
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 0.23s
                      Time elapsed: 00:05:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 277/1 [0m                       

                       Computation: 338319 steps/s (collection: 0.065s, learning 0.226s)
                       Mean reward: 849.47
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.5057
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 0.29s
                      Time elapsed: 00:05:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 278/1 [0m                       

                       Computation: 472976 steps/s (collection: 0.060s, learning 0.148s)
                       Mean reward: 860.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.1746
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7615
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 0.21s
                      Time elapsed: 00:05:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 279/1 [0m                       

                       Computation: 458566 steps/s (collection: 0.055s, learning 0.159s)
                       Mean reward: 846.96
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.0795
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 0.21s
                      Time elapsed: 00:05:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 280/1 [0m                       

                       Computation: 591578 steps/s (collection: 0.041s, learning 0.125s)
                       Mean reward: 866.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.7741
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 0.17s
                      Time elapsed: 00:05:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 281/1 [0m                       

                       Computation: 631497 steps/s (collection: 0.058s, learning 0.098s)
                       Mean reward: 860.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.3446
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7740
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 0.16s
                      Time elapsed: 00:05:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 282/1 [0m                       

                       Computation: 736549 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 851.10
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.7742
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 101.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 0.13s
                      Time elapsed: 00:05:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 283/1 [0m                       

                       Computation: 609379 steps/s (collection: 0.045s, learning 0.116s)
                       Mean reward: 871.73
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.9267
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7709
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 0.16s
                      Time elapsed: 00:05:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 284/1 [0m                       

                       Computation: 483546 steps/s (collection: 0.044s, learning 0.159s)
                       Mean reward: 854.56
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.7918
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 0.20s
                      Time elapsed: 00:05:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 285/1 [0m                       

                       Computation: 487641 steps/s (collection: 0.047s, learning 0.155s)
                       Mean reward: 856.03
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.1434
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 0.20s
                      Time elapsed: 00:05:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 286/1 [0m                       

                       Computation: 682946 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 847.76
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.0440
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7563
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 0.14s
                      Time elapsed: 00:05:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 287/1 [0m                       

                       Computation: 707507 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 843.42
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.7805
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 0.14s
                      Time elapsed: 00:05:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 288/1 [0m                       

                       Computation: 357139 steps/s (collection: 0.064s, learning 0.212s)
                       Mean reward: 839.20
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.6734
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 0.28s
                      Time elapsed: 00:05:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 289/1 [0m                       

                       Computation: 694510 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 846.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.1518
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 0.14s
                      Time elapsed: 00:05:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 290/1 [0m                       

                       Computation: 613159 steps/s (collection: 0.039s, learning 0.122s)
                       Mean reward: 842.59
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.2888
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7626
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 0.16s
                      Time elapsed: 00:05:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 291/1 [0m                       

                       Computation: 668490 steps/s (collection: 0.037s, learning 0.110s)
                       Mean reward: 845.17
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.4105
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 0.15s
                      Time elapsed: 00:05:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 292/1 [0m                       

                       Computation: 573099 steps/s (collection: 0.037s, learning 0.134s)
                       Mean reward: 840.94
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.3347
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7598
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 102.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 0.17s
                      Time elapsed: 00:05:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 293/1 [0m                       

                       Computation: 600491 steps/s (collection: 0.042s, learning 0.122s)
                       Mean reward: 800.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 154.6817
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7082
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 0.16s
                      Time elapsed: 00:05:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 294/1 [0m                       

                       Computation: 617632 steps/s (collection: 0.039s, learning 0.121s)
                       Mean reward: 852.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.9620
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7679
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 0.16s
                      Time elapsed: 00:05:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 295/1 [0m                       

                       Computation: 656222 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 827.60
               Mean episode length: 246.87
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.7793
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7296
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 0.15s
                      Time elapsed: 00:05:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 296/1 [0m                       

                       Computation: 549047 steps/s (collection: 0.047s, learning 0.132s)
                       Mean reward: 840.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.0438
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7560
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 0.18s
                      Time elapsed: 00:05:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 297/1 [0m                       

                       Computation: 541418 steps/s (collection: 0.064s, learning 0.118s)
                       Mean reward: 844.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.4058
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 0.18s
                      Time elapsed: 00:05:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 298/1 [0m                       

                       Computation: 737260 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 854.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.2221
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7648
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 0.13s
                      Time elapsed: 00:05:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 299/1 [0m                       

                       Computation: 799091 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 847.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.7857
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 0.12s
                      Time elapsed: 00:05:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 300/1 [0m                       

                       Computation: 734059 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 847.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.2674
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7543
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 0.13s
                      Time elapsed: 00:05:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 301/1 [0m                       

                       Computation: 715806 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 831.24
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.5750
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7437
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 0.14s
                      Time elapsed: 00:05:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 302/1 [0m                       

                       Computation: 523260 steps/s (collection: 0.053s, learning 0.135s)
                       Mean reward: 856.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.6202
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7726
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 0.19s
                      Time elapsed: 00:05:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 303/1 [0m                       

                       Computation: 473683 steps/s (collection: 0.078s, learning 0.130s)
                       Mean reward: 845.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.3407
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 100.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 0.21s
                      Time elapsed: 00:05:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 304/1 [0m                       

                       Computation: 653803 steps/s (collection: 0.043s, learning 0.108s)
                       Mean reward: 850.26
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1482
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 0.15s
                      Time elapsed: 00:05:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 305/1 [0m                       

                       Computation: 583301 steps/s (collection: 0.044s, learning 0.125s)
                       Mean reward: 849.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.1374
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 0.17s
                      Time elapsed: 00:05:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 306/1 [0m                       

                       Computation: 714149 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 845.26
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.5991
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7455
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 0.14s
                      Time elapsed: 00:05:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 307/1 [0m                       

                       Computation: 565920 steps/s (collection: 0.069s, learning 0.104s)
                       Mean reward: 838.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.6749
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7566
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 0.17s
                      Time elapsed: 00:05:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 308/1 [0m                       

                       Computation: 464885 steps/s (collection: 0.053s, learning 0.159s)
                       Mean reward: 843.59
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.6067
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7461
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 0.21s
                      Time elapsed: 00:05:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 309/1 [0m                       

                       Computation: 751228 steps/s (collection: 0.045s, learning 0.086s)
                       Mean reward: 843.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.1797
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7598
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 0.13s
                      Time elapsed: 00:05:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 310/1 [0m                       

                       Computation: 559158 steps/s (collection: 0.051s, learning 0.125s)
                       Mean reward: 861.73
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9688
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7705
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 0.18s
                      Time elapsed: 00:06:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 311/1 [0m                       

                       Computation: 654177 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 853.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.7452
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7676
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 0.15s
                      Time elapsed: 00:06:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 312/1 [0m                       

                       Computation: 530174 steps/s (collection: 0.052s, learning 0.133s)
                       Mean reward: 855.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.6382
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 0.19s
                      Time elapsed: 00:06:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 313/1 [0m                       

                       Computation: 479321 steps/s (collection: 0.047s, learning 0.159s)
                       Mean reward: 850.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.3523
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7852
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 101.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 0.21s
                      Time elapsed: 00:06:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 314/1 [0m                       

                       Computation: 501491 steps/s (collection: 0.055s, learning 0.141s)
                       Mean reward: 845.59
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.2983
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 0.20s
                      Time elapsed: 00:06:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 315/1 [0m                       

                       Computation: 458208 steps/s (collection: 0.055s, learning 0.160s)
                       Mean reward: 847.90
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.8303
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7551
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 0.21s
                      Time elapsed: 00:06:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 316/1 [0m                       

                       Computation: 717552 steps/s (collection: 0.054s, learning 0.083s)
                       Mean reward: 853.73
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.6775
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 0.14s
                      Time elapsed: 00:06:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 317/1 [0m                       

                       Computation: 785979 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 862.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.5745
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 0.13s
                      Time elapsed: 00:06:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 318/1 [0m                       

                       Computation: 623403 steps/s (collection: 0.041s, learning 0.117s)
                       Mean reward: 842.77
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9303
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7544
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 0.16s
                      Time elapsed: 00:06:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 319/1 [0m                       

                       Computation: 594109 steps/s (collection: 0.039s, learning 0.127s)
                       Mean reward: 862.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.2832
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 0.17s
                      Time elapsed: 00:06:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 320/1 [0m                       

                       Computation: 337381 steps/s (collection: 0.049s, learning 0.242s)
                       Mean reward: 861.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.6037
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 0.29s
                      Time elapsed: 00:06:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 321/1 [0m                       

                       Computation: 608502 steps/s (collection: 0.046s, learning 0.116s)
                       Mean reward: 841.25
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9446
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7556
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 0.16s
                      Time elapsed: 00:06:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 322/1 [0m                       

                       Computation: 614509 steps/s (collection: 0.047s, learning 0.113s)
                       Mean reward: 855.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.2284
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7622
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 0.16s
                      Time elapsed: 00:06:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 323/1 [0m                       

                       Computation: 705602 steps/s (collection: 0.033s, learning 0.106s)
                       Mean reward: 853.07
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.3395
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7508
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 103.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 0.14s
                      Time elapsed: 00:06:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 324/1 [0m                       

                       Computation: 717725 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 836.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.5422
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 0.14s
                      Time elapsed: 00:06:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 325/1 [0m                       

                       Computation: 588962 steps/s (collection: 0.039s, learning 0.127s)
                       Mean reward: 861.73
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.2235
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7531
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 0.17s
                      Time elapsed: 00:06:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 326/1 [0m                       

                       Computation: 518059 steps/s (collection: 0.041s, learning 0.149s)
                       Mean reward: 848.66
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.8908
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7484
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 0.19s
                      Time elapsed: 00:06:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 327/1 [0m                       

                       Computation: 470098 steps/s (collection: 0.074s, learning 0.135s)
                       Mean reward: 853.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.2421
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 0.21s
                      Time elapsed: 00:06:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 328/1 [0m                       

                       Computation: 520753 steps/s (collection: 0.045s, learning 0.143s)
                       Mean reward: 846.40
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.9023
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7654
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 0.19s
                      Time elapsed: 00:06:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 329/1 [0m                       

                       Computation: 718620 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 863.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.2267
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 0.14s
                      Time elapsed: 00:06:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 330/1 [0m                       

                       Computation: 451639 steps/s (collection: 0.085s, learning 0.133s)
                       Mean reward: 860.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.2473
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7602
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 0.22s
                      Time elapsed: 00:06:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 331/1 [0m                       

                       Computation: 739222 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 857.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.7991
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 0.13s
                      Time elapsed: 00:06:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 332/1 [0m                       

                       Computation: 689702 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 845.61
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.5825
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.7501
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 0.14s
                      Time elapsed: 00:06:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 333/1 [0m                       

                       Computation: 803949 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 853.98
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.4387
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 0.12s
                      Time elapsed: 00:06:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 334/1 [0m                       

                       Computation: 738723 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 857.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.5489
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 100.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 0.13s
                      Time elapsed: 00:06:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 335/1 [0m                       

                       Computation: 832803 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 849.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.9883
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 0.12s
                      Time elapsed: 00:06:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 336/1 [0m                       

                       Computation: 846285 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 869.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.5327
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 0.12s
                      Time elapsed: 00:06:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 337/1 [0m                       

                       Computation: 823331 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 850.73
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.6346
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 0.12s
                      Time elapsed: 00:06:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 338/1 [0m                       

                       Computation: 761772 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 859.45
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.0240
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 0.13s
                      Time elapsed: 00:06:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 339/1 [0m                       

                       Computation: 539216 steps/s (collection: 0.045s, learning 0.138s)
                       Mean reward: 849.95
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.1969
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7587
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 0.18s
                      Time elapsed: 00:06:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 340/1 [0m                       

                       Computation: 525432 steps/s (collection: 0.045s, learning 0.143s)
                       Mean reward: 842.05
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.5691
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 0.19s
                      Time elapsed: 00:06:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 341/1 [0m                       

                       Computation: 646180 steps/s (collection: 0.040s, learning 0.112s)
                       Mean reward: 837.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.5994
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7596
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 0.15s
                      Time elapsed: 00:06:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 342/1 [0m                       

                       Computation: 538441 steps/s (collection: 0.051s, learning 0.132s)
                       Mean reward: 860.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.4542
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 0.18s
                      Time elapsed: 00:06:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 343/1 [0m                       

                       Computation: 517349 steps/s (collection: 0.047s, learning 0.143s)
                       Mean reward: 861.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.0809
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 0.19s
                      Time elapsed: 00:06:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 344/1 [0m                       

                       Computation: 734995 steps/s (collection: 0.049s, learning 0.085s)
                       Mean reward: 852.99
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.0673
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 102.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 0.13s
                      Time elapsed: 00:06:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 345/1 [0m                       

                       Computation: 501456 steps/s (collection: 0.052s, learning 0.144s)
                       Mean reward: 872.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 174.0667
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 0.20s
                      Time elapsed: 00:06:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 346/1 [0m                       

                       Computation: 621819 steps/s (collection: 0.046s, learning 0.112s)
                       Mean reward: 861.40
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.7504
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 0.16s
                      Time elapsed: 00:06:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 347/1 [0m                       

                       Computation: 655081 steps/s (collection: 0.045s, learning 0.105s)
                       Mean reward: 837.56
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.2805
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 0.15s
                      Time elapsed: 00:06:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 348/1 [0m                       

                       Computation: 753340 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 850.41
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.2560
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 0.13s
                      Time elapsed: 00:06:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 349/1 [0m                       

                       Computation: 604268 steps/s (collection: 0.039s, learning 0.124s)
                       Mean reward: 856.67
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.6861
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 0.16s
                      Time elapsed: 00:06:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 350/1 [0m                       

                       Computation: 592348 steps/s (collection: 0.045s, learning 0.121s)
                       Mean reward: 849.07
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9630
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 0.17s
                      Time elapsed: 00:06:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 351/1 [0m                       

                       Computation: 364938 steps/s (collection: 0.064s, learning 0.205s)
                       Mean reward: 850.59
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.3274
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.7689
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 0.27s
                      Time elapsed: 00:06:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 352/1 [0m                       

                       Computation: 417004 steps/s (collection: 0.046s, learning 0.190s)
                       Mean reward: 847.23
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.0855
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 0.24s
                      Time elapsed: 00:06:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 353/1 [0m                       

                       Computation: 567834 steps/s (collection: 0.042s, learning 0.132s)
                       Mean reward: 841.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.2235
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.7627
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 0.17s
                      Time elapsed: 00:06:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 354/1 [0m                       

                       Computation: 536430 steps/s (collection: 0.052s, learning 0.132s)
                       Mean reward: 844.73
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.4524
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 0.18s
                      Time elapsed: 00:06:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 355/1 [0m                       

                       Computation: 704445 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 844.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.8622
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 99.4583
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 0.14s
                      Time elapsed: 00:06:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 356/1 [0m                       

                       Computation: 669746 steps/s (collection: 0.036s, learning 0.111s)
                       Mean reward: 857.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.0811
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 0.15s
                      Time elapsed: 00:06:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 357/1 [0m                       

                       Computation: 763230 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 844.08
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.3001
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7582
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 0.13s
                      Time elapsed: 00:06:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 358/1 [0m                       

                       Computation: 757215 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 846.75
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.5484
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7444
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 0.13s
                      Time elapsed: 00:06:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 359/1 [0m                       

                       Computation: 844548 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 853.70
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.1967
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7610
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 0.12s
                      Time elapsed: 00:07:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 360/1 [0m                       

                       Computation: 801575 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 853.07
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.9465
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 0.12s
                      Time elapsed: 00:07:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 361/1 [0m                       

                       Computation: 814369 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 857.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.8497
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 0.12s
                      Time elapsed: 00:07:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 362/1 [0m                       

                       Computation: 781394 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 826.12
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.9390
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7445
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 0.13s
                      Time elapsed: 00:07:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 363/1 [0m                       

                       Computation: 871400 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 863.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.9966
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 0.11s
                      Time elapsed: 00:07:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 364/1 [0m                       

                       Computation: 601115 steps/s (collection: 0.038s, learning 0.126s)
                       Mean reward: 853.34
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.2222
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7522
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 0.16s
                      Time elapsed: 00:07:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 365/1 [0m                       

                       Computation: 572432 steps/s (collection: 0.037s, learning 0.135s)
                       Mean reward: 852.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.8103
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 101.0417
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 0.17s
                      Time elapsed: 00:07:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 366/1 [0m                       

                       Computation: 659606 steps/s (collection: 0.048s, learning 0.101s)
                       Mean reward: 860.30
               Mean episode length: 246.96
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.1722
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7305
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 0.15s
                      Time elapsed: 00:07:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 367/1 [0m                       

                       Computation: 830691 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 803.14
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.6354
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7341
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 0.12s
                      Time elapsed: 00:07:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 368/1 [0m                       

                       Computation: 830727 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 842.83
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.0797
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7487
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 0.12s
                      Time elapsed: 00:07:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 369/1 [0m                       

                       Computation: 812358 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 827.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.7149
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7362
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 0.12s
                      Time elapsed: 00:07:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 370/1 [0m                       

                       Computation: 722668 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 836.86
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.5717
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7438
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 0.14s
                      Time elapsed: 00:07:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 371/1 [0m                       

                       Computation: 821189 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 850.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0976
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7574
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 0.12s
                      Time elapsed: 00:07:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 372/1 [0m                       

                       Computation: 748659 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 840.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.7405
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 0.13s
                      Time elapsed: 00:07:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 373/1 [0m                       

                       Computation: 724866 steps/s (collection: 0.050s, learning 0.086s)
                       Mean reward: 831.77
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.8633
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7350
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 0.14s
                      Time elapsed: 00:07:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 374/1 [0m                       

                       Computation: 646692 steps/s (collection: 0.040s, learning 0.112s)
                       Mean reward: 851.42
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.6458
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7442
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 0.15s
                      Time elapsed: 00:07:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 375/1 [0m                       

                       Computation: 711746 steps/s (collection: 0.037s, learning 0.101s)
                       Mean reward: 841.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.4380
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7597
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 103.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 0.14s
                      Time elapsed: 00:07:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 376/1 [0m                       

                       Computation: 711661 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 861.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4639
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 0.14s
                      Time elapsed: 00:07:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 377/1 [0m                       

                       Computation: 768751 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 860.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.4559
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7895
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 0.13s
                      Time elapsed: 00:07:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 378/1 [0m                       

                       Computation: 557502 steps/s (collection: 0.042s, learning 0.134s)
                       Mean reward: 855.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0806
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7604
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 0.18s
                      Time elapsed: 00:07:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 379/1 [0m                       

                       Computation: 779903 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 846.89
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.1752
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7444
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 0.13s
                      Time elapsed: 00:07:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 380/1 [0m                       

                       Computation: 779509 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 838.90
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.0955
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7396
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 0.13s
                      Time elapsed: 00:07:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 381/1 [0m                       

                       Computation: 786402 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 861.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5721
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 0.13s
                      Time elapsed: 00:07:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 382/1 [0m                       

                       Computation: 786295 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 846.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.6312
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7538
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 0.13s
                      Time elapsed: 00:07:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 383/1 [0m                       

                       Computation: 789859 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 869.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.6287
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7595
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 0.12s
                      Time elapsed: 00:07:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 384/1 [0m                       

                       Computation: 649535 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 853.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.9094
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 0.15s
                      Time elapsed: 00:07:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 385/1 [0m                       

                       Computation: 545964 steps/s (collection: 0.048s, learning 0.132s)
                       Mean reward: 868.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.8879
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7675
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 0.18s
                      Time elapsed: 00:07:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 386/1 [0m                       

                       Computation: 493223 steps/s (collection: 0.045s, learning 0.155s)
                       Mean reward: 863.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.1928
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7459
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 100.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 0.20s
                      Time elapsed: 00:07:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 387/1 [0m                       

                       Computation: 801474 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 835.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9972
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7556
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 0.12s
                      Time elapsed: 00:07:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 388/1 [0m                       

                       Computation: 763326 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 852.12
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.8064
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7570
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 0.13s
                      Time elapsed: 00:07:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 389/1 [0m                       

                       Computation: 670025 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 860.75
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.4115
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7610
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 0.15s
                      Time elapsed: 00:07:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 390/1 [0m                       

                       Computation: 637546 steps/s (collection: 0.049s, learning 0.106s)
                       Mean reward: 862.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.1037
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 0.15s
                      Time elapsed: 00:07:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 391/1 [0m                       

                       Computation: 706355 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 843.21
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.7247
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7531
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 0.14s
                      Time elapsed: 00:07:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 392/1 [0m                       

                       Computation: 550510 steps/s (collection: 0.037s, learning 0.142s)
                       Mean reward: 844.53
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.4177
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7476
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 0.18s
                      Time elapsed: 00:07:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 393/1 [0m                       

                       Computation: 643594 steps/s (collection: 0.039s, learning 0.114s)
                       Mean reward: 852.41
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.4488
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7583
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 0.15s
                      Time elapsed: 00:07:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 394/1 [0m                       

                       Computation: 566386 steps/s (collection: 0.044s, learning 0.130s)
                       Mean reward: 847.52
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.2615
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7404
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 0.17s
                      Time elapsed: 00:07:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 395/1 [0m                       

                       Computation: 825918 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 847.76
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.3884
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7459
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 0.12s
                      Time elapsed: 00:07:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 396/1 [0m                       

                       Computation: 319585 steps/s (collection: 0.061s, learning 0.247s)
                       Mean reward: 851.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.9335
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7560
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 101.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 0.31s
                      Time elapsed: 00:07:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 397/1 [0m                       

                       Computation: 583599 steps/s (collection: 0.059s, learning 0.110s)
                       Mean reward: 847.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.3889
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7320
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 0.17s
                      Time elapsed: 00:07:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 398/1 [0m                       

                       Computation: 572442 steps/s (collection: 0.046s, learning 0.126s)
                       Mean reward: 852.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.1379
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7403
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 0.17s
                      Time elapsed: 00:07:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 399/1 [0m                       

                       Computation: 711114 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 836.12
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.7540
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7386
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 0.14s
                      Time elapsed: 00:07:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 400/1 [0m                       

                       Computation: 660360 steps/s (collection: 0.041s, learning 0.108s)
                       Mean reward: 849.11
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.4198
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 0.15s
                      Time elapsed: 00:07:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 401/1 [0m                       

                       Computation: 659314 steps/s (collection: 0.038s, learning 0.111s)
                       Mean reward: 841.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.6284
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 0.15s
                      Time elapsed: 00:07:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 402/1 [0m                       

                       Computation: 561160 steps/s (collection: 0.045s, learning 0.130s)
                       Mean reward: 829.32
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.2307
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7339
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 0.18s
                      Time elapsed: 00:07:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 403/1 [0m                       

                       Computation: 537743 steps/s (collection: 0.043s, learning 0.140s)
                       Mean reward: 842.07
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.5781
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7433
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 0.18s
                      Time elapsed: 00:07:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 404/1 [0m                       

                       Computation: 650813 steps/s (collection: 0.043s, learning 0.109s)
                       Mean reward: 835.75
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.4118
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7523
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 0.15s
                      Time elapsed: 00:07:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 405/1 [0m                       

                       Computation: 462867 steps/s (collection: 0.040s, learning 0.172s)
                       Mean reward: 863.51
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.0390
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7637
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 0.21s
                      Time elapsed: 00:07:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 406/1 [0m                       

                       Computation: 588487 steps/s (collection: 0.052s, learning 0.116s)
                       Mean reward: 849.84
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.1383
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7586
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 0.17s
                      Time elapsed: 00:07:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 407/1 [0m                       

                       Computation: 574001 steps/s (collection: 0.045s, learning 0.126s)
                       Mean reward: 851.93
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9590
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7648
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 98.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 0.17s
                      Time elapsed: 00:07:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 408/1 [0m                       

                       Computation: 708489 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 870.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.6195
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7490
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 0.14s
                      Time elapsed: 00:07:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 409/1 [0m                       

                       Computation: 675845 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 861.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.2001
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7531
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 0.15s
                      Time elapsed: 00:07:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 410/1 [0m                       

                       Computation: 481680 steps/s (collection: 0.054s, learning 0.150s)
                       Mean reward: 859.37
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.1615
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7514
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 0.20s
                      Time elapsed: 00:07:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 411/1 [0m                       

                       Computation: 430262 steps/s (collection: 0.087s, learning 0.142s)
                       Mean reward: 848.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.6038
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7472
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 0.23s
                      Time elapsed: 00:07:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 412/1 [0m                       

                       Computation: 556276 steps/s (collection: 0.048s, learning 0.129s)
                       Mean reward: 848.43
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.6390
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7425
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 0.18s
                      Time elapsed: 00:08:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 413/1 [0m                       

                       Computation: 601343 steps/s (collection: 0.041s, learning 0.122s)
                       Mean reward: 852.60
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.4888
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7516
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 0.16s
                      Time elapsed: 00:08:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 414/1 [0m                       

                       Computation: 712228 steps/s (collection: 0.050s, learning 0.088s)
                       Mean reward: 843.92
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.8217
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7413
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 0.14s
                      Time elapsed: 00:08:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 415/1 [0m                       

                       Computation: 471666 steps/s (collection: 0.052s, learning 0.156s)
                       Mean reward: 838.82
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.7365
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7456
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 0.21s
                      Time elapsed: 00:08:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 416/1 [0m                       

                       Computation: 725881 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 854.64
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.2771
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7490
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 0.14s
                      Time elapsed: 00:08:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 417/1 [0m                       

                       Computation: 663163 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 850.14
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.2522
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7450
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 100.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 0.15s
                      Time elapsed: 00:08:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 418/1 [0m                       

                       Computation: 606597 steps/s (collection: 0.040s, learning 0.123s)
                       Mean reward: 842.44
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9195
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7449
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 0.16s
                      Time elapsed: 00:08:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 419/1 [0m                       

                       Computation: 727051 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 853.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.3321
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7413
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 0.14s
                      Time elapsed: 00:08:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 420/1 [0m                       

                       Computation: 605717 steps/s (collection: 0.041s, learning 0.121s)
                       Mean reward: 854.51
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.7733
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 0.16s
                      Time elapsed: 00:08:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 421/1 [0m                       

                       Computation: 543101 steps/s (collection: 0.042s, learning 0.139s)
                       Mean reward: 851.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.4944
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 0.18s
                      Time elapsed: 00:08:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 422/1 [0m                       

                       Computation: 509218 steps/s (collection: 0.049s, learning 0.144s)
                       Mean reward: 846.83
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.4705
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7472
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 0.19s
                      Time elapsed: 00:08:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 423/1 [0m                       

                       Computation: 442642 steps/s (collection: 0.048s, learning 0.175s)
                       Mean reward: 851.64
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.4947
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 0.22s
                      Time elapsed: 00:08:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 424/1 [0m                       

                       Computation: 804674 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 860.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.8087
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 0.12s
                      Time elapsed: 00:08:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 425/1 [0m                       

                       Computation: 767769 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 866.54
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.0607
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7587
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 0.13s
                      Time elapsed: 00:08:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 426/1 [0m                       

                       Computation: 580602 steps/s (collection: 0.047s, learning 0.122s)
                       Mean reward: 862.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.5965
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7635
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 0.17s
                      Time elapsed: 00:08:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 427/1 [0m                       

                       Computation: 541464 steps/s (collection: 0.055s, learning 0.127s)
                       Mean reward: 844.78
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.4246
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7460
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 0.18s
                      Time elapsed: 00:08:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 428/1 [0m                       

                       Computation: 576388 steps/s (collection: 0.046s, learning 0.125s)
                       Mean reward: 842.99
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.0954
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7403
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 97.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 0.17s
                      Time elapsed: 00:08:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 429/1 [0m                       

                       Computation: 758322 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 829.45
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.6870
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7382
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 0.13s
                      Time elapsed: 00:08:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 430/1 [0m                       

                       Computation: 669496 steps/s (collection: 0.050s, learning 0.097s)
                       Mean reward: 851.89
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.6148
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7519
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 0.15s
                      Time elapsed: 00:08:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 431/1 [0m                       

                       Computation: 644064 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 839.97
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.8746
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7431
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 0.15s
                      Time elapsed: 00:08:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 432/1 [0m                       

                       Computation: 562368 steps/s (collection: 0.044s, learning 0.131s)
                       Mean reward: 852.67
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.9284
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7506
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 0.17s
                      Time elapsed: 00:08:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 433/1 [0m                       

                       Computation: 525599 steps/s (collection: 0.055s, learning 0.133s)
                       Mean reward: 859.54
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.3799
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7596
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 0.19s
                      Time elapsed: 00:08:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 434/1 [0m                       

                       Computation: 600974 steps/s (collection: 0.051s, learning 0.113s)
                       Mean reward: 858.50
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.7873
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7539
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 0.16s
                      Time elapsed: 00:08:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 435/1 [0m                       

                       Computation: 717479 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 833.74
               Mean episode length: 247.51
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.9491
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7422
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 0.14s
                      Time elapsed: 00:08:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 436/1 [0m                       

                       Computation: 502383 steps/s (collection: 0.048s, learning 0.148s)
                       Mean reward: 845.14
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.1919
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7529
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 0.20s
                      Time elapsed: 00:08:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 437/1 [0m                       

                       Computation: 398092 steps/s (collection: 0.053s, learning 0.194s)
                       Mean reward: 862.29
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.5140
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.7626
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 0.25s
                      Time elapsed: 00:08:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 438/1 [0m                       

                       Computation: 628020 steps/s (collection: 0.041s, learning 0.116s)
                       Mean reward: 831.16
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 160.7632
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7247
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 99.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 0.16s
                      Time elapsed: 00:08:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 439/1 [0m                       

                       Computation: 727017 steps/s (collection: 0.045s, learning 0.090s)
                       Mean reward: 792.28
               Mean episode length: 243.82
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 158.1528
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7015
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 0.14s
                      Time elapsed: 00:08:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 440/1 [0m                       

                       Computation: 612961 steps/s (collection: 0.042s, learning 0.119s)
                       Mean reward: 823.71
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 159.0815
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7257
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 0.16s
                      Time elapsed: 00:08:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 441/1 [0m                       

                       Computation: 611878 steps/s (collection: 0.048s, learning 0.113s)
                       Mean reward: 825.27
               Mean episode length: 247.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 163.6251
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7203
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 0.16s
                      Time elapsed: 00:08:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 442/1 [0m                       

                       Computation: 822807 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 826.48
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 165.1207
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7252
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 0.12s
                      Time elapsed: 00:08:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 443/1 [0m                       

                       Computation: 771858 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 839.29
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.6438
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7336
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 0.13s
                      Time elapsed: 00:08:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 444/1 [0m                       

                       Computation: 743221 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 847.50
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.5676
       Episode_Reward/object_height 0.0246
     Episode_Reward/reaching_object 0.7437
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 0.13s
                      Time elapsed: 00:08:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 445/1 [0m                       

                       Computation: 661772 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 852.98
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.8313
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7464
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 0.15s
                      Time elapsed: 00:08:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 446/1 [0m                       

                       Computation: 734989 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 848.42
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.7104
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 0.13s
                      Time elapsed: 00:08:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 447/1 [0m                       

                       Computation: 639094 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 859.94
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.7728
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7527
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 0.15s
                      Time elapsed: 00:08:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 448/1 [0m                       

                       Computation: 696480 steps/s (collection: 0.045s, learning 0.097s)
                       Mean reward: 858.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.9746
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 100.4583
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 0.14s
                      Time elapsed: 00:08:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 449/1 [0m                       

                       Computation: 627389 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 859.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.0722
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7736
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 0.16s
                      Time elapsed: 00:08:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 450/1 [0m                       

                       Computation: 583954 steps/s (collection: 0.042s, learning 0.126s)
                       Mean reward: 874.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 174.4564
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 0.17s
                      Time elapsed: 00:08:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 451/1 [0m                       

                       Computation: 581615 steps/s (collection: 0.047s, learning 0.122s)
                       Mean reward: 843.26
               Mean episode length: 247.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.3386
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7561
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 0.17s
                      Time elapsed: 00:08:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 452/1 [0m                       

                       Computation: 587239 steps/s (collection: 0.039s, learning 0.128s)
                       Mean reward: 859.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.3344
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 0.17s
                      Time elapsed: 00:08:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 453/1 [0m                       

                       Computation: 650244 steps/s (collection: 0.040s, learning 0.111s)
                       Mean reward: 871.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.2948
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 0.15s
                      Time elapsed: 00:08:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 454/1 [0m                       

                       Computation: 724469 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 868.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.2148
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 0.14s
                      Time elapsed: 00:08:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 455/1 [0m                       

                       Computation: 627935 steps/s (collection: 0.045s, learning 0.112s)
                       Mean reward: 864.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.7339
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 0.16s
                      Time elapsed: 00:08:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 456/1 [0m                       

                       Computation: 600160 steps/s (collection: 0.053s, learning 0.111s)
                       Mean reward: 856.28
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.4639
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 0.16s
                      Time elapsed: 00:08:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 457/1 [0m                       

                       Computation: 418415 steps/s (collection: 0.046s, learning 0.189s)
                       Mean reward: 869.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.1838
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 0.23s
                      Time elapsed: 00:08:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 458/1 [0m                       

                       Computation: 600873 steps/s (collection: 0.043s, learning 0.121s)
                       Mean reward: 851.06
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.3974
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 0.16s
                      Time elapsed: 00:08:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 459/1 [0m                       

                       Computation: 644888 steps/s (collection: 0.038s, learning 0.115s)
                       Mean reward: 857.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.6879
       Episode_Reward/object_height 0.0246
     Episode_Reward/reaching_object 0.7653
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 97.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 0.15s
                      Time elapsed: 00:08:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 460/1 [0m                       

                       Computation: 588900 steps/s (collection: 0.040s, learning 0.127s)
                       Mean reward: 861.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.0406
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 0.17s
                      Time elapsed: 00:08:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 461/1 [0m                       

                       Computation: 624071 steps/s (collection: 0.040s, learning 0.117s)
                       Mean reward: 861.50
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.4438
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7654
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 0.16s
                      Time elapsed: 00:08:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 462/1 [0m                       

                       Computation: 631590 steps/s (collection: 0.039s, learning 0.117s)
                       Mean reward: 848.18
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.0837
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 0.16s
                      Time elapsed: 00:09:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 463/1 [0m                       

                       Computation: 717030 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 847.77
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.6777
       Episode_Reward/object_height 0.0242
     Episode_Reward/reaching_object 0.7632
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 0.14s
                      Time elapsed: 00:09:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 464/1 [0m                       

                       Computation: 737015 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 841.18
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.1864
       Episode_Reward/object_height 0.0248
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 0.13s
                      Time elapsed: 00:09:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 465/1 [0m                       

                       Computation: 668101 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 855.47
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.4610
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7599
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 0.15s
                      Time elapsed: 00:09:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 466/1 [0m                       

                       Computation: 588578 steps/s (collection: 0.043s, learning 0.125s)
                       Mean reward: 865.60
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.7486
       Episode_Reward/object_height 0.0272
     Episode_Reward/reaching_object 0.7687
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 0.17s
                      Time elapsed: 00:09:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 467/1 [0m                       

                       Computation: 778201 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 862.18
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.8940
       Episode_Reward/object_height 0.0262
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 0.13s
                      Time elapsed: 00:09:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 468/1 [0m                       

                       Computation: 394380 steps/s (collection: 0.068s, learning 0.181s)
                       Mean reward: 862.45
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.4309
       Episode_Reward/object_height 0.0263
     Episode_Reward/reaching_object 0.7589
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 0.25s
                      Time elapsed: 00:09:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 469/1 [0m                       

                       Computation: 385956 steps/s (collection: 0.052s, learning 0.203s)
                       Mean reward: 863.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.6652
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7690
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 99.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 0.25s
                      Time elapsed: 00:09:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 470/1 [0m                       

                       Computation: 443006 steps/s (collection: 0.055s, learning 0.167s)
                       Mean reward: 875.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.3572
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 0.22s
                      Time elapsed: 00:09:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 471/1 [0m                       

                       Computation: 392357 steps/s (collection: 0.061s, learning 0.190s)
                       Mean reward: 845.63
               Mean episode length: 244.42
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.4514
       Episode_Reward/object_height 0.0249
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 0.25s
                      Time elapsed: 00:09:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 472/1 [0m                       

                       Computation: 481711 steps/s (collection: 0.055s, learning 0.150s)
                       Mean reward: 864.53
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.1082
       Episode_Reward/object_height 0.0255
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 0.20s
                      Time elapsed: 00:09:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 473/1 [0m                       

                       Computation: 689981 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 865.64
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.7305
       Episode_Reward/object_height 0.0251
     Episode_Reward/reaching_object 0.7543
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 0.14s
                      Time elapsed: 00:09:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 474/1 [0m                       

                       Computation: 711290 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 844.13
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.3775
       Episode_Reward/object_height 0.0241
     Episode_Reward/reaching_object 0.7451
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 0.14s
                      Time elapsed: 00:09:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 475/1 [0m                       

                       Computation: 541609 steps/s (collection: 0.040s, learning 0.141s)
                       Mean reward: 844.50
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.9092
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7470
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 0.18s
                      Time elapsed: 00:09:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 476/1 [0m                       

                       Computation: 608428 steps/s (collection: 0.042s, learning 0.120s)
                       Mean reward: 860.47
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.9120
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 0.16s
                      Time elapsed: 00:09:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 477/1 [0m                       

                       Computation: 595182 steps/s (collection: 0.047s, learning 0.118s)
                       Mean reward: 864.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.7683
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 0.17s
                      Time elapsed: 00:09:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 478/1 [0m                       

                       Computation: 486868 steps/s (collection: 0.055s, learning 0.147s)
                       Mean reward: 853.32
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.0204
       Episode_Reward/object_height 0.0217
     Episode_Reward/reaching_object 0.7630
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 0.20s
                      Time elapsed: 00:09:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 479/1 [0m                       

                       Computation: 763370 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 830.34
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 162.7864
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7385
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 0.13s
                      Time elapsed: 00:09:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 480/1 [0m                       

                       Computation: 781116 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 860.46
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.1985
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7560
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 96.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 0.13s
                      Time elapsed: 00:09:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 481/1 [0m                       

                       Computation: 638467 steps/s (collection: 0.042s, learning 0.112s)
                       Mean reward: 821.52
               Mean episode length: 246.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.9445
       Episode_Reward/object_height 0.0163
     Episode_Reward/reaching_object 0.7524
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 0.15s
                      Time elapsed: 00:09:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 482/1 [0m                       

                       Computation: 428789 steps/s (collection: 0.061s, learning 0.168s)
                       Mean reward: 839.06
               Mean episode length: 246.21
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.2367
       Episode_Reward/object_height 0.0143
     Episode_Reward/reaching_object 0.7472
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 0.23s
                      Time elapsed: 00:09:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 483/1 [0m                       

                       Computation: 460968 steps/s (collection: 0.073s, learning 0.141s)
                       Mean reward: 845.74
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.7971
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 0.21s
                      Time elapsed: 00:09:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 484/1 [0m                       

                       Computation: 467219 steps/s (collection: 0.047s, learning 0.163s)
                       Mean reward: 860.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.6655
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 0.21s
                      Time elapsed: 00:09:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 485/1 [0m                       

                       Computation: 579885 steps/s (collection: 0.046s, learning 0.124s)
                       Mean reward: 871.08
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.5914
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 0.17s
                      Time elapsed: 00:09:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 486/1 [0m                       

                       Computation: 736891 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 859.15
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.2474
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 0.13s
                      Time elapsed: 00:09:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 487/1 [0m                       

                       Computation: 654445 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 849.59
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.4094
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7568
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 0.15s
                      Time elapsed: 00:09:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 488/1 [0m                       

                       Computation: 476871 steps/s (collection: 0.045s, learning 0.161s)
                       Mean reward: 840.01
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9723
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7508
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 0.21s
                      Time elapsed: 00:09:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 489/1 [0m                       

                       Computation: 524099 steps/s (collection: 0.052s, learning 0.136s)
                       Mean reward: 858.00
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.8983
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 0.19s
                      Time elapsed: 00:09:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 490/1 [0m                       

                       Computation: 526827 steps/s (collection: 0.050s, learning 0.136s)
                       Mean reward: 856.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.9523
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 97.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 0.19s
                      Time elapsed: 00:09:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 491/1 [0m                       

                       Computation: 432610 steps/s (collection: 0.047s, learning 0.181s)
                       Mean reward: 787.21
               Mean episode length: 245.92
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 156.0328
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7195
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 0.23s
                      Time elapsed: 00:09:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 492/1 [0m                       

                       Computation: 736822 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 864.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.1800
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7787
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 0.13s
                      Time elapsed: 00:09:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 493/1 [0m                       

                       Computation: 599749 steps/s (collection: 0.050s, learning 0.114s)
                       Mean reward: 843.76
               Mean episode length: 245.93
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.0624
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7513
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 0.16s
                      Time elapsed: 00:09:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 494/1 [0m                       

                       Computation: 564479 steps/s (collection: 0.040s, learning 0.135s)
                       Mean reward: 848.21
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.1029
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 0.17s
                      Time elapsed: 00:09:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 495/1 [0m                       

                       Computation: 512840 steps/s (collection: 0.055s, learning 0.137s)
                       Mean reward: 859.29
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.8719
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 0.19s
                      Time elapsed: 00:09:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 496/1 [0m                       

                       Computation: 645930 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 845.47
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.3181
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 0.15s
                      Time elapsed: 00:09:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 497/1 [0m                       

                       Computation: 619213 steps/s (collection: 0.054s, learning 0.105s)
                       Mean reward: 855.60
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.7295
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7598
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 0.16s
                      Time elapsed: 00:09:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 498/1 [0m                       

                       Computation: 598959 steps/s (collection: 0.041s, learning 0.124s)
                       Mean reward: 855.40
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.9668
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 0.16s
                      Time elapsed: 00:09:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 499/1 [0m                       

                       Computation: 679187 steps/s (collection: 0.045s, learning 0.100s)
                       Mean reward: 852.75
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.0183
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7629
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 0.14s
                      Time elapsed: 00:09:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 500/1 [0m                       

                       Computation: 591482 steps/s (collection: 0.050s, learning 0.117s)
                       Mean reward: 868.81
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.2756
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 99.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 0.17s
                      Time elapsed: 00:09:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 501/1 [0m                       

                       Computation: 618030 steps/s (collection: 0.041s, learning 0.118s)
                       Mean reward: 845.31
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.1344
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 0.16s
                      Time elapsed: 00:09:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 502/1 [0m                       

                       Computation: 694285 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 842.62
               Mean episode length: 242.33
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.3214
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7605
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 0.14s
                      Time elapsed: 00:09:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 503/1 [0m                       

                       Computation: 509664 steps/s (collection: 0.056s, learning 0.137s)
                       Mean reward: 855.91
               Mean episode length: 246.52
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.0197
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7581
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 0.19s
                      Time elapsed: 00:09:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 504/1 [0m                       

                       Computation: 641695 steps/s (collection: 0.041s, learning 0.113s)
                       Mean reward: 852.48
               Mean episode length: 246.17
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.8818
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 0.15s
                      Time elapsed: 00:09:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 505/1 [0m                       

                       Computation: 548465 steps/s (collection: 0.043s, learning 0.137s)
                       Mean reward: 862.25
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.9041
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 0.18s
                      Time elapsed: 00:09:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 506/1 [0m                       

                       Computation: 689729 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 856.83
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.7996
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 0.14s
                      Time elapsed: 00:09:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 507/1 [0m                       

                       Computation: 533732 steps/s (collection: 0.046s, learning 0.138s)
                       Mean reward: 852.59
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.0145
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 0.18s
                      Time elapsed: 00:09:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 508/1 [0m                       

                       Computation: 758692 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 858.68
               Mean episode length: 247.28
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.1372
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 0.13s
                      Time elapsed: 00:09:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 509/1 [0m                       

                       Computation: 551196 steps/s (collection: 0.063s, learning 0.116s)
                       Mean reward: 850.11
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.3123
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 0.18s
                      Time elapsed: 00:09:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 510/1 [0m                       

                       Computation: 706043 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 854.08
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.5769
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.7538
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 0.14s
                      Time elapsed: 00:09:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 511/1 [0m                       

                       Computation: 506161 steps/s (collection: 0.045s, learning 0.149s)
                       Mean reward: 856.53
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.9215
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 95.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 0.19s
                      Time elapsed: 00:10:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 512/1 [0m                       

                       Computation: 727575 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 852.17
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.7400
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7597
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 0.14s
                      Time elapsed: 00:10:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 513/1 [0m                       

                       Computation: 711720 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 815.57
               Mean episode length: 240.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 162.8447
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7262
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 0.14s
                      Time elapsed: 00:10:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 514/1 [0m                       

                       Computation: 694318 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 839.80
               Mean episode length: 246.30
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.0779
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7357
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 0.14s
                      Time elapsed: 00:10:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 515/1 [0m                       

                       Computation: 634734 steps/s (collection: 0.037s, learning 0.117s)
                       Mean reward: 854.06
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.7513
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 0.15s
                      Time elapsed: 00:10:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 516/1 [0m                       

                       Computation: 608840 steps/s (collection: 0.047s, learning 0.115s)
                       Mean reward: 838.30
               Mean episode length: 245.34
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.5577
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7397
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 0.16s
                      Time elapsed: 00:10:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 517/1 [0m                       

                       Computation: 571413 steps/s (collection: 0.041s, learning 0.131s)
                       Mean reward: 851.86
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.7516
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 0.17s
                      Time elapsed: 00:10:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 518/1 [0m                       

                       Computation: 427877 steps/s (collection: 0.055s, learning 0.175s)
                       Mean reward: 845.69
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.8857
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7575
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 0.23s
                      Time elapsed: 00:10:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 519/1 [0m                       

                       Computation: 522663 steps/s (collection: 0.055s, learning 0.133s)
                       Mean reward: 828.19
               Mean episode length: 243.97
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.4815
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7223
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 0.19s
                      Time elapsed: 00:10:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 520/1 [0m                       

                       Computation: 767931 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 841.85
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.2812
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7404
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 0.13s
                      Time elapsed: 00:10:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 521/1 [0m                       

                       Computation: 661982 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 837.94
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.0181
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7340
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 96.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 0.15s
                      Time elapsed: 00:10:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 522/1 [0m                       

                       Computation: 798181 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 839.43
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.2217
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7120
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 0.12s
                      Time elapsed: 00:10:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 523/1 [0m                       

                       Computation: 473560 steps/s (collection: 0.049s, learning 0.159s)
                       Mean reward: 842.03
               Mean episode length: 245.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.6881
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7379
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 0.21s
                      Time elapsed: 00:10:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 524/1 [0m                       

                       Computation: 648635 steps/s (collection: 0.049s, learning 0.103s)
                       Mean reward: 834.27
               Mean episode length: 247.36
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.8602
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7422
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 0.15s
                      Time elapsed: 00:10:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 525/1 [0m                       

                       Computation: 537497 steps/s (collection: 0.042s, learning 0.141s)
                       Mean reward: 843.44
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.5264
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7467
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 0.18s
                      Time elapsed: 00:10:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 526/1 [0m                       

                       Computation: 579624 steps/s (collection: 0.046s, learning 0.124s)
                       Mean reward: 839.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.4699
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 0.17s
                      Time elapsed: 00:10:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 527/1 [0m                       

                       Computation: 499026 steps/s (collection: 0.042s, learning 0.155s)
                       Mean reward: 834.65
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.1234
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 0.20s
                      Time elapsed: 00:10:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 528/1 [0m                       

                       Computation: 527421 steps/s (collection: 0.058s, learning 0.129s)
                       Mean reward: 860.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6355
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7687
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 0.19s
                      Time elapsed: 00:10:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 529/1 [0m                       

                       Computation: 482269 steps/s (collection: 0.059s, learning 0.145s)
                       Mean reward: 833.55
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.5626
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7443
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 0.20s
                      Time elapsed: 00:10:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 530/1 [0m                       

                       Computation: 485890 steps/s (collection: 0.054s, learning 0.148s)
                       Mean reward: 857.11
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.3945
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 0.20s
                      Time elapsed: 00:10:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 531/1 [0m                       

                       Computation: 445100 steps/s (collection: 0.050s, learning 0.171s)
                       Mean reward: 849.76
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.3976
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 0.22s
                      Time elapsed: 00:10:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 532/1 [0m                       

                       Computation: 545916 steps/s (collection: 0.062s, learning 0.119s)
                       Mean reward: 854.17
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9043
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7754
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 93.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 0.18s
                      Time elapsed: 00:10:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 533/1 [0m                       

                       Computation: 558473 steps/s (collection: 0.061s, learning 0.116s)
                       Mean reward: 818.73
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.2500
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7354
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 0.18s
                      Time elapsed: 00:10:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 534/1 [0m                       

                       Computation: 517745 steps/s (collection: 0.044s, learning 0.146s)
                       Mean reward: 843.98
               Mean episode length: 247.57
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.7177
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7542
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 0.19s
                      Time elapsed: 00:10:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 535/1 [0m                       

                       Computation: 552192 steps/s (collection: 0.043s, learning 0.136s)
                       Mean reward: 827.81
               Mean episode length: 245.86
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.6418
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7455
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 0.18s
                      Time elapsed: 00:10:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 536/1 [0m                       

                       Computation: 427341 steps/s (collection: 0.067s, learning 0.163s)
                       Mean reward: 842.51
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.9351
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 0.23s
                      Time elapsed: 00:10:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 537/1 [0m                       

                       Computation: 553173 steps/s (collection: 0.043s, learning 0.134s)
                       Mean reward: 842.85
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.1756
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 0.18s
                      Time elapsed: 00:10:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 538/1 [0m                       

                       Computation: 413759 steps/s (collection: 0.067s, learning 0.171s)
                       Mean reward: 859.40
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.2173
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7709
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 0.24s
                      Time elapsed: 00:10:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 539/1 [0m                       

                       Computation: 606691 steps/s (collection: 0.046s, learning 0.117s)
                       Mean reward: 847.64
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1021
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7737
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 0.16s
                      Time elapsed: 00:10:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 540/1 [0m                       

                       Computation: 478090 steps/s (collection: 0.045s, learning 0.161s)
                       Mean reward: 865.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.3585
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 0.21s
                      Time elapsed: 00:10:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 541/1 [0m                       

                       Computation: 506765 steps/s (collection: 0.055s, learning 0.139s)
                       Mean reward: 858.28
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.9603
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 0.19s
                      Time elapsed: 00:10:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 542/1 [0m                       

                       Computation: 640178 steps/s (collection: 0.046s, learning 0.108s)
                       Mean reward: 860.37
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.2424
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7770
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 94.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 0.15s
                      Time elapsed: 00:10:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 543/1 [0m                       

                       Computation: 523349 steps/s (collection: 0.049s, learning 0.139s)
                       Mean reward: 850.12
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.8567
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 0.19s
                      Time elapsed: 00:10:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 544/1 [0m                       

                       Computation: 640275 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 844.47
               Mean episode length: 244.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.9085
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7445
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 0.15s
                      Time elapsed: 00:10:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 545/1 [0m                       

                       Computation: 659665 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 846.23
               Mean episode length: 245.09
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.3872
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 0.15s
                      Time elapsed: 00:10:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 546/1 [0m                       

                       Computation: 600854 steps/s (collection: 0.050s, learning 0.114s)
                       Mean reward: 841.98
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.3338
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7566
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 0.16s
                      Time elapsed: 00:10:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 547/1 [0m                       

                       Computation: 603235 steps/s (collection: 0.048s, learning 0.115s)
                       Mean reward: 836.93
               Mean episode length: 246.55
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.0102
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7563
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 0.16s
                      Time elapsed: 00:10:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 548/1 [0m                       

                       Computation: 709479 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 854.12
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1743
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 0.14s
                      Time elapsed: 00:10:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 549/1 [0m                       

                       Computation: 630034 steps/s (collection: 0.048s, learning 0.109s)
                       Mean reward: 851.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.6969
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 0.16s
                      Time elapsed: 00:10:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 550/1 [0m                       

                       Computation: 852695 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 860.04
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.6531
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 0.12s
                      Time elapsed: 00:10:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 551/1 [0m                       

                       Computation: 492328 steps/s (collection: 0.041s, learning 0.159s)
                       Mean reward: 861.11
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.5654
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 0.20s
                      Time elapsed: 00:10:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 552/1 [0m                       

                       Computation: 772554 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 859.37
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.3245
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 0.13s
                      Time elapsed: 00:10:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 553/1 [0m                       

                       Computation: 734779 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 859.85
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.3829
       Episode_Reward/object_height 0.0123
     Episode_Reward/reaching_object 0.7527
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 91.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 0.13s
                      Time elapsed: 00:10:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 554/1 [0m                       

                       Computation: 571206 steps/s (collection: 0.046s, learning 0.126s)
                       Mean reward: 842.24
               Mean episode length: 245.27
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.6130
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7508
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 0.17s
                      Time elapsed: 00:10:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 555/1 [0m                       

                       Computation: 576426 steps/s (collection: 0.050s, learning 0.121s)
                       Mean reward: 851.41
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.0093
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 0.17s
                      Time elapsed: 00:10:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 556/1 [0m                       

                       Computation: 395053 steps/s (collection: 0.072s, learning 0.177s)
                       Mean reward: 828.17
               Mean episode length: 244.98
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.0213
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.7468
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 0.25s
                      Time elapsed: 00:10:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 557/1 [0m                       

                       Computation: 680496 steps/s (collection: 0.037s, learning 0.107s)
                       Mean reward: 847.67
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.5190
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 0.14s
                      Time elapsed: 00:10:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 558/1 [0m                       

                       Computation: 679591 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 839.65
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.6205
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7586
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 0.14s
                      Time elapsed: 00:10:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 559/1 [0m                       

                       Computation: 662859 steps/s (collection: 0.038s, learning 0.110s)
                       Mean reward: 843.86
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.2917
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7576
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 0.15s
                      Time elapsed: 00:11:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 560/1 [0m                       

                       Computation: 765811 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 849.25
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.0133
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7570
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 0.13s
                      Time elapsed: 00:11:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 561/1 [0m                       

                       Computation: 633857 steps/s (collection: 0.041s, learning 0.115s)
                       Mean reward: 846.14
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.7020
       Episode_Reward/object_height 0.0182
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 0.16s
                      Time elapsed: 00:11:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 562/1 [0m                       

                       Computation: 797146 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 844.76
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.0272
       Episode_Reward/object_height 0.0178
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 0.12s
                      Time elapsed: 00:11:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 563/1 [0m                       

                       Computation: 815156 steps/s (collection: 0.033s, learning 0.088s)
                       Mean reward: 848.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.4397
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 92.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 0.12s
                      Time elapsed: 00:11:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 564/1 [0m                       

                       Computation: 638963 steps/s (collection: 0.039s, learning 0.115s)
                       Mean reward: 868.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.9150
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 0.15s
                      Time elapsed: 00:11:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 565/1 [0m                       

                       Computation: 455597 steps/s (collection: 0.041s, learning 0.175s)
                       Mean reward: 835.77
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 159.1550
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7211
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 0.22s
                      Time elapsed: 00:11:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 566/1 [0m                       

                       Computation: 705694 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 825.30
               Mean episode length: 244.46
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.4295
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7448
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 0.14s
                      Time elapsed: 00:11:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 567/1 [0m                       

                       Computation: 396992 steps/s (collection: 0.039s, learning 0.209s)
                       Mean reward: 841.70
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.4512
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7545
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 0.25s
                      Time elapsed: 00:11:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 568/1 [0m                       

                       Computation: 795778 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 847.88
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.2718
       Episode_Reward/object_height 0.0164
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 0.12s
                      Time elapsed: 00:11:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 569/1 [0m                       

                       Computation: 784616 steps/s (collection: 0.045s, learning 0.081s)
                       Mean reward: 858.52
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.9986
       Episode_Reward/object_height 0.0156
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 0.13s
                      Time elapsed: 00:11:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 570/1 [0m                       

                       Computation: 852382 steps/s (collection: 0.037s, learning 0.078s)
                       Mean reward: 866.94
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.7646
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7838
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 0.12s
                      Time elapsed: 00:11:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 571/1 [0m                       

                       Computation: 841219 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 856.60
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.1696
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7653
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 0.12s
                      Time elapsed: 00:11:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 572/1 [0m                       

                       Computation: 441752 steps/s (collection: 0.042s, learning 0.181s)
                       Mean reward: 866.21
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4933
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7825
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 0.22s
                      Time elapsed: 00:11:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 573/1 [0m                       

                       Computation: 786853 steps/s (collection: 0.033s, learning 0.092s)
                       Mean reward: 850.70
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.2987
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 93.8333
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 0.12s
                      Time elapsed: 00:11:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 574/1 [0m                       

                       Computation: 819142 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 843.64
               Mean episode length: 246.94
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5700
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 0.12s
                      Time elapsed: 00:11:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 575/1 [0m                       

                       Computation: 842549 steps/s (collection: 0.034s, learning 0.083s)
                       Mean reward: 837.58
               Mean episode length: 246.95
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.4405
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7531
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 0.12s
                      Time elapsed: 00:11:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 576/1 [0m                       

                       Computation: 875868 steps/s (collection: 0.034s, learning 0.078s)
                       Mean reward: 848.80
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.4403
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 0.11s
                      Time elapsed: 00:11:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 577/1 [0m                       

                       Computation: 819893 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 857.08
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.7345
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7788
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 0.12s
                      Time elapsed: 00:11:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 578/1 [0m                       

                       Computation: 811367 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 849.78
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.1014
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7754
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 0.12s
                      Time elapsed: 00:11:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 579/1 [0m                       

                       Computation: 849148 steps/s (collection: 0.033s, learning 0.083s)
                       Mean reward: 849.04
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8594
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 0.12s
                      Time elapsed: 00:11:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 580/1 [0m                       

                       Computation: 518226 steps/s (collection: 0.034s, learning 0.156s)
                       Mean reward: 860.78
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1508
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 0.19s
                      Time elapsed: 00:11:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 581/1 [0m                       

                       Computation: 754673 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 848.30
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.7675
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7733
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 0.13s
                      Time elapsed: 00:11:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 582/1 [0m                       

                       Computation: 719820 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 858.10
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.8152
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 0.14s
                      Time elapsed: 00:11:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 583/1 [0m                       

                       Computation: 648724 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 858.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.3749
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7751
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 0.15s
                      Time elapsed: 00:11:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 584/1 [0m                       

                       Computation: 694682 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 859.65
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9229
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 90.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 0.14s
                      Time elapsed: 00:11:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 585/1 [0m                       

                       Computation: 522726 steps/s (collection: 0.060s, learning 0.128s)
                       Mean reward: 857.21
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.2739
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 0.19s
                      Time elapsed: 00:11:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 586/1 [0m                       

                       Computation: 700660 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 847.01
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.8093
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 0.14s
                      Time elapsed: 00:11:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 587/1 [0m                       

                       Computation: 481084 steps/s (collection: 0.040s, learning 0.164s)
                       Mean reward: 864.45
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.6611
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7790
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 0.20s
                      Time elapsed: 00:11:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 588/1 [0m                       

                       Computation: 556818 steps/s (collection: 0.042s, learning 0.135s)
                       Mean reward: 858.86
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6594
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 0.18s
                      Time elapsed: 00:11:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 589/1 [0m                       

                       Computation: 762149 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 841.41
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.0241
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 0.13s
                      Time elapsed: 00:11:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 590/1 [0m                       

                       Computation: 802778 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 843.55
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.3502
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 0.12s
                      Time elapsed: 00:11:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 591/1 [0m                       

                       Computation: 753119 steps/s (collection: 0.034s, learning 0.097s)
                       Mean reward: 849.78
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.5263
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7740
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 0.13s
                      Time elapsed: 00:11:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 592/1 [0m                       

                       Computation: 671424 steps/s (collection: 0.038s, learning 0.109s)
                       Mean reward: 851.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5362
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 0.15s
                      Time elapsed: 00:11:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 593/1 [0m                       

                       Computation: 921835 steps/s (collection: 0.033s, learning 0.073s)
                       Mean reward: 851.96
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.9075
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7775
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 0.11s
                      Time elapsed: 00:11:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 594/1 [0m                       

                       Computation: 820570 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 854.92
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5005
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7799
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 92.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 0.12s
                      Time elapsed: 00:11:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 595/1 [0m                       

                       Computation: 606449 steps/s (collection: 0.036s, learning 0.126s)
                       Mean reward: 825.39
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.4044
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7330
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 0.16s
                      Time elapsed: 00:11:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 596/1 [0m                       

                       Computation: 829249 steps/s (collection: 0.043s, learning 0.076s)
                       Mean reward: 834.08
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.7678
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 0.12s
                      Time elapsed: 00:11:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 597/1 [0m                       

                       Computation: 652657 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 852.97
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.3051
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7608
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 0.15s
                      Time elapsed: 00:11:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 598/1 [0m                       

                       Computation: 686358 steps/s (collection: 0.039s, learning 0.104s)
                       Mean reward: 853.01
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.4313
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 0.14s
                      Time elapsed: 00:11:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 599/1 [0m                       

                       Computation: 508317 steps/s (collection: 0.042s, learning 0.151s)
                       Mean reward: 859.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.3746
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 0.19s
                      Time elapsed: 00:11:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 600/1 [0m                       

                       Computation: 463112 steps/s (collection: 0.050s, learning 0.163s)
                       Mean reward: 858.34
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7291
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7791
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 0.21s
                      Time elapsed: 00:11:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 601/1 [0m                       

                       Computation: 654775 steps/s (collection: 0.037s, learning 0.113s)
                       Mean reward: 858.25
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.0430
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7754
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 0.15s
                      Time elapsed: 00:11:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 602/1 [0m                       

                       Computation: 705174 steps/s (collection: 0.036s, learning 0.103s)
                       Mean reward: 859.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8442
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 0.14s
                      Time elapsed: 00:11:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 603/1 [0m                       

                       Computation: 578367 steps/s (collection: 0.034s, learning 0.136s)
                       Mean reward: 863.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4368
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7758
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 0.17s
                      Time elapsed: 00:11:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 604/1 [0m                       

                       Computation: 895663 steps/s (collection: 0.033s, learning 0.077s)
                       Mean reward: 855.32
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.7516
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 0.11s
                      Time elapsed: 00:11:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 605/1 [0m                       

                       Computation: 884786 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 858.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.1736
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7945
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 89.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 0.11s
                      Time elapsed: 00:11:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 606/1 [0m                       

                       Computation: 712238 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 858.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6222
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7836
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 0.14s
                      Time elapsed: 00:11:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 607/1 [0m                       

                       Computation: 927083 steps/s (collection: 0.037s, learning 0.070s)
                       Mean reward: 847.02
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.0752
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 0.11s
                      Time elapsed: 00:11:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 608/1 [0m                       

                       Computation: 721416 steps/s (collection: 0.033s, learning 0.103s)
                       Mean reward: 854.23
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.7283
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 0.14s
                      Time elapsed: 00:11:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 609/1 [0m                       

                       Computation: 585400 steps/s (collection: 0.040s, learning 0.128s)
                       Mean reward: 854.04
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8360
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 0.17s
                      Time elapsed: 00:11:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 610/1 [0m                       

                       Computation: 801956 steps/s (collection: 0.033s, learning 0.089s)
                       Mean reward: 855.70
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.9610
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 0.12s
                      Time elapsed: 00:11:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 611/1 [0m                       

                       Computation: 810865 steps/s (collection: 0.045s, learning 0.077s)
                       Mean reward: 860.71
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9871
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 0.12s
                      Time elapsed: 00:11:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 612/1 [0m                       

                       Computation: 774826 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 849.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.0748
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 0.13s
                      Time elapsed: 00:11:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 613/1 [0m                       

                       Computation: 716604 steps/s (collection: 0.034s, learning 0.104s)
                       Mean reward: 861.33
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5978
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7758
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 0.14s
                      Time elapsed: 00:11:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 614/1 [0m                       

                       Computation: 639203 steps/s (collection: 0.048s, learning 0.106s)
                       Mean reward: 868.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.9355
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 0.15s
                      Time elapsed: 00:11:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 615/1 [0m                       

                       Computation: 802591 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 861.79
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.3171
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7662
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 90.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 0.12s
                      Time elapsed: 00:12:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 616/1 [0m                       

                       Computation: 625157 steps/s (collection: 0.054s, learning 0.103s)
                       Mean reward: 833.38
               Mean episode length: 247.23
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.4154
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 0.16s
                      Time elapsed: 00:12:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 617/1 [0m                       

                       Computation: 822126 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 854.70
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.6377
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 0.12s
                      Time elapsed: 00:12:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 618/1 [0m                       

                       Computation: 498052 steps/s (collection: 0.051s, learning 0.147s)
                       Mean reward: 856.33
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.3053
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 0.20s
                      Time elapsed: 00:12:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 619/1 [0m                       

                       Computation: 535521 steps/s (collection: 0.051s, learning 0.133s)
                       Mean reward: 856.82
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.3697
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 0.18s
                      Time elapsed: 00:12:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 620/1 [0m                       

                       Computation: 646559 steps/s (collection: 0.050s, learning 0.102s)
                       Mean reward: 858.10
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.4856
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 0.15s
                      Time elapsed: 00:12:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 621/1 [0m                       

                       Computation: 743312 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 868.20
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6135
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 0.13s
                      Time elapsed: 00:12:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 622/1 [0m                       

                       Computation: 803603 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 852.71
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.3798
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 0.12s
                      Time elapsed: 00:12:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 623/1 [0m                       

                       Computation: 727244 steps/s (collection: 0.035s, learning 0.100s)
                       Mean reward: 866.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6287
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7904
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 0.14s
                      Time elapsed: 00:12:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 624/1 [0m                       

                       Computation: 513346 steps/s (collection: 0.044s, learning 0.147s)
                       Mean reward: 838.37
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.8966
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 0.19s
                      Time elapsed: 00:12:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 625/1 [0m                       

                       Computation: 723093 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 840.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.9939
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 93.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 0.14s
                      Time elapsed: 00:12:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 626/1 [0m                       

                       Computation: 657155 steps/s (collection: 0.047s, learning 0.103s)
                       Mean reward: 852.31
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.6441
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 0.15s
                      Time elapsed: 00:12:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 627/1 [0m                       

                       Computation: 461451 steps/s (collection: 0.075s, learning 0.139s)
                       Mean reward: 810.57
               Mean episode length: 245.28
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.5308
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7475
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 0.21s
                      Time elapsed: 00:12:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 628/1 [0m                       

                       Computation: 373001 steps/s (collection: 0.061s, learning 0.203s)
                       Mean reward: 813.38
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.8353
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7436
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 0.26s
                      Time elapsed: 00:12:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 629/1 [0m                       

                       Computation: 710718 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 829.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.9004
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 0.14s
                      Time elapsed: 00:12:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 630/1 [0m                       

                       Computation: 600410 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 838.32
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.5877
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 0.16s
                      Time elapsed: 00:12:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 631/1 [0m                       

                       Computation: 727580 steps/s (collection: 0.036s, learning 0.099s)
                       Mean reward: 844.31
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.4359
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7632
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 0.14s
                      Time elapsed: 00:12:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 632/1 [0m                       

                       Computation: 648499 steps/s (collection: 0.038s, learning 0.114s)
                       Mean reward: 840.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.5389
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 0.15s
                      Time elapsed: 00:12:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 633/1 [0m                       

                       Computation: 638381 steps/s (collection: 0.037s, learning 0.117s)
                       Mean reward: 844.83
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.4232
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 0.15s
                      Time elapsed: 00:12:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 634/1 [0m                       

                       Computation: 498137 steps/s (collection: 0.049s, learning 0.148s)
                       Mean reward: 852.39
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.3978
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 0.20s
                      Time elapsed: 00:12:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 635/1 [0m                       

                       Computation: 699539 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 860.77
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.3410
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 0.14s
                      Time elapsed: 00:12:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 636/1 [0m                       

                       Computation: 702440 steps/s (collection: 0.035s, learning 0.105s)
                       Mean reward: 850.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.3071
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7705
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 89.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 0.14s
                      Time elapsed: 00:12:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 637/1 [0m                       

                       Computation: 506077 steps/s (collection: 0.058s, learning 0.137s)
                       Mean reward: 853.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.6364
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7799
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 0.19s
                      Time elapsed: 00:12:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 638/1 [0m                       

                       Computation: 375074 steps/s (collection: 0.086s, learning 0.176s)
                       Mean reward: 852.65
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.3235
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 0.26s
                      Time elapsed: 00:12:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 639/1 [0m                       

                       Computation: 548818 steps/s (collection: 0.046s, learning 0.134s)
                       Mean reward: 854.01
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1272
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 0.18s
                      Time elapsed: 00:12:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 640/1 [0m                       

                       Computation: 471175 steps/s (collection: 0.051s, learning 0.157s)
                       Mean reward: 847.83
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.1082
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 0.21s
                      Time elapsed: 00:12:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 641/1 [0m                       

                       Computation: 863773 steps/s (collection: 0.033s, learning 0.081s)
                       Mean reward: 840.77
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.8498
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7673
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 0.11s
                      Time elapsed: 00:12:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 642/1 [0m                       

                       Computation: 862215 steps/s (collection: 0.034s, learning 0.081s)
                       Mean reward: 859.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9291
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7736
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 0.11s
                      Time elapsed: 00:12:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 643/1 [0m                       

                       Computation: 534972 steps/s (collection: 0.056s, learning 0.128s)
                       Mean reward: 853.73
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1408
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7605
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 0.18s
                      Time elapsed: 00:12:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 644/1 [0m                       

                       Computation: 453984 steps/s (collection: 0.056s, learning 0.161s)
                       Mean reward: 857.91
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.2611
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 0.22s
                      Time elapsed: 00:12:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 645/1 [0m                       

                       Computation: 640417 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 853.44
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8147
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 0.15s
                      Time elapsed: 00:12:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 646/1 [0m                       

                       Computation: 717755 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 860.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5515
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 91.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 0.14s
                      Time elapsed: 00:12:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 647/1 [0m                       

                       Computation: 585870 steps/s (collection: 0.045s, learning 0.123s)
                       Mean reward: 859.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1020
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7689
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 0.17s
                      Time elapsed: 00:12:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 648/1 [0m                       

                       Computation: 831330 steps/s (collection: 0.034s, learning 0.084s)
                       Mean reward: 856.05
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.2291
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7673
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 0.12s
                      Time elapsed: 00:12:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 649/1 [0m                       

                       Computation: 724318 steps/s (collection: 0.035s, learning 0.101s)
                       Mean reward: 856.52
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0599
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 0.14s
                      Time elapsed: 00:12:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 650/1 [0m                       

                       Computation: 800243 steps/s (collection: 0.034s, learning 0.088s)
                       Mean reward: 848.31
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.5545
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7556
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 0.12s
                      Time elapsed: 00:12:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 651/1 [0m                       

                       Computation: 687118 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 850.83
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.1992
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 0.14s
                      Time elapsed: 00:12:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 652/1 [0m                       

                       Computation: 798716 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 836.74
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.8003
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7530
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 0.12s
                      Time elapsed: 00:12:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 653/1 [0m                       

                       Computation: 815829 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 851.44
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.3322
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 0.12s
                      Time elapsed: 00:12:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 654/1 [0m                       

                       Computation: 753190 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 839.31
               Mean episode length: 246.69
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.3266
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7599
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 0.13s
                      Time elapsed: 00:12:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 655/1 [0m                       

                       Computation: 777044 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 837.96
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.2716
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 0.13s
                      Time elapsed: 00:12:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 656/1 [0m                       

                       Computation: 764862 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 852.07
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.3935
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7599
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 0.13s
                      Time elapsed: 00:12:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 657/1 [0m                       

                       Computation: 572420 steps/s (collection: 0.042s, learning 0.130s)
                       Mean reward: 843.68
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.6705
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7319
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 87.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 0.17s
                      Time elapsed: 00:12:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 658/1 [0m                       

                       Computation: 825409 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 828.44
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 157.1614
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7155
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 0.12s
                      Time elapsed: 00:12:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 659/1 [0m                       

                       Computation: 842713 steps/s (collection: 0.034s, learning 0.083s)
                       Mean reward: 834.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.4362
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 0.12s
                      Time elapsed: 00:12:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 660/1 [0m                       

                       Computation: 804137 steps/s (collection: 0.035s, learning 0.087s)
                       Mean reward: 845.86
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.1524
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7517
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 0.12s
                      Time elapsed: 00:12:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 661/1 [0m                       

                       Computation: 811259 steps/s (collection: 0.034s, learning 0.087s)
                       Mean reward: 846.80
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.3223
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 0.12s
                      Time elapsed: 00:12:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 662/1 [0m                       

                       Computation: 818509 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 835.12
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.6797
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7487
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 0.12s
                      Time elapsed: 00:12:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 663/1 [0m                       

                       Computation: 875085 steps/s (collection: 0.035s, learning 0.077s)
                       Mean reward: 860.69
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8758
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 0.11s
                      Time elapsed: 00:12:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 664/1 [0m                       

                       Computation: 781468 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 851.14
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.4751
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7616
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 0.13s
                      Time elapsed: 00:12:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 665/1 [0m                       

                       Computation: 764635 steps/s (collection: 0.035s, learning 0.094s)
                       Mean reward: 853.52
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0144
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 0.13s
                      Time elapsed: 00:12:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 666/1 [0m                       

                       Computation: 767232 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 860.03
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4839
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7757
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 0.13s
                      Time elapsed: 00:12:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 667/1 [0m                       

                       Computation: 616602 steps/s (collection: 0.043s, learning 0.116s)
                       Mean reward: 860.46
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.8659
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 88.3750
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 0.16s
                      Time elapsed: 00:12:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 668/1 [0m                       

                       Computation: 573406 steps/s (collection: 0.043s, learning 0.128s)
                       Mean reward: 846.35
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.5112
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7609
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 0.17s
                      Time elapsed: 00:13:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 669/1 [0m                       

                       Computation: 741845 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 873.76
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.2296
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7865
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 0.13s
                      Time elapsed: 00:13:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 670/1 [0m                       

                       Computation: 771432 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 866.06
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7399
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 0.13s
                      Time elapsed: 00:13:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 671/1 [0m                       

                       Computation: 851041 steps/s (collection: 0.034s, learning 0.082s)
                       Mean reward: 859.90
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1511
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 0.12s
                      Time elapsed: 00:13:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 672/1 [0m                       

                       Computation: 747423 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 861.58
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.7337
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7643
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 0.13s
                      Time elapsed: 00:13:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 673/1 [0m                       

                       Computation: 725249 steps/s (collection: 0.035s, learning 0.101s)
                       Mean reward: 846.74
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.4564
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7575
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 0.14s
                      Time elapsed: 00:13:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 674/1 [0m                       

                       Computation: 636014 steps/s (collection: 0.036s, learning 0.118s)
                       Mean reward: 852.07
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0370
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 0.15s
                      Time elapsed: 00:13:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 675/1 [0m                       

                       Computation: 836468 steps/s (collection: 0.038s, learning 0.080s)
                       Mean reward: 860.76
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.9054
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 0.12s
                      Time elapsed: 00:13:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 676/1 [0m                       

                       Computation: 532645 steps/s (collection: 0.050s, learning 0.135s)
                       Mean reward: 847.32
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.7669
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 0.18s
                      Time elapsed: 00:13:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 677/1 [0m                       

                       Computation: 545999 steps/s (collection: 0.049s, learning 0.131s)
                       Mean reward: 840.94
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.7116
       Episode_Reward/object_height 0.0120
     Episode_Reward/reaching_object 0.7578
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 0.18s
                      Time elapsed: 00:13:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 678/1 [0m                       

                       Computation: 544401 steps/s (collection: 0.046s, learning 0.135s)
                       Mean reward: 868.31
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.4072
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 85.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 0.18s
                      Time elapsed: 00:13:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 679/1 [0m                       

                       Computation: 532895 steps/s (collection: 0.055s, learning 0.129s)
                       Mean reward: 867.10
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.1727
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 0.18s
                      Time elapsed: 00:13:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 680/1 [0m                       

                       Computation: 630363 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 853.75
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.6561
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 0.16s
                      Time elapsed: 00:13:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 681/1 [0m                       

                       Computation: 406535 steps/s (collection: 0.049s, learning 0.193s)
                       Mean reward: 841.66
               Mean episode length: 245.77
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.3555
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 0.24s
                      Time elapsed: 00:13:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 682/1 [0m                       

                       Computation: 687308 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 862.79
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.0933
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 0.14s
                      Time elapsed: 00:13:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 683/1 [0m                       

                       Computation: 525533 steps/s (collection: 0.046s, learning 0.142s)
                       Mean reward: 852.31
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.5312
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7530
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 0.19s
                      Time elapsed: 00:13:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 684/1 [0m                       

                       Computation: 627980 steps/s (collection: 0.038s, learning 0.119s)
                       Mean reward: 858.13
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.0714
       Episode_Reward/object_height 0.0148
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 0.16s
                      Time elapsed: 00:13:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 685/1 [0m                       

                       Computation: 694578 steps/s (collection: 0.037s, learning 0.105s)
                       Mean reward: 849.40
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.4357
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7679
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 0.14s
                      Time elapsed: 00:13:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 686/1 [0m                       

                       Computation: 870368 steps/s (collection: 0.035s, learning 0.078s)
                       Mean reward: 851.76
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.3137
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 0.11s
                      Time elapsed: 00:13:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 687/1 [0m                       

                       Computation: 877563 steps/s (collection: 0.035s, learning 0.077s)
                       Mean reward: 868.59
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.1428
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7781
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 0.11s
                      Time elapsed: 00:13:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 688/1 [0m                       

                       Computation: 775903 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 868.99
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 174.0959
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7930
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 85.7917
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 0.13s
                      Time elapsed: 00:13:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 689/1 [0m                       

                       Computation: 711173 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 865.14
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.4625
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 0.14s
                      Time elapsed: 00:13:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 690/1 [0m                       

                       Computation: 692449 steps/s (collection: 0.037s, learning 0.105s)
                       Mean reward: 851.29
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.6085
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 0.14s
                      Time elapsed: 00:13:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 691/1 [0m                       

                       Computation: 783190 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 849.07
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.4483
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 0.13s
                      Time elapsed: 00:13:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 692/1 [0m                       

                       Computation: 498784 steps/s (collection: 0.064s, learning 0.133s)
                       Mean reward: 856.52
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.9634
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 0.20s
                      Time elapsed: 00:13:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 693/1 [0m                       

                       Computation: 617020 steps/s (collection: 0.047s, learning 0.113s)
                       Mean reward: 861.34
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.1104
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 0.16s
                      Time elapsed: 00:13:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 694/1 [0m                       

                       Computation: 811348 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 876.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 174.5352
       Episode_Reward/object_height 0.0132
     Episode_Reward/reaching_object 0.7836
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 0.12s
                      Time elapsed: 00:13:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 695/1 [0m                       

                       Computation: 877294 steps/s (collection: 0.034s, learning 0.078s)
                       Mean reward: 868.10
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.1538
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 0.11s
                      Time elapsed: 00:13:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 696/1 [0m                       

                       Computation: 633591 steps/s (collection: 0.059s, learning 0.096s)
                       Mean reward: 865.84
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.4982
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 0.16s
                      Time elapsed: 00:13:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 697/1 [0m                       

                       Computation: 858331 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 860.05
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.0728
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 0.11s
                      Time elapsed: 00:13:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 698/1 [0m                       

                       Computation: 836778 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 862.98
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.1676
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 87.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 0.12s
                      Time elapsed: 00:13:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 699/1 [0m                       

                       Computation: 825923 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 873.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.2950
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7903
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 0.12s
                      Time elapsed: 00:13:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 700/1 [0m                       

                       Computation: 598836 steps/s (collection: 0.041s, learning 0.124s)
                       Mean reward: 869.46
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6783
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 0.16s
                      Time elapsed: 00:13:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 701/1 [0m                       

                       Computation: 545955 steps/s (collection: 0.046s, learning 0.134s)
                       Mean reward: 866.21
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7026
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 0.18s
                      Time elapsed: 00:13:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 702/1 [0m                       

                       Computation: 683924 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 863.73
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8924
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 0.14s
                      Time elapsed: 00:13:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 703/1 [0m                       

                       Computation: 528771 steps/s (collection: 0.044s, learning 0.142s)
                       Mean reward: 861.46
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.3443
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7592
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 0.19s
                      Time elapsed: 00:13:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 704/1 [0m                       

                       Computation: 749956 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 855.10
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8640
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 0.13s
                      Time elapsed: 00:13:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 705/1 [0m                       

                       Computation: 704601 steps/s (collection: 0.036s, learning 0.104s)
                       Mean reward: 862.04
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.2452
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7742
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 0.14s
                      Time elapsed: 00:13:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 706/1 [0m                       

                       Computation: 829678 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 876.58
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.7129
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 0.12s
                      Time elapsed: 00:13:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 707/1 [0m                       

                       Computation: 791534 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 861.91
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.2754
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 0.12s
                      Time elapsed: 00:13:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 708/1 [0m                       

                       Computation: 784298 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 871.33
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5021
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 0.13s
                      Time elapsed: 00:13:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 709/1 [0m                       

                       Computation: 788958 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 866.82
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.8455
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7571
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 84.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 0.12s
                      Time elapsed: 00:13:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 710/1 [0m                       

                       Computation: 666099 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 814.69
               Mean episode length: 246.72
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.8145
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7361
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 0.15s
                      Time elapsed: 00:13:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 711/1 [0m                       

                       Computation: 826833 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 860.72
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.5782
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 0.12s
                      Time elapsed: 00:13:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 712/1 [0m                       

                       Computation: 558660 steps/s (collection: 0.041s, learning 0.135s)
                       Mean reward: 854.70
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.6315
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7643
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 0.18s
                      Time elapsed: 00:13:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 713/1 [0m                       

                       Computation: 759802 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 850.13
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.6280
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 0.13s
                      Time elapsed: 00:13:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 714/1 [0m                       

                       Computation: 809248 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 860.27
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.2837
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 0.12s
                      Time elapsed: 00:13:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 715/1 [0m                       

                       Computation: 763682 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 861.10
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.1459
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 0.13s
                      Time elapsed: 00:13:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 716/1 [0m                       

                       Computation: 794838 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 860.37
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8179
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 0.12s
                      Time elapsed: 00:13:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 717/1 [0m                       

                       Computation: 818538 steps/s (collection: 0.034s, learning 0.086s)
                       Mean reward: 864.34
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.5747
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 0.12s
                      Time elapsed: 00:13:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 718/1 [0m                       

                       Computation: 615836 steps/s (collection: 0.036s, learning 0.123s)
                       Mean reward: 865.24
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0585
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 0.16s
                      Time elapsed: 00:13:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 719/1 [0m                       

                       Computation: 545262 steps/s (collection: 0.053s, learning 0.128s)
                       Mean reward: 862.49
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.6461
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 85.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 0.18s
                      Time elapsed: 00:13:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 720/1 [0m                       

                       Computation: 549136 steps/s (collection: 0.035s, learning 0.144s)
                       Mean reward: 855.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5483
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 0.18s
                      Time elapsed: 00:13:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 721/1 [0m                       

                       Computation: 769260 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 864.07
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4025
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7869
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 0.13s
                      Time elapsed: 00:14:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 722/1 [0m                       

                       Computation: 806640 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 871.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2967
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7851
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 0.12s
                      Time elapsed: 00:14:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 723/1 [0m                       

                       Computation: 764776 steps/s (collection: 0.035s, learning 0.093s)
                       Mean reward: 875.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4058
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7908
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 0.13s
                      Time elapsed: 00:14:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 724/1 [0m                       

                       Computation: 863644 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 871.31
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3605
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7840
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 0.11s
                      Time elapsed: 00:14:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 725/1 [0m                       

                       Computation: 686050 steps/s (collection: 0.035s, learning 0.108s)
                       Mean reward: 872.37
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5163
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7873
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 0.14s
                      Time elapsed: 00:14:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 726/1 [0m                       

                       Computation: 614790 steps/s (collection: 0.042s, learning 0.118s)
                       Mean reward: 862.04
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0651
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7778
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 0.16s
                      Time elapsed: 00:14:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 727/1 [0m                       

                       Computation: 698511 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 855.01
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2454
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 0.14s
                      Time elapsed: 00:14:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 728/1 [0m                       

                       Computation: 633455 steps/s (collection: 0.044s, learning 0.112s)
                       Mean reward: 869.21
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7592
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 0.16s
                      Time elapsed: 00:14:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 729/1 [0m                       

                       Computation: 468356 steps/s (collection: 0.050s, learning 0.160s)
                       Mean reward: 862.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.5286
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7833
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 0.21s
                      Time elapsed: 00:14:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 730/1 [0m                       

                       Computation: 856459 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 865.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.0285
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 82.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 0.11s
                      Time elapsed: 00:14:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 731/1 [0m                       

                       Computation: 793077 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 862.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.4671
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7810
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 0.12s
                      Time elapsed: 00:14:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 732/1 [0m                       

                       Computation: 786067 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 859.37
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6608
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7755
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 0.13s
                      Time elapsed: 00:14:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 733/1 [0m                       

                       Computation: 796422 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 863.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.3474
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 0.12s
                      Time elapsed: 00:14:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 734/1 [0m                       

                       Computation: 803276 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 859.23
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6490
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7727
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 0.12s
                      Time elapsed: 00:14:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 735/1 [0m                       

                       Computation: 783516 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 867.67
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9554
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7773
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 0.13s
                      Time elapsed: 00:14:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 736/1 [0m                       

                       Computation: 728673 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 858.11
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6506
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 0.13s
                      Time elapsed: 00:14:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 737/1 [0m                       

                       Computation: 743605 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 869.05
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.2611
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 0.13s
                      Time elapsed: 00:14:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 738/1 [0m                       

                       Computation: 729373 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 853.68
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.9184
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7478
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 0.13s
                      Time elapsed: 00:14:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 739/1 [0m                       

                       Computation: 648863 steps/s (collection: 0.042s, learning 0.109s)
                       Mean reward: 846.14
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.7582
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7536
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 0.15s
                      Time elapsed: 00:14:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 740/1 [0m                       

                       Computation: 751777 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 857.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.7656
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 84.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 0.13s
                      Time elapsed: 00:14:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 741/1 [0m                       

                       Computation: 571479 steps/s (collection: 0.038s, learning 0.134s)
                       Mean reward: 850.60
               Mean episode length: 246.45
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.0684
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7474
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 0.17s
                      Time elapsed: 00:14:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 742/1 [0m                       

                       Computation: 709596 steps/s (collection: 0.047s, learning 0.092s)
                       Mean reward: 835.84
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.2193
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7368
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 0.14s
                      Time elapsed: 00:14:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 743/1 [0m                       

                       Computation: 723981 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 855.56
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.3934
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7520
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 0.14s
                      Time elapsed: 00:14:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 744/1 [0m                       

                       Computation: 622256 steps/s (collection: 0.035s, learning 0.123s)
                       Mean reward: 846.49
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.9745
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7496
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 0.16s
                      Time elapsed: 00:14:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 745/1 [0m                       

                       Computation: 777972 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 854.89
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.2314
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7521
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 0.13s
                      Time elapsed: 00:14:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 746/1 [0m                       

                       Computation: 850362 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 859.36
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9824
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7519
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 0.12s
                      Time elapsed: 00:14:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 747/1 [0m                       

                       Computation: 767912 steps/s (collection: 0.048s, learning 0.080s)
                       Mean reward: 861.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.3344
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7530
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 0.13s
                      Time elapsed: 00:14:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 748/1 [0m                       

                       Computation: 459002 steps/s (collection: 0.044s, learning 0.170s)
                       Mean reward: 849.21
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.7478
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7505
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 0.21s
                      Time elapsed: 00:14:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 749/1 [0m                       

                       Computation: 532324 steps/s (collection: 0.045s, learning 0.140s)
                       Mean reward: 845.41
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.9265
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 0.18s
                      Time elapsed: 00:14:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 750/1 [0m                       

                       Computation: 579498 steps/s (collection: 0.056s, learning 0.114s)
                       Mean reward: 848.29
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.9193
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7526
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 86.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 0.17s
                      Time elapsed: 00:14:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 751/1 [0m                       

                       Computation: 763580 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 822.03
               Mean episode length: 246.30
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.7811
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7265
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 0.13s
                      Time elapsed: 00:14:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 752/1 [0m                       

                       Computation: 726310 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 852.39
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9358
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 0.14s
                      Time elapsed: 00:14:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 753/1 [0m                       

                       Computation: 739170 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 843.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.7729
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 0.13s
                      Time elapsed: 00:14:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 754/1 [0m                       

                       Computation: 813863 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 846.78
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.0957
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7464
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 0.12s
                      Time elapsed: 00:14:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 755/1 [0m                       

                       Computation: 847211 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 854.79
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.2440
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 0.12s
                      Time elapsed: 00:14:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 756/1 [0m                       

                       Computation: 826987 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 860.15
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.1774
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7551
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 0.12s
                      Time elapsed: 00:14:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 757/1 [0m                       

                       Computation: 719402 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 861.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.3183
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 0.14s
                      Time elapsed: 00:14:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 758/1 [0m                       

                       Computation: 537100 steps/s (collection: 0.044s, learning 0.140s)
                       Mean reward: 860.07
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9313
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7608
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 0.18s
                      Time elapsed: 00:14:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 759/1 [0m                       

                       Computation: 746451 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 860.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.5066
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 0.13s
                      Time elapsed: 00:14:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 760/1 [0m                       

                       Computation: 700805 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 864.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0771
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7626
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 0.14s
                      Time elapsed: 00:14:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 761/1 [0m                       

                       Computation: 746614 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 862.58
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0143
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 83.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 0.13s
                      Time elapsed: 00:14:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 762/1 [0m                       

                       Computation: 649152 steps/s (collection: 0.036s, learning 0.115s)
                       Mean reward: 866.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.2328
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 0.15s
                      Time elapsed: 00:14:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 763/1 [0m                       

                       Computation: 624912 steps/s (collection: 0.043s, learning 0.114s)
                       Mean reward: 858.85
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8042
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7556
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 0.16s
                      Time elapsed: 00:14:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 764/1 [0m                       

                       Computation: 818519 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 853.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.3461
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 0.12s
                      Time elapsed: 00:14:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 765/1 [0m                       

                       Computation: 804856 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 851.96
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.7600
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 0.12s
                      Time elapsed: 00:14:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 766/1 [0m                       

                       Computation: 667470 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 872.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2255
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 0.15s
                      Time elapsed: 00:14:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 767/1 [0m                       

                       Computation: 622054 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 869.43
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2463
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 0.16s
                      Time elapsed: 00:14:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 768/1 [0m                       

                       Computation: 602823 steps/s (collection: 0.041s, learning 0.122s)
                       Mean reward: 872.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6603
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 0.16s
                      Time elapsed: 00:14:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 769/1 [0m                       

                       Computation: 415265 steps/s (collection: 0.072s, learning 0.165s)
                       Mean reward: 872.79
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6307
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 0.24s
                      Time elapsed: 00:14:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 770/1 [0m                       

                       Computation: 550900 steps/s (collection: 0.043s, learning 0.135s)
                       Mean reward: 871.19
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6030
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 0.18s
                      Time elapsed: 00:14:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 771/1 [0m                       

                       Computation: 538968 steps/s (collection: 0.045s, learning 0.138s)
                       Mean reward: 868.05
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7841
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 85.4583
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 0.18s
                      Time elapsed: 00:14:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 772/1 [0m                       

                       Computation: 531697 steps/s (collection: 0.051s, learning 0.134s)
                       Mean reward: 867.76
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8889
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 0.18s
                      Time elapsed: 00:14:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 773/1 [0m                       

                       Computation: 445681 steps/s (collection: 0.043s, learning 0.178s)
                       Mean reward: 864.93
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.4897
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7452
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 0.22s
                      Time elapsed: 00:14:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 774/1 [0m                       

                       Computation: 686771 steps/s (collection: 0.048s, learning 0.095s)
                       Mean reward: 853.32
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8534
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7480
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 0.14s
                      Time elapsed: 00:15:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 775/1 [0m                       

                       Computation: 555033 steps/s (collection: 0.042s, learning 0.135s)
                       Mean reward: 855.37
               Mean episode length: 247.44
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.6891
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7402
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 0.18s
                      Time elapsed: 00:15:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 776/1 [0m                       

                       Computation: 546170 steps/s (collection: 0.054s, learning 0.126s)
                       Mean reward: 863.98
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7156
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 0.18s
                      Time elapsed: 00:15:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 777/1 [0m                       

                       Computation: 535907 steps/s (collection: 0.047s, learning 0.137s)
                       Mean reward: 852.07
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.1408
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7395
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 0.18s
                      Time elapsed: 00:15:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 778/1 [0m                       

                       Computation: 534022 steps/s (collection: 0.042s, learning 0.142s)
                       Mean reward: 847.95
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.4876
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 0.18s
                      Time elapsed: 00:15:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 779/1 [0m                       

                       Computation: 558329 steps/s (collection: 0.040s, learning 0.137s)
                       Mean reward: 837.87
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.6621
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 0.18s
                      Time elapsed: 00:15:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 780/1 [0m                       

                       Computation: 780013 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 827.38
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.7740
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7459
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 0.13s
                      Time elapsed: 00:15:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 781/1 [0m                       

                       Computation: 777253 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 844.65
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9971
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7482
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 0.13s
                      Time elapsed: 00:15:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 782/1 [0m                       

                       Computation: 720654 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 844.44
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.3458
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7469
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 81.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 0.14s
                      Time elapsed: 00:15:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 783/1 [0m                       

                       Computation: 645574 steps/s (collection: 0.036s, learning 0.116s)
                       Mean reward: 855.33
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5463
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7490
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 0.15s
                      Time elapsed: 00:15:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 784/1 [0m                       

                       Computation: 580004 steps/s (collection: 0.040s, learning 0.130s)
                       Mean reward: 855.69
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5761
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7546
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 0.17s
                      Time elapsed: 00:15:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 785/1 [0m                       

                       Computation: 628255 steps/s (collection: 0.045s, learning 0.111s)
                       Mean reward: 854.26
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5935
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7557
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 0.16s
                      Time elapsed: 00:15:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 786/1 [0m                       

                       Computation: 648104 steps/s (collection: 0.039s, learning 0.113s)
                       Mean reward: 860.86
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6228
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7548
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 0.15s
                      Time elapsed: 00:15:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 787/1 [0m                       

                       Computation: 724618 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 868.35
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.9232
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 0.14s
                      Time elapsed: 00:15:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 788/1 [0m                       

                       Computation: 579041 steps/s (collection: 0.048s, learning 0.122s)
                       Mean reward: 844.47
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.5512
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7511
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 0.17s
                      Time elapsed: 00:15:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 789/1 [0m                       

                       Computation: 343936 steps/s (collection: 0.105s, learning 0.181s)
                       Mean reward: 861.62
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9377
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 0.29s
                      Time elapsed: 00:15:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 790/1 [0m                       

                       Computation: 429670 steps/s (collection: 0.044s, learning 0.185s)
                       Mean reward: 849.64
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9673
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 0.23s
                      Time elapsed: 00:15:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 791/1 [0m                       

                       Computation: 751803 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 857.57
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.6838
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7523
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 0.13s
                      Time elapsed: 00:15:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 792/1 [0m                       

                       Computation: 793929 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 860.23
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1361
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 82.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 0.12s
                      Time elapsed: 00:15:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 793/1 [0m                       

                       Computation: 421764 steps/s (collection: 0.054s, learning 0.179s)
                       Mean reward: 862.12
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1490
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 0.23s
                      Time elapsed: 00:15:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 794/1 [0m                       

                       Computation: 624085 steps/s (collection: 0.048s, learning 0.110s)
                       Mean reward: 851.10
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.3166
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 0.16s
                      Time elapsed: 00:15:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 795/1 [0m                       

                       Computation: 530059 steps/s (collection: 0.045s, learning 0.140s)
                       Mean reward: 863.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7289
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 0.19s
                      Time elapsed: 00:15:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 796/1 [0m                       

                       Computation: 571447 steps/s (collection: 0.041s, learning 0.131s)
                       Mean reward: 865.53
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.5858
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7669
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 0.17s
                      Time elapsed: 00:15:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 797/1 [0m                       

                       Computation: 616809 steps/s (collection: 0.046s, learning 0.113s)
                       Mean reward: 853.06
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5849
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 0.16s
                      Time elapsed: 00:15:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 798/1 [0m                       

                       Computation: 629650 steps/s (collection: 0.045s, learning 0.111s)
                       Mean reward: 843.47
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.8325
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7521
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 0.16s
                      Time elapsed: 00:15:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 799/1 [0m                       

                       Computation: 642057 steps/s (collection: 0.041s, learning 0.113s)
                       Mean reward: 846.30
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.5586
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 0.15s
                      Time elapsed: 00:15:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 800/1 [0m                       

                       Computation: 511188 steps/s (collection: 0.053s, learning 0.139s)
                       Mean reward: 853.07
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.5886
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 0.19s
                      Time elapsed: 00:15:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 801/1 [0m                       

                       Computation: 643443 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 858.45
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.2313
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7644
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 0.15s
                      Time elapsed: 00:15:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 802/1 [0m                       

                       Computation: 651864 steps/s (collection: 0.045s, learning 0.106s)
                       Mean reward: 876.31
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4006
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7799
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 0.15s
                      Time elapsed: 00:15:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 803/1 [0m                       

                       Computation: 505316 steps/s (collection: 0.040s, learning 0.155s)
                       Mean reward: 869.19
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4240
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7736
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 80.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 0.19s
                      Time elapsed: 00:15:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 804/1 [0m                       

                       Computation: 390742 steps/s (collection: 0.051s, learning 0.201s)
                       Mean reward: 868.31
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2321
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 0.25s
                      Time elapsed: 00:15:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 805/1 [0m                       

                       Computation: 544309 steps/s (collection: 0.046s, learning 0.135s)
                       Mean reward: 858.33
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.7350
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 0.18s
                      Time elapsed: 00:15:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 806/1 [0m                       

                       Computation: 687147 steps/s (collection: 0.038s, learning 0.105s)
                       Mean reward: 870.01
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.1096
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 0.14s
                      Time elapsed: 00:15:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 807/1 [0m                       

                       Computation: 761710 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 864.17
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9775
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 0.13s
                      Time elapsed: 00:15:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 808/1 [0m                       

                       Computation: 555106 steps/s (collection: 0.050s, learning 0.127s)
                       Mean reward: 864.76
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4481
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 0.18s
                      Time elapsed: 00:15:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 809/1 [0m                       

                       Computation: 427202 steps/s (collection: 0.051s, learning 0.180s)
                       Mean reward: 870.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7810
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 0.23s
                      Time elapsed: 00:15:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 810/1 [0m                       

                       Computation: 408620 steps/s (collection: 0.051s, learning 0.190s)
                       Mean reward: 865.45
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1873
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 0.24s
                      Time elapsed: 00:15:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 811/1 [0m                       

                       Computation: 659296 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 853.14
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5242
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7669
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 0.15s
                      Time elapsed: 00:15:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 812/1 [0m                       

                       Computation: 421741 steps/s (collection: 0.043s, learning 0.191s)
                       Mean reward: 865.13
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.0083
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7737
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 0.23s
                      Time elapsed: 00:15:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 813/1 [0m                       

                       Computation: 357209 steps/s (collection: 0.055s, learning 0.221s)
                       Mean reward: 867.28
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6079
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 81.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 0.28s
                      Time elapsed: 00:15:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 814/1 [0m                       

                       Computation: 608343 steps/s (collection: 0.042s, learning 0.120s)
                       Mean reward: 815.18
               Mean episode length: 246.19
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 160.2897
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7383
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 0.16s
                      Time elapsed: 00:15:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 815/1 [0m                       

                       Computation: 704385 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 857.39
               Mean episode length: 246.64
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.7412
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7683
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 0.14s
                      Time elapsed: 00:15:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 816/1 [0m                       

                       Computation: 720118 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 863.38
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7720
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 0.14s
                      Time elapsed: 00:15:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 817/1 [0m                       

                       Computation: 764952 steps/s (collection: 0.035s, learning 0.094s)
                       Mean reward: 862.67
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4195
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7653
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 0.13s
                      Time elapsed: 00:15:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 818/1 [0m                       

                       Computation: 689730 steps/s (collection: 0.039s, learning 0.104s)
                       Mean reward: 849.70
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.4439
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7622
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 0.14s
                      Time elapsed: 00:15:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 819/1 [0m                       

                       Computation: 572818 steps/s (collection: 0.051s, learning 0.121s)
                       Mean reward: 856.71
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.9923
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 0.17s
                      Time elapsed: 00:15:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 820/1 [0m                       

                       Computation: 541443 steps/s (collection: 0.044s, learning 0.138s)
                       Mean reward: 863.94
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.2130
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 0.18s
                      Time elapsed: 00:15:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 821/1 [0m                       

                       Computation: 684882 steps/s (collection: 0.036s, learning 0.108s)
                       Mean reward: 863.24
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1019
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 0.14s
                      Time elapsed: 00:16:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 822/1 [0m                       

                       Computation: 694561 steps/s (collection: 0.038s, learning 0.104s)
                       Mean reward: 862.58
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.0442
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7558
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 0.14s
                      Time elapsed: 00:16:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 823/1 [0m                       

                       Computation: 652839 steps/s (collection: 0.039s, learning 0.112s)
                       Mean reward: 868.07
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5074
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7552
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 83.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 0.15s
                      Time elapsed: 00:16:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 824/1 [0m                       

                       Computation: 682412 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 864.60
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.3828
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7588
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 0.14s
                      Time elapsed: 00:16:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 825/1 [0m                       

                       Computation: 725434 steps/s (collection: 0.036s, learning 0.100s)
                       Mean reward: 824.67
               Mean episode length: 239.99
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.2775
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7375
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 0.14s
                      Time elapsed: 00:16:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 826/1 [0m                       

                       Computation: 728500 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 848.22
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9004
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 0.13s
                      Time elapsed: 00:16:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 827/1 [0m                       

                       Computation: 837718 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 852.66
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.4906
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7517
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 0.12s
                      Time elapsed: 00:16:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 828/1 [0m                       

                       Computation: 642745 steps/s (collection: 0.050s, learning 0.103s)
                       Mean reward: 853.31
               Mean episode length: 247.15
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.9317
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 0.15s
                      Time elapsed: 00:16:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 829/1 [0m                       

                       Computation: 668685 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 871.46
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.8497
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 0.15s
                      Time elapsed: 00:16:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 830/1 [0m                       

                       Computation: 739989 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 865.15
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.0721
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7696
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 0.13s
                      Time elapsed: 00:16:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 831/1 [0m                       

                       Computation: 614237 steps/s (collection: 0.051s, learning 0.110s)
                       Mean reward: 857.16
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.4503
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 0.16s
                      Time elapsed: 00:16:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 832/1 [0m                       

                       Computation: 780214 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 868.49
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.9820
       Episode_Reward/object_height 0.0120
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 0.13s
                      Time elapsed: 00:16:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 833/1 [0m                       

                       Computation: 720089 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 843.54
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.0528
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7508
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 0.14s
                      Time elapsed: 00:16:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 834/1 [0m                       

                       Computation: 836420 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 839.01
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.8219
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7446
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 79.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 0.12s
                      Time elapsed: 00:16:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 835/1 [0m                       

                       Computation: 773991 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 826.09
               Mean episode length: 246.64
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.6123
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7389
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 0.13s
                      Time elapsed: 00:16:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 836/1 [0m                       

                       Computation: 514710 steps/s (collection: 0.053s, learning 0.138s)
                       Mean reward: 815.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.8516
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7448
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 0.19s
                      Time elapsed: 00:16:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 837/1 [0m                       

                       Computation: 328721 steps/s (collection: 0.079s, learning 0.220s)
                       Mean reward: 836.07
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.2490
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 0.30s
                      Time elapsed: 00:16:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 838/1 [0m                       

                       Computation: 588559 steps/s (collection: 0.045s, learning 0.123s)
                       Mean reward: 840.26
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.3217
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 0.17s
                      Time elapsed: 00:16:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 839/1 [0m                       

                       Computation: 313878 steps/s (collection: 0.067s, learning 0.246s)
                       Mean reward: 859.80
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.0966
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7583
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 0.31s
                      Time elapsed: 00:16:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 840/1 [0m                       

                       Computation: 378700 steps/s (collection: 0.056s, learning 0.203s)
                       Mean reward: 860.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.2798
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 0.26s
                      Time elapsed: 00:16:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 841/1 [0m                       

                       Computation: 595630 steps/s (collection: 0.040s, learning 0.125s)
                       Mean reward: 861.64
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.5505
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 0.17s
                      Time elapsed: 00:16:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 842/1 [0m                       

                       Computation: 616374 steps/s (collection: 0.036s, learning 0.124s)
                       Mean reward: 865.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3499
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 0.16s
                      Time elapsed: 00:16:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 843/1 [0m                       

                       Computation: 623827 steps/s (collection: 0.037s, learning 0.121s)
                       Mean reward: 863.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0831
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 0.16s
                      Time elapsed: 00:16:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 844/1 [0m                       

                       Computation: 571776 steps/s (collection: 0.048s, learning 0.124s)
                       Mean reward: 857.20
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.3630
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 81.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 0.17s
                      Time elapsed: 00:16:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 845/1 [0m                       

                       Computation: 535628 steps/s (collection: 0.046s, learning 0.138s)
                       Mean reward: 849.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.8415
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 0.18s
                      Time elapsed: 00:16:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 846/1 [0m                       

                       Computation: 800868 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 867.11
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.0143
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7399
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 0.12s
                      Time elapsed: 00:16:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 847/1 [0m                       

                       Computation: 473674 steps/s (collection: 0.039s, learning 0.168s)
                       Mean reward: 867.37
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7106
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 0.21s
                      Time elapsed: 00:16:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 848/1 [0m                       

                       Computation: 669298 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 864.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.0452
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 0.15s
                      Time elapsed: 00:16:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 849/1 [0m                       

                       Computation: 619993 steps/s (collection: 0.041s, learning 0.118s)
                       Mean reward: 867.66
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7534
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 0.16s
                      Time elapsed: 00:16:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 850/1 [0m                       

                       Computation: 728879 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 872.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.6826
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 0.13s
                      Time elapsed: 00:16:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 851/1 [0m                       

                       Computation: 740083 steps/s (collection: 0.035s, learning 0.098s)
                       Mean reward: 862.79
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7922
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 0.13s
                      Time elapsed: 00:16:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 852/1 [0m                       

                       Computation: 758221 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 868.48
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.1522
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7781
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 0.13s
                      Time elapsed: 00:16:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 853/1 [0m                       

                       Computation: 697185 steps/s (collection: 0.036s, learning 0.105s)
                       Mean reward: 864.16
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8205
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 0.14s
                      Time elapsed: 00:16:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 854/1 [0m                       

                       Computation: 532651 steps/s (collection: 0.038s, learning 0.147s)
                       Mean reward: 856.49
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1176
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7620
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 0.18s
                      Time elapsed: 00:16:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 855/1 [0m                       

                       Computation: 641524 steps/s (collection: 0.041s, learning 0.113s)
                       Mean reward: 867.83
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.5236
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 78.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 0.15s
                      Time elapsed: 00:16:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 856/1 [0m                       

                       Computation: 604799 steps/s (collection: 0.037s, learning 0.126s)
                       Mean reward: 830.35
               Mean episode length: 243.60
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.6817
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7388
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 0.16s
                      Time elapsed: 00:16:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 857/1 [0m                       

                       Computation: 819106 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 874.12
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.2921
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 0.12s
                      Time elapsed: 00:16:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 858/1 [0m                       

                       Computation: 786342 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 861.98
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6048
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 0.13s
                      Time elapsed: 00:16:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 859/1 [0m                       

                       Computation: 499952 steps/s (collection: 0.042s, learning 0.155s)
                       Mean reward: 860.98
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5059
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 0.20s
                      Time elapsed: 00:16:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 860/1 [0m                       

                       Computation: 662893 steps/s (collection: 0.038s, learning 0.111s)
                       Mean reward: 866.24
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.3329
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 0.15s
                      Time elapsed: 00:16:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 861/1 [0m                       

                       Computation: 799370 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 871.61
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.9035
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 0.12s
                      Time elapsed: 00:16:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 862/1 [0m                       

                       Computation: 646603 steps/s (collection: 0.037s, learning 0.115s)
                       Mean reward: 865.01
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7766
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7671
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 0.15s
                      Time elapsed: 00:16:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 863/1 [0m                       

                       Computation: 581647 steps/s (collection: 0.049s, learning 0.120s)
                       Mean reward: 869.68
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.2338
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 0.17s
                      Time elapsed: 00:16:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 864/1 [0m                       

                       Computation: 505344 steps/s (collection: 0.046s, learning 0.149s)
                       Mean reward: 852.88
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.9660
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7571
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 0.19s
                      Time elapsed: 00:16:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 865/1 [0m                       

                       Computation: 351361 steps/s (collection: 0.068s, learning 0.212s)
                       Mean reward: 853.48
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.4087
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7398
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 79.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 0.28s
                      Time elapsed: 00:16:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 866/1 [0m                       

                       Computation: 558582 steps/s (collection: 0.046s, learning 0.130s)
                       Mean reward: 847.88
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.3619
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 0.18s
                      Time elapsed: 00:16:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 867/1 [0m                       

                       Computation: 707391 steps/s (collection: 0.035s, learning 0.103s)
                       Mean reward: 857.62
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5389
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 0.14s
                      Time elapsed: 00:16:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 868/1 [0m                       

                       Computation: 595685 steps/s (collection: 0.050s, learning 0.115s)
                       Mean reward: 862.41
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6397
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 0.17s
                      Time elapsed: 00:16:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 869/1 [0m                       

                       Computation: 390379 steps/s (collection: 0.045s, learning 0.207s)
                       Mean reward: 857.94
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5295
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7564
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 0.25s
                      Time elapsed: 00:16:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 870/1 [0m                       

                       Computation: 667970 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 866.62
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1537
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 0.15s
                      Time elapsed: 00:16:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 871/1 [0m                       

                       Computation: 586232 steps/s (collection: 0.045s, learning 0.123s)
                       Mean reward: 851.15
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5209
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.7521
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 0.17s
                      Time elapsed: 00:16:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 872/1 [0m                       

                       Computation: 718591 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 860.93
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7556
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 0.14s
                      Time elapsed: 00:17:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 873/1 [0m                       

                       Computation: 765845 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 851.46
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.4861
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.7475
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 0.13s
                      Time elapsed: 00:17:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 874/1 [0m                       

                       Computation: 592043 steps/s (collection: 0.039s, learning 0.128s)
                       Mean reward: 865.98
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6555
       Episode_Reward/object_height 0.0127
     Episode_Reward/reaching_object 0.7643
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 0.17s
                      Time elapsed: 00:17:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 875/1 [0m                       

                       Computation: 816016 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 864.88
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.2899
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 82.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 0.12s
                      Time elapsed: 00:17:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 876/1 [0m                       

                       Computation: 608076 steps/s (collection: 0.051s, learning 0.111s)
                       Mean reward: 836.27
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.7144
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.7358
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 0.16s
                      Time elapsed: 00:17:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 877/1 [0m                       

                       Computation: 826360 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 854.42
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.9911
       Episode_Reward/object_height 0.0132
     Episode_Reward/reaching_object 0.7439
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 0.12s
                      Time elapsed: 00:17:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 878/1 [0m                       

                       Computation: 639571 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 873.22
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.7528
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 0.15s
                      Time elapsed: 00:17:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 879/1 [0m                       

                       Computation: 510898 steps/s (collection: 0.052s, learning 0.140s)
                       Mean reward: 858.38
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.2432
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 0.19s
                      Time elapsed: 00:17:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 880/1 [0m                       

                       Computation: 515872 steps/s (collection: 0.055s, learning 0.136s)
                       Mean reward: 856.45
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.0192
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 0.19s
                      Time elapsed: 00:17:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 881/1 [0m                       

                       Computation: 437962 steps/s (collection: 0.050s, learning 0.174s)
                       Mean reward: 855.82
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.4929
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 0.22s
                      Time elapsed: 00:17:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 882/1 [0m                       

                       Computation: 691033 steps/s (collection: 0.037s, learning 0.105s)
                       Mean reward: 868.78
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.7481
       Episode_Reward/object_height 0.0143
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 0.14s
                      Time elapsed: 00:17:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 883/1 [0m                       

                       Computation: 311535 steps/s (collection: 0.069s, learning 0.247s)
                       Mean reward: 858.13
               Mean episode length: 247.41
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.1796
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 0.32s
                      Time elapsed: 00:17:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 884/1 [0m                       

                       Computation: 578092 steps/s (collection: 0.050s, learning 0.121s)
                       Mean reward: 860.35
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.8113
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 0.17s
                      Time elapsed: 00:17:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 885/1 [0m                       

                       Computation: 437954 steps/s (collection: 0.054s, learning 0.171s)
                       Mean reward: 862.51
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8001
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 0.22s
                      Time elapsed: 00:17:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 886/1 [0m                       

                       Computation: 356466 steps/s (collection: 0.059s, learning 0.217s)
                       Mean reward: 868.90
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.5835
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 78.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 0.28s
                      Time elapsed: 00:17:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 887/1 [0m                       

                       Computation: 354799 steps/s (collection: 0.054s, learning 0.224s)
                       Mean reward: 844.12
               Mean episode length: 242.54
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.6080
       Episode_Reward/object_height 0.0129
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 0.28s
                      Time elapsed: 00:17:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 888/1 [0m                       

                       Computation: 531894 steps/s (collection: 0.047s, learning 0.138s)
                       Mean reward: 855.19
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5543
       Episode_Reward/object_height 0.0127
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 0.18s
                      Time elapsed: 00:17:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 889/1 [0m                       

                       Computation: 574059 steps/s (collection: 0.047s, learning 0.124s)
                       Mean reward: 864.05
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7031
       Episode_Reward/object_height 0.0127
     Episode_Reward/reaching_object 0.7726
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 0.17s
                      Time elapsed: 00:17:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 890/1 [0m                       

                       Computation: 495009 steps/s (collection: 0.060s, learning 0.139s)
                       Mean reward: 858.31
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5676
       Episode_Reward/object_height 0.0127
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 0.20s
                      Time elapsed: 00:17:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 891/1 [0m                       

                       Computation: 549666 steps/s (collection: 0.043s, learning 0.136s)
                       Mean reward: 861.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4639
       Episode_Reward/object_height 0.0129
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 0.18s
                      Time elapsed: 00:17:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 892/1 [0m                       

                       Computation: 532910 steps/s (collection: 0.044s, learning 0.140s)
                       Mean reward: 863.42
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.8551
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 0.18s
                      Time elapsed: 00:17:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 893/1 [0m                       

                       Computation: 409529 steps/s (collection: 0.055s, learning 0.185s)
                       Mean reward: 855.62
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.6006
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7598
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 0.24s
                      Time elapsed: 00:17:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 894/1 [0m                       

                       Computation: 688189 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 857.00
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.0332
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 0.14s
                      Time elapsed: 00:17:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 895/1 [0m                       

                       Computation: 547503 steps/s (collection: 0.040s, learning 0.140s)
                       Mean reward: 862.54
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7013
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 0.18s
                      Time elapsed: 00:17:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 896/1 [0m                       

                       Computation: 704433 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 866.74
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.7780
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 80.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 0.14s
                      Time elapsed: 00:17:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 897/1 [0m                       

                       Computation: 532378 steps/s (collection: 0.049s, learning 0.136s)
                       Mean reward: 851.58
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.5455
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 0.18s
                      Time elapsed: 00:17:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 898/1 [0m                       

                       Computation: 644033 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 832.48
               Mean episode length: 241.45
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9499
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 0.15s
                      Time elapsed: 00:17:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 899/1 [0m                       

                       Computation: 705667 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 867.45
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.0883
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7818
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 0.14s
                      Time elapsed: 00:17:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 900/1 [0m                       

                       Computation: 583578 steps/s (collection: 0.041s, learning 0.127s)
                       Mean reward: 855.88
               Mean episode length: 246.65
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.9702
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 0.17s
                      Time elapsed: 00:17:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 901/1 [0m                       

                       Computation: 636112 steps/s (collection: 0.036s, learning 0.119s)
                       Mean reward: 857.85
               Mean episode length: 245.89
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.8671
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 0.15s
                      Time elapsed: 00:17:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 902/1 [0m                       

                       Computation: 815548 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 876.08
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 174.1617
       Episode_Reward/object_height 0.0176
     Episode_Reward/reaching_object 0.7855
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 0.12s
                      Time elapsed: 00:17:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 903/1 [0m                       

                       Computation: 552175 steps/s (collection: 0.037s, learning 0.141s)
                       Mean reward: 867.99
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.0886
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7801
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 0.18s
                      Time elapsed: 00:17:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 904/1 [0m                       

                       Computation: 516788 steps/s (collection: 0.054s, learning 0.137s)
                       Mean reward: 869.70
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.0811
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7790
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 0.19s
                      Time elapsed: 00:17:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 905/1 [0m                       

                       Computation: 673270 steps/s (collection: 0.039s, learning 0.107s)
                       Mean reward: 843.40
               Mean episode length: 246.70
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.7504
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 0.15s
                      Time elapsed: 00:17:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 906/1 [0m                       

                       Computation: 464430 steps/s (collection: 0.045s, learning 0.167s)
                       Mean reward: 869.05
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.9615
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 0.21s
                      Time elapsed: 00:17:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 907/1 [0m                       

                       Computation: 458150 steps/s (collection: 0.051s, learning 0.164s)
                       Mean reward: 871.19
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.3033
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7654
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 76.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 0.21s
                      Time elapsed: 00:17:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 908/1 [0m                       

                       Computation: 544401 steps/s (collection: 0.051s, learning 0.130s)
                       Mean reward: 865.53
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.3121
       Episode_Reward/object_height 0.0169
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 0.18s
                      Time elapsed: 00:17:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 909/1 [0m                       

                       Computation: 730714 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 852.80
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.1455
       Episode_Reward/object_height 0.0164
     Episode_Reward/reaching_object 0.7563
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 0.13s
                      Time elapsed: 00:17:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 910/1 [0m                       

                       Computation: 764411 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 868.74
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.5635
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 0.13s
                      Time elapsed: 00:17:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 911/1 [0m                       

                       Computation: 772270 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 866.91
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.6950
       Episode_Reward/object_height 0.0165
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 0.13s
                      Time elapsed: 00:17:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 912/1 [0m                       

                       Computation: 717866 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 854.48
               Mean episode length: 247.05
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.7044
       Episode_Reward/object_height 0.0162
     Episode_Reward/reaching_object 0.7624
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 0.14s
                      Time elapsed: 00:17:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 913/1 [0m                       

                       Computation: 663232 steps/s (collection: 0.056s, learning 0.092s)
                       Mean reward: 863.04
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.4208
       Episode_Reward/object_height 0.0164
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 0.15s
                      Time elapsed: 00:17:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 914/1 [0m                       

                       Computation: 531409 steps/s (collection: 0.046s, learning 0.139s)
                       Mean reward: 855.20
               Mean episode length: 245.31
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.9724
       Episode_Reward/object_height 0.0159
     Episode_Reward/reaching_object 0.7629
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 0.18s
                      Time elapsed: 00:17:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 915/1 [0m                       

                       Computation: 564946 steps/s (collection: 0.040s, learning 0.134s)
                       Mean reward: 866.26
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6347
       Episode_Reward/object_height 0.0163
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 0.17s
                      Time elapsed: 00:17:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 916/1 [0m                       

                       Computation: 759972 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 852.33
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.9324
       Episode_Reward/object_height 0.0160
     Episode_Reward/reaching_object 0.7526
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 0.13s
                      Time elapsed: 00:17:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 917/1 [0m                       

                       Computation: 627888 steps/s (collection: 0.040s, learning 0.117s)
                       Mean reward: 849.30
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.9254
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7323
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 77.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 0.16s
                      Time elapsed: 00:17:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 918/1 [0m                       

                       Computation: 528324 steps/s (collection: 0.066s, learning 0.120s)
                       Mean reward: 850.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.2807
       Episode_Reward/object_height 0.0155
     Episode_Reward/reaching_object 0.7291
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 0.19s
                      Time elapsed: 00:17:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 919/1 [0m                       

                       Computation: 812716 steps/s (collection: 0.034s, learning 0.087s)
                       Mean reward: 840.97
               Mean episode length: 246.28
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.2783
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7414
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 0.12s
                      Time elapsed: 00:17:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 920/1 [0m                       

                       Computation: 364460 steps/s (collection: 0.077s, learning 0.193s)
                       Mean reward: 852.51
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5387
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 0.27s
                      Time elapsed: 00:18:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 921/1 [0m                       

                       Computation: 852741 steps/s (collection: 0.034s, learning 0.081s)
                       Mean reward: 849.20
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5596
       Episode_Reward/object_height 0.0160
     Episode_Reward/reaching_object 0.7486
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 0.12s
                      Time elapsed: 00:18:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 922/1 [0m                       

                       Computation: 842351 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 846.59
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.8263
       Episode_Reward/object_height 0.0157
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 0.12s
                      Time elapsed: 00:18:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 923/1 [0m                       

                       Computation: 646886 steps/s (collection: 0.051s, learning 0.101s)
                       Mean reward: 850.60
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.2364
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7429
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 0.15s
                      Time elapsed: 00:18:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 924/1 [0m                       

                       Computation: 755474 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 865.86
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9057
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7616
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 0.13s
                      Time elapsed: 00:18:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 925/1 [0m                       

                       Computation: 638249 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 864.50
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5964
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 0.15s
                      Time elapsed: 00:18:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 926/1 [0m                       

                       Computation: 538414 steps/s (collection: 0.057s, learning 0.126s)
                       Mean reward: 865.84
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.2677
       Episode_Reward/object_height 0.0149
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 0.18s
                      Time elapsed: 00:18:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 927/1 [0m                       

                       Computation: 642757 steps/s (collection: 0.037s, learning 0.116s)
                       Mean reward: 875.24
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.8542
       Episode_Reward/object_height 0.0148
     Episode_Reward/reaching_object 0.7842
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 0.15s
                      Time elapsed: 00:18:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 928/1 [0m                       

                       Computation: 800540 steps/s (collection: 0.033s, learning 0.090s)
                       Mean reward: 875.18
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6691
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7846
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 73.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 0.12s
                      Time elapsed: 00:18:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 929/1 [0m                       

                       Computation: 630120 steps/s (collection: 0.037s, learning 0.119s)
                       Mean reward: 879.20
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.3656
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 0.16s
                      Time elapsed: 00:18:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 930/1 [0m                       

                       Computation: 801250 steps/s (collection: 0.034s, learning 0.088s)
                       Mean reward: 872.44
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.5657
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7803
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 0.12s
                      Time elapsed: 00:18:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 931/1 [0m                       

                       Computation: 874364 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 879.44
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.8609
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7899
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 0.11s
                      Time elapsed: 00:18:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 932/1 [0m                       

                       Computation: 695895 steps/s (collection: 0.050s, learning 0.091s)
                       Mean reward: 877.11
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.9252
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 0.14s
                      Time elapsed: 00:18:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 933/1 [0m                       

                       Computation: 615025 steps/s (collection: 0.044s, learning 0.116s)
                       Mean reward: 860.83
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8265
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.7771
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 0.16s
                      Time elapsed: 00:18:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 934/1 [0m                       

                       Computation: 380931 steps/s (collection: 0.075s, learning 0.183s)
                       Mean reward: 869.28
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6160
       Episode_Reward/object_height 0.0123
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 0.26s
                      Time elapsed: 00:18:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 935/1 [0m                       

                       Computation: 687158 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 877.21
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.2245
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 0.14s
                      Time elapsed: 00:18:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 936/1 [0m                       

                       Computation: 409134 steps/s (collection: 0.056s, learning 0.185s)
                       Mean reward: 859.29
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.3319
       Episode_Reward/object_height 0.0129
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 0.24s
                      Time elapsed: 00:18:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 937/1 [0m                       

                       Computation: 537098 steps/s (collection: 0.049s, learning 0.134s)
                       Mean reward: 873.46
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.0018
       Episode_Reward/object_height 0.0132
     Episode_Reward/reaching_object 0.7834
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 0.18s
                      Time elapsed: 00:18:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 938/1 [0m                       

                       Computation: 519097 steps/s (collection: 0.046s, learning 0.143s)
                       Mean reward: 856.79
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0102
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7589
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 75.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 0.19s
                      Time elapsed: 00:18:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 939/1 [0m                       

                       Computation: 466710 steps/s (collection: 0.052s, learning 0.159s)
                       Mean reward: 819.90
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.9784
       Episode_Reward/object_height 0.0123
     Episode_Reward/reaching_object 0.7210
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 0.21s
                      Time elapsed: 00:18:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 940/1 [0m                       

                       Computation: 519963 steps/s (collection: 0.043s, learning 0.147s)
                       Mean reward: 796.46
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 157.9747
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7247
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 0.19s
                      Time elapsed: 00:18:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 941/1 [0m                       

                       Computation: 593921 steps/s (collection: 0.052s, learning 0.114s)
                       Mean reward: 813.59
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.0076
       Episode_Reward/object_height 0.0123
     Episode_Reward/reaching_object 0.7352
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 0.17s
                      Time elapsed: 00:18:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 942/1 [0m                       

                       Computation: 583129 steps/s (collection: 0.052s, learning 0.117s)
                       Mean reward: 826.74
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.4993
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.7409
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 0.17s
                      Time elapsed: 00:18:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 943/1 [0m                       

                       Computation: 504021 steps/s (collection: 0.047s, learning 0.149s)
                       Mean reward: 838.73
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.0568
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.7505
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 0.20s
                      Time elapsed: 00:18:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 944/1 [0m                       

                       Computation: 554099 steps/s (collection: 0.042s, learning 0.136s)
                       Mean reward: 856.35
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.7530
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.7662
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 0.18s
                      Time elapsed: 00:18:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 945/1 [0m                       

                       Computation: 490857 steps/s (collection: 0.043s, learning 0.158s)
                       Mean reward: 867.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.5369
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 0.20s
                      Time elapsed: 00:18:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 946/1 [0m                       

                       Computation: 547477 steps/s (collection: 0.046s, learning 0.134s)
                       Mean reward: 868.23
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.5367
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 0.18s
                      Time elapsed: 00:18:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 947/1 [0m                       

                       Computation: 740814 steps/s (collection: 0.034s, learning 0.099s)
                       Mean reward: 873.59
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.3310
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 0.13s
                      Time elapsed: 00:18:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 948/1 [0m                       

                       Computation: 636656 steps/s (collection: 0.033s, learning 0.122s)
                       Mean reward: 872.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.8088
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7887
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 78.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 0.15s
                      Time elapsed: 00:18:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 949/1 [0m                       

                       Computation: 773187 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 881.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.4308
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 0.13s
                      Time elapsed: 00:18:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 950/1 [0m                       

                       Computation: 790730 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 858.25
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.3979
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 0.12s
                      Time elapsed: 00:18:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 951/1 [0m                       

                       Computation: 892885 steps/s (collection: 0.034s, learning 0.077s)
                       Mean reward: 877.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.7414
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 0.11s
                      Time elapsed: 00:18:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 952/1 [0m                       

                       Computation: 539416 steps/s (collection: 0.038s, learning 0.145s)
                       Mean reward: 864.65
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8803
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 0.18s
                      Time elapsed: 00:18:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 953/1 [0m                       

                       Computation: 704641 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 878.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.0080
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 0.14s
                      Time elapsed: 00:18:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 954/1 [0m                       

                       Computation: 478717 steps/s (collection: 0.051s, learning 0.155s)
                       Mean reward: 876.31
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.4046
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 0.21s
                      Time elapsed: 00:18:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 955/1 [0m                       

                       Computation: 675564 steps/s (collection: 0.036s, learning 0.109s)
                       Mean reward: 874.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9185
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 0.15s
                      Time elapsed: 00:18:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 956/1 [0m                       

                       Computation: 756203 steps/s (collection: 0.033s, learning 0.097s)
                       Mean reward: 853.26
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.7543
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7501
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 0.13s
                      Time elapsed: 00:18:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 957/1 [0m                       

                       Computation: 818400 steps/s (collection: 0.033s, learning 0.087s)
                       Mean reward: 876.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.7404
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7804
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 0.12s
                      Time elapsed: 00:18:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 958/1 [0m                       

                       Computation: 454012 steps/s (collection: 0.039s, learning 0.178s)
                       Mean reward: 882.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.8042
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7899
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 0.22s
                      Time elapsed: 00:18:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 959/1 [0m                       

                       Computation: 676122 steps/s (collection: 0.038s, learning 0.107s)
                       Mean reward: 879.04
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5901
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 74.7083
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 0.15s
                      Time elapsed: 00:18:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 960/1 [0m                       

                       Computation: 566164 steps/s (collection: 0.041s, learning 0.133s)
                       Mean reward: 870.62
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7000
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7757
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 0.17s
                      Time elapsed: 00:18:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 961/1 [0m                       

                       Computation: 833783 steps/s (collection: 0.035s, learning 0.083s)
                       Mean reward: 880.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9248
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7821
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 0.12s
                      Time elapsed: 00:18:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 962/1 [0m                       

                       Computation: 893448 steps/s (collection: 0.031s, learning 0.079s)
                       Mean reward: 871.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0870
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 0.11s
                      Time elapsed: 00:18:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 963/1 [0m                       

                       Computation: 520504 steps/s (collection: 0.039s, learning 0.150s)
                       Mean reward: 882.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.6114
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7884
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 0.19s
                      Time elapsed: 00:18:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 964/1 [0m                       

                       Computation: 802608 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 881.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.6035
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 0.12s
                      Time elapsed: 00:18:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 965/1 [0m                       

                       Computation: 913897 steps/s (collection: 0.035s, learning 0.072s)
                       Mean reward: 881.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.4933
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7811
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 0.11s
                      Time elapsed: 00:18:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 966/1 [0m                       

                       Computation: 398533 steps/s (collection: 0.043s, learning 0.203s)
                       Mean reward: 876.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.6228
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 0.25s
                      Time elapsed: 00:18:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 967/1 [0m                       

                       Computation: 741089 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 871.67
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7049
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 0.13s
                      Time elapsed: 00:18:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 968/1 [0m                       

                       Computation: 447764 steps/s (collection: 0.061s, learning 0.159s)
                       Mean reward: 880.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.3754
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7791
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 0.22s
                      Time elapsed: 00:18:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 969/1 [0m                       

                       Computation: 909555 steps/s (collection: 0.033s, learning 0.076s)
                       Mean reward: 878.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3190
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7788
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 76.9167
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 0.11s
                      Time elapsed: 00:18:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 970/1 [0m                       

                       Computation: 475177 steps/s (collection: 0.034s, learning 0.173s)
                       Mean reward: 882.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 176.1800
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7932
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 0.21s
                      Time elapsed: 00:18:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 971/1 [0m                       

                       Computation: 673202 steps/s (collection: 0.034s, learning 0.112s)
                       Mean reward: 867.86
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3343
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 0.15s
                      Time elapsed: 00:18:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 972/1 [0m                       

                       Computation: 608628 steps/s (collection: 0.038s, learning 0.124s)
                       Mean reward: 867.02
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8183
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 0.16s
                      Time elapsed: 00:19:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 973/1 [0m                       

                       Computation: 681536 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 876.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3749
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7696
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 0.14s
                      Time elapsed: 00:19:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 974/1 [0m                       

                       Computation: 785100 steps/s (collection: 0.035s, learning 0.091s)
                       Mean reward: 876.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3967
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 0.13s
                      Time elapsed: 00:19:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 975/1 [0m                       

                       Computation: 632095 steps/s (collection: 0.047s, learning 0.109s)
                       Mean reward: 877.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8526
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7782
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 0.16s
                      Time elapsed: 00:19:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 976/1 [0m                       

                       Computation: 639416 steps/s (collection: 0.041s, learning 0.113s)
                       Mean reward: 880.31
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.3028
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 0.15s
                      Time elapsed: 00:19:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 977/1 [0m                       

                       Computation: 657198 steps/s (collection: 0.043s, learning 0.107s)
                       Mean reward: 870.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5026
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 0.15s
                      Time elapsed: 00:19:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 978/1 [0m                       

                       Computation: 655310 steps/s (collection: 0.038s, learning 0.113s)
                       Mean reward: 876.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.7489
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7755
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 0.15s
                      Time elapsed: 00:19:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 979/1 [0m                       

                       Computation: 484203 steps/s (collection: 0.045s, learning 0.159s)
                       Mean reward: 881.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.7423
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7787
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 0.20s
                      Time elapsed: 00:19:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 980/1 [0m                       

                       Computation: 545919 steps/s (collection: 0.053s, learning 0.127s)
                       Mean reward: 879.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.6989
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 73.6667
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 0.18s
                      Time elapsed: 00:19:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 981/1 [0m                       

                       Computation: 564223 steps/s (collection: 0.067s, learning 0.108s)
                       Mean reward: 873.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4147
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 0.17s
                      Time elapsed: 00:19:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 982/1 [0m                       

                       Computation: 666836 steps/s (collection: 0.038s, learning 0.110s)
                       Mean reward: 878.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8358
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7834
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 0.15s
                      Time elapsed: 00:19:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 983/1 [0m                       

                       Computation: 602882 steps/s (collection: 0.044s, learning 0.119s)
                       Mean reward: 878.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.0657
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 0.16s
                      Time elapsed: 00:19:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 984/1 [0m                       

                       Computation: 650949 steps/s (collection: 0.042s, learning 0.109s)
                       Mean reward: 875.17
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0976
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 0.15s
                      Time elapsed: 00:19:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 985/1 [0m                       

                       Computation: 525604 steps/s (collection: 0.045s, learning 0.142s)
                       Mean reward: 877.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.0339
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7737
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 0.19s
                      Time elapsed: 00:19:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 986/1 [0m                       

                       Computation: 573038 steps/s (collection: 0.045s, learning 0.127s)
                       Mean reward: 874.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3282
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 0.17s
                      Time elapsed: 00:19:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 987/1 [0m                       

                       Computation: 464665 steps/s (collection: 0.050s, learning 0.162s)
                       Mean reward: 878.99
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.2261
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 0.21s
                      Time elapsed: 00:19:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 988/1 [0m                       

                       Computation: 528423 steps/s (collection: 0.052s, learning 0.134s)
                       Mean reward: 877.40
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8655
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 0.19s
                      Time elapsed: 00:19:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 989/1 [0m                       

                       Computation: 584999 steps/s (collection: 0.046s, learning 0.123s)
                       Mean reward: 872.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.4410
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7551
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 0.17s
                      Time elapsed: 00:19:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 990/1 [0m                       

                       Computation: 565285 steps/s (collection: 0.039s, learning 0.135s)
                       Mean reward: 878.45
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.3947
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 75.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 0.17s
                      Time elapsed: 00:19:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 991/1 [0m                       

                       Computation: 819368 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 867.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.3879
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 0.12s
                      Time elapsed: 00:19:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 992/1 [0m                       

                       Computation: 745761 steps/s (collection: 0.035s, learning 0.097s)
                       Mean reward: 869.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8246
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 0.13s
                      Time elapsed: 00:19:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 993/1 [0m                       

                       Computation: 789209 steps/s (collection: 0.033s, learning 0.092s)
                       Mean reward: 869.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2635
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7671
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 0.12s
                      Time elapsed: 00:19:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 994/1 [0m                       

                       Computation: 610275 steps/s (collection: 0.038s, learning 0.123s)
                       Mean reward: 879.07
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9561
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 0.16s
                      Time elapsed: 00:19:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 995/1 [0m                       

                       Computation: 714686 steps/s (collection: 0.036s, learning 0.102s)
                       Mean reward: 877.80
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8421
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 0.14s
                      Time elapsed: 00:19:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 996/1 [0m                       

                       Computation: 685662 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 882.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.5190
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 0.14s
                      Time elapsed: 00:19:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 997/1 [0m                       

                       Computation: 905975 steps/s (collection: 0.034s, learning 0.075s)
                       Mean reward: 882.51
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.8918
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 0.11s
                      Time elapsed: 00:19:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 998/1 [0m                       

                       Computation: 871070 steps/s (collection: 0.035s, learning 0.078s)
                       Mean reward: 879.41
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.2366
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 0.11s
                      Time elapsed: 00:19:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 999/1 [0m                       

                       Computation: 518688 steps/s (collection: 0.050s, learning 0.140s)
                       Mean reward: 884.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.9567
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7801
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 0.19s
                      Time elapsed: 00:19:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1000/1 [0m                       

                       Computation: 709328 steps/s (collection: 0.033s, learning 0.106s)
                       Mean reward: 880.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 176.3388
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 78.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 0.14s
                      Time elapsed: 00:19:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1001/1 [0m                       

                       Computation: 578951 steps/s (collection: 0.046s, learning 0.124s)
                       Mean reward: 884.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 176.5222
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7668
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 0.17s
                      Time elapsed: 00:19:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1002/1 [0m                       

                       Computation: 863167 steps/s (collection: 0.033s, learning 0.081s)
                       Mean reward: 873.60
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.9565
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7626
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 0.11s
                      Time elapsed: 00:19:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1003/1 [0m                       

                       Computation: 529886 steps/s (collection: 0.036s, learning 0.150s)
                       Mean reward: 880.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.2507
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 0.19s
                      Time elapsed: 00:19:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1004/1 [0m                       

                       Computation: 440023 steps/s (collection: 0.055s, learning 0.168s)
                       Mean reward: 880.64
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.4940
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 0.22s
                      Time elapsed: 00:19:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1005/1 [0m                       

                       Computation: 960842 steps/s (collection: 0.034s, learning 0.068s)
                       Mean reward: 881.28
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.4482
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 0.10s
                      Time elapsed: 00:19:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1006/1 [0m                       

                       Computation: 839692 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 883.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.9693
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7791
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 0.12s
                      Time elapsed: 00:19:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1007/1 [0m                       

                       Computation: 881518 steps/s (collection: 0.036s, learning 0.076s)
                       Mean reward: 878.16
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.9714
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7838
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 0.11s
                      Time elapsed: 00:19:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1008/1 [0m                       

                       Computation: 910605 steps/s (collection: 0.032s, learning 0.076s)
                       Mean reward: 875.06
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.4990
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7782
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 0.11s
                      Time elapsed: 00:19:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1009/1 [0m                       

                       Computation: 897617 steps/s (collection: 0.034s, learning 0.076s)
                       Mean reward: 874.44
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.3341
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7675
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 0.11s
                      Time elapsed: 00:19:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1010/1 [0m                       

                       Computation: 877113 steps/s (collection: 0.034s, learning 0.078s)
                       Mean reward: 872.53
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.9573
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7608
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 0.11s
                      Time elapsed: 00:19:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1011/1 [0m                       

                       Computation: 893623 steps/s (collection: 0.032s, learning 0.078s)
                       Mean reward: 865.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.3160
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7434
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 74.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 0.11s
                      Time elapsed: 00:19:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1012/1 [0m                       

                       Computation: 357376 steps/s (collection: 0.059s, learning 0.217s)
                       Mean reward: 871.93
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.9806
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 0.28s
                      Time elapsed: 00:19:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1013/1 [0m                       

                       Computation: 784831 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 875.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.4756
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 0.13s
                      Time elapsed: 00:19:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1014/1 [0m                       

                       Computation: 918609 steps/s (collection: 0.033s, learning 0.075s)
                       Mean reward: 880.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.2172
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 0.11s
                      Time elapsed: 00:19:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1015/1 [0m                       

                       Computation: 358159 steps/s (collection: 0.057s, learning 0.217s)
                       Mean reward: 874.73
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.9283
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 0.27s
                      Time elapsed: 00:19:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1016/1 [0m                       

                       Computation: 633852 steps/s (collection: 0.045s, learning 0.111s)
                       Mean reward: 878.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.9709
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7890
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 0.16s
                      Time elapsed: 00:19:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1017/1 [0m                       

                       Computation: 604629 steps/s (collection: 0.044s, learning 0.119s)
                       Mean reward: 882.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.5145
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7900
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 0.16s
                      Time elapsed: 00:19:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1018/1 [0m                       

                       Computation: 575769 steps/s (collection: 0.042s, learning 0.128s)
                       Mean reward: 882.06
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.6828
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 0.17s
                      Time elapsed: 00:19:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1019/1 [0m                       

                       Computation: 905172 steps/s (collection: 0.034s, learning 0.074s)
                       Mean reward: 882.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.9787
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 0.11s
                      Time elapsed: 00:19:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1020/1 [0m                       

                       Computation: 902227 steps/s (collection: 0.032s, learning 0.077s)
                       Mean reward: 878.03
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.4045
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 0.11s
                      Time elapsed: 00:19:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1021/1 [0m                       

                       Computation: 645967 steps/s (collection: 0.040s, learning 0.113s)
                       Mean reward: 880.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.2627
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 77.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 0.15s
                      Time elapsed: 00:19:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1022/1 [0m                       

                       Computation: 938461 steps/s (collection: 0.034s, learning 0.070s)
                       Mean reward: 878.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.6295
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 0.10s
                      Time elapsed: 00:19:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1023/1 [0m                       

                       Computation: 891704 steps/s (collection: 0.034s, learning 0.076s)
                       Mean reward: 883.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.7903
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7866
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 0.11s
                      Time elapsed: 00:19:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1024/1 [0m                       

                       Computation: 767413 steps/s (collection: 0.034s, learning 0.094s)
                       Mean reward: 875.37
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.9050
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7850
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 0.13s
                      Time elapsed: 00:19:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1025/1 [0m                       

                       Computation: 682222 steps/s (collection: 0.042s, learning 0.102s)
                       Mean reward: 875.95
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.0659
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 0.14s
                      Time elapsed: 00:20:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1026/1 [0m                       

                       Computation: 746137 steps/s (collection: 0.035s, learning 0.097s)
                       Mean reward: 873.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.9687
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 0.13s
                      Time elapsed: 00:20:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1027/1 [0m                       

                       Computation: 541484 steps/s (collection: 0.077s, learning 0.105s)
                       Mean reward: 873.94
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.1148
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 0.18s
                      Time elapsed: 00:20:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1028/1 [0m                       

                       Computation: 572200 steps/s (collection: 0.041s, learning 0.131s)
                       Mean reward: 874.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.0451
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7882
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 0.17s
                      Time elapsed: 00:20:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1029/1 [0m                       

                       Computation: 371919 steps/s (collection: 0.067s, learning 0.197s)
                       Mean reward: 858.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.9791
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7790
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 0.26s
                      Time elapsed: 00:20:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1030/1 [0m                       

                       Computation: 783168 steps/s (collection: 0.034s, learning 0.092s)
                       Mean reward: 863.20
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9986
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7884
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 0.13s
                      Time elapsed: 00:20:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1031/1 [0m                       

                       Computation: 601372 steps/s (collection: 0.035s, learning 0.128s)
                       Mean reward: 870.50
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.4533
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7858
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 0.16s
                      Time elapsed: 00:20:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1032/1 [0m                       

                       Computation: 905766 steps/s (collection: 0.035s, learning 0.074s)
                       Mean reward: 871.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.6298
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 73.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 0.11s
                      Time elapsed: 00:20:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1033/1 [0m                       

                       Computation: 606821 steps/s (collection: 0.056s, learning 0.106s)
                       Mean reward: 870.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6941
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7851
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 0.16s
                      Time elapsed: 00:20:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1034/1 [0m                       

                       Computation: 717870 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 869.15
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.0246
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 0.14s
                      Time elapsed: 00:20:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1035/1 [0m                       

                       Computation: 578216 steps/s (collection: 0.045s, learning 0.125s)
                       Mean reward: 872.45
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.4988
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 0.17s
                      Time elapsed: 00:20:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1036/1 [0m                       

                       Computation: 596274 steps/s (collection: 0.037s, learning 0.128s)
                       Mean reward: 874.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.2052
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7857
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 0.16s
                      Time elapsed: 00:20:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1037/1 [0m                       

                       Computation: 453448 steps/s (collection: 0.038s, learning 0.179s)
                       Mean reward: 874.55
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.7992
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 0.22s
                      Time elapsed: 00:20:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1038/1 [0m                       

                       Computation: 636615 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 878.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.8634
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7827
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 0.15s
                      Time elapsed: 00:20:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1039/1 [0m                       

                       Computation: 764740 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 874.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.8772
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7812
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 0.13s
                      Time elapsed: 00:20:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1040/1 [0m                       

                       Computation: 592588 steps/s (collection: 0.037s, learning 0.129s)
                       Mean reward: 876.54
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.5170
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 0.17s
                      Time elapsed: 00:20:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1041/1 [0m                       

                       Computation: 545896 steps/s (collection: 0.045s, learning 0.135s)
                       Mean reward: 868.70
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7437
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 0.18s
                      Time elapsed: 00:20:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1042/1 [0m                       

                       Computation: 591741 steps/s (collection: 0.040s, learning 0.126s)
                       Mean reward: 876.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8928
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7861
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 75.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 0.17s
                      Time elapsed: 00:20:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1043/1 [0m                       

                       Computation: 761846 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 884.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 176.2859
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.8041
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 0.13s
                      Time elapsed: 00:20:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1044/1 [0m                       

                       Computation: 580617 steps/s (collection: 0.042s, learning 0.127s)
                       Mean reward: 875.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9535
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7918
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 0.17s
                      Time elapsed: 00:20:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1045/1 [0m                       

                       Computation: 508232 steps/s (collection: 0.050s, learning 0.144s)
                       Mean reward: 875.18
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5018
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7826
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 0.19s
                      Time elapsed: 00:20:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1046/1 [0m                       

                       Computation: 567926 steps/s (collection: 0.052s, learning 0.122s)
                       Mean reward: 878.56
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.1502
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 0.17s
                      Time elapsed: 00:20:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1047/1 [0m                       

                       Computation: 707457 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 876.08
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2503
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7807
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 0.14s
                      Time elapsed: 00:20:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1048/1 [0m                       

                       Computation: 849719 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 869.70
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5110
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 0.12s
                      Time elapsed: 00:20:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1049/1 [0m                       

                       Computation: 722118 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 882.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.5044
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7812
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 0.14s
                      Time elapsed: 00:20:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1050/1 [0m                       

                       Computation: 740904 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 881.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.7402
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7901
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 0.13s
                      Time elapsed: 00:20:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1051/1 [0m                       

                       Computation: 893888 steps/s (collection: 0.034s, learning 0.076s)
                       Mean reward: 878.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.0284
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7871
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 0.11s
                      Time elapsed: 00:20:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1052/1 [0m                       

                       Computation: 874595 steps/s (collection: 0.035s, learning 0.077s)
                       Mean reward: 869.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2451
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7805
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 0.11s
                      Time elapsed: 00:20:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1053/1 [0m                       

                       Computation: 580177 steps/s (collection: 0.049s, learning 0.121s)
                       Mean reward: 853.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.1441
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 72.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 0.17s
                      Time elapsed: 00:20:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1054/1 [0m                       

                       Computation: 740223 steps/s (collection: 0.034s, learning 0.098s)
                       Mean reward: 873.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.1522
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 0.13s
                      Time elapsed: 00:20:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1055/1 [0m                       

                       Computation: 726878 steps/s (collection: 0.035s, learning 0.100s)
                       Mean reward: 867.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8844
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7790
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 0.14s
                      Time elapsed: 00:20:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1056/1 [0m                       

                       Computation: 820668 steps/s (collection: 0.034s, learning 0.086s)
                       Mean reward: 856.38
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5414
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 0.12s
                      Time elapsed: 00:20:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1057/1 [0m                       

                       Computation: 774762 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 861.46
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.3736
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7754
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 0.13s
                      Time elapsed: 00:20:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1058/1 [0m                       

                       Computation: 644619 steps/s (collection: 0.043s, learning 0.109s)
                       Mean reward: 869.17
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9448
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 0.15s
                      Time elapsed: 00:20:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1059/1 [0m                       

                       Computation: 640445 steps/s (collection: 0.057s, learning 0.096s)
                       Mean reward: 877.67
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8584
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7909
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 0.15s
                      Time elapsed: 00:20:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1060/1 [0m                       

                       Computation: 694145 steps/s (collection: 0.037s, learning 0.105s)
                       Mean reward: 863.26
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6843
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 0.14s
                      Time elapsed: 00:20:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1061/1 [0m                       

                       Computation: 520230 steps/s (collection: 0.059s, learning 0.130s)
                       Mean reward: 871.54
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0101
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7783
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 0.19s
                      Time elapsed: 00:20:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1062/1 [0m                       

                       Computation: 632400 steps/s (collection: 0.044s, learning 0.111s)
                       Mean reward: 861.95
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0901
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7796
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 0.16s
                      Time elapsed: 00:20:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1063/1 [0m                       

                       Computation: 736441 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 856.65
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.9628
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7554
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 74.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 0.13s
                      Time elapsed: 00:20:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1064/1 [0m                       

                       Computation: 688467 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 822.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 161.2044
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7129
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 0.14s
                      Time elapsed: 00:20:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1065/1 [0m                       

                       Computation: 599899 steps/s (collection: 0.040s, learning 0.124s)
                       Mean reward: 830.68
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.8626
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7195
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 0.16s
                      Time elapsed: 00:20:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1066/1 [0m                       

                       Computation: 688088 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 820.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.4530
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7178
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 0.14s
                      Time elapsed: 00:20:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1067/1 [0m                       

                       Computation: 576403 steps/s (collection: 0.041s, learning 0.130s)
                       Mean reward: 827.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.0378
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7133
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 0.17s
                      Time elapsed: 00:20:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1068/1 [0m                       

                       Computation: 545967 steps/s (collection: 0.056s, learning 0.125s)
                       Mean reward: 819.79
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.9272
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7157
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 0.18s
                      Time elapsed: 00:20:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1069/1 [0m                       

                       Computation: 558501 steps/s (collection: 0.047s, learning 0.129s)
                       Mean reward: 814.70
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.9231
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7169
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 0.18s
                      Time elapsed: 00:20:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1070/1 [0m                       

                       Computation: 341082 steps/s (collection: 0.055s, learning 0.234s)
                       Mean reward: 811.89
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.1968
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7137
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 0.29s
                      Time elapsed: 00:20:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1071/1 [0m                       

                       Computation: 731530 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 826.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.2764
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7237
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 0.13s
                      Time elapsed: 00:20:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1072/1 [0m                       

                       Computation: 845609 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 844.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.8606
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7338
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 0.12s
                      Time elapsed: 00:20:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1073/1 [0m                       

                       Computation: 753131 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 844.72
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.5045
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7396
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 77.0000
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 0.13s
                      Time elapsed: 00:20:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1074/1 [0m                       

                       Computation: 750264 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 810.11
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.6302
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7225
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 0.13s
                      Time elapsed: 00:20:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1075/1 [0m                       

                       Computation: 853066 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 840.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.1483
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 0.12s
                      Time elapsed: 00:20:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1076/1 [0m                       

                       Computation: 869727 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 858.39
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.0830
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 0.11s
                      Time elapsed: 00:20:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1077/1 [0m                       

                       Computation: 819231 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 865.11
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9654
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 0.12s
                      Time elapsed: 00:20:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1078/1 [0m                       

                       Computation: 814539 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 861.94
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4599
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 0.12s
                      Time elapsed: 00:20:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1079/1 [0m                       

                       Computation: 773467 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 869.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2403
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 0.13s
                      Time elapsed: 00:21:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1080/1 [0m                       

                       Computation: 767918 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 870.82
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6062
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7781
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 0.13s
                      Time elapsed: 00:21:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1081/1 [0m                       

                       Computation: 504971 steps/s (collection: 0.054s, learning 0.141s)
                       Mean reward: 872.43
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8393
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7778
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 0.19s
                      Time elapsed: 00:21:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1082/1 [0m                       

                       Computation: 437798 steps/s (collection: 0.069s, learning 0.156s)
                       Mean reward: 874.43
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7908
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 0.22s
                      Time elapsed: 00:21:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1083/1 [0m                       

                       Computation: 613264 steps/s (collection: 0.050s, learning 0.111s)
                       Mean reward: 860.57
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.1895
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 0.16s
                      Time elapsed: 00:21:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1084/1 [0m                       

                       Computation: 670836 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 875.38
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9276
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7792
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 73.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 0.15s
                      Time elapsed: 00:21:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1085/1 [0m                       

                       Computation: 730713 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 865.56
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.9181
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7790
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 0.13s
                      Time elapsed: 00:21:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1086/1 [0m                       

                       Computation: 688861 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 873.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8299
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 0.14s
                      Time elapsed: 00:21:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1087/1 [0m                       

                       Computation: 482956 steps/s (collection: 0.061s, learning 0.142s)
                       Mean reward: 864.83
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.4394
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7754
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 0.20s
                      Time elapsed: 00:21:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1088/1 [0m                       

                       Computation: 668105 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 871.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3197
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 0.15s
                      Time elapsed: 00:21:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1089/1 [0m                       

                       Computation: 566846 steps/s (collection: 0.038s, learning 0.135s)
                       Mean reward: 873.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0350
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7780
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 0.17s
                      Time elapsed: 00:21:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1090/1 [0m                       

                       Computation: 642646 steps/s (collection: 0.046s, learning 0.107s)
                       Mean reward: 880.81
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.4904
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7847
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 0.15s
                      Time elapsed: 00:21:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1091/1 [0m                       

                       Computation: 559485 steps/s (collection: 0.055s, learning 0.121s)
                       Mean reward: 872.78
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7888
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7784
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 0.18s
                      Time elapsed: 00:21:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1092/1 [0m                       

                       Computation: 558500 steps/s (collection: 0.037s, learning 0.140s)
                       Mean reward: 877.07
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.7935
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7807
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 0.18s
                      Time elapsed: 00:21:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1093/1 [0m                       

                       Computation: 630255 steps/s (collection: 0.038s, learning 0.118s)
                       Mean reward: 870.76
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.4092
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 0.16s
                      Time elapsed: 00:21:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1094/1 [0m                       

                       Computation: 477027 steps/s (collection: 0.047s, learning 0.160s)
                       Mean reward: 869.63
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.9433
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7696
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 75.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 0.21s
                      Time elapsed: 00:21:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1095/1 [0m                       

                       Computation: 561610 steps/s (collection: 0.059s, learning 0.116s)
                       Mean reward: 875.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.6940
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 0.18s
                      Time elapsed: 00:21:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1096/1 [0m                       

                       Computation: 528277 steps/s (collection: 0.048s, learning 0.138s)
                       Mean reward: 864.02
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0612
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 0.19s
                      Time elapsed: 00:21:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1097/1 [0m                       

                       Computation: 594103 steps/s (collection: 0.039s, learning 0.127s)
                       Mean reward: 873.41
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8951
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 0.17s
                      Time elapsed: 00:21:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1098/1 [0m                       

                       Computation: 748846 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 873.74
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0049
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7810
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 0.13s
                      Time elapsed: 00:21:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1099/1 [0m                       

                       Computation: 748355 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 877.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9700
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7893
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 0.13s
                      Time elapsed: 00:21:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1100/1 [0m                       

                       Computation: 753164 steps/s (collection: 0.035s, learning 0.096s)
                       Mean reward: 880.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.3210
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7871
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 0.13s
                      Time elapsed: 00:21:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1101/1 [0m                       

                       Computation: 823056 steps/s (collection: 0.033s, learning 0.086s)
                       Mean reward: 870.51
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8638
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 0.12s
                      Time elapsed: 00:21:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1102/1 [0m                       

                       Computation: 638148 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 857.94
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.3820
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7687
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 0.15s
                      Time elapsed: 00:21:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1103/1 [0m                       

                       Computation: 795792 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 869.68
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.3310
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 0.12s
                      Time elapsed: 00:21:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1104/1 [0m                       

                       Computation: 625819 steps/s (collection: 0.047s, learning 0.111s)
                       Mean reward: 875.03
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2092
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 0.16s
                      Time elapsed: 00:21:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1105/1 [0m                       

                       Computation: 779851 steps/s (collection: 0.034s, learning 0.092s)
                       Mean reward: 875.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.9956
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7773
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 71.9167
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 0.13s
                      Time elapsed: 00:21:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1106/1 [0m                       

                       Computation: 795013 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 854.85
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8954
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 0.12s
                      Time elapsed: 00:21:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1107/1 [0m                       

                       Computation: 785054 steps/s (collection: 0.034s, learning 0.092s)
                       Mean reward: 874.43
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0959
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 0.13s
                      Time elapsed: 00:21:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1108/1 [0m                       

                       Computation: 799416 steps/s (collection: 0.033s, learning 0.090s)
                       Mean reward: 865.84
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.9354
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 0.12s
                      Time elapsed: 00:21:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1109/1 [0m                       

                       Computation: 766110 steps/s (collection: 0.035s, learning 0.093s)
                       Mean reward: 868.52
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9987
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 0.13s
                      Time elapsed: 00:21:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1110/1 [0m                       

                       Computation: 728123 steps/s (collection: 0.035s, learning 0.100s)
                       Mean reward: 856.72
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9666
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 0.14s
                      Time elapsed: 00:21:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1111/1 [0m                       

                       Computation: 730568 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 866.65
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3437
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 0.13s
                      Time elapsed: 00:21:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1112/1 [0m                       

                       Computation: 441087 steps/s (collection: 0.042s, learning 0.181s)
                       Mean reward: 872.12
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.1907
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7610
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 0.22s
                      Time elapsed: 00:21:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1113/1 [0m                       

                       Computation: 733256 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 866.77
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.3932
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7543
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 0.13s
                      Time elapsed: 00:21:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1114/1 [0m                       

                       Computation: 798616 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 868.51
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8899
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 0.12s
                      Time elapsed: 00:21:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1115/1 [0m                       

                       Computation: 694243 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 869.67
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.3100
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7561
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 74.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 0.14s
                      Time elapsed: 00:21:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1116/1 [0m                       

                       Computation: 650347 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 848.95
               Mean episode length: 244.84
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.7441
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7523
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 0.15s
                      Time elapsed: 00:21:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1117/1 [0m                       

                       Computation: 719940 steps/s (collection: 0.034s, learning 0.103s)
                       Mean reward: 875.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5367
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 0.14s
                      Time elapsed: 00:21:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1118/1 [0m                       

                       Computation: 744042 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 878.61
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8875
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7850
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 0.13s
                      Time elapsed: 00:21:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1119/1 [0m                       

                       Computation: 725151 steps/s (collection: 0.045s, learning 0.091s)
                       Mean reward: 874.53
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5080
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7852
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 0.14s
                      Time elapsed: 00:21:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1120/1 [0m                       

                       Computation: 761752 steps/s (collection: 0.035s, learning 0.095s)
                       Mean reward: 866.48
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8393
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 0.13s
                      Time elapsed: 00:21:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1121/1 [0m                       

                       Computation: 730503 steps/s (collection: 0.035s, learning 0.099s)
                       Mean reward: 864.62
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0565
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 0.13s
                      Time elapsed: 00:21:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1122/1 [0m                       

                       Computation: 750442 steps/s (collection: 0.035s, learning 0.096s)
                       Mean reward: 869.00
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3168
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 0.13s
                      Time elapsed: 00:21:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1123/1 [0m                       

                       Computation: 802041 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 869.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3410
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 0.12s
                      Time elapsed: 00:21:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1124/1 [0m                       

                       Computation: 798856 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 877.16
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4398
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 0.12s
                      Time elapsed: 00:21:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1125/1 [0m                       

                       Computation: 595184 steps/s (collection: 0.043s, learning 0.122s)
                       Mean reward: 872.22
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5580
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.7715
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 76.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 0.17s
                      Time elapsed: 00:21:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1126/1 [0m                       

                       Computation: 761603 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 865.30
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6717
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7866
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 0.13s
                      Time elapsed: 00:21:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1127/1 [0m                       

                       Computation: 659237 steps/s (collection: 0.038s, learning 0.112s)
                       Mean reward: 867.52
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7548
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 0.15s
                      Time elapsed: 00:21:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1128/1 [0m                       

                       Computation: 798523 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 871.03
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3616
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 0.12s
                      Time elapsed: 00:21:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1129/1 [0m                       

                       Computation: 795640 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 881.19
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.6296
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 0.12s
                      Time elapsed: 00:21:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1130/1 [0m                       

                       Computation: 791922 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 879.10
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.0334
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7742
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 0.12s
                      Time elapsed: 00:21:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1131/1 [0m                       

                       Computation: 670709 steps/s (collection: 0.036s, learning 0.110s)
                       Mean reward: 873.03
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7134
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 0.15s
                      Time elapsed: 00:21:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1132/1 [0m                       

                       Computation: 711157 steps/s (collection: 0.035s, learning 0.104s)
                       Mean reward: 876.77
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5165
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7796
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 0.14s
                      Time elapsed: 00:21:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1133/1 [0m                       

                       Computation: 786324 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 875.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3585
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 0.13s
                      Time elapsed: 00:21:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1134/1 [0m                       

                       Computation: 646333 steps/s (collection: 0.045s, learning 0.107s)
                       Mean reward: 873.47
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.6636
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7755
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 0.15s
                      Time elapsed: 00:22:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1135/1 [0m                       

                       Computation: 786154 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 877.66
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9448
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 0.13s
                      Time elapsed: 00:22:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1136/1 [0m                       

                       Computation: 582079 steps/s (collection: 0.053s, learning 0.116s)
                       Mean reward: 877.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.3279
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 72.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 0.17s
                      Time elapsed: 00:22:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1137/1 [0m                       

                       Computation: 532288 steps/s (collection: 0.045s, learning 0.140s)
                       Mean reward: 857.09
               Mean episode length: 246.03
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.1877
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 0.18s
                      Time elapsed: 00:22:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1138/1 [0m                       

                       Computation: 553276 steps/s (collection: 0.053s, learning 0.125s)
                       Mean reward: 872.23
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.6427
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 0.18s
                      Time elapsed: 00:22:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1139/1 [0m                       

                       Computation: 689219 steps/s (collection: 0.054s, learning 0.089s)
                       Mean reward: 871.20
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3172
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 0.14s
                      Time elapsed: 00:22:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1140/1 [0m                       

                       Computation: 666407 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 873.45
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8588
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 0.15s
                      Time elapsed: 00:22:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1141/1 [0m                       

                       Computation: 707649 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 874.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2296
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 0.14s
                      Time elapsed: 00:22:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1142/1 [0m                       

                       Computation: 574605 steps/s (collection: 0.045s, learning 0.126s)
                       Mean reward: 867.76
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6685
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 0.17s
                      Time elapsed: 00:22:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1143/1 [0m                       

                       Computation: 553632 steps/s (collection: 0.041s, learning 0.137s)
                       Mean reward: 871.97
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.5056
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 0.18s
                      Time elapsed: 00:22:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1144/1 [0m                       

                       Computation: 794069 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 862.75
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.0825
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 0.12s
                      Time elapsed: 00:22:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1145/1 [0m                       

                       Computation: 729377 steps/s (collection: 0.037s, learning 0.097s)
                       Mean reward: 863.31
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.0042
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7771
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 0.13s
                      Time elapsed: 00:22:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1146/1 [0m                       

                       Computation: 696974 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 869.95
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.9070
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 75.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 0.14s
                      Time elapsed: 00:22:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1147/1 [0m                       

                       Computation: 823064 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 855.87
               Mean episode length: 246.13
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.4775
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 0.12s
                      Time elapsed: 00:22:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1148/1 [0m                       

                       Computation: 797623 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 852.52
               Mean episode length: 246.37
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.4507
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7564
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 0.12s
                      Time elapsed: 00:22:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1149/1 [0m                       

                       Computation: 829255 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 859.50
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6798
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 0.12s
                      Time elapsed: 00:22:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1150/1 [0m                       

                       Computation: 865784 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 856.97
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.6179
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 0.11s
                      Time elapsed: 00:22:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1151/1 [0m                       

                       Computation: 725223 steps/s (collection: 0.036s, learning 0.100s)
                       Mean reward: 861.51
               Mean episode length: 248.42
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1913
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7643
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 0.14s
                      Time elapsed: 00:22:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1152/1 [0m                       

                       Computation: 736540 steps/s (collection: 0.035s, learning 0.098s)
                       Mean reward: 862.92
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6293
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7651
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 0.13s
                      Time elapsed: 00:22:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1153/1 [0m                       

                       Computation: 863830 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 866.40
               Mean episode length: 248.17
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4521
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 0.11s
                      Time elapsed: 00:22:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1154/1 [0m                       

                       Computation: 901917 steps/s (collection: 0.034s, learning 0.075s)
                       Mean reward: 864.79
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.3319
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7758
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 0.11s
                      Time elapsed: 00:22:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1155/1 [0m                       

                       Computation: 814895 steps/s (collection: 0.035s, learning 0.086s)
                       Mean reward: 864.76
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.9665
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 0.12s
                      Time elapsed: 00:22:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1156/1 [0m                       

                       Computation: 731725 steps/s (collection: 0.034s, learning 0.101s)
                       Mean reward: 845.64
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.3198
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 0.13s
                      Time elapsed: 00:22:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1157/1 [0m                       

                       Computation: 873893 steps/s (collection: 0.035s, learning 0.077s)
                       Mean reward: 856.18
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.7340
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 71.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 0.11s
                      Time elapsed: 00:22:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1158/1 [0m                       

                       Computation: 752629 steps/s (collection: 0.035s, learning 0.096s)
                       Mean reward: 823.38
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.7260
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 0.13s
                      Time elapsed: 00:22:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1159/1 [0m                       

                       Computation: 718035 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 856.19
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1077
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7709
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 0.14s
                      Time elapsed: 00:22:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1160/1 [0m                       

                       Computation: 692257 steps/s (collection: 0.036s, learning 0.106s)
                       Mean reward: 862.82
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.0133
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 0.14s
                      Time elapsed: 00:22:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1161/1 [0m                       

                       Computation: 763834 steps/s (collection: 0.035s, learning 0.093s)
                       Mean reward: 856.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6408
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 0.13s
                      Time elapsed: 00:22:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1162/1 [0m                       

                       Computation: 623750 steps/s (collection: 0.045s, learning 0.113s)
                       Mean reward: 871.50
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8738
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7773
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 0.16s
                      Time elapsed: 00:22:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1163/1 [0m                       

                       Computation: 737469 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 860.97
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5062
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 0.13s
                      Time elapsed: 00:22:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1164/1 [0m                       

                       Computation: 750293 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 851.90
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.6762
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7634
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 0.13s
                      Time elapsed: 00:22:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1165/1 [0m                       

                       Computation: 752002 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 862.42
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.1504
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7875
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 0.13s
                      Time elapsed: 00:22:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1166/1 [0m                       

                       Computation: 679092 steps/s (collection: 0.036s, learning 0.109s)
                       Mean reward: 870.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.4627
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7831
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 0.14s
                      Time elapsed: 00:22:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1167/1 [0m                       

                       Computation: 686292 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 871.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0930
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 73.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 0.14s
                      Time elapsed: 00:22:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1168/1 [0m                       

                       Computation: 730280 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 879.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.2921
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 0.13s
                      Time elapsed: 00:22:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1169/1 [0m                       

                       Computation: 721065 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 870.11
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7608
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7859
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 0.14s
                      Time elapsed: 00:22:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1170/1 [0m                       

                       Computation: 773107 steps/s (collection: 0.035s, learning 0.092s)
                       Mean reward: 858.07
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1270
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 0.13s
                      Time elapsed: 00:22:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1171/1 [0m                       

                       Computation: 655278 steps/s (collection: 0.048s, learning 0.103s)
                       Mean reward: 861.23
               Mean episode length: 248.28
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6515
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 0.15s
                      Time elapsed: 00:22:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1172/1 [0m                       

                       Computation: 849801 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 868.83
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.5450
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7810
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 0.12s
                      Time elapsed: 00:22:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1173/1 [0m                       

                       Computation: 687300 steps/s (collection: 0.036s, learning 0.108s)
                       Mean reward: 880.10
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.3106
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7914
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 0.14s
                      Time elapsed: 00:22:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1174/1 [0m                       

                       Computation: 808332 steps/s (collection: 0.034s, learning 0.087s)
                       Mean reward: 870.35
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3817
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7835
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 0.12s
                      Time elapsed: 00:22:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1175/1 [0m                       

                       Computation: 593820 steps/s (collection: 0.045s, learning 0.121s)
                       Mean reward: 878.27
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5598
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7963
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 0.17s
                      Time elapsed: 00:22:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1176/1 [0m                       

                       Computation: 709551 steps/s (collection: 0.035s, learning 0.103s)
                       Mean reward: 874.07
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9880
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7813
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 0.14s
                      Time elapsed: 00:22:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1177/1 [0m                       

                       Computation: 713086 steps/s (collection: 0.036s, learning 0.102s)
                       Mean reward: 876.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3474
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7870
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 0.14s
                      Time elapsed: 00:22:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1178/1 [0m                       

                       Computation: 526032 steps/s (collection: 0.041s, learning 0.146s)
                       Mean reward: 872.89
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5246
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7913
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 69.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 0.19s
                      Time elapsed: 00:22:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1179/1 [0m                       

                       Computation: 627899 steps/s (collection: 0.037s, learning 0.119s)
                       Mean reward: 882.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.8151
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.8022
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 0.16s
                      Time elapsed: 00:22:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1180/1 [0m                       

                       Computation: 592245 steps/s (collection: 0.038s, learning 0.128s)
                       Mean reward: 874.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3319
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7907
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 0.17s
                      Time elapsed: 00:22:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1181/1 [0m                       

                       Computation: 550015 steps/s (collection: 0.040s, learning 0.139s)
                       Mean reward: 878.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.8195
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7987
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 0.18s
                      Time elapsed: 00:22:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1182/1 [0m                       

                       Computation: 832845 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 865.47
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3939
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 0.12s
                      Time elapsed: 00:22:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1183/1 [0m                       

                       Computation: 644449 steps/s (collection: 0.045s, learning 0.108s)
                       Mean reward: 870.66
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5168
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 0.15s
                      Time elapsed: 00:22:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1184/1 [0m                       

                       Computation: 588736 steps/s (collection: 0.048s, learning 0.119s)
                       Mean reward: 877.92
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5904
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7885
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 0.17s
                      Time elapsed: 00:22:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1185/1 [0m                       

                       Computation: 738858 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 876.34
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5599
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7992
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 0.13s
                      Time elapsed: 00:22:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1186/1 [0m                       

                       Computation: 623102 steps/s (collection: 0.058s, learning 0.100s)
                       Mean reward: 875.17
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0210
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7926
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 0.16s
                      Time elapsed: 00:22:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1187/1 [0m                       

                       Computation: 627667 steps/s (collection: 0.049s, learning 0.108s)
                       Mean reward: 875.73
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3492
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7933
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 0.16s
                      Time elapsed: 00:22:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1188/1 [0m                       

                       Computation: 771907 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 870.09
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.0507
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7906
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 71.7083
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 0.13s
                      Time elapsed: 00:22:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1189/1 [0m                       

                       Computation: 547388 steps/s (collection: 0.060s, learning 0.120s)
                       Mean reward: 847.38
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.4309
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 0.18s
                      Time elapsed: 00:22:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1190/1 [0m                       

                       Computation: 568595 steps/s (collection: 0.038s, learning 0.135s)
                       Mean reward: 851.64
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3656
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 0.17s
                      Time elapsed: 00:23:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1191/1 [0m                       

                       Computation: 571697 steps/s (collection: 0.054s, learning 0.118s)
                       Mean reward: 842.35
               Mean episode length: 247.11
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.0131
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 0.17s
                      Time elapsed: 00:23:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1192/1 [0m                       

                       Computation: 441369 steps/s (collection: 0.059s, learning 0.164s)
                       Mean reward: 848.17
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.9639
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7733
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 0.22s
                      Time elapsed: 00:23:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1193/1 [0m                       

                       Computation: 375867 steps/s (collection: 0.049s, learning 0.212s)
                       Mean reward: 867.55
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.4048
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7855
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 0.26s
                      Time elapsed: 00:23:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1194/1 [0m                       

                       Computation: 485365 steps/s (collection: 0.054s, learning 0.149s)
                       Mean reward: 865.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.0450
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7896
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 0.20s
                      Time elapsed: 00:23:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1195/1 [0m                       

                       Computation: 433592 steps/s (collection: 0.061s, learning 0.166s)
                       Mean reward: 877.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8104
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7924
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 0.23s
                      Time elapsed: 00:23:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1196/1 [0m                       

                       Computation: 547508 steps/s (collection: 0.063s, learning 0.117s)
                       Mean reward: 868.67
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5014
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7840
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 0.18s
                      Time elapsed: 00:23:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1197/1 [0m                       

                       Computation: 513205 steps/s (collection: 0.049s, learning 0.143s)
                       Mean reward: 871.87
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8875
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7873
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 0.19s
                      Time elapsed: 00:23:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1198/1 [0m                       

                       Computation: 556851 steps/s (collection: 0.049s, learning 0.128s)
                       Mean reward: 861.91
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.5810
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7834
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 74.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 0.18s
                      Time elapsed: 00:23:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1199/1 [0m                       

                       Computation: 374166 steps/s (collection: 0.077s, learning 0.186s)
                       Mean reward: 843.73
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 161.4750
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7467
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 0.26s
                      Time elapsed: 00:23:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1200/1 [0m                       

                       Computation: 383953 steps/s (collection: 0.077s, learning 0.179s)
                       Mean reward: 856.42
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.5866
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 0.26s
                      Time elapsed: 00:23:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1201/1 [0m                       

                       Computation: 537336 steps/s (collection: 0.049s, learning 0.133s)
                       Mean reward: 867.91
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8019
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7844
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 0.18s
                      Time elapsed: 00:23:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1202/1 [0m                       

                       Computation: 438712 steps/s (collection: 0.047s, learning 0.178s)
                       Mean reward: 868.81
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1536
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 0.22s
                      Time elapsed: 00:23:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1203/1 [0m                       

                       Computation: 410632 steps/s (collection: 0.069s, learning 0.170s)
                       Mean reward: 870.79
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1993
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 0.24s
                      Time elapsed: 00:23:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1204/1 [0m                       

                       Computation: 439793 steps/s (collection: 0.053s, learning 0.171s)
                       Mean reward: 874.86
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.9423
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 0.22s
                      Time elapsed: 00:23:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1205/1 [0m                       

                       Computation: 258848 steps/s (collection: 0.110s, learning 0.269s)
                       Mean reward: 865.91
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8382
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 0.38s
                      Time elapsed: 00:23:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1206/1 [0m                       

                       Computation: 421283 steps/s (collection: 0.061s, learning 0.172s)
                       Mean reward: 866.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5346
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7716
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 0.23s
                      Time elapsed: 00:23:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1207/1 [0m                       

                       Computation: 479841 steps/s (collection: 0.053s, learning 0.152s)
                       Mean reward: 858.61
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.6336
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7634
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 0.20s
                      Time elapsed: 00:23:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1208/1 [0m                       

                       Computation: 476859 steps/s (collection: 0.056s, learning 0.151s)
                       Mean reward: 873.61
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0215
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 0.21s
                      Time elapsed: 00:23:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1209/1 [0m                       

                       Computation: 705843 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 869.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9021
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7876
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 70.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 0.14s
                      Time elapsed: 00:23:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1210/1 [0m                       

                       Computation: 733156 steps/s (collection: 0.035s, learning 0.099s)
                       Mean reward: 866.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4570
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7879
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 0.13s
                      Time elapsed: 00:23:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1211/1 [0m                       

                       Computation: 787549 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 865.21
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.2529
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7868
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 0.12s
                      Time elapsed: 00:23:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1212/1 [0m                       

                       Computation: 407757 steps/s (collection: 0.062s, learning 0.179s)
                       Mean reward: 867.75
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1691
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7883
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 0.24s
                      Time elapsed: 00:23:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1213/1 [0m                       

                       Computation: 721132 steps/s (collection: 0.045s, learning 0.091s)
                       Mean reward: 870.60
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5223
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7884
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 0.14s
                      Time elapsed: 00:23:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1214/1 [0m                       

                       Computation: 736710 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 855.15
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.5875
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7703
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 0.13s
                      Time elapsed: 00:23:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1215/1 [0m                       

                       Computation: 367601 steps/s (collection: 0.056s, learning 0.211s)
                       Mean reward: 871.86
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4388
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7833
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 0.27s
                      Time elapsed: 00:23:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1216/1 [0m                       

                       Computation: 358327 steps/s (collection: 0.073s, learning 0.202s)
                       Mean reward: 865.01
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.0290
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 0.27s
                      Time elapsed: 00:23:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1217/1 [0m                       

                       Computation: 408270 steps/s (collection: 0.053s, learning 0.188s)
                       Mean reward: 864.93
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3276
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 0.24s
                      Time elapsed: 00:23:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1218/1 [0m                       

                       Computation: 371344 steps/s (collection: 0.099s, learning 0.166s)
                       Mean reward: 872.61
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8551
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 0.26s
                      Time elapsed: 00:23:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1219/1 [0m                       

                       Computation: 413003 steps/s (collection: 0.065s, learning 0.174s)
                       Mean reward: 871.61
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6320
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7910
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 72.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 0.24s
                      Time elapsed: 00:23:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1220/1 [0m                       

                       Computation: 443192 steps/s (collection: 0.049s, learning 0.173s)
                       Mean reward: 846.06
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0559
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 0.22s
                      Time elapsed: 00:23:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1221/1 [0m                       

                       Computation: 469126 steps/s (collection: 0.066s, learning 0.144s)
                       Mean reward: 860.28
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0899
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7669
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 0.21s
                      Time elapsed: 00:23:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1222/1 [0m                       

                       Computation: 462487 steps/s (collection: 0.065s, learning 0.148s)
                       Mean reward: 857.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6284
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 0.21s
                      Time elapsed: 00:23:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1223/1 [0m                       

                       Computation: 422742 steps/s (collection: 0.061s, learning 0.172s)
                       Mean reward: 853.57
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7834
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 0.23s
                      Time elapsed: 00:23:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1224/1 [0m                       

                       Computation: 381043 steps/s (collection: 0.060s, learning 0.198s)
                       Mean reward: 853.38
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.4482
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7608
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 0.26s
                      Time elapsed: 00:23:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1225/1 [0m                       

                       Computation: 514558 steps/s (collection: 0.050s, learning 0.142s)
                       Mean reward: 873.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.1033
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 0.19s
                      Time elapsed: 00:23:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1226/1 [0m                       

                       Computation: 502877 steps/s (collection: 0.050s, learning 0.146s)
                       Mean reward: 875.81
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8912
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7929
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 0.20s
                      Time elapsed: 00:23:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1227/1 [0m                       

                       Computation: 454922 steps/s (collection: 0.073s, learning 0.143s)
                       Mean reward: 866.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6522
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7873
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 0.22s
                      Time elapsed: 00:23:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1228/1 [0m                       

                       Computation: 414312 steps/s (collection: 0.057s, learning 0.181s)
                       Mean reward: 866.41
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.9696
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7942
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 0.24s
                      Time elapsed: 00:24:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1229/1 [0m                       

                       Computation: 485280 steps/s (collection: 0.060s, learning 0.143s)
                       Mean reward: 876.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.4517
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7992
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 0.20s
                      Time elapsed: 00:24:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1230/1 [0m                       

                       Computation: 472013 steps/s (collection: 0.056s, learning 0.153s)
                       Mean reward: 875.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 163.3310
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 69.0417
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 0.21s
                      Time elapsed: 00:24:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1231/1 [0m                       

                       Computation: 449853 steps/s (collection: 0.049s, learning 0.170s)
                       Mean reward: 870.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2451
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7968
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 0.22s
                      Time elapsed: 00:24:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1232/1 [0m                       

                       Computation: 305926 steps/s (collection: 0.097s, learning 0.225s)
                       Mean reward: 866.52
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1352
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7901
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 0.32s
                      Time elapsed: 00:24:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1233/1 [0m                       

                       Computation: 535197 steps/s (collection: 0.055s, learning 0.129s)
                       Mean reward: 874.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0586
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7928
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 0.18s
                      Time elapsed: 00:24:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1234/1 [0m                       

                       Computation: 449516 steps/s (collection: 0.058s, learning 0.161s)
                       Mean reward: 873.25
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0207
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7916
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 0.22s
                      Time elapsed: 00:24:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1235/1 [0m                       

                       Computation: 722845 steps/s (collection: 0.036s, learning 0.100s)
                       Mean reward: 879.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.1004
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7959
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 0.14s
                      Time elapsed: 00:24:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1236/1 [0m                       

                       Computation: 435332 steps/s (collection: 0.044s, learning 0.182s)
                       Mean reward: 860.05
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.5188
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 0.23s
                      Time elapsed: 00:24:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1237/1 [0m                       

                       Computation: 670553 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 877.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8931
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7930
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 0.15s
                      Time elapsed: 00:24:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1238/1 [0m                       

                       Computation: 672452 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 862.18
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7099
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7826
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 0.15s
                      Time elapsed: 00:24:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1239/1 [0m                       

                       Computation: 821153 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 873.27
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8556
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7935
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 0.12s
                      Time elapsed: 00:24:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1240/1 [0m                       

                       Computation: 769204 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 875.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9852
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7932
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 71.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 0.13s
                      Time elapsed: 00:24:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1241/1 [0m                       

                       Computation: 730538 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 865.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.2560
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7801
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 0.13s
                      Time elapsed: 00:24:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1242/1 [0m                       

                       Computation: 798151 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 874.21
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8326
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7973
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 0.12s
                      Time elapsed: 00:24:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1243/1 [0m                       

                       Computation: 511443 steps/s (collection: 0.052s, learning 0.141s)
                       Mean reward: 868.41
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3401
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7840
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 0.19s
                      Time elapsed: 00:24:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1244/1 [0m                       

                       Computation: 544724 steps/s (collection: 0.054s, learning 0.127s)
                       Mean reward: 867.63
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.4733
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7839
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 0.18s
                      Time elapsed: 00:24:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1245/1 [0m                       

                       Computation: 705723 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 861.76
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4174
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 0.14s
                      Time elapsed: 00:24:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1246/1 [0m                       

                       Computation: 799669 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 861.78
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.7201
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 0.12s
                      Time elapsed: 00:24:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1247/1 [0m                       

                       Computation: 422742 steps/s (collection: 0.039s, learning 0.194s)
                       Mean reward: 864.43
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3354
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7791
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 0.23s
                      Time elapsed: 00:24:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1248/1 [0m                       

                       Computation: 571245 steps/s (collection: 0.042s, learning 0.131s)
                       Mean reward: 876.51
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3533
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7881
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 0.17s
                      Time elapsed: 00:24:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1249/1 [0m                       

                       Computation: 463243 steps/s (collection: 0.036s, learning 0.176s)
                       Mean reward: 879.12
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.0099
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7865
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 0.21s
                      Time elapsed: 00:24:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1250/1 [0m                       

                       Computation: 487133 steps/s (collection: 0.054s, learning 0.148s)
                       Mean reward: 851.83
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.0540
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7564
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 73.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 0.20s
                      Time elapsed: 00:24:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1251/1 [0m                       

                       Computation: 677181 steps/s (collection: 0.047s, learning 0.099s)
                       Mean reward: 828.35
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.6358
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7427
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 0.15s
                      Time elapsed: 00:24:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1252/1 [0m                       

                       Computation: 551644 steps/s (collection: 0.044s, learning 0.135s)
                       Mean reward: 854.07
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.0573
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7426
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 0.18s
                      Time elapsed: 00:24:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1253/1 [0m                       

                       Computation: 433806 steps/s (collection: 0.045s, learning 0.182s)
                       Mean reward: 840.09
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.5132
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7383
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 0.23s
                      Time elapsed: 00:24:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1254/1 [0m                       

                       Computation: 749592 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 834.81
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.4678
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7332
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 0.13s
                      Time elapsed: 00:24:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1255/1 [0m                       

                       Computation: 636563 steps/s (collection: 0.056s, learning 0.098s)
                       Mean reward: 861.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4546
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 0.15s
                      Time elapsed: 00:24:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1256/1 [0m                       

                       Computation: 847492 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 874.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.1273
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 0.12s
                      Time elapsed: 00:24:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1257/1 [0m                       

                       Computation: 752282 steps/s (collection: 0.035s, learning 0.096s)
                       Mean reward: 865.22
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3313
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 0.13s
                      Time elapsed: 00:24:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1258/1 [0m                       

                       Computation: 792793 steps/s (collection: 0.034s, learning 0.089s)
                       Mean reward: 868.72
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.4038
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 0.12s
                      Time elapsed: 00:24:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1259/1 [0m                       

                       Computation: 593340 steps/s (collection: 0.050s, learning 0.116s)
                       Mean reward: 860.91
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7733
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7804
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 0.17s
                      Time elapsed: 00:24:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1260/1 [0m                       

                       Computation: 677604 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 878.21
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.0279
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7945
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 0.15s
                      Time elapsed: 00:24:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1261/1 [0m                       

                       Computation: 604470 steps/s (collection: 0.039s, learning 0.124s)
                       Mean reward: 870.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 176.3312
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.8057
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 69.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 0.16s
                      Time elapsed: 00:24:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1262/1 [0m                       

                       Computation: 586832 steps/s (collection: 0.047s, learning 0.121s)
                       Mean reward: 873.56
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4789
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.8004
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 0.17s
                      Time elapsed: 00:24:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1263/1 [0m                       

                       Computation: 703401 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 875.08
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9411
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7882
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 0.14s
                      Time elapsed: 00:24:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1264/1 [0m                       

                       Computation: 780721 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 860.50
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.0289
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7920
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 0.13s
                      Time elapsed: 00:24:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1265/1 [0m                       

                       Computation: 630650 steps/s (collection: 0.044s, learning 0.112s)
                       Mean reward: 872.61
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.1408
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7930
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 0.16s
                      Time elapsed: 00:24:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1266/1 [0m                       

                       Computation: 764287 steps/s (collection: 0.035s, learning 0.093s)
                       Mean reward: 865.25
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.9770
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7920
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 0.13s
                      Time elapsed: 00:24:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1267/1 [0m                       

                       Computation: 758239 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 871.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7342
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7884
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 0.13s
                      Time elapsed: 00:24:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1268/1 [0m                       

                       Computation: 665623 steps/s (collection: 0.036s, learning 0.111s)
                       Mean reward: 869.46
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0429
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7916
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 0.15s
                      Time elapsed: 00:24:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1269/1 [0m                       

                       Computation: 542087 steps/s (collection: 0.043s, learning 0.139s)
                       Mean reward: 881.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.6341
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7972
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 0.18s
                      Time elapsed: 00:24:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1270/1 [0m                       

                       Computation: 565560 steps/s (collection: 0.050s, learning 0.124s)
                       Mean reward: 881.07
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.5150
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7945
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 0.17s
                      Time elapsed: 00:24:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1271/1 [0m                       

                       Computation: 737042 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 848.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7745
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 71.8333
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 0.13s
                      Time elapsed: 00:24:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1272/1 [0m                       

                       Computation: 636478 steps/s (collection: 0.040s, learning 0.115s)
                       Mean reward: 827.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.0227
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7558
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 0.15s
                      Time elapsed: 00:24:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1273/1 [0m                       

                       Computation: 745385 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 846.48
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.1435
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 0.13s
                      Time elapsed: 00:24:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1274/1 [0m                       

                       Computation: 809515 steps/s (collection: 0.036s, learning 0.086s)
                       Mean reward: 860.89
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.4056
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 0.12s
                      Time elapsed: 00:24:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1275/1 [0m                       

                       Computation: 733615 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 875.26
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5926
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7896
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 0.13s
                      Time elapsed: 00:24:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1276/1 [0m                       

                       Computation: 591439 steps/s (collection: 0.058s, learning 0.108s)
                       Mean reward: 873.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.1309
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 0.17s
                      Time elapsed: 00:24:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1277/1 [0m                       

                       Computation: 530871 steps/s (collection: 0.055s, learning 0.130s)
                       Mean reward: 874.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2026
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7905
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 0.19s
                      Time elapsed: 00:25:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1278/1 [0m                       

                       Computation: 633367 steps/s (collection: 0.039s, learning 0.117s)
                       Mean reward: 863.85
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.2890
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 0.16s
                      Time elapsed: 00:25:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1279/1 [0m                       

                       Computation: 313354 steps/s (collection: 0.051s, learning 0.263s)
                       Mean reward: 878.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.7922
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7858
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 0.31s
                      Time elapsed: 00:25:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1280/1 [0m                       

                       Computation: 583789 steps/s (collection: 0.042s, learning 0.126s)
                       Mean reward: 865.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1111
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 0.17s
                      Time elapsed: 00:25:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1281/1 [0m                       

                       Computation: 477098 steps/s (collection: 0.061s, learning 0.146s)
                       Mean reward: 872.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.9273
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7959
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 0.21s
                      Time elapsed: 00:25:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1282/1 [0m                       

                       Computation: 790133 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 874.20
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.1961
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7942
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 68.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 0.12s
                      Time elapsed: 00:25:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1283/1 [0m                       

                       Computation: 812386 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 875.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.7935
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7987
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 0.12s
                      Time elapsed: 00:25:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1284/1 [0m                       

                       Computation: 796172 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 864.15
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4105
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 0.12s
                      Time elapsed: 00:25:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1285/1 [0m                       

                       Computation: 799057 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 874.15
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0064
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7947
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 0.12s
                      Time elapsed: 00:25:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1286/1 [0m                       

                       Computation: 569003 steps/s (collection: 0.038s, learning 0.135s)
                       Mean reward: 875.41
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3305
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7932
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 0.17s
                      Time elapsed: 00:25:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1287/1 [0m                       

                       Computation: 417298 steps/s (collection: 0.062s, learning 0.174s)
                       Mean reward: 876.47
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.4514
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7997
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 0.24s
                      Time elapsed: 00:25:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1288/1 [0m                       

                       Computation: 547981 steps/s (collection: 0.043s, learning 0.136s)
                       Mean reward: 877.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6074
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.8013
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 0.18s
                      Time elapsed: 00:25:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1289/1 [0m                       

                       Computation: 689577 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 875.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0017
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5094
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7909
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 0.14s
                      Time elapsed: 00:25:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1290/1 [0m                       

                       Computation: 739997 steps/s (collection: 0.036s, learning 0.097s)
                       Mean reward: 870.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8038
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7895
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 0.13s
                      Time elapsed: 00:25:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1291/1 [0m                       

                       Computation: 627802 steps/s (collection: 0.042s, learning 0.114s)
                       Mean reward: 874.34
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2048
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7898
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 0.16s
                      Time elapsed: 00:25:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1292/1 [0m                       

                       Computation: 738980 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 876.94
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.9585
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7922
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 70.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 0.13s
                      Time elapsed: 00:25:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1293/1 [0m                       

                       Computation: 775820 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 873.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.1891
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7876
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 0.13s
                      Time elapsed: 00:25:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1294/1 [0m                       

                       Computation: 764649 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 869.97
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4544
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7918
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 0.13s
                      Time elapsed: 00:25:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1295/1 [0m                       

                       Computation: 531112 steps/s (collection: 0.047s, learning 0.138s)
                       Mean reward: 876.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.4007
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7868
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 0.19s
                      Time elapsed: 00:25:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1296/1 [0m                       

                       Computation: 406320 steps/s (collection: 0.055s, learning 0.187s)
                       Mean reward: 877.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.8553
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7964
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 0.24s
                      Time elapsed: 00:25:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1297/1 [0m                       

                       Computation: 403914 steps/s (collection: 0.068s, learning 0.175s)
                       Mean reward: 864.43
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3253
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 0.24s
                      Time elapsed: 00:25:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1298/1 [0m                       

                       Computation: 407856 steps/s (collection: 0.061s, learning 0.180s)
                       Mean reward: 875.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3268
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7922
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 0.24s
                      Time elapsed: 00:25:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1299/1 [0m                       

                       Computation: 525048 steps/s (collection: 0.045s, learning 0.143s)
                       Mean reward: 873.98
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2340
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7869
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 0.19s
                      Time elapsed: 00:25:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1300/1 [0m                       

                       Computation: 401077 steps/s (collection: 0.081s, learning 0.164s)
                       Mean reward: 867.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.0501
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7869
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 0.25s
                      Time elapsed: 00:25:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1301/1 [0m                       

                       Computation: 576467 steps/s (collection: 0.054s, learning 0.117s)
                       Mean reward: 871.61
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5215
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7897
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 0.17s
                      Time elapsed: 00:25:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1302/1 [0m                       

                       Computation: 556905 steps/s (collection: 0.050s, learning 0.127s)
                       Mean reward: 879.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.1903
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7938
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 0.18s
                      Time elapsed: 00:25:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1303/1 [0m                       

                       Computation: 601165 steps/s (collection: 0.046s, learning 0.118s)
                       Mean reward: 874.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7526
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 67.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 0.16s
                      Time elapsed: 00:25:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1304/1 [0m                       

                       Computation: 386925 steps/s (collection: 0.071s, learning 0.183s)
                       Mean reward: 876.41
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.4617
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.8047
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 0.25s
                      Time elapsed: 00:25:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1305/1 [0m                       

                       Computation: 482840 steps/s (collection: 0.048s, learning 0.156s)
                       Mean reward: 872.71
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.6478
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7951
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 0.20s
                      Time elapsed: 00:25:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1306/1 [0m                       

                       Computation: 377182 steps/s (collection: 0.068s, learning 0.193s)
                       Mean reward: 872.11
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7096
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7917
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 0.26s
                      Time elapsed: 00:25:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1307/1 [0m                       

                       Computation: 653144 steps/s (collection: 0.045s, learning 0.106s)
                       Mean reward: 868.74
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3824
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 0.15s
                      Time elapsed: 00:25:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1308/1 [0m                       

                       Computation: 534677 steps/s (collection: 0.036s, learning 0.148s)
                       Mean reward: 872.92
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0787
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7893
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 0.18s
                      Time elapsed: 00:25:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1309/1 [0m                       

                       Computation: 561616 steps/s (collection: 0.043s, learning 0.132s)
                       Mean reward: 871.60
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4629
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 0.18s
                      Time elapsed: 00:25:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1310/1 [0m                       

                       Computation: 612043 steps/s (collection: 0.037s, learning 0.124s)
                       Mean reward: 852.29
               Mean episode length: 248.19
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.2924
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7581
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 0.16s
                      Time elapsed: 00:25:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1311/1 [0m                       

                       Computation: 498668 steps/s (collection: 0.045s, learning 0.152s)
                       Mean reward: 882.78
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.8416
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7905
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 0.20s
                      Time elapsed: 00:25:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1312/1 [0m                       

                       Computation: 605326 steps/s (collection: 0.039s, learning 0.124s)
                       Mean reward: 874.87
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0876
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7899
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 0.16s
                      Time elapsed: 00:25:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1313/1 [0m                       

                       Computation: 636191 steps/s (collection: 0.045s, learning 0.110s)
                       Mean reward: 868.87
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.6195
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7924
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 69.0000
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 0.15s
                      Time elapsed: 00:25:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1314/1 [0m                       

                       Computation: 517205 steps/s (collection: 0.040s, learning 0.150s)
                       Mean reward: 874.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8537
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7876
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 0.19s
                      Time elapsed: 00:25:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1315/1 [0m                       

                       Computation: 763573 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 868.21
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1721
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7868
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 0.13s
                      Time elapsed: 00:25:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1316/1 [0m                       

                       Computation: 573306 steps/s (collection: 0.041s, learning 0.131s)
                       Mean reward: 869.43
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2629
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7885
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 0.17s
                      Time elapsed: 00:25:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1317/1 [0m                       

                       Computation: 822516 steps/s (collection: 0.034s, learning 0.086s)
                       Mean reward: 875.64
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.5995
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7935
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 0.12s
                      Time elapsed: 00:25:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1318/1 [0m                       

                       Computation: 542692 steps/s (collection: 0.066s, learning 0.116s)
                       Mean reward: 869.48
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1717
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7865
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 0.18s
                      Time elapsed: 00:25:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1319/1 [0m                       

                       Computation: 820211 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 876.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.2077
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7944
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 0.12s
                      Time elapsed: 00:25:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1320/1 [0m                       

                       Computation: 874827 steps/s (collection: 0.032s, learning 0.080s)
                       Mean reward: 873.12
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7465
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 0.11s
                      Time elapsed: 00:25:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1321/1 [0m                       

                       Computation: 783860 steps/s (collection: 0.032s, learning 0.093s)
                       Mean reward: 880.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.3208
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7904
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 0.13s
                      Time elapsed: 00:25:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1322/1 [0m                       

                       Computation: 860844 steps/s (collection: 0.032s, learning 0.082s)
                       Mean reward: 865.00
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.8077
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7866
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 0.11s
                      Time elapsed: 00:25:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1323/1 [0m                       

                       Computation: 810795 steps/s (collection: 0.034s, learning 0.087s)
                       Mean reward: 869.80
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8337
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 71.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 0.12s
                      Time elapsed: 00:25:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1324/1 [0m                       

                       Computation: 778417 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 871.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.3598
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7826
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 0.13s
                      Time elapsed: 00:25:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1325/1 [0m                       

                       Computation: 940950 steps/s (collection: 0.033s, learning 0.072s)
                       Mean reward: 857.76
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.9557
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 0.10s
                      Time elapsed: 00:25:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1326/1 [0m                       

                       Computation: 915005 steps/s (collection: 0.035s, learning 0.072s)
                       Mean reward: 871.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5349
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 0.11s
                      Time elapsed: 00:26:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1327/1 [0m                       

                       Computation: 583756 steps/s (collection: 0.056s, learning 0.113s)
                       Mean reward: 866.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4527
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7743
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 0.17s
                      Time elapsed: 00:26:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1328/1 [0m                       

                       Computation: 881476 steps/s (collection: 0.035s, learning 0.077s)
                       Mean reward: 878.16
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8967
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7851
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 0.11s
                      Time elapsed: 00:26:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1329/1 [0m                       

                       Computation: 678668 steps/s (collection: 0.046s, learning 0.099s)
                       Mean reward: 870.91
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5541
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7865
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 0.14s
                      Time elapsed: 00:26:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1330/1 [0m                       

                       Computation: 706923 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 867.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6235
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7899
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 0.14s
                      Time elapsed: 00:26:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1331/1 [0m                       

                       Computation: 868602 steps/s (collection: 0.032s, learning 0.081s)
                       Mean reward: 869.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.5233
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7838
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 0.11s
                      Time elapsed: 00:26:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1332/1 [0m                       

                       Computation: 800411 steps/s (collection: 0.033s, learning 0.090s)
                       Mean reward: 880.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.3584
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7937
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 0.12s
                      Time elapsed: 00:26:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1333/1 [0m                       

                       Computation: 853962 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 875.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.5524
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7858
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 0.12s
                      Time elapsed: 00:26:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1334/1 [0m                       

                       Computation: 942694 steps/s (collection: 0.031s, learning 0.073s)
                       Mean reward: 872.20
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4895
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 68.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 0.10s
                      Time elapsed: 00:26:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1335/1 [0m                       

                       Computation: 808011 steps/s (collection: 0.034s, learning 0.088s)
                       Mean reward: 857.34
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.2093
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7546
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 0.12s
                      Time elapsed: 00:26:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1336/1 [0m                       

                       Computation: 765983 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 852.84
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.6666
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 0.13s
                      Time elapsed: 00:26:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1337/1 [0m                       

                       Computation: 796906 steps/s (collection: 0.032s, learning 0.092s)
                       Mean reward: 864.03
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2622
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 0.12s
                      Time elapsed: 00:26:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1338/1 [0m                       

                       Computation: 707400 steps/s (collection: 0.035s, learning 0.104s)
                       Mean reward: 864.46
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2221
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 0.14s
                      Time elapsed: 00:26:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1339/1 [0m                       

                       Computation: 752404 steps/s (collection: 0.034s, learning 0.097s)
                       Mean reward: 861.58
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3838
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7703
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 0.13s
                      Time elapsed: 00:26:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1340/1 [0m                       

                       Computation: 593790 steps/s (collection: 0.051s, learning 0.115s)
                       Mean reward: 860.72
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.4603
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 0.17s
                      Time elapsed: 00:26:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1341/1 [0m                       

                       Computation: 652740 steps/s (collection: 0.040s, learning 0.111s)
                       Mean reward: 845.53
               Mean episode length: 245.56
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0507
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 0.15s
                      Time elapsed: 00:26:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1342/1 [0m                       

                       Computation: 700875 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 841.31
               Mean episode length: 246.18
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.0246
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 0.14s
                      Time elapsed: 00:26:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1343/1 [0m                       

                       Computation: 747393 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 841.30
               Mean episode length: 244.15
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.6346
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 0.13s
                      Time elapsed: 00:26:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1344/1 [0m                       

                       Computation: 860362 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 865.38
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.4531
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7669
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 69.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 0.11s
                      Time elapsed: 00:26:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1345/1 [0m                       

                       Computation: 635416 steps/s (collection: 0.041s, learning 0.114s)
                       Mean reward: 774.34
               Mean episode length: 244.69
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 152.8048
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.6908
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 0.15s
                      Time elapsed: 00:26:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1346/1 [0m                       

                       Computation: 483861 steps/s (collection: 0.039s, learning 0.165s)
                       Mean reward: 695.14
               Mean episode length: 233.99
         Episode_Reward/action_rate -0.0018
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 137.8471
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.6311
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 0.20s
                      Time elapsed: 00:26:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1347/1 [0m                       

                       Computation: 779319 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 728.84
               Mean episode length: 243.06
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 144.3790
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.6565
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 0.13s
                      Time elapsed: 00:26:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1348/1 [0m                       

                       Computation: 470232 steps/s (collection: 0.036s, learning 0.173s)
                       Mean reward: 736.11
               Mean episode length: 241.81
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 147.4129
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.6669
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 0.21s
                      Time elapsed: 00:26:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1349/1 [0m                       

                       Computation: 656628 steps/s (collection: 0.037s, learning 0.113s)
                       Mean reward: 710.44
               Mean episode length: 241.74
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 141.3928
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.6492
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 0.15s
                      Time elapsed: 00:26:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1350/1 [0m                       

                       Computation: 861259 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 731.70
               Mean episode length: 243.15
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 146.5449
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.6709
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 0.11s
                      Time elapsed: 00:26:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1351/1 [0m                       

                       Computation: 820193 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 699.09
               Mean episode length: 245.56
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 140.1296
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.6559
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 0.12s
                      Time elapsed: 00:26:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1352/1 [0m                       

                       Computation: 753263 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 692.09
               Mean episode length: 245.66
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 137.4678
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.6414
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 0.13s
                      Time elapsed: 00:26:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1353/1 [0m                       

                       Computation: 797822 steps/s (collection: 0.032s, learning 0.091s)
                       Mean reward: 731.45
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 145.8296
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.6670
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 0.12s
                      Time elapsed: 00:26:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1354/1 [0m                       

                       Computation: 607023 steps/s (collection: 0.042s, learning 0.120s)
                       Mean reward: 730.48
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 145.8699
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.6804
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 0.16s
                      Time elapsed: 00:26:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1355/1 [0m                       

                       Computation: 900172 steps/s (collection: 0.035s, learning 0.074s)
                       Mean reward: 657.83
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 136.7121
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.6505
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 64.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 0.11s
                      Time elapsed: 00:26:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1356/1 [0m                       

                       Computation: 714175 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 688.52
               Mean episode length: 244.99
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 133.7772
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.6251
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 0.14s
                      Time elapsed: 00:26:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1357/1 [0m                       

                       Computation: 619692 steps/s (collection: 0.034s, learning 0.125s)
                       Mean reward: 693.85
               Mean episode length: 242.57
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 137.5990
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.6446
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 0.16s
                      Time elapsed: 00:26:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1358/1 [0m                       

                       Computation: 944876 steps/s (collection: 0.033s, learning 0.072s)
                       Mean reward: 740.59
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 148.6054
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.6839
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 0.10s
                      Time elapsed: 00:26:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1359/1 [0m                       

                       Computation: 527635 steps/s (collection: 0.041s, learning 0.145s)
                       Mean reward: 748.98
               Mean episode length: 243.67
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 150.3508
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.6871
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 0.19s
                      Time elapsed: 00:26:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1360/1 [0m                       

                       Computation: 746768 steps/s (collection: 0.034s, learning 0.098s)
                       Mean reward: 757.82
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 150.7307
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.6903
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 0.13s
                      Time elapsed: 00:26:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1361/1 [0m                       

                       Computation: 712145 steps/s (collection: 0.048s, learning 0.090s)
                       Mean reward: 805.03
               Mean episode length: 246.68
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.6190
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7261
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 0.14s
                      Time elapsed: 00:26:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1362/1 [0m                       

                       Computation: 836094 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 821.04
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.8671
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7351
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 0.12s
                      Time elapsed: 00:26:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1363/1 [0m                       

                       Computation: 853333 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 796.90
               Mean episode length: 246.53
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 159.0252
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7207
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 0.12s
                      Time elapsed: 00:26:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1364/1 [0m                       

                       Computation: 636924 steps/s (collection: 0.035s, learning 0.119s)
                       Mean reward: 845.02
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.3676
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7696
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 0.15s
                      Time elapsed: 00:26:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1365/1 [0m                       

                       Computation: 659533 steps/s (collection: 0.040s, learning 0.109s)
                       Mean reward: 835.83
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.1356
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7440
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 66.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 0.15s
                      Time elapsed: 00:26:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1366/1 [0m                       

                       Computation: 732808 steps/s (collection: 0.036s, learning 0.098s)
                       Mean reward: 785.98
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 155.6110
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7083
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 0.13s
                      Time elapsed: 00:26:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1367/1 [0m                       

                       Computation: 770776 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 775.91
               Mean episode length: 242.44
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 157.7471
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7109
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 0.13s
                      Time elapsed: 00:26:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1368/1 [0m                       

                       Computation: 858317 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 804.51
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.0564
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7223
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 0.11s
                      Time elapsed: 00:26:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1369/1 [0m                       

                       Computation: 866017 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 794.74
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 156.5293
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7096
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 0.11s
                      Time elapsed: 00:26:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1370/1 [0m                       

                       Computation: 648291 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 820.47
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.9892
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7397
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 0.15s
                      Time elapsed: 00:26:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1371/1 [0m                       

                       Computation: 607371 steps/s (collection: 0.040s, learning 0.122s)
                       Mean reward: 828.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.1278
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 0.16s
                      Time elapsed: 00:26:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1372/1 [0m                       

                       Computation: 767849 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 802.59
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.0771
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7257
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 0.13s
                      Time elapsed: 00:26:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1373/1 [0m                       

                       Computation: 888445 steps/s (collection: 0.033s, learning 0.077s)
                       Mean reward: 801.51
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.0705
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7367
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 0.11s
                      Time elapsed: 00:26:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1374/1 [0m                       

                       Computation: 930309 steps/s (collection: 0.032s, learning 0.074s)
                       Mean reward: 855.23
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8519
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 0.11s
                      Time elapsed: 00:26:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1375/1 [0m                       

                       Computation: 914242 steps/s (collection: 0.033s, learning 0.075s)
                       Mean reward: 848.15
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.7314
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 68.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 0.11s
                      Time elapsed: 00:26:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1376/1 [0m                       

                       Computation: 922807 steps/s (collection: 0.033s, learning 0.074s)
                       Mean reward: 831.01
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.5275
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7558
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 0.11s
                      Time elapsed: 00:26:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1377/1 [0m                       

                       Computation: 963616 steps/s (collection: 0.033s, learning 0.070s)
                       Mean reward: 845.18
               Mean episode length: 244.78
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7417
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 0.10s
                      Time elapsed: 00:26:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1378/1 [0m                       

                       Computation: 599328 steps/s (collection: 0.038s, learning 0.127s)
                       Mean reward: 856.34
               Mean episode length: 247.27
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.6119
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 0.16s
                      Time elapsed: 00:26:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1379/1 [0m                       

                       Computation: 904894 steps/s (collection: 0.033s, learning 0.075s)
                       Mean reward: 858.48
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.9964
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7798
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 0.11s
                      Time elapsed: 00:26:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1380/1 [0m                       

                       Computation: 869325 steps/s (collection: 0.033s, learning 0.080s)
                       Mean reward: 868.88
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.2807
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7855
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 0.11s
                      Time elapsed: 00:26:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1381/1 [0m                       

                       Computation: 885448 steps/s (collection: 0.033s, learning 0.079s)
                       Mean reward: 854.29
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1894
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7632
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 0.11s
                      Time elapsed: 00:26:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1382/1 [0m                       

                       Computation: 822536 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 868.24
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8114
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 0.12s
                      Time elapsed: 00:26:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1383/1 [0m                       

                       Computation: 846849 steps/s (collection: 0.033s, learning 0.083s)
                       Mean reward: 858.63
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.9924
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 0.12s
                      Time elapsed: 00:26:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1384/1 [0m                       

                       Computation: 894744 steps/s (collection: 0.034s, learning 0.076s)
                       Mean reward: 860.38
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.2102
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 0.11s
                      Time elapsed: 00:26:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1385/1 [0m                       

                       Computation: 885238 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 847.43
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.9807
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 0.11s
                      Time elapsed: 00:27:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1386/1 [0m                       

                       Computation: 681773 steps/s (collection: 0.033s, learning 0.111s)
                       Mean reward: 859.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4564
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 64.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 0.14s
                      Time elapsed: 00:27:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1387/1 [0m                       

                       Computation: 775256 steps/s (collection: 0.035s, learning 0.092s)
                       Mean reward: 857.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.8372
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 0.13s
                      Time elapsed: 00:27:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1388/1 [0m                       

                       Computation: 793819 steps/s (collection: 0.032s, learning 0.092s)
                       Mean reward: 877.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9337
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7929
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 0.12s
                      Time elapsed: 00:27:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1389/1 [0m                       

                       Computation: 811783 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 868.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0293
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7821
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 0.12s
                      Time elapsed: 00:27:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1390/1 [0m                       

                       Computation: 850337 steps/s (collection: 0.032s, learning 0.084s)
                       Mean reward: 863.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.0064
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 0.12s
                      Time elapsed: 00:27:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1391/1 [0m                       

                       Computation: 863470 steps/s (collection: 0.031s, learning 0.083s)
                       Mean reward: 865.83
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.2351
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7851
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 0.11s
                      Time elapsed: 00:27:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1392/1 [0m                       

                       Computation: 812714 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 875.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4357
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7907
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 0.12s
                      Time elapsed: 00:27:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1393/1 [0m                       

                       Computation: 772943 steps/s (collection: 0.034s, learning 0.094s)
                       Mean reward: 868.97
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0344
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 0.13s
                      Time elapsed: 00:27:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1394/1 [0m                       

                       Computation: 560915 steps/s (collection: 0.045s, learning 0.130s)
                       Mean reward: 867.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.5736
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7810
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 0.18s
                      Time elapsed: 00:27:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1395/1 [0m                       

                       Computation: 755837 steps/s (collection: 0.035s, learning 0.095s)
                       Mean reward: 863.95
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8381
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7787
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 0.13s
                      Time elapsed: 00:27:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1396/1 [0m                       

                       Computation: 770906 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 876.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7601
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7929
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 67.0417
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 0.13s
                      Time elapsed: 00:27:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1397/1 [0m                       

                       Computation: 667905 steps/s (collection: 0.038s, learning 0.109s)
                       Mean reward: 869.02
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7089
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 0.15s
                      Time elapsed: 00:27:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1398/1 [0m                       

                       Computation: 758388 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 871.40
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8478
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7965
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 0.13s
                      Time elapsed: 00:27:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1399/1 [0m                       

                       Computation: 539877 steps/s (collection: 0.043s, learning 0.140s)
                       Mean reward: 874.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0700
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7923
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 0.18s
                      Time elapsed: 00:27:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1400/1 [0m                       

                       Computation: 640378 steps/s (collection: 0.038s, learning 0.116s)
                       Mean reward: 873.68
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.9668
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7934
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 0.15s
                      Time elapsed: 00:27:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1401/1 [0m                       

                       Computation: 820735 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 874.23
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.1682
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7963
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 0.12s
                      Time elapsed: 00:27:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1402/1 [0m                       

                       Computation: 835701 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 875.87
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9180
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.8008
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 0.12s
                      Time elapsed: 00:27:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1403/1 [0m                       

                       Computation: 873489 steps/s (collection: 0.037s, learning 0.076s)
                       Mean reward: 885.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 176.2640
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.8003
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 0.11s
                      Time elapsed: 00:27:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1404/1 [0m                       

                       Computation: 672659 steps/s (collection: 0.052s, learning 0.095s)
                       Mean reward: 871.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2306
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7956
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 0.15s
                      Time elapsed: 00:27:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1405/1 [0m                       

                       Computation: 665219 steps/s (collection: 0.041s, learning 0.106s)
                       Mean reward: 881.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.5966
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.8028
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 0.15s
                      Time elapsed: 00:27:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1406/1 [0m                       

                       Computation: 846404 steps/s (collection: 0.034s, learning 0.082s)
                       Mean reward: 874.55
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.6245
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 0.12s
                      Time elapsed: 00:27:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1407/1 [0m                       

                       Computation: 609660 steps/s (collection: 0.033s, learning 0.128s)
                       Mean reward: 872.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2464
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 63.5833
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 0.16s
                      Time elapsed: 00:27:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1408/1 [0m                       

                       Computation: 719180 steps/s (collection: 0.047s, learning 0.090s)
                       Mean reward: 862.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6420
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 0.14s
                      Time elapsed: 00:27:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1409/1 [0m                       

                       Computation: 673971 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 865.56
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6444
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 0.15s
                      Time elapsed: 00:27:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1410/1 [0m                       

                       Computation: 521423 steps/s (collection: 0.052s, learning 0.137s)
                       Mean reward: 871.77
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4489
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7833
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 0.19s
                      Time elapsed: 00:27:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1411/1 [0m                       

                       Computation: 778957 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 867.98
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.9409
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7726
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 0.13s
                      Time elapsed: 00:27:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1412/1 [0m                       

                       Computation: 696948 steps/s (collection: 0.035s, learning 0.106s)
                       Mean reward: 863.66
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.4181
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7770
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 0.14s
                      Time elapsed: 00:27:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1413/1 [0m                       

                       Computation: 622012 steps/s (collection: 0.042s, learning 0.117s)
                       Mean reward: 859.20
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.9853
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7716
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 0.16s
                      Time elapsed: 00:27:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1414/1 [0m                       

                       Computation: 703835 steps/s (collection: 0.033s, learning 0.106s)
                       Mean reward: 872.24
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.9920
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 0.14s
                      Time elapsed: 00:27:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1415/1 [0m                       

                       Computation: 591898 steps/s (collection: 0.046s, learning 0.121s)
                       Mean reward: 862.49
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.0374
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 0.17s
                      Time elapsed: 00:27:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1416/1 [0m                       

                       Computation: 655350 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 868.16
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4905
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7894
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 0.15s
                      Time elapsed: 00:27:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1417/1 [0m                       

                       Computation: 528297 steps/s (collection: 0.045s, learning 0.141s)
                       Mean reward: 872.33
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.8188
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7912
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 65.7083
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 0.19s
                      Time elapsed: 00:27:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1418/1 [0m                       

                       Computation: 517288 steps/s (collection: 0.054s, learning 0.137s)
                       Mean reward: 864.62
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.2083
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 0.19s
                      Time elapsed: 00:27:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1419/1 [0m                       

                       Computation: 630050 steps/s (collection: 0.042s, learning 0.115s)
                       Mean reward: 854.72
               Mean episode length: 246.25
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.9545
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 0.16s
                      Time elapsed: 00:27:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1420/1 [0m                       

                       Computation: 512800 steps/s (collection: 0.069s, learning 0.123s)
                       Mean reward: 860.59
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0474
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 0.19s
                      Time elapsed: 00:27:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1421/1 [0m                       

                       Computation: 615766 steps/s (collection: 0.041s, learning 0.119s)
                       Mean reward: 861.28
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.5800
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7727
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 0.16s
                      Time elapsed: 00:27:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1422/1 [0m                       

                       Computation: 663762 steps/s (collection: 0.036s, learning 0.112s)
                       Mean reward: 871.74
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7010
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7784
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 0.15s
                      Time elapsed: 00:27:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1423/1 [0m                       

                       Computation: 635706 steps/s (collection: 0.039s, learning 0.116s)
                       Mean reward: 872.50
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6861
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7826
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 0.15s
                      Time elapsed: 00:27:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1424/1 [0m                       

                       Computation: 679738 steps/s (collection: 0.038s, learning 0.106s)
                       Mean reward: 868.68
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2766
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7807
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 0.14s
                      Time elapsed: 00:27:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1425/1 [0m                       

                       Computation: 411773 steps/s (collection: 0.041s, learning 0.198s)
                       Mean reward: 864.25
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1401
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 0.24s
                      Time elapsed: 00:27:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1426/1 [0m                       

                       Computation: 518460 steps/s (collection: 0.050s, learning 0.140s)
                       Mean reward: 859.92
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.4913
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 0.19s
                      Time elapsed: 00:27:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1427/1 [0m                       

                       Computation: 331860 steps/s (collection: 0.063s, learning 0.233s)
                       Mean reward: 860.65
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7415
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 0.30s
                      Time elapsed: 00:27:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1428/1 [0m                       

                       Computation: 575767 steps/s (collection: 0.047s, learning 0.124s)
                       Mean reward: 874.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.3633
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 62.0417
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 0.17s
                      Time elapsed: 00:27:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1429/1 [0m                       

                       Computation: 593775 steps/s (collection: 0.038s, learning 0.128s)
                       Mean reward: 862.35
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.9771
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7834
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 0.17s
                      Time elapsed: 00:27:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1430/1 [0m                       

                       Computation: 650548 steps/s (collection: 0.032s, learning 0.119s)
                       Mean reward: 865.47
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5844
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 0.15s
                      Time elapsed: 00:27:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1431/1 [0m                       

                       Computation: 661154 steps/s (collection: 0.051s, learning 0.098s)
                       Mean reward: 850.61
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.4148
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 0.15s
                      Time elapsed: 00:27:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1432/1 [0m                       

                       Computation: 581278 steps/s (collection: 0.046s, learning 0.124s)
                       Mean reward: 865.54
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2638
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 0.17s
                      Time elapsed: 00:27:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1433/1 [0m                       

                       Computation: 604621 steps/s (collection: 0.046s, learning 0.117s)
                       Mean reward: 854.35
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.2299
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7711
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 0.16s
                      Time elapsed: 00:27:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1434/1 [0m                       

                       Computation: 511431 steps/s (collection: 0.055s, learning 0.137s)
                       Mean reward: 877.52
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.6100
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7912
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 0.19s
                      Time elapsed: 00:27:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1435/1 [0m                       

                       Computation: 482794 steps/s (collection: 0.036s, learning 0.168s)
                       Mean reward: 875.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.3641
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7957
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 0.20s
                      Time elapsed: 00:27:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1436/1 [0m                       

                       Computation: 732782 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 876.83
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.2842
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7852
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 0.13s
                      Time elapsed: 00:27:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1437/1 [0m                       

                       Computation: 639690 steps/s (collection: 0.038s, learning 0.116s)
                       Mean reward: 868.33
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0019
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2888
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7849
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 0.15s
                      Time elapsed: 00:27:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1438/1 [0m                       

                       Computation: 493262 steps/s (collection: 0.040s, learning 0.159s)
                       Mean reward: 876.04
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.5704
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 64.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 0.20s
                      Time elapsed: 00:27:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1439/1 [0m                       

                       Computation: 502178 steps/s (collection: 0.044s, learning 0.152s)
                       Mean reward: 854.08
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.5896
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 0.20s
                      Time elapsed: 00:27:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1440/1 [0m                       

                       Computation: 350852 steps/s (collection: 0.055s, learning 0.225s)
                       Mean reward: 865.99
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1628
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7790
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 0.28s
                      Time elapsed: 00:28:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1441/1 [0m                       

                       Computation: 510209 steps/s (collection: 0.054s, learning 0.139s)
                       Mean reward: 865.66
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6367
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 0.19s
                      Time elapsed: 00:28:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1442/1 [0m                       

                       Computation: 480245 steps/s (collection: 0.041s, learning 0.164s)
                       Mean reward: 872.95
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1890
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7782
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 0.20s
                      Time elapsed: 00:28:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1443/1 [0m                       

                       Computation: 498203 steps/s (collection: 0.053s, learning 0.145s)
                       Mean reward: 870.31
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4413
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7851
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 0.20s
                      Time elapsed: 00:28:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1444/1 [0m                       

                       Computation: 507498 steps/s (collection: 0.038s, learning 0.156s)
                       Mean reward: 870.73
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1649
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 0.19s
                      Time elapsed: 00:28:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1445/1 [0m                       

                       Computation: 550291 steps/s (collection: 0.042s, learning 0.137s)
                       Mean reward: 874.13
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.6845
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 0.18s
                      Time elapsed: 00:28:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1446/1 [0m                       

                       Computation: 738059 steps/s (collection: 0.033s, learning 0.101s)
                       Mean reward: 875.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3626
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7916
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 0.13s
                      Time elapsed: 00:28:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1447/1 [0m                       

                       Computation: 545510 steps/s (collection: 0.047s, learning 0.133s)
                       Mean reward: 871.83
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7514
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7910
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 0.18s
                      Time elapsed: 00:28:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1448/1 [0m                       

                       Computation: 588260 steps/s (collection: 0.033s, learning 0.134s)
                       Mean reward: 872.53
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5708
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 66.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 0.17s
                      Time elapsed: 00:28:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1449/1 [0m                       

                       Computation: 603151 steps/s (collection: 0.042s, learning 0.121s)
                       Mean reward: 884.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.9953
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7894
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 0.16s
                      Time elapsed: 00:28:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1450/1 [0m                       

                       Computation: 529555 steps/s (collection: 0.038s, learning 0.148s)
                       Mean reward: 842.93
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.8886
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 0.19s
                      Time elapsed: 00:28:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1451/1 [0m                       

                       Computation: 463282 steps/s (collection: 0.082s, learning 0.130s)
                       Mean reward: 849.92
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.2732
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 0.21s
                      Time elapsed: 00:28:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1452/1 [0m                       

                       Computation: 706625 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 859.69
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3453
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 0.14s
                      Time elapsed: 00:28:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1453/1 [0m                       

                       Computation: 794865 steps/s (collection: 0.034s, learning 0.090s)
                       Mean reward: 861.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1178
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 0.12s
                      Time elapsed: 00:28:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1454/1 [0m                       

                       Computation: 808837 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 867.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.2330
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7878
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 0.12s
                      Time elapsed: 00:28:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1455/1 [0m                       

                       Computation: 716655 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 866.79
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3905
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 0.14s
                      Time elapsed: 00:28:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1456/1 [0m                       

                       Computation: 580921 steps/s (collection: 0.046s, learning 0.123s)
                       Mean reward: 873.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0753
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7873
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 0.17s
                      Time elapsed: 00:28:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1457/1 [0m                       

                       Computation: 424448 steps/s (collection: 0.045s, learning 0.187s)
                       Mean reward: 870.06
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5756
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 0.23s
                      Time elapsed: 00:28:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1458/1 [0m                       

                       Computation: 574985 steps/s (collection: 0.042s, learning 0.129s)
                       Mean reward: 877.22
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6909
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7891
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 0.17s
                      Time elapsed: 00:28:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1459/1 [0m                       

                       Computation: 676938 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 871.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.8488
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 62.9167
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 0.15s
                      Time elapsed: 00:28:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1460/1 [0m                       

                       Computation: 649136 steps/s (collection: 0.050s, learning 0.101s)
                       Mean reward: 849.03
               Mean episode length: 246.25
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8548
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7696
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 0.15s
                      Time elapsed: 00:28:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1461/1 [0m                       

                       Computation: 640557 steps/s (collection: 0.044s, learning 0.109s)
                       Mean reward: 861.79
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.0440
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7859
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 0.15s
                      Time elapsed: 00:28:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1462/1 [0m                       

                       Computation: 689461 steps/s (collection: 0.037s, learning 0.106s)
                       Mean reward: 871.75
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5303
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7827
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 0.14s
                      Time elapsed: 00:28:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1463/1 [0m                       

                       Computation: 448032 steps/s (collection: 0.041s, learning 0.178s)
                       Mean reward: 871.23
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.9812
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 0.22s
                      Time elapsed: 00:28:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1464/1 [0m                       

                       Computation: 690539 steps/s (collection: 0.047s, learning 0.096s)
                       Mean reward: 871.50
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8943
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7846
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 0.14s
                      Time elapsed: 00:28:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1465/1 [0m                       

                       Computation: 799265 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 872.57
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4609
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 0.12s
                      Time elapsed: 00:28:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1466/1 [0m                       

                       Computation: 469035 steps/s (collection: 0.050s, learning 0.160s)
                       Mean reward: 862.93
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0580
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 0.21s
                      Time elapsed: 00:28:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1467/1 [0m                       

                       Computation: 681580 steps/s (collection: 0.037s, learning 0.107s)
                       Mean reward: 875.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3429
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7939
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 0.14s
                      Time elapsed: 00:28:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1468/1 [0m                       

                       Computation: 638525 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 865.65
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5498
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 0.15s
                      Time elapsed: 00:28:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1469/1 [0m                       

                       Computation: 762983 steps/s (collection: 0.033s, learning 0.095s)
                       Mean reward: 869.13
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.7202
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7824
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 65.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 0.13s
                      Time elapsed: 00:28:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1470/1 [0m                       

                       Computation: 393151 steps/s (collection: 0.060s, learning 0.190s)
                       Mean reward: 838.80
               Mean episode length: 246.68
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.1350
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 0.25s
                      Time elapsed: 00:28:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1471/1 [0m                       

                       Computation: 391979 steps/s (collection: 0.058s, learning 0.193s)
                       Mean reward: 859.23
               Mean episode length: 246.61
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.5503
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 0.25s
                      Time elapsed: 00:28:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1472/1 [0m                       

                       Computation: 726582 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 862.12
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.2406
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7850
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 0.14s
                      Time elapsed: 00:28:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1473/1 [0m                       

                       Computation: 685769 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 864.88
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0107
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7882
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 0.14s
                      Time elapsed: 00:28:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1474/1 [0m                       

                       Computation: 604468 steps/s (collection: 0.038s, learning 0.125s)
                       Mean reward: 858.52
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.3989
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7743
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 0.16s
                      Time elapsed: 00:28:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1475/1 [0m                       

                       Computation: 550522 steps/s (collection: 0.039s, learning 0.140s)
                       Mean reward: 864.73
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.8849
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 0.18s
                      Time elapsed: 00:28:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1476/1 [0m                       

                       Computation: 573190 steps/s (collection: 0.041s, learning 0.130s)
                       Mean reward: 878.96
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.9988
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7906
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 0.17s
                      Time elapsed: 00:28:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1477/1 [0m                       

                       Computation: 786183 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 862.97
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.8253
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 0.13s
                      Time elapsed: 00:28:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1478/1 [0m                       

                       Computation: 823887 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 862.45
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6899
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 0.12s
                      Time elapsed: 00:28:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1479/1 [0m                       

                       Computation: 742968 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 868.88
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.9704
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7880
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 0.13s
                      Time elapsed: 00:28:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1480/1 [0m                       

                       Computation: 652264 steps/s (collection: 0.036s, learning 0.115s)
                       Mean reward: 869.98
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2823
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 61.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 0.15s
                      Time elapsed: 00:28:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1481/1 [0m                       

                       Computation: 458425 steps/s (collection: 0.057s, learning 0.157s)
                       Mean reward: 856.07
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.8049
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 0.21s
                      Time elapsed: 00:28:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1482/1 [0m                       

                       Computation: 627589 steps/s (collection: 0.038s, learning 0.119s)
                       Mean reward: 854.16
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.5906
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7707
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 0.16s
                      Time elapsed: 00:28:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1483/1 [0m                       

                       Computation: 532655 steps/s (collection: 0.048s, learning 0.137s)
                       Mean reward: 862.35
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.7635
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 0.18s
                      Time elapsed: 00:28:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1484/1 [0m                       

                       Computation: 437541 steps/s (collection: 0.063s, learning 0.162s)
                       Mean reward: 863.04
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.9778
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7821
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 0.22s
                      Time elapsed: 00:28:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1485/1 [0m                       

                       Computation: 554459 steps/s (collection: 0.041s, learning 0.136s)
                       Mean reward: 872.53
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5961
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7914
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 0.18s
                      Time elapsed: 00:28:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1486/1 [0m                       

                       Computation: 427911 steps/s (collection: 0.068s, learning 0.162s)
                       Mean reward: 868.72
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0020
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.8746
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7866
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 0.23s
                      Time elapsed: 00:28:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1487/1 [0m                       

                       Computation: 495166 steps/s (collection: 0.045s, learning 0.154s)
                       Mean reward: 863.15
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9655
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 0.20s
                      Time elapsed: 00:28:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1488/1 [0m                       

                       Computation: 547473 steps/s (collection: 0.052s, learning 0.128s)
                       Mean reward: 861.89
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7189
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7773
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 0.18s
                      Time elapsed: 00:28:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1489/1 [0m                       

                       Computation: 438464 steps/s (collection: 0.071s, learning 0.153s)
                       Mean reward: 864.46
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3126
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7863
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 0.22s
                      Time elapsed: 00:28:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1490/1 [0m                       

                       Computation: 736149 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 873.32
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4601
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 63.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 0.13s
                      Time elapsed: 00:29:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1491/1 [0m                       

                       Computation: 609754 steps/s (collection: 0.041s, learning 0.120s)
                       Mean reward: 848.70
               Mean episode length: 245.21
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.6304
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7696
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 0.16s
                      Time elapsed: 00:29:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1492/1 [0m                       

                       Computation: 661867 steps/s (collection: 0.043s, learning 0.106s)
                       Mean reward: 857.12
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1753
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 0.15s
                      Time elapsed: 00:29:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1493/1 [0m                       

                       Computation: 581574 steps/s (collection: 0.044s, learning 0.125s)
                       Mean reward: 875.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0568
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7936
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 0.17s
                      Time elapsed: 00:29:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1494/1 [0m                       

                       Computation: 680606 steps/s (collection: 0.044s, learning 0.101s)
                       Mean reward: 867.52
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2740
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7792
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 0.14s
                      Time elapsed: 00:29:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1495/1 [0m                       

                       Computation: 775862 steps/s (collection: 0.034s, learning 0.093s)
                       Mean reward: 861.72
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0021
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1795
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7826
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 0.13s
                      Time elapsed: 00:29:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1496/1 [0m                       

                       Computation: 803952 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 865.81
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6037
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7807
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 0.12s
                      Time elapsed: 00:29:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1497/1 [0m                       

                       Computation: 688307 steps/s (collection: 0.038s, learning 0.105s)
                       Mean reward: 854.32
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.8835
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 0.14s
                      Time elapsed: 00:29:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1498/1 [0m                       

                       Computation: 743976 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 861.25
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.5635
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 0.13s
                      Time elapsed: 00:29:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1499/1 [0m                       

                       Computation: 368304 steps/s (collection: 0.068s, learning 0.199s)
                       Mean reward: 866.51
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4249
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7855
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 0.27s
                      Time elapsed: 00:29:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1500/1 [0m                       

                       Computation: 313840 steps/s (collection: 0.066s, learning 0.247s)
                       Mean reward: 863.85
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.7717
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 65.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 0.31s
                      Time elapsed: 00:29:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1501/1 [0m                       

                       Computation: 627893 steps/s (collection: 0.043s, learning 0.114s)
                       Mean reward: 853.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.9696
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7845
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 147554304
                    Iteration time: 0.16s
                      Time elapsed: 00:29:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1502/1 [0m                       

                       Computation: 505060 steps/s (collection: 0.056s, learning 0.139s)
                       Mean reward: 834.36
               Mean episode length: 243.78
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.1232
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 147652608
                    Iteration time: 0.19s
                      Time elapsed: 00:29:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1503/1 [0m                       

                       Computation: 636488 steps/s (collection: 0.045s, learning 0.110s)
                       Mean reward: 840.98
               Mean episode length: 245.89
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.9205
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 147750912
                    Iteration time: 0.15s
                      Time elapsed: 00:29:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1504/1 [0m                       

                       Computation: 764192 steps/s (collection: 0.034s, learning 0.094s)
                       Mean reward: 860.94
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1697
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 147849216
                    Iteration time: 0.13s
                      Time elapsed: 00:29:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1505/1 [0m                       

                       Computation: 686019 steps/s (collection: 0.051s, learning 0.093s)
                       Mean reward: 860.64
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1082
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7798
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 147947520
                    Iteration time: 0.14s
                      Time elapsed: 00:29:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1506/1 [0m                       

                       Computation: 590334 steps/s (collection: 0.038s, learning 0.129s)
                       Mean reward: 868.32
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3836
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 148045824
                    Iteration time: 0.17s
                      Time elapsed: 00:29:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1507/1 [0m                       

                       Computation: 499350 steps/s (collection: 0.046s, learning 0.151s)
                       Mean reward: 864.43
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6781
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 148144128
                    Iteration time: 0.20s
                      Time elapsed: 00:29:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1508/1 [0m                       

                       Computation: 794472 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 858.79
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.6820
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7846
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 148242432
                    Iteration time: 0.12s
                      Time elapsed: 00:29:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1509/1 [0m                       

                       Computation: 745220 steps/s (collection: 0.050s, learning 0.082s)
                       Mean reward: 871.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0022
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6612
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 148340736
                    Iteration time: 0.13s
                      Time elapsed: 00:29:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1510/1 [0m                       

                       Computation: 390500 steps/s (collection: 0.067s, learning 0.185s)
                       Mean reward: 829.99
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0023
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.6427
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 148439040
                    Iteration time: 0.25s
                      Time elapsed: 00:29:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1511/1 [0m                       

                       Computation: 804685 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 377.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0031
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 69.9516
       Episode_Reward/object_height 0.0048
     Episode_Reward/reaching_object 0.5104
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 60.8333
--------------------------------------------------------------------------------
                   Total timesteps: 148537344
                    Iteration time: 0.12s
                      Time elapsed: 00:29:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1512/1 [0m                       

                       Computation: 696786 steps/s (collection: 0.048s, learning 0.093s)
                       Mean reward: 12.60
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 1.7693
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.3337
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 148635648
                    Iteration time: 0.14s
                      Time elapsed: 00:29:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1513/1 [0m                       

                       Computation: 415458 steps/s (collection: 0.058s, learning 0.179s)
                       Mean reward: 24.04
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 4.4574
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3397
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 148733952
                    Iteration time: 0.24s
                      Time elapsed: 00:29:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1514/1 [0m                       

                       Computation: 799883 steps/s (collection: 0.045s, learning 0.078s)
                       Mean reward: 39.83
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 7.4766
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3540
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 148832256
                    Iteration time: 0.12s
                      Time elapsed: 00:29:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1515/1 [0m                       

                       Computation: 712584 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 34.80
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 6.1364
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3548
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 148930560
                    Iteration time: 0.14s
                      Time elapsed: 00:29:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1516/1 [0m                       

                       Computation: 665728 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 62.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 12.1822
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3729
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 149028864
                    Iteration time: 0.15s
                      Time elapsed: 00:29:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1517/1 [0m                       

                       Computation: 660298 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 56.59
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 10.6867
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3745
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 149127168
                    Iteration time: 0.15s
                      Time elapsed: 00:29:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1518/1 [0m                       

                       Computation: 658078 steps/s (collection: 0.051s, learning 0.099s)
                       Mean reward: 69.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 15.1039
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3817
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 149225472
                    Iteration time: 0.15s
                      Time elapsed: 00:29:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1519/1 [0m                       

                       Computation: 496352 steps/s (collection: 0.068s, learning 0.131s)
                       Mean reward: 105.16
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 19.9692
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3935
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 149323776
                    Iteration time: 0.20s
                      Time elapsed: 00:29:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1520/1 [0m                       

                       Computation: 581328 steps/s (collection: 0.052s, learning 0.118s)
                       Mean reward: 103.30
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 20.3867
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.4037
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 149422080
                    Iteration time: 0.17s
                      Time elapsed: 00:29:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1521/1 [0m                       

                       Computation: 496797 steps/s (collection: 0.052s, learning 0.146s)
                       Mean reward: 124.67
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 22.7382
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4040
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 63.1250
--------------------------------------------------------------------------------
                   Total timesteps: 149520384
                    Iteration time: 0.20s
                      Time elapsed: 00:29:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1522/1 [0m                       

                       Computation: 375119 steps/s (collection: 0.056s, learning 0.206s)
                       Mean reward: 138.48
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 28.5810
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.4331
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 149618688
                    Iteration time: 0.26s
                      Time elapsed: 00:29:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1523/1 [0m                       

                       Computation: 642984 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 139.81
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 30.3446
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.4322
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 149716992
                    Iteration time: 0.15s
                      Time elapsed: 00:29:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1524/1 [0m                       

                       Computation: 858337 steps/s (collection: 0.041s, learning 0.074s)
                       Mean reward: 205.94
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0034
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 40.3812
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.4561
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 149815296
                    Iteration time: 0.11s
                      Time elapsed: 00:29:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1525/1 [0m                       

                       Computation: 843754 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 223.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0034
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 43.3472
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4604
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 149913600
                    Iteration time: 0.12s
                      Time elapsed: 00:29:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1526/1 [0m                       

                       Computation: 701291 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 227.69
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0033
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 44.9550
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4620
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 150011904
                    Iteration time: 0.14s
                      Time elapsed: 00:29:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1527/1 [0m                       

                       Computation: 631933 steps/s (collection: 0.039s, learning 0.117s)
                       Mean reward: 256.27
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0033
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 50.8680
       Episode_Reward/object_height 0.0039
     Episode_Reward/reaching_object 0.4848
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 150110208
                    Iteration time: 0.16s
                      Time elapsed: 00:29:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1528/1 [0m                       

                       Computation: 583417 steps/s (collection: 0.050s, learning 0.118s)
                       Mean reward: 286.91
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0032
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.4920
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.4916
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 150208512
                    Iteration time: 0.17s
                      Time elapsed: 00:29:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1529/1 [0m                       

                       Computation: 653151 steps/s (collection: 0.040s, learning 0.111s)
                       Mean reward: 304.65
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0032
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 59.0606
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4973
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 150306816
                    Iteration time: 0.15s
                      Time elapsed: 00:29:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1530/1 [0m                       

                       Computation: 340297 steps/s (collection: 0.092s, learning 0.197s)
                       Mean reward: 343.13
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0031
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.9226
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.5157
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 150405120
                    Iteration time: 0.29s
                      Time elapsed: 00:29:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1531/1 [0m                       

                       Computation: 483409 steps/s (collection: 0.041s, learning 0.163s)
                       Mean reward: 341.25
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0032
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 66.8681
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.5223
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 150503424
                    Iteration time: 0.20s
                      Time elapsed: 00:29:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1532/1 [0m                       

                       Computation: 720580 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 388.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0031
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 82.7387
       Episode_Reward/object_height 0.0049
     Episode_Reward/reaching_object 0.5726
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 59.5833
--------------------------------------------------------------------------------
                   Total timesteps: 150601728
                    Iteration time: 0.14s
                      Time elapsed: 00:29:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1533/1 [0m                       

                       Computation: 549158 steps/s (collection: 0.061s, learning 0.118s)
                       Mean reward: 424.96
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 84.2759
       Episode_Reward/object_height 0.0049
     Episode_Reward/reaching_object 0.5643
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 150700032
                    Iteration time: 0.18s
                      Time elapsed: 00:29:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1534/1 [0m                       

                       Computation: 531603 steps/s (collection: 0.044s, learning 0.141s)
                       Mean reward: 465.56
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 91.6232
       Episode_Reward/object_height 0.0051
     Episode_Reward/reaching_object 0.5818
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 150798336
                    Iteration time: 0.18s
                      Time elapsed: 00:29:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1535/1 [0m                       

                       Computation: 627475 steps/s (collection: 0.047s, learning 0.110s)
                       Mean reward: 492.84
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 98.1346
       Episode_Reward/object_height 0.0053
     Episode_Reward/reaching_object 0.5891
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 150896640
                    Iteration time: 0.16s
                      Time elapsed: 00:29:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1536/1 [0m                       

                       Computation: 720405 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 516.58
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 102.4373
       Episode_Reward/object_height 0.0053
     Episode_Reward/reaching_object 0.6052
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 150994944
                    Iteration time: 0.14s
                      Time elapsed: 00:29:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1537/1 [0m                       

                       Computation: 753324 steps/s (collection: 0.049s, learning 0.082s)
                       Mean reward: 519.16
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 103.7823
       Episode_Reward/object_height 0.0054
     Episode_Reward/reaching_object 0.6076
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 151093248
                    Iteration time: 0.13s
                      Time elapsed: 00:29:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1538/1 [0m                       

                       Computation: 796379 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 531.07
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 105.3958
       Episode_Reward/object_height 0.0054
     Episode_Reward/reaching_object 0.6082
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 151191552
                    Iteration time: 0.12s
                      Time elapsed: 00:29:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1539/1 [0m                       

                       Computation: 780291 steps/s (collection: 0.035s, learning 0.091s)
                       Mean reward: 554.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 108.7258
       Episode_Reward/object_height 0.0056
     Episode_Reward/reaching_object 0.6208
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 151289856
                    Iteration time: 0.13s
                      Time elapsed: 00:30:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1540/1 [0m                       

                       Computation: 448084 steps/s (collection: 0.064s, learning 0.155s)
                       Mean reward: 574.23
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 114.6343
       Episode_Reward/object_height 0.0057
     Episode_Reward/reaching_object 0.6334
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 151388160
                    Iteration time: 0.22s
                      Time elapsed: 00:30:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1541/1 [0m                       

                       Computation: 684900 steps/s (collection: 0.045s, learning 0.099s)
                       Mean reward: 596.31
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 119.2898
       Episode_Reward/object_height 0.0058
     Episode_Reward/reaching_object 0.6341
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 151486464
                    Iteration time: 0.14s
                      Time elapsed: 00:30:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1542/1 [0m                       

                       Computation: 606731 steps/s (collection: 0.046s, learning 0.117s)
                       Mean reward: 609.39
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 118.9602
       Episode_Reward/object_height 0.0058
     Episode_Reward/reaching_object 0.6335
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 61.3750
--------------------------------------------------------------------------------
                   Total timesteps: 151584768
                    Iteration time: 0.16s
                      Time elapsed: 00:30:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1543/1 [0m                       

                       Computation: 668328 steps/s (collection: 0.044s, learning 0.103s)
                       Mean reward: 620.33
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 120.7093
       Episode_Reward/object_height 0.0057
     Episode_Reward/reaching_object 0.6322
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 151683072
                    Iteration time: 0.15s
                      Time elapsed: 00:30:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1544/1 [0m                       

                       Computation: 723215 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 643.31
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 129.2237
       Episode_Reward/object_height 0.0060
     Episode_Reward/reaching_object 0.6666
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 151781376
                    Iteration time: 0.14s
                      Time elapsed: 00:30:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1545/1 [0m                       

                       Computation: 637364 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 650.49
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 128.4251
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.6550
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 151879680
                    Iteration time: 0.15s
                      Time elapsed: 00:30:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1546/1 [0m                       

                       Computation: 536541 steps/s (collection: 0.037s, learning 0.146s)
                       Mean reward: 652.99
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 129.2118
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.6583
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 151977984
                    Iteration time: 0.18s
                      Time elapsed: 00:30:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1547/1 [0m                       

                       Computation: 471521 steps/s (collection: 0.060s, learning 0.148s)
                       Mean reward: 642.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 128.1384
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.6531
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 152076288
                    Iteration time: 0.21s
                      Time elapsed: 00:30:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1548/1 [0m                       

                       Computation: 849073 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 644.97
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 128.9649
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.6581
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152174592
                    Iteration time: 0.12s
                      Time elapsed: 00:30:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1549/1 [0m                       

                       Computation: 676839 steps/s (collection: 0.038s, learning 0.107s)
                       Mean reward: 667.12
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 133.1995
       Episode_Reward/object_height 0.0060
     Episode_Reward/reaching_object 0.6699
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 152272896
                    Iteration time: 0.15s
                      Time elapsed: 00:30:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1550/1 [0m                       

                       Computation: 715374 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 675.08
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 134.4246
       Episode_Reward/object_height 0.0060
     Episode_Reward/reaching_object 0.6718
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 152371200
                    Iteration time: 0.14s
                      Time elapsed: 00:30:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1551/1 [0m                       

                       Computation: 599331 steps/s (collection: 0.046s, learning 0.118s)
                       Mean reward: 682.44
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 136.2859
       Episode_Reward/object_height 0.0060
     Episode_Reward/reaching_object 0.6774
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 152469504
                    Iteration time: 0.16s
                      Time elapsed: 00:30:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1552/1 [0m                       

                       Computation: 679010 steps/s (collection: 0.038s, learning 0.107s)
                       Mean reward: 692.59
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 137.2312
       Episode_Reward/object_height 0.0060
     Episode_Reward/reaching_object 0.6703
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 152567808
                    Iteration time: 0.14s
                      Time elapsed: 00:30:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1553/1 [0m                       

                       Computation: 554905 steps/s (collection: 0.041s, learning 0.136s)
                       Mean reward: 689.53
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 133.6637
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.6645
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 58.0833
--------------------------------------------------------------------------------
                   Total timesteps: 152666112
                    Iteration time: 0.18s
                      Time elapsed: 00:30:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1554/1 [0m                       

                       Computation: 802650 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 677.62
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 134.6111
       Episode_Reward/object_height 0.0058
     Episode_Reward/reaching_object 0.6710
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 152764416
                    Iteration time: 0.12s
                      Time elapsed: 00:30:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1555/1 [0m                       

                       Computation: 761806 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 700.87
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 139.1747
       Episode_Reward/object_height 0.0060
     Episode_Reward/reaching_object 0.6710
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 152862720
                    Iteration time: 0.13s
                      Time elapsed: 00:30:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1556/1 [0m                       

                       Computation: 761381 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 715.55
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 142.7769
       Episode_Reward/object_height 0.0060
     Episode_Reward/reaching_object 0.6869
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 152961024
                    Iteration time: 0.13s
                      Time elapsed: 00:30:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1557/1 [0m                       

                       Computation: 861009 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 719.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 142.7530
       Episode_Reward/object_height 0.0060
     Episode_Reward/reaching_object 0.6893
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 153059328
                    Iteration time: 0.11s
                      Time elapsed: 00:30:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1558/1 [0m                       

                       Computation: 859052 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 739.87
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 146.7923
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.6954
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 153157632
                    Iteration time: 0.11s
                      Time elapsed: 00:30:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1559/1 [0m                       

                       Computation: 837402 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 727.77
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 144.0658
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.6925
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 153255936
                    Iteration time: 0.12s
                      Time elapsed: 00:30:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1560/1 [0m                       

                       Computation: 823393 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 731.02
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 145.8322
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.6953
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 153354240
                    Iteration time: 0.12s
                      Time elapsed: 00:30:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1561/1 [0m                       

                       Computation: 742350 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 738.33
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 147.6889
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.7073
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 153452544
                    Iteration time: 0.13s
                      Time elapsed: 00:30:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1562/1 [0m                       

                       Computation: 722773 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 758.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.3140
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7017
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 153550848
                    Iteration time: 0.14s
                      Time elapsed: 00:30:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1563/1 [0m                       

                       Computation: 777975 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 721.74
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 142.3761
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.6803
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 60.1667
--------------------------------------------------------------------------------
                   Total timesteps: 153649152
                    Iteration time: 0.13s
                      Time elapsed: 00:30:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1564/1 [0m                       

                       Computation: 751202 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 691.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 137.9300
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.6718
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 153747456
                    Iteration time: 0.13s
                      Time elapsed: 00:30:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1565/1 [0m                       

                       Computation: 638000 steps/s (collection: 0.036s, learning 0.118s)
                       Mean reward: 740.73
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 145.8515
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.6967
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 153845760
                    Iteration time: 0.15s
                      Time elapsed: 00:30:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1566/1 [0m                       

                       Computation: 756081 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 740.86
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 147.6683
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.6944
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 153944064
                    Iteration time: 0.13s
                      Time elapsed: 00:30:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1567/1 [0m                       

                       Computation: 764284 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 743.24
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 148.3115
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.6983
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 154042368
                    Iteration time: 0.13s
                      Time elapsed: 00:30:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1568/1 [0m                       

                       Computation: 559920 steps/s (collection: 0.053s, learning 0.123s)
                       Mean reward: 759.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.0806
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.7104
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 154140672
                    Iteration time: 0.18s
                      Time elapsed: 00:30:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1569/1 [0m                       

                       Computation: 581381 steps/s (collection: 0.045s, learning 0.124s)
                       Mean reward: 749.04
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 149.5371
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.6980
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 154238976
                    Iteration time: 0.17s
                      Time elapsed: 00:30:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1570/1 [0m                       

                       Computation: 654162 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 748.22
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 148.6568
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.6983
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 154337280
                    Iteration time: 0.15s
                      Time elapsed: 00:30:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1571/1 [0m                       

                       Computation: 588612 steps/s (collection: 0.056s, learning 0.111s)
                       Mean reward: 757.85
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.3260
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7084
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 154435584
                    Iteration time: 0.17s
                      Time elapsed: 00:30:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1572/1 [0m                       

                       Computation: 623931 steps/s (collection: 0.045s, learning 0.113s)
                       Mean reward: 746.50
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 149.1424
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7087
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 154533888
                    Iteration time: 0.16s
                      Time elapsed: 00:30:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1573/1 [0m                       

                       Computation: 672580 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 761.50
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 150.8273
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.7095
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 62.5833
--------------------------------------------------------------------------------
                   Total timesteps: 154632192
                    Iteration time: 0.15s
                      Time elapsed: 00:30:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1574/1 [0m                       

                       Computation: 595117 steps/s (collection: 0.040s, learning 0.126s)
                       Mean reward: 777.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 154.2222
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7189
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 154730496
                    Iteration time: 0.17s
                      Time elapsed: 00:30:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1575/1 [0m                       

                       Computation: 670972 steps/s (collection: 0.046s, learning 0.101s)
                       Mean reward: 757.03
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.4579
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7111
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 154828800
                    Iteration time: 0.15s
                      Time elapsed: 00:30:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1576/1 [0m                       

                       Computation: 634759 steps/s (collection: 0.038s, learning 0.117s)
                       Mean reward: 758.36
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.0939
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7109
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 154927104
                    Iteration time: 0.15s
                      Time elapsed: 00:30:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1577/1 [0m                       

                       Computation: 645698 steps/s (collection: 0.038s, learning 0.114s)
                       Mean reward: 747.86
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 149.2776
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.7023
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 155025408
                    Iteration time: 0.15s
                      Time elapsed: 00:30:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1578/1 [0m                       

                       Computation: 764530 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 775.99
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 154.3240
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7177
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 155123712
                    Iteration time: 0.13s
                      Time elapsed: 00:30:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1579/1 [0m                       

                       Computation: 719158 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 758.07
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.7300
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7009
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 155222016
                    Iteration time: 0.14s
                      Time elapsed: 00:30:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1580/1 [0m                       

                       Computation: 614983 steps/s (collection: 0.037s, learning 0.122s)
                       Mean reward: 750.31
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 149.6544
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.7019
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 155320320
                    Iteration time: 0.16s
                      Time elapsed: 00:30:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1581/1 [0m                       

                       Computation: 757019 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 761.59
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.3209
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7095
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 155418624
                    Iteration time: 0.13s
                      Time elapsed: 00:30:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1582/1 [0m                       

                       Computation: 439745 steps/s (collection: 0.046s, learning 0.177s)
                       Mean reward: 775.90
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 154.5511
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7155
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 155516928
                    Iteration time: 0.22s
                      Time elapsed: 00:30:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1583/1 [0m                       

                       Computation: 655668 steps/s (collection: 0.039s, learning 0.111s)
                       Mean reward: 760.36
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 151.9920
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7102
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 155615232
                    Iteration time: 0.15s
                      Time elapsed: 00:30:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1584/1 [0m                       

                       Computation: 482118 steps/s (collection: 0.050s, learning 0.154s)
                       Mean reward: 780.82
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 153.2113
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7075
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 58.7917
--------------------------------------------------------------------------------
                   Total timesteps: 155713536
                    Iteration time: 0.20s
                      Time elapsed: 00:30:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1585/1 [0m                       

                       Computation: 502693 steps/s (collection: 0.057s, learning 0.139s)
                       Mean reward: 787.47
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 155.9077
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7133
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 155811840
                    Iteration time: 0.20s
                      Time elapsed: 00:30:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1586/1 [0m                       

                       Computation: 750875 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 772.58
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 153.3012
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7133
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 155910144
                    Iteration time: 0.13s
                      Time elapsed: 00:30:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1587/1 [0m                       

                       Computation: 550608 steps/s (collection: 0.053s, learning 0.126s)
                       Mean reward: 790.10
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 157.6119
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7192
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 156008448
                    Iteration time: 0.18s
                      Time elapsed: 00:30:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1588/1 [0m                       

                       Computation: 527964 steps/s (collection: 0.047s, learning 0.140s)
                       Mean reward: 783.04
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 156.4126
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7175
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 156106752
                    Iteration time: 0.19s
                      Time elapsed: 00:30:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1589/1 [0m                       

                       Computation: 631712 steps/s (collection: 0.046s, learning 0.110s)
                       Mean reward: 792.18
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 157.4706
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7198
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 156205056
                    Iteration time: 0.16s
                      Time elapsed: 00:30:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1590/1 [0m                       

                       Computation: 723715 steps/s (collection: 0.036s, learning 0.100s)
                       Mean reward: 771.96
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 154.8516
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7186
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 156303360
                    Iteration time: 0.14s
                      Time elapsed: 00:30:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1591/1 [0m                       

                       Computation: 750201 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 785.18
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 155.3313
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7140
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 156401664
                    Iteration time: 0.13s
                      Time elapsed: 00:30:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1592/1 [0m                       

                       Computation: 826420 steps/s (collection: 0.035s, learning 0.084s)
                       Mean reward: 779.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 154.6305
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7032
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 156499968
                    Iteration time: 0.12s
                      Time elapsed: 00:31:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1593/1 [0m                       

                       Computation: 881352 steps/s (collection: 0.036s, learning 0.076s)
                       Mean reward: 789.42
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 156.7537
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7189
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 156598272
                    Iteration time: 0.11s
                      Time elapsed: 00:31:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1594/1 [0m                       

                       Computation: 792668 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 810.04
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 155.0490
       Episode_Reward/object_height 0.0069
     Episode_Reward/reaching_object 0.7097
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 61.0833
--------------------------------------------------------------------------------
                   Total timesteps: 156696576
                    Iteration time: 0.12s
                      Time elapsed: 00:31:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1595/1 [0m                       

                       Computation: 767912 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 802.75
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 160.0056
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7203
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 156794880
                    Iteration time: 0.13s
                      Time elapsed: 00:31:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1596/1 [0m                       

                       Computation: 782512 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 805.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 161.2506
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7257
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 156893184
                    Iteration time: 0.13s
                      Time elapsed: 00:31:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1597/1 [0m                       

                       Computation: 824632 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 809.31
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 160.9629
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7210
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 156991488
                    Iteration time: 0.12s
                      Time elapsed: 00:31:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1598/1 [0m                       

                       Computation: 731104 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 824.13
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.1489
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7320
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 157089792
                    Iteration time: 0.13s
                      Time elapsed: 00:31:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1599/1 [0m                       

                       Computation: 821551 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 797.94
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.6489
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7112
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 157188096
                    Iteration time: 0.12s
                      Time elapsed: 00:31:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1600/1 [0m                       

                       Computation: 724657 steps/s (collection: 0.034s, learning 0.102s)
                       Mean reward: 812.79
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 161.7756
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7229
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 157286400
                    Iteration time: 0.14s
                      Time elapsed: 00:31:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1601/1 [0m                       

                       Computation: 698491 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 830.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.0532
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7293
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 157384704
                    Iteration time: 0.14s
                      Time elapsed: 00:31:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1602/1 [0m                       

                       Computation: 791076 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 813.02
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 161.6289
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7216
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 157483008
                    Iteration time: 0.12s
                      Time elapsed: 00:31:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1603/1 [0m                       

                       Computation: 588483 steps/s (collection: 0.040s, learning 0.127s)
                       Mean reward: 813.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.2985
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7215
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 157581312
                    Iteration time: 0.17s
                      Time elapsed: 00:31:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1604/1 [0m                       

                       Computation: 602878 steps/s (collection: 0.040s, learning 0.123s)
                       Mean reward: 814.47
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.5921
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7285
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 157679616
                    Iteration time: 0.16s
                      Time elapsed: 00:31:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1605/1 [0m                       

                       Computation: 787698 steps/s (collection: 0.034s, learning 0.091s)
                       Mean reward: 830.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.2998
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7250
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 57.5417
--------------------------------------------------------------------------------
                   Total timesteps: 157777920
                    Iteration time: 0.12s
                      Time elapsed: 00:31:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1606/1 [0m                       

                       Computation: 766151 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 836.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.3572
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7305
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 157876224
                    Iteration time: 0.13s
                      Time elapsed: 00:31:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1607/1 [0m                       

                       Computation: 819210 steps/s (collection: 0.035s, learning 0.085s)
                       Mean reward: 824.78
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.0482
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7247
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 157974528
                    Iteration time: 0.12s
                      Time elapsed: 00:31:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1608/1 [0m                       

                       Computation: 867254 steps/s (collection: 0.033s, learning 0.080s)
                       Mean reward: 833.07
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.9826
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.7312
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 158072832
                    Iteration time: 0.11s
                      Time elapsed: 00:31:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1609/1 [0m                       

                       Computation: 710248 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 839.66
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.9077
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7317
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 158171136
                    Iteration time: 0.14s
                      Time elapsed: 00:31:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1610/1 [0m                       

                       Computation: 711939 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 836.82
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.5502
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7355
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 158269440
                    Iteration time: 0.14s
                      Time elapsed: 00:31:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1611/1 [0m                       

                       Computation: 501505 steps/s (collection: 0.043s, learning 0.153s)
                       Mean reward: 851.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2289
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 158367744
                    Iteration time: 0.20s
                      Time elapsed: 00:31:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1612/1 [0m                       

                       Computation: 744618 steps/s (collection: 0.038s, learning 0.094s)
                       Mean reward: 853.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.3935
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 158466048
                    Iteration time: 0.13s
                      Time elapsed: 00:31:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1613/1 [0m                       

                       Computation: 786244 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 853.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.2401
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 158564352
                    Iteration time: 0.13s
                      Time elapsed: 00:31:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1614/1 [0m                       

                       Computation: 605029 steps/s (collection: 0.037s, learning 0.125s)
                       Mean reward: 853.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.4808
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7629
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 158662656
                    Iteration time: 0.16s
                      Time elapsed: 00:31:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1615/1 [0m                       

                       Computation: 739006 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 843.35
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.4250
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7313
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 60.0000
--------------------------------------------------------------------------------
                   Total timesteps: 158760960
                    Iteration time: 0.13s
                      Time elapsed: 00:31:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1616/1 [0m                       

                       Computation: 858371 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 834.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.9656
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.7393
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 158859264
                    Iteration time: 0.11s
                      Time elapsed: 00:31:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1617/1 [0m                       

                       Computation: 694897 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 828.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.2163
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.7438
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 158957568
                    Iteration time: 0.14s
                      Time elapsed: 00:31:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1618/1 [0m                       

                       Computation: 853386 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 841.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.9388
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 159055872
                    Iteration time: 0.12s
                      Time elapsed: 00:31:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1619/1 [0m                       

                       Computation: 833020 steps/s (collection: 0.035s, learning 0.083s)
                       Mean reward: 852.62
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8610
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 159154176
                    Iteration time: 0.12s
                      Time elapsed: 00:31:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1620/1 [0m                       

                       Computation: 801806 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 856.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.1645
       Episode_Reward/object_height 0.0074
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 159252480
                    Iteration time: 0.12s
                      Time elapsed: 00:31:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1621/1 [0m                       

                       Computation: 841500 steps/s (collection: 0.036s, learning 0.081s)
                       Mean reward: 847.40
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0336
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.7601
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 159350784
                    Iteration time: 0.12s
                      Time elapsed: 00:31:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1622/1 [0m                       

                       Computation: 852003 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 865.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1924
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7669
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 159449088
                    Iteration time: 0.12s
                      Time elapsed: 00:31:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1623/1 [0m                       

                       Computation: 826014 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 862.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6999
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 159547392
                    Iteration time: 0.12s
                      Time elapsed: 00:31:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1624/1 [0m                       

                       Computation: 818852 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 862.63
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.7598
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.7715
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 159645696
                    Iteration time: 0.12s
                      Time elapsed: 00:31:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1625/1 [0m                       

                       Computation: 845417 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 865.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.7362
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7668
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 62.4167
--------------------------------------------------------------------------------
                   Total timesteps: 159744000
                    Iteration time: 0.12s
                      Time elapsed: 00:31:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1626/1 [0m                       

                       Computation: 852780 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 859.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6027
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 159842304
                    Iteration time: 0.12s
                      Time elapsed: 00:31:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1627/1 [0m                       

                       Computation: 757925 steps/s (collection: 0.036s, learning 0.094s)
                       Mean reward: 853.05
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.2418
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 159940608
                    Iteration time: 0.13s
                      Time elapsed: 00:31:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1628/1 [0m                       

                       Computation: 824167 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 853.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.9231
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7543
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 160038912
                    Iteration time: 0.12s
                      Time elapsed: 00:31:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1629/1 [0m                       

                       Computation: 854342 steps/s (collection: 0.035s, learning 0.081s)
                       Mean reward: 858.11
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0092
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 160137216
                    Iteration time: 0.12s
                      Time elapsed: 00:31:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1630/1 [0m                       

                       Computation: 795355 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 864.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1197
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 160235520
                    Iteration time: 0.12s
                      Time elapsed: 00:31:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1631/1 [0m                       

                       Computation: 810701 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 864.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1888
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7605
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 160333824
                    Iteration time: 0.12s
                      Time elapsed: 00:31:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1632/1 [0m                       

                       Computation: 733913 steps/s (collection: 0.036s, learning 0.098s)
                       Mean reward: 868.90
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0036
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 160432128
                    Iteration time: 0.13s
                      Time elapsed: 00:31:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1633/1 [0m                       

                       Computation: 743391 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 863.38
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.2330
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 160530432
                    Iteration time: 0.13s
                      Time elapsed: 00:31:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1634/1 [0m                       

                       Computation: 729377 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 861.05
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.5777
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7707
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 160628736
                    Iteration time: 0.13s
                      Time elapsed: 00:31:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1635/1 [0m                       

                       Computation: 817612 steps/s (collection: 0.034s, learning 0.086s)
                       Mean reward: 862.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.3745
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 160727040
                    Iteration time: 0.12s
                      Time elapsed: 00:31:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1636/1 [0m                       

                       Computation: 737404 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 865.11
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.3866
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 58.6667
--------------------------------------------------------------------------------
                   Total timesteps: 160825344
                    Iteration time: 0.13s
                      Time elapsed: 00:31:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1637/1 [0m                       

                       Computation: 644433 steps/s (collection: 0.037s, learning 0.116s)
                       Mean reward: 847.02
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.3286
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7615
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 160923648
                    Iteration time: 0.15s
                      Time elapsed: 00:31:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1638/1 [0m                       

                       Computation: 664928 steps/s (collection: 0.042s, learning 0.106s)
                       Mean reward: 865.16
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6192
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 161021952
                    Iteration time: 0.15s
                      Time elapsed: 00:31:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1639/1 [0m                       

                       Computation: 601124 steps/s (collection: 0.057s, learning 0.107s)
                       Mean reward: 869.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.2151
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 161120256
                    Iteration time: 0.16s
                      Time elapsed: 00:31:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1640/1 [0m                       

                       Computation: 542615 steps/s (collection: 0.041s, learning 0.140s)
                       Mean reward: 869.96
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5824
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7812
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 161218560
                    Iteration time: 0.18s
                      Time elapsed: 00:31:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1641/1 [0m                       

                       Computation: 698379 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 869.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.2560
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 161316864
                    Iteration time: 0.14s
                      Time elapsed: 00:31:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1642/1 [0m                       

                       Computation: 709869 steps/s (collection: 0.037s, learning 0.102s)
                       Mean reward: 866.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5513
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 161415168
                    Iteration time: 0.14s
                      Time elapsed: 00:31:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1643/1 [0m                       

                       Computation: 647370 steps/s (collection: 0.040s, learning 0.112s)
                       Mean reward: 860.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.7118
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7716
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 161513472
                    Iteration time: 0.15s
                      Time elapsed: 00:31:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1644/1 [0m                       

                       Computation: 611491 steps/s (collection: 0.040s, learning 0.121s)
                       Mean reward: 871.33
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5915
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 161611776
                    Iteration time: 0.16s
                      Time elapsed: 00:31:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1645/1 [0m                       

                       Computation: 668301 steps/s (collection: 0.041s, learning 0.106s)
                       Mean reward: 871.36
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4221
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7715
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 161710080
                    Iteration time: 0.15s
                      Time elapsed: 00:31:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1646/1 [0m                       

                       Computation: 590138 steps/s (collection: 0.056s, learning 0.111s)
                       Mean reward: 872.92
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.3950
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 61.1250
--------------------------------------------------------------------------------
                   Total timesteps: 161808384
                    Iteration time: 0.17s
                      Time elapsed: 00:31:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1647/1 [0m                       

                       Computation: 694606 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 874.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.1755
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 161906688
                    Iteration time: 0.14s
                      Time elapsed: 00:31:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1648/1 [0m                       

                       Computation: 792327 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 867.78
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.0249
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 162004992
                    Iteration time: 0.12s
                      Time elapsed: 00:32:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1649/1 [0m                       

                       Computation: 801393 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 866.67
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.4083
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 162103296
                    Iteration time: 0.12s
                      Time elapsed: 00:32:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1650/1 [0m                       

                       Computation: 755766 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 868.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0619
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7740
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 162201600
                    Iteration time: 0.13s
                      Time elapsed: 00:32:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1651/1 [0m                       

                       Computation: 834149 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 871.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5841
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 162299904
                    Iteration time: 0.12s
                      Time elapsed: 00:32:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1652/1 [0m                       

                       Computation: 741930 steps/s (collection: 0.035s, learning 0.097s)
                       Mean reward: 869.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2067
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 162398208
                    Iteration time: 0.13s
                      Time elapsed: 00:32:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1653/1 [0m                       

                       Computation: 828720 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 862.11
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4618
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 162496512
                    Iteration time: 0.12s
                      Time elapsed: 00:32:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1654/1 [0m                       

                       Computation: 854549 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 873.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9381
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 162594816
                    Iteration time: 0.12s
                      Time elapsed: 00:32:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1655/1 [0m                       

                       Computation: 793559 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 868.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9322
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 162693120
                    Iteration time: 0.12s
                      Time elapsed: 00:32:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1656/1 [0m                       

                       Computation: 811083 steps/s (collection: 0.035s, learning 0.087s)
                       Mean reward: 875.26
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7384
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 162791424
                    Iteration time: 0.12s
                      Time elapsed: 00:32:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1657/1 [0m                       

                       Computation: 697041 steps/s (collection: 0.035s, learning 0.106s)
                       Mean reward: 868.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8428
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7770
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 57.6250
--------------------------------------------------------------------------------
                   Total timesteps: 162889728
                    Iteration time: 0.14s
                      Time elapsed: 00:32:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1658/1 [0m                       

                       Computation: 712142 steps/s (collection: 0.035s, learning 0.103s)
                       Mean reward: 863.42
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.3604
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7648
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 162988032
                    Iteration time: 0.14s
                      Time elapsed: 00:32:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1659/1 [0m                       

                       Computation: 770114 steps/s (collection: 0.034s, learning 0.093s)
                       Mean reward: 868.20
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.6877
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7740
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 163086336
                    Iteration time: 0.13s
                      Time elapsed: 00:32:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1660/1 [0m                       

                       Computation: 757829 steps/s (collection: 0.034s, learning 0.095s)
                       Mean reward: 867.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0560
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 163184640
                    Iteration time: 0.13s
                      Time elapsed: 00:32:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1661/1 [0m                       

                       Computation: 783243 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 862.14
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.1165
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 163282944
                    Iteration time: 0.13s
                      Time elapsed: 00:32:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1662/1 [0m                       

                       Computation: 830493 steps/s (collection: 0.035s, learning 0.083s)
                       Mean reward: 876.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.6402
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 163381248
                    Iteration time: 0.12s
                      Time elapsed: 00:32:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1663/1 [0m                       

                       Computation: 595134 steps/s (collection: 0.036s, learning 0.129s)
                       Mean reward: 867.60
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7796
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 163479552
                    Iteration time: 0.17s
                      Time elapsed: 00:32:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1664/1 [0m                       

                       Computation: 738615 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 874.18
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2920
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7747
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 163577856
                    Iteration time: 0.13s
                      Time elapsed: 00:32:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1665/1 [0m                       

                       Computation: 711945 steps/s (collection: 0.050s, learning 0.088s)
                       Mean reward: 871.56
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.6700
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 163676160
                    Iteration time: 0.14s
                      Time elapsed: 00:32:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1666/1 [0m                       

                       Computation: 771364 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 874.08
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.5635
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 163774464
                    Iteration time: 0.13s
                      Time elapsed: 00:32:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1667/1 [0m                       

                       Computation: 813046 steps/s (collection: 0.035s, learning 0.086s)
                       Mean reward: 871.05
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.2808
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 59.9167
--------------------------------------------------------------------------------
                   Total timesteps: 163872768
                    Iteration time: 0.12s
                      Time elapsed: 00:32:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1668/1 [0m                       

                       Computation: 719135 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 856.04
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.4692
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 163971072
                    Iteration time: 0.14s
                      Time elapsed: 00:32:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1669/1 [0m                       

                       Computation: 726383 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 854.10
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1763
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7508
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 164069376
                    Iteration time: 0.14s
                      Time elapsed: 00:32:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1670/1 [0m                       

                       Computation: 636397 steps/s (collection: 0.038s, learning 0.117s)
                       Mean reward: 854.28
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.7141
       Episode_Reward/object_height 0.0123
     Episode_Reward/reaching_object 0.7412
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 164167680
                    Iteration time: 0.15s
                      Time elapsed: 00:32:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1671/1 [0m                       

                       Computation: 567389 steps/s (collection: 0.045s, learning 0.128s)
                       Mean reward: 865.07
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.3306
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.7512
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 164265984
                    Iteration time: 0.17s
                      Time elapsed: 00:32:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1672/1 [0m                       

                       Computation: 577475 steps/s (collection: 0.036s, learning 0.135s)
                       Mean reward: 873.44
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.8213
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 164364288
                    Iteration time: 0.17s
                      Time elapsed: 00:32:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1673/1 [0m                       

                       Computation: 637645 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 862.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.4015
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.7569
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 164462592
                    Iteration time: 0.15s
                      Time elapsed: 00:32:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1674/1 [0m                       

                       Computation: 392626 steps/s (collection: 0.038s, learning 0.212s)
                       Mean reward: 870.18
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.1073
       Episode_Reward/object_height 0.0126
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 164560896
                    Iteration time: 0.25s
                      Time elapsed: 00:32:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1675/1 [0m                       

                       Computation: 667244 steps/s (collection: 0.038s, learning 0.109s)
                       Mean reward: 867.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 172.5489
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.7627
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 164659200
                    Iteration time: 0.15s
                      Time elapsed: 00:32:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1676/1 [0m                       

                       Computation: 705305 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 861.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4329
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 164757504
                    Iteration time: 0.14s
                      Time elapsed: 00:32:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1677/1 [0m                       

                       Computation: 573976 steps/s (collection: 0.070s, learning 0.101s)
                       Mean reward: 872.14
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.6844
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 164855808
                    Iteration time: 0.17s
                      Time elapsed: 00:32:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1678/1 [0m                       

                       Computation: 619868 steps/s (collection: 0.053s, learning 0.106s)
                       Mean reward: 870.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.2332
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.7715
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 56.5000
--------------------------------------------------------------------------------
                   Total timesteps: 164954112
                    Iteration time: 0.16s
                      Time elapsed: 00:32:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1679/1 [0m                       

                       Computation: 804260 steps/s (collection: 0.035s, learning 0.088s)
                       Mean reward: 871.92
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.6493
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 165052416
                    Iteration time: 0.12s
                      Time elapsed: 00:32:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1680/1 [0m                       

                       Computation: 710017 steps/s (collection: 0.036s, learning 0.103s)
                       Mean reward: 878.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0024
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.8179
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 165150720
                    Iteration time: 0.14s
                      Time elapsed: 00:32:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1681/1 [0m                       

                       Computation: 816664 steps/s (collection: 0.035s, learning 0.086s)
                       Mean reward: 873.30
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9151
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 165249024
                    Iteration time: 0.12s
                      Time elapsed: 00:32:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1682/1 [0m                       

                       Computation: 507764 steps/s (collection: 0.058s, learning 0.136s)
                       Mean reward: 876.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8524
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 165347328
                    Iteration time: 0.19s
                      Time elapsed: 00:32:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1683/1 [0m                       

                       Computation: 607489 steps/s (collection: 0.051s, learning 0.111s)
                       Mean reward: 869.90
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9909
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 165445632
                    Iteration time: 0.16s
                      Time elapsed: 00:32:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1684/1 [0m                       

                       Computation: 694561 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 874.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9573
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 165543936
                    Iteration time: 0.14s
                      Time elapsed: 00:32:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1685/1 [0m                       

                       Computation: 560025 steps/s (collection: 0.044s, learning 0.132s)
                       Mean reward: 872.15
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5373
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 165642240
                    Iteration time: 0.18s
                      Time elapsed: 00:32:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1686/1 [0m                       

                       Computation: 551565 steps/s (collection: 0.038s, learning 0.141s)
                       Mean reward: 872.35
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5384
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 165740544
                    Iteration time: 0.18s
                      Time elapsed: 00:32:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1687/1 [0m                       

                       Computation: 608074 steps/s (collection: 0.043s, learning 0.119s)
                       Mean reward: 871.09
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.1628
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7705
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 165838848
                    Iteration time: 0.16s
                      Time elapsed: 00:32:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1688/1 [0m                       

                       Computation: 564556 steps/s (collection: 0.037s, learning 0.137s)
                       Mean reward: 874.22
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9008
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 58.7083
--------------------------------------------------------------------------------
                   Total timesteps: 165937152
                    Iteration time: 0.17s
                      Time elapsed: 00:32:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1689/1 [0m                       

                       Computation: 703602 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 860.74
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0228
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 166035456
                    Iteration time: 0.14s
                      Time elapsed: 00:32:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1690/1 [0m                       

                       Computation: 453981 steps/s (collection: 0.051s, learning 0.166s)
                       Mean reward: 861.13
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0329
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7575
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 166133760
                    Iteration time: 0.22s
                      Time elapsed: 00:32:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1691/1 [0m                       

                       Computation: 626084 steps/s (collection: 0.044s, learning 0.113s)
                       Mean reward: 858.63
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9239
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 166232064
                    Iteration time: 0.16s
                      Time elapsed: 00:32:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1692/1 [0m                       

                       Computation: 810790 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 862.37
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7826
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7586
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 166330368
                    Iteration time: 0.12s
                      Time elapsed: 00:32:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1693/1 [0m                       

                       Computation: 773730 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 867.37
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.3666
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7615
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 166428672
                    Iteration time: 0.13s
                      Time elapsed: 00:32:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1694/1 [0m                       

                       Computation: 881406 steps/s (collection: 0.033s, learning 0.079s)
                       Mean reward: 859.00
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8070
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7602
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 166526976
                    Iteration time: 0.11s
                      Time elapsed: 00:32:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1695/1 [0m                       

                       Computation: 713575 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 873.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8888
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7699
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 166625280
                    Iteration time: 0.14s
                      Time elapsed: 00:32:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1696/1 [0m                       

                       Computation: 714820 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 870.49
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3856
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 166723584
                    Iteration time: 0.14s
                      Time elapsed: 00:32:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1697/1 [0m                       

                       Computation: 869751 steps/s (collection: 0.034s, learning 0.079s)
                       Mean reward: 872.25
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0859
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7705
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 166821888
                    Iteration time: 0.11s
                      Time elapsed: 00:32:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1698/1 [0m                       

                       Computation: 477353 steps/s (collection: 0.092s, learning 0.114s)
                       Mean reward: 874.05
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0232
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7687
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 60.9583
--------------------------------------------------------------------------------
                   Total timesteps: 166920192
                    Iteration time: 0.21s
                      Time elapsed: 00:32:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1699/1 [0m                       

                       Computation: 572434 steps/s (collection: 0.049s, learning 0.123s)
                       Mean reward: 858.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9418
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 167018496
                    Iteration time: 0.17s
                      Time elapsed: 00:32:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1700/1 [0m                       

                       Computation: 717858 steps/s (collection: 0.036s, learning 0.101s)
                       Mean reward: 831.37
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.8907
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7360
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 167116800
                    Iteration time: 0.14s
                      Time elapsed: 00:32:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1701/1 [0m                       

                       Computation: 706173 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 836.41
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.8725
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7380
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 167215104
                    Iteration time: 0.14s
                      Time elapsed: 00:32:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1702/1 [0m                       

                       Computation: 782959 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 851.37
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.5190
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7418
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 167313408
                    Iteration time: 0.13s
                      Time elapsed: 00:32:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1703/1 [0m                       

                       Computation: 571436 steps/s (collection: 0.043s, learning 0.129s)
                       Mean reward: 858.14
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9833
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7490
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 167411712
                    Iteration time: 0.17s
                      Time elapsed: 00:33:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1704/1 [0m                       

                       Computation: 726812 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 852.13
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.9926
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7471
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 167510016
                    Iteration time: 0.14s
                      Time elapsed: 00:33:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1705/1 [0m                       

                       Computation: 671606 steps/s (collection: 0.037s, learning 0.109s)
                       Mean reward: 844.06
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.0377
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7395
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 167608320
                    Iteration time: 0.15s
                      Time elapsed: 00:33:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1706/1 [0m                       

                       Computation: 701585 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 839.47
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.4057
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7410
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 167706624
                    Iteration time: 0.14s
                      Time elapsed: 00:33:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1707/1 [0m                       

                       Computation: 497152 steps/s (collection: 0.044s, learning 0.154s)
                       Mean reward: 845.68
               Mean episode length: 246.43
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.8203
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7489
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 167804928
                    Iteration time: 0.20s
                      Time elapsed: 00:33:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1708/1 [0m                       

                       Computation: 570365 steps/s (collection: 0.040s, learning 0.132s)
                       Mean reward: 865.37
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.6483
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 167903232
                    Iteration time: 0.17s
                      Time elapsed: 00:33:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1709/1 [0m                       

                       Computation: 753752 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 875.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.5344
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7754
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 57.1667
--------------------------------------------------------------------------------
                   Total timesteps: 168001536
                    Iteration time: 0.13s
                      Time elapsed: 00:33:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1710/1 [0m                       

                       Computation: 726045 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 834.20
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.7260
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7363
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 168099840
                    Iteration time: 0.14s
                      Time elapsed: 00:33:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1711/1 [0m                       

                       Computation: 379592 steps/s (collection: 0.065s, learning 0.194s)
                       Mean reward: 859.03
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8512
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7545
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 168198144
                    Iteration time: 0.26s
                      Time elapsed: 00:33:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1712/1 [0m                       

                       Computation: 530318 steps/s (collection: 0.056s, learning 0.129s)
                       Mean reward: 870.23
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3802
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7673
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 168296448
                    Iteration time: 0.19s
                      Time elapsed: 00:33:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1713/1 [0m                       

                       Computation: 402659 steps/s (collection: 0.057s, learning 0.187s)
                       Mean reward: 872.32
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9510
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 168394752
                    Iteration time: 0.24s
                      Time elapsed: 00:33:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1714/1 [0m                       

                       Computation: 479427 steps/s (collection: 0.041s, learning 0.165s)
                       Mean reward: 870.58
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9230
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 168493056
                    Iteration time: 0.21s
                      Time elapsed: 00:33:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1715/1 [0m                       

                       Computation: 547176 steps/s (collection: 0.045s, learning 0.135s)
                       Mean reward: 861.05
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0025
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4295
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7475
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 168591360
                    Iteration time: 0.18s
                      Time elapsed: 00:33:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1716/1 [0m                       

                       Computation: 606733 steps/s (collection: 0.049s, learning 0.113s)
                       Mean reward: 857.87
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6028
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7535
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 168689664
                    Iteration time: 0.16s
                      Time elapsed: 00:33:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1717/1 [0m                       

                       Computation: 525510 steps/s (collection: 0.050s, learning 0.138s)
                       Mean reward: 854.26
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.3895
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7500
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 168787968
                    Iteration time: 0.19s
                      Time elapsed: 00:33:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1718/1 [0m                       

                       Computation: 673626 steps/s (collection: 0.043s, learning 0.103s)
                       Mean reward: 866.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3652
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 168886272
                    Iteration time: 0.15s
                      Time elapsed: 00:33:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1719/1 [0m                       

                       Computation: 440812 steps/s (collection: 0.053s, learning 0.170s)
                       Mean reward: 875.21
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9847
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 59.2917
--------------------------------------------------------------------------------
                   Total timesteps: 168984576
                    Iteration time: 0.22s
                      Time elapsed: 00:33:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1720/1 [0m                       

                       Computation: 488335 steps/s (collection: 0.052s, learning 0.150s)
                       Mean reward: 852.48
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9127
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 169082880
                    Iteration time: 0.20s
                      Time elapsed: 00:33:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1721/1 [0m                       

                       Computation: 634119 steps/s (collection: 0.051s, learning 0.105s)
                       Mean reward: 865.38
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8103
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7635
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 169181184
                    Iteration time: 0.16s
                      Time elapsed: 00:33:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1722/1 [0m                       

                       Computation: 576426 steps/s (collection: 0.044s, learning 0.127s)
                       Mean reward: 872.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8735
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 169279488
                    Iteration time: 0.17s
                      Time elapsed: 00:33:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1723/1 [0m                       

                       Computation: 568150 steps/s (collection: 0.054s, learning 0.120s)
                       Mean reward: 876.03
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5801
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7749
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 169377792
                    Iteration time: 0.17s
                      Time elapsed: 00:33:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1724/1 [0m                       

                       Computation: 540026 steps/s (collection: 0.046s, learning 0.136s)
                       Mean reward: 872.87
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8376
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7801
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 169476096
                    Iteration time: 0.18s
                      Time elapsed: 00:33:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1725/1 [0m                       

                       Computation: 581820 steps/s (collection: 0.059s, learning 0.110s)
                       Mean reward: 877.96
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.8832
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 169574400
                    Iteration time: 0.17s
                      Time elapsed: 00:33:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1726/1 [0m                       

                       Computation: 776960 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 866.40
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.7204
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7676
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 169672704
                    Iteration time: 0.13s
                      Time elapsed: 00:33:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1727/1 [0m                       

                       Computation: 757578 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 879.67
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.1499
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 169771008
                    Iteration time: 0.13s
                      Time elapsed: 00:33:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1728/1 [0m                       

                       Computation: 819404 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 881.23
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.4341
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 169869312
                    Iteration time: 0.12s
                      Time elapsed: 00:33:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1729/1 [0m                       

                       Computation: 705740 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 879.94
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.4937
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7849
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 169967616
                    Iteration time: 0.14s
                      Time elapsed: 00:33:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1730/1 [0m                       

                       Computation: 773171 steps/s (collection: 0.037s, learning 0.090s)
                       Mean reward: 877.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5339
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7775
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 55.7083
--------------------------------------------------------------------------------
                   Total timesteps: 170065920
                    Iteration time: 0.13s
                      Time elapsed: 00:33:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1731/1 [0m                       

                       Computation: 786148 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 859.75
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6242
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 170164224
                    Iteration time: 0.13s
                      Time elapsed: 00:33:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1732/1 [0m                       

                       Computation: 766495 steps/s (collection: 0.036s, learning 0.092s)
                       Mean reward: 872.47
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7183
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 170262528
                    Iteration time: 0.13s
                      Time elapsed: 00:33:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1733/1 [0m                       

                       Computation: 666271 steps/s (collection: 0.044s, learning 0.104s)
                       Mean reward: 876.98
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.4735
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7873
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 170360832
                    Iteration time: 0.15s
                      Time elapsed: 00:33:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1734/1 [0m                       

                       Computation: 641764 steps/s (collection: 0.040s, learning 0.113s)
                       Mean reward: 873.00
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8371
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 170459136
                    Iteration time: 0.15s
                      Time elapsed: 00:33:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1735/1 [0m                       

                       Computation: 767570 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 880.85
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.2827
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7812
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 170557440
                    Iteration time: 0.13s
                      Time elapsed: 00:33:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1736/1 [0m                       

                       Computation: 675115 steps/s (collection: 0.041s, learning 0.105s)
                       Mean reward: 868.86
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1542
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 170655744
                    Iteration time: 0.15s
                      Time elapsed: 00:33:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1737/1 [0m                       

                       Computation: 578549 steps/s (collection: 0.043s, learning 0.127s)
                       Mean reward: 871.56
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.3838
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 170754048
                    Iteration time: 0.17s
                      Time elapsed: 00:33:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1738/1 [0m                       

                       Computation: 549025 steps/s (collection: 0.047s, learning 0.133s)
                       Mean reward: 874.26
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2763
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7835
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 170852352
                    Iteration time: 0.18s
                      Time elapsed: 00:33:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1739/1 [0m                       

                       Computation: 497680 steps/s (collection: 0.050s, learning 0.148s)
                       Mean reward: 879.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.8959
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7807
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 170950656
                    Iteration time: 0.20s
                      Time elapsed: 00:33:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1740/1 [0m                       

                       Computation: 584645 steps/s (collection: 0.038s, learning 0.130s)
                       Mean reward: 875.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.2418
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7824
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 58.2083
--------------------------------------------------------------------------------
                   Total timesteps: 171048960
                    Iteration time: 0.17s
                      Time elapsed: 00:33:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1741/1 [0m                       

                       Computation: 539955 steps/s (collection: 0.056s, learning 0.126s)
                       Mean reward: 866.41
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.9381
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 171147264
                    Iteration time: 0.18s
                      Time elapsed: 00:33:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1742/1 [0m                       

                       Computation: 583221 steps/s (collection: 0.045s, learning 0.124s)
                       Mean reward: 873.77
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.1633
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 171245568
                    Iteration time: 0.17s
                      Time elapsed: 00:33:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1743/1 [0m                       

                       Computation: 606331 steps/s (collection: 0.039s, learning 0.124s)
                       Mean reward: 868.79
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4208
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 171343872
                    Iteration time: 0.16s
                      Time elapsed: 00:33:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1744/1 [0m                       

                       Computation: 711855 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 879.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.1407
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7861
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 171442176
                    Iteration time: 0.14s
                      Time elapsed: 00:33:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1745/1 [0m                       

                       Computation: 706749 steps/s (collection: 0.049s, learning 0.090s)
                       Mean reward: 876.29
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6537
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7866
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 171540480
                    Iteration time: 0.14s
                      Time elapsed: 00:33:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1746/1 [0m                       

                       Computation: 464396 steps/s (collection: 0.055s, learning 0.157s)
                       Mean reward: 880.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.9122
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7917
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 171638784
                    Iteration time: 0.21s
                      Time elapsed: 00:33:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1747/1 [0m                       

                       Computation: 659358 steps/s (collection: 0.039s, learning 0.110s)
                       Mean reward: 882.85
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.6132
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7907
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 171737088
                    Iteration time: 0.15s
                      Time elapsed: 00:33:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1748/1 [0m                       

                       Computation: 747226 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 875.34
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2809
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 171835392
                    Iteration time: 0.13s
                      Time elapsed: 00:33:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1749/1 [0m                       

                       Computation: 410227 steps/s (collection: 0.078s, learning 0.162s)
                       Mean reward: 881.76
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.6600
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7907
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 171933696
                    Iteration time: 0.24s
                      Time elapsed: 00:33:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1750/1 [0m                       

                       Computation: 429952 steps/s (collection: 0.062s, learning 0.167s)
                       Mean reward: 877.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6009
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7880
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 60.5833
--------------------------------------------------------------------------------
                   Total timesteps: 172032000
                    Iteration time: 0.23s
                      Time elapsed: 00:33:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1751/1 [0m                       

                       Computation: 467899 steps/s (collection: 0.057s, learning 0.154s)
                       Mean reward: 876.23
               Mean episode length: 248.63
         Episode_Reward/action_rate -0.0026
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6490
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7869
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 172130304
                    Iteration time: 0.21s
                      Time elapsed: 00:33:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1752/1 [0m                       

                       Computation: 694413 steps/s (collection: 0.061s, learning 0.081s)
                       Mean reward: 874.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8936
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7857
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 172228608
                    Iteration time: 0.14s
                      Time elapsed: 00:33:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1753/1 [0m                       

                       Computation: 647591 steps/s (collection: 0.053s, learning 0.099s)
                       Mean reward: 874.00
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2774
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7845
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 172326912
                    Iteration time: 0.15s
                      Time elapsed: 00:33:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1754/1 [0m                       

                       Computation: 428116 steps/s (collection: 0.070s, learning 0.160s)
                       Mean reward: 874.19
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3646
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7906
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 172425216
                    Iteration time: 0.23s
                      Time elapsed: 00:34:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1755/1 [0m                       

                       Computation: 393151 steps/s (collection: 0.080s, learning 0.171s)
                       Mean reward: 878.95
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5589
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7906
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 172523520
                    Iteration time: 0.25s
                      Time elapsed: 00:34:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1756/1 [0m                       

                       Computation: 767758 steps/s (collection: 0.035s, learning 0.094s)
                       Mean reward: 876.58
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.4932
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7867
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 172621824
                    Iteration time: 0.13s
                      Time elapsed: 00:34:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1757/1 [0m                       

                       Computation: 663880 steps/s (collection: 0.037s, learning 0.111s)
                       Mean reward: 876.46
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5248
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7842
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 172720128
                    Iteration time: 0.15s
                      Time elapsed: 00:34:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1758/1 [0m                       

                       Computation: 713210 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 859.87
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.3281
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7709
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 172818432
                    Iteration time: 0.14s
                      Time elapsed: 00:34:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1759/1 [0m                       

                       Computation: 724324 steps/s (collection: 0.035s, learning 0.101s)
                       Mean reward: 873.49
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.9361
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 172916736
                    Iteration time: 0.14s
                      Time elapsed: 00:34:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1760/1 [0m                       

                       Computation: 667001 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 872.91
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7745
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 173015040
                    Iteration time: 0.15s
                      Time elapsed: 00:34:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1761/1 [0m                       

                       Computation: 495031 steps/s (collection: 0.048s, learning 0.151s)
                       Mean reward: 873.25
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.5037
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7742
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 56.6250
--------------------------------------------------------------------------------
                   Total timesteps: 173113344
                    Iteration time: 0.20s
                      Time elapsed: 00:34:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1762/1 [0m                       

                       Computation: 475714 steps/s (collection: 0.086s, learning 0.121s)
                       Mean reward: 861.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.9906
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 173211648
                    Iteration time: 0.21s
                      Time elapsed: 00:34:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1763/1 [0m                       

                       Computation: 771268 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 873.38
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.8909
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 173309952
                    Iteration time: 0.13s
                      Time elapsed: 00:34:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1764/1 [0m                       

                       Computation: 694009 steps/s (collection: 0.036s, learning 0.106s)
                       Mean reward: 867.23
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0027
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6558
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7775
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 173408256
                    Iteration time: 0.14s
                      Time elapsed: 00:34:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1765/1 [0m                       

                       Computation: 845249 steps/s (collection: 0.036s, learning 0.080s)
                       Mean reward: 865.48
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4908
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 173506560
                    Iteration time: 0.12s
                      Time elapsed: 00:34:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1766/1 [0m                       

                       Computation: 916416 steps/s (collection: 0.033s, learning 0.075s)
                       Mean reward: 871.89
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.4720
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 173604864
                    Iteration time: 0.11s
                      Time elapsed: 00:34:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1767/1 [0m                       

                       Computation: 732958 steps/s (collection: 0.034s, learning 0.100s)
                       Mean reward: 871.89
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2508
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7758
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 173703168
                    Iteration time: 0.13s
                      Time elapsed: 00:34:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1768/1 [0m                       

                       Computation: 597293 steps/s (collection: 0.039s, learning 0.126s)
                       Mean reward: 872.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5877
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 173801472
                    Iteration time: 0.16s
                      Time elapsed: 00:34:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1769/1 [0m                       

                       Computation: 849806 steps/s (collection: 0.035s, learning 0.080s)
                       Mean reward: 877.64
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.7329
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 173899776
                    Iteration time: 0.12s
                      Time elapsed: 00:34:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1770/1 [0m                       

                       Computation: 844122 steps/s (collection: 0.033s, learning 0.084s)
                       Mean reward: 880.91
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0028
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.6210
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7849
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 173998080
                    Iteration time: 0.12s
                      Time elapsed: 00:34:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1771/1 [0m                       

                       Computation: 627010 steps/s (collection: 0.044s, learning 0.113s)
                       Mean reward: 844.76
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3684
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7592
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 58.7500
--------------------------------------------------------------------------------
                   Total timesteps: 174096384
                    Iteration time: 0.16s
                      Time elapsed: 00:34:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1772/1 [0m                       

                       Computation: 699472 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 813.74
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.3159
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7382
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 174194688
                    Iteration time: 0.14s
                      Time elapsed: 00:34:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1773/1 [0m                       

                       Computation: 673267 steps/s (collection: 0.039s, learning 0.107s)
                       Mean reward: 789.07
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 155.3889
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7141
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 174292992
                    Iteration time: 0.15s
                      Time elapsed: 00:34:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1774/1 [0m                       

                       Computation: 425446 steps/s (collection: 0.056s, learning 0.176s)
                       Mean reward: 798.67
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 158.9314
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7259
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 174391296
                    Iteration time: 0.23s
                      Time elapsed: 00:34:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1775/1 [0m                       

                       Computation: 793013 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 812.01
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 161.3735
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7313
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 174489600
                    Iteration time: 0.12s
                      Time elapsed: 00:34:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1776/1 [0m                       

                       Computation: 779158 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 828.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.0528
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7441
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 174587904
                    Iteration time: 0.13s
                      Time elapsed: 00:34:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1777/1 [0m                       

                       Computation: 666373 steps/s (collection: 0.037s, learning 0.111s)
                       Mean reward: 834.69
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.6860
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7568
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 174686208
                    Iteration time: 0.15s
                      Time elapsed: 00:34:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1778/1 [0m                       

                       Computation: 428246 steps/s (collection: 0.061s, learning 0.169s)
                       Mean reward: 855.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.1066
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 174784512
                    Iteration time: 0.23s
                      Time elapsed: 00:34:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1779/1 [0m                       

                       Computation: 690712 steps/s (collection: 0.036s, learning 0.107s)
                       Mean reward: 874.35
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.1222
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7869
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 174882816
                    Iteration time: 0.14s
                      Time elapsed: 00:34:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1780/1 [0m                       

                       Computation: 701396 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 877.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.7503
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7910
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 174981120
                    Iteration time: 0.14s
                      Time elapsed: 00:34:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1781/1 [0m                       

                       Computation: 869494 steps/s (collection: 0.031s, learning 0.083s)
                       Mean reward: 871.73
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0029
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.2710
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 175079424
                    Iteration time: 0.11s
                      Time elapsed: 00:34:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1782/1 [0m                       

                       Computation: 728028 steps/s (collection: 0.035s, learning 0.101s)
                       Mean reward: 874.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8826
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 55.2917
--------------------------------------------------------------------------------
                   Total timesteps: 175177728
                    Iteration time: 0.14s
                      Time elapsed: 00:34:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1783/1 [0m                       

                       Computation: 704604 steps/s (collection: 0.052s, learning 0.088s)
                       Mean reward: 864.99
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6125
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 175276032
                    Iteration time: 0.14s
                      Time elapsed: 00:34:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1784/1 [0m                       

                       Computation: 470649 steps/s (collection: 0.046s, learning 0.163s)
                       Mean reward: 868.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8784
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 175374336
                    Iteration time: 0.21s
                      Time elapsed: 00:34:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1785/1 [0m                       

                       Computation: 565248 steps/s (collection: 0.033s, learning 0.141s)
                       Mean reward: 872.54
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.9324
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 175472640
                    Iteration time: 0.17s
                      Time elapsed: 00:34:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1786/1 [0m                       

                       Computation: 492517 steps/s (collection: 0.051s, learning 0.149s)
                       Mean reward: 872.95
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.8006
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7826
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 175570944
                    Iteration time: 0.20s
                      Time elapsed: 00:34:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1787/1 [0m                       

                       Computation: 543345 steps/s (collection: 0.040s, learning 0.141s)
                       Mean reward: 871.11
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5573
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 175669248
                    Iteration time: 0.18s
                      Time elapsed: 00:34:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1788/1 [0m                       

                       Computation: 772836 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 875.31
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.1755
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7770
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 175767552
                    Iteration time: 0.13s
                      Time elapsed: 00:34:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1789/1 [0m                       

                       Computation: 725196 steps/s (collection: 0.037s, learning 0.099s)
                       Mean reward: 873.23
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.9797
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 175865856
                    Iteration time: 0.14s
                      Time elapsed: 00:34:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1790/1 [0m                       

                       Computation: 790997 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 872.61
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6229
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 175964160
                    Iteration time: 0.12s
                      Time elapsed: 00:34:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1791/1 [0m                       

                       Computation: 790850 steps/s (collection: 0.034s, learning 0.091s)
                       Mean reward: 874.08
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0530
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 176062464
                    Iteration time: 0.12s
                      Time elapsed: 00:34:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1792/1 [0m                       

                       Computation: 803803 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 868.51
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4076
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 57.3333
--------------------------------------------------------------------------------
                   Total timesteps: 176160768
                    Iteration time: 0.12s
                      Time elapsed: 00:34:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1793/1 [0m                       

                       Computation: 795556 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 852.05
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0030
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.6210
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7615
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 176259072
                    Iteration time: 0.12s
                      Time elapsed: 00:34:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1794/1 [0m                       

                       Computation: 811058 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 865.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0031
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.0719
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 176357376
                    Iteration time: 0.12s
                      Time elapsed: 00:34:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1795/1 [0m                       

                       Computation: 743784 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 870.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0031
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4300
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 176455680
                    Iteration time: 0.13s
                      Time elapsed: 00:34:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1796/1 [0m                       

                       Computation: 652276 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 865.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0031
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.7178
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 176553984
                    Iteration time: 0.15s
                      Time elapsed: 00:34:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1797/1 [0m                       

                       Computation: 823288 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 870.87
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0031
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5406
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 176652288
                    Iteration time: 0.12s
                      Time elapsed: 00:34:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1798/1 [0m                       

                       Computation: 777896 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 877.49
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0031
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9067
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7882
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 176750592
                    Iteration time: 0.13s
                      Time elapsed: 00:34:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1799/1 [0m                       

                       Computation: 725510 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 868.04
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0032
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.7169
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 176848896
                    Iteration time: 0.14s
                      Time elapsed: 00:34:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1800/1 [0m                       

                       Computation: 666314 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 867.00
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0032
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1694
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7703
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 176947200
                    Iteration time: 0.15s
                      Time elapsed: 00:34:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1801/1 [0m                       

                       Computation: 585010 steps/s (collection: 0.044s, learning 0.125s)
                       Mean reward: 871.44
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0032
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5066
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 177045504
                    Iteration time: 0.17s
                      Time elapsed: 00:34:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1802/1 [0m                       

                       Computation: 795672 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 871.67
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0033
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7248
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 177143808
                    Iteration time: 0.12s
                      Time elapsed: 00:34:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1803/1 [0m                       

                       Computation: 592499 steps/s (collection: 0.039s, learning 0.127s)
                       Mean reward: 871.74
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0032
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.5391
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 53.7500
--------------------------------------------------------------------------------
                   Total timesteps: 177242112
                    Iteration time: 0.17s
                      Time elapsed: 00:34:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1804/1 [0m                       

                       Computation: 889173 steps/s (collection: 0.033s, learning 0.078s)
                       Mean reward: 855.68
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0032
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5149
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 177340416
                    Iteration time: 0.11s
                      Time elapsed: 00:34:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1805/1 [0m                       

                       Computation: 496303 steps/s (collection: 0.033s, learning 0.165s)
                       Mean reward: 871.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0033
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4080
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7821
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 177438720
                    Iteration time: 0.20s
                      Time elapsed: 00:34:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1806/1 [0m                       

                       Computation: 691903 steps/s (collection: 0.033s, learning 0.109s)
                       Mean reward: 873.02
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0033
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0833
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7788
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 177537024
                    Iteration time: 0.14s
                      Time elapsed: 00:34:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1807/1 [0m                       

                       Computation: 689443 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 877.11
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0033
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6991
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 177635328
                    Iteration time: 0.14s
                      Time elapsed: 00:34:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1808/1 [0m                       

                       Computation: 640110 steps/s (collection: 0.041s, learning 0.113s)
                       Mean reward: 870.31
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0034
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5238
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7798
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 177733632
                    Iteration time: 0.15s
                      Time elapsed: 00:35:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1809/1 [0m                       

                       Computation: 604853 steps/s (collection: 0.042s, learning 0.121s)
                       Mean reward: 867.02
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0034
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5836
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 177831936
                    Iteration time: 0.16s
                      Time elapsed: 00:35:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1810/1 [0m                       

                       Computation: 621971 steps/s (collection: 0.039s, learning 0.119s)
                       Mean reward: 870.97
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0034
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.2288
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 177930240
                    Iteration time: 0.16s
                      Time elapsed: 00:35:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1811/1 [0m                       

                       Computation: 864298 steps/s (collection: 0.035s, learning 0.079s)
                       Mean reward: 873.94
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0034
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7497
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 178028544
                    Iteration time: 0.11s
                      Time elapsed: 00:35:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1812/1 [0m                       

                       Computation: 717333 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 875.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2664
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 178126848
                    Iteration time: 0.14s
                      Time elapsed: 00:35:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1813/1 [0m                       

                       Computation: 894051 steps/s (collection: 0.033s, learning 0.077s)
                       Mean reward: 873.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.6364
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 56.2500
--------------------------------------------------------------------------------
                   Total timesteps: 178225152
                    Iteration time: 0.11s
                      Time elapsed: 00:35:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1814/1 [0m                       

                       Computation: 565210 steps/s (collection: 0.061s, learning 0.113s)
                       Mean reward: 851.86
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6455
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 178323456
                    Iteration time: 0.17s
                      Time elapsed: 00:35:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1815/1 [0m                       

                       Computation: 597394 steps/s (collection: 0.045s, learning 0.120s)
                       Mean reward: 835.97
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.8999
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7398
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 178421760
                    Iteration time: 0.16s
                      Time elapsed: 00:35:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1816/1 [0m                       

                       Computation: 879067 steps/s (collection: 0.034s, learning 0.078s)
                       Mean reward: 848.54
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.0434
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7469
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 178520064
                    Iteration time: 0.11s
                      Time elapsed: 00:35:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1817/1 [0m                       

                       Computation: 721483 steps/s (collection: 0.035s, learning 0.101s)
                       Mean reward: 867.27
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8320
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 178618368
                    Iteration time: 0.14s
                      Time elapsed: 00:35:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1818/1 [0m                       

                       Computation: 686148 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 868.60
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.1836
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7610
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 178716672
                    Iteration time: 0.14s
                      Time elapsed: 00:35:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1819/1 [0m                       

                       Computation: 818802 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 861.43
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.9047
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 178814976
                    Iteration time: 0.12s
                      Time elapsed: 00:35:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1820/1 [0m                       

                       Computation: 717741 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 870.19
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.4868
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 178913280
                    Iteration time: 0.14s
                      Time elapsed: 00:35:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1821/1 [0m                       

                       Computation: 521446 steps/s (collection: 0.048s, learning 0.141s)
                       Mean reward: 871.30
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3936
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7792
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 179011584
                    Iteration time: 0.19s
                      Time elapsed: 00:35:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1822/1 [0m                       

                       Computation: 616252 steps/s (collection: 0.043s, learning 0.117s)
                       Mean reward: 878.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8803
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7867
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 179109888
                    Iteration time: 0.16s
                      Time elapsed: 00:35:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1823/1 [0m                       

                       Computation: 563143 steps/s (collection: 0.034s, learning 0.141s)
                       Mean reward: 875.09
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2252
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7803
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 58.6250
--------------------------------------------------------------------------------
                   Total timesteps: 179208192
                    Iteration time: 0.17s
                      Time elapsed: 00:35:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1824/1 [0m                       

                       Computation: 815551 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 879.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.0086
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7938
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 179306496
                    Iteration time: 0.12s
                      Time elapsed: 00:35:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1825/1 [0m                       

                       Computation: 828727 steps/s (collection: 0.033s, learning 0.086s)
                       Mean reward: 874.76
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4875
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7942
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 179404800
                    Iteration time: 0.12s
                      Time elapsed: 00:35:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1826/1 [0m                       

                       Computation: 684403 steps/s (collection: 0.036s, learning 0.108s)
                       Mean reward: 874.39
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3401
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7949
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 179503104
                    Iteration time: 0.14s
                      Time elapsed: 00:35:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1827/1 [0m                       

                       Computation: 813212 steps/s (collection: 0.034s, learning 0.087s)
                       Mean reward: 872.50
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7893
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 179601408
                    Iteration time: 0.12s
                      Time elapsed: 00:35:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1828/1 [0m                       

                       Computation: 548971 steps/s (collection: 0.049s, learning 0.130s)
                       Mean reward: 860.79
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0034
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6639
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 179699712
                    Iteration time: 0.18s
                      Time elapsed: 00:35:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1829/1 [0m                       

                       Computation: 503283 steps/s (collection: 0.055s, learning 0.140s)
                       Mean reward: 871.06
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5569
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7855
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 179798016
                    Iteration time: 0.20s
                      Time elapsed: 00:35:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1830/1 [0m                       

                       Computation: 715617 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 863.11
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.8817
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 179896320
                    Iteration time: 0.14s
                      Time elapsed: 00:35:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1831/1 [0m                       

                       Computation: 744596 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 855.50
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0885
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 179994624
                    Iteration time: 0.13s
                      Time elapsed: 00:35:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1832/1 [0m                       

                       Computation: 674210 steps/s (collection: 0.035s, learning 0.111s)
                       Mean reward: 869.96
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0034
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.0769
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 180092928
                    Iteration time: 0.15s
                      Time elapsed: 00:35:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1833/1 [0m                       

                       Computation: 838490 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 865.91
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3228
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 180191232
                    Iteration time: 0.12s
                      Time elapsed: 00:35:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1834/1 [0m                       

                       Computation: 545087 steps/s (collection: 0.038s, learning 0.142s)
                       Mean reward: 859.74
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.0911
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7510
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 54.8333
--------------------------------------------------------------------------------
                   Total timesteps: 180289536
                    Iteration time: 0.18s
                      Time elapsed: 00:35:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1835/1 [0m                       

                       Computation: 663027 steps/s (collection: 0.033s, learning 0.115s)
                       Mean reward: 831.51
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.1861
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7458
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 180387840
                    Iteration time: 0.15s
                      Time elapsed: 00:35:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1836/1 [0m                       

                       Computation: 726363 steps/s (collection: 0.034s, learning 0.102s)
                       Mean reward: 805.59
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 160.6000
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7321
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 180486144
                    Iteration time: 0.14s
                      Time elapsed: 00:35:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1837/1 [0m                       

                       Computation: 698103 steps/s (collection: 0.035s, learning 0.106s)
                       Mean reward: 788.96
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 156.7437
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7201
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 180584448
                    Iteration time: 0.14s
                      Time elapsed: 00:35:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1838/1 [0m                       

                       Computation: 499454 steps/s (collection: 0.043s, learning 0.154s)
                       Mean reward: 822.09
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 163.0190
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7397
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 180682752
                    Iteration time: 0.20s
                      Time elapsed: 00:35:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1839/1 [0m                       

                       Computation: 702651 steps/s (collection: 0.036s, learning 0.104s)
                       Mean reward: 829.35
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.0344
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 180781056
                    Iteration time: 0.14s
                      Time elapsed: 00:35:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1840/1 [0m                       

                       Computation: 485106 steps/s (collection: 0.045s, learning 0.158s)
                       Mean reward: 842.45
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.4690
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7468
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 180879360
                    Iteration time: 0.20s
                      Time elapsed: 00:35:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1841/1 [0m                       

                       Computation: 839923 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 838.55
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.3003
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7470
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 180977664
                    Iteration time: 0.12s
                      Time elapsed: 00:35:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1842/1 [0m                       

                       Computation: 534302 steps/s (collection: 0.041s, learning 0.143s)
                       Mean reward: 852.33
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8039
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7592
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 181075968
                    Iteration time: 0.18s
                      Time elapsed: 00:35:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1843/1 [0m                       

                       Computation: 581387 steps/s (collection: 0.041s, learning 0.128s)
                       Mean reward: 855.91
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.3654
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7629
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 181174272
                    Iteration time: 0.17s
                      Time elapsed: 00:35:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1844/1 [0m                       

                       Computation: 774474 steps/s (collection: 0.035s, learning 0.092s)
                       Mean reward: 857.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.8075
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7604
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 57.1667
--------------------------------------------------------------------------------
                   Total timesteps: 181272576
                    Iteration time: 0.13s
                      Time elapsed: 00:35:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1845/1 [0m                       

                       Computation: 604725 steps/s (collection: 0.043s, learning 0.120s)
                       Mean reward: 861.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.4422
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7484
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 181370880
                    Iteration time: 0.16s
                      Time elapsed: 00:35:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1846/1 [0m                       

                       Computation: 850906 steps/s (collection: 0.045s, learning 0.071s)
                       Mean reward: 864.74
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6383
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 181469184
                    Iteration time: 0.12s
                      Time elapsed: 00:35:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1847/1 [0m                       

                       Computation: 527968 steps/s (collection: 0.051s, learning 0.135s)
                       Mean reward: 870.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.3119
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 181567488
                    Iteration time: 0.19s
                      Time elapsed: 00:35:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1848/1 [0m                       

                       Computation: 826642 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 871.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4290
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7780
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 181665792
                    Iteration time: 0.12s
                      Time elapsed: 00:35:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1849/1 [0m                       

                       Computation: 770852 steps/s (collection: 0.035s, learning 0.093s)
                       Mean reward: 867.90
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.9941
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 181764096
                    Iteration time: 0.13s
                      Time elapsed: 00:35:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1850/1 [0m                       

                       Computation: 926007 steps/s (collection: 0.031s, learning 0.075s)
                       Mean reward: 875.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0035
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0112
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 181862400
                    Iteration time: 0.11s
                      Time elapsed: 00:35:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1851/1 [0m                       

                       Computation: 630043 steps/s (collection: 0.061s, learning 0.096s)
                       Mean reward: 876.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0823
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 181960704
                    Iteration time: 0.16s
                      Time elapsed: 00:35:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1852/1 [0m                       

                       Computation: 802408 steps/s (collection: 0.034s, learning 0.088s)
                       Mean reward: 872.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.3835
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 182059008
                    Iteration time: 0.12s
                      Time elapsed: 00:35:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1853/1 [0m                       

                       Computation: 604865 steps/s (collection: 0.041s, learning 0.122s)
                       Mean reward: 879.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.3146
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7874
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 182157312
                    Iteration time: 0.16s
                      Time elapsed: 00:35:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1854/1 [0m                       

                       Computation: 776959 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 877.74
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8765
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 182255616
                    Iteration time: 0.13s
                      Time elapsed: 00:35:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1855/1 [0m                       

                       Computation: 780044 steps/s (collection: 0.034s, learning 0.093s)
                       Mean reward: 876.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2026
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 53.6667
--------------------------------------------------------------------------------
                   Total timesteps: 182353920
                    Iteration time: 0.13s
                      Time elapsed: 00:35:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1856/1 [0m                       

                       Computation: 878062 steps/s (collection: 0.037s, learning 0.075s)
                       Mean reward: 867.36
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7580
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7822
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 182452224
                    Iteration time: 0.11s
                      Time elapsed: 00:35:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1857/1 [0m                       

                       Computation: 770220 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 874.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0244
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7895
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 182550528
                    Iteration time: 0.13s
                      Time elapsed: 00:35:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1858/1 [0m                       

                       Computation: 664832 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 879.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9117
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7910
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 182648832
                    Iteration time: 0.15s
                      Time elapsed: 00:35:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1859/1 [0m                       

                       Computation: 719546 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 880.44
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.3854
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7880
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 182747136
                    Iteration time: 0.14s
                      Time elapsed: 00:35:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1860/1 [0m                       

                       Computation: 428844 steps/s (collection: 0.046s, learning 0.183s)
                       Mean reward: 875.88
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2119
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7870
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 182845440
                    Iteration time: 0.23s
                      Time elapsed: 00:35:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1861/1 [0m                       

                       Computation: 838316 steps/s (collection: 0.034s, learning 0.083s)
                       Mean reward: 883.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 176.0220
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7879
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 182943744
                    Iteration time: 0.12s
                      Time elapsed: 00:35:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1862/1 [0m                       

                       Computation: 859752 steps/s (collection: 0.033s, learning 0.082s)
                       Mean reward: 878.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9976
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7893
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 183042048
                    Iteration time: 0.11s
                      Time elapsed: 00:35:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1863/1 [0m                       

                       Computation: 675819 steps/s (collection: 0.036s, learning 0.110s)
                       Mean reward: 878.87
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9060
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7878
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 183140352
                    Iteration time: 0.15s
                      Time elapsed: 00:35:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1864/1 [0m                       

                       Computation: 794417 steps/s (collection: 0.033s, learning 0.091s)
                       Mean reward: 884.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 176.3225
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7951
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 183238656
                    Iteration time: 0.12s
                      Time elapsed: 00:35:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1865/1 [0m                       

                       Computation: 772993 steps/s (collection: 0.036s, learning 0.091s)
                       Mean reward: 878.32
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7231
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7850
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 56.1667
--------------------------------------------------------------------------------
                   Total timesteps: 183336960
                    Iteration time: 0.13s
                      Time elapsed: 00:36:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1866/1 [0m                       

                       Computation: 743513 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 881.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.4967
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7991
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 183435264
                    Iteration time: 0.13s
                      Time elapsed: 00:36:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1867/1 [0m                       

                       Computation: 707371 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 884.62
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 176.2560
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7903
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 183533568
                    Iteration time: 0.14s
                      Time elapsed: 00:36:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1868/1 [0m                       

                       Computation: 741647 steps/s (collection: 0.036s, learning 0.097s)
                       Mean reward: 878.22
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5955
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 183631872
                    Iteration time: 0.13s
                      Time elapsed: 00:36:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1869/1 [0m                       

                       Computation: 758420 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 876.15
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2761
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7897
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 183730176
                    Iteration time: 0.13s
                      Time elapsed: 00:36:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1870/1 [0m                       

                       Computation: 638351 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 875.38
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.1078
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7900
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 183828480
                    Iteration time: 0.15s
                      Time elapsed: 00:36:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1871/1 [0m                       

                       Computation: 513858 steps/s (collection: 0.046s, learning 0.146s)
                       Mean reward: 871.02
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5971
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7812
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 183926784
                    Iteration time: 0.19s
                      Time elapsed: 00:36:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1872/1 [0m                       

                       Computation: 803702 steps/s (collection: 0.034s, learning 0.088s)
                       Mean reward: 880.64
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.4559
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7850
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 184025088
                    Iteration time: 0.12s
                      Time elapsed: 00:36:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1873/1 [0m                       

                       Computation: 862203 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 882.74
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0036
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.7329
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7922
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 184123392
                    Iteration time: 0.11s
                      Time elapsed: 00:36:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1874/1 [0m                       

                       Computation: 869909 steps/s (collection: 0.032s, learning 0.081s)
                       Mean reward: 876.68
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6284
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7877
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 184221696
                    Iteration time: 0.11s
                      Time elapsed: 00:36:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1875/1 [0m                       

                       Computation: 690176 steps/s (collection: 0.037s, learning 0.106s)
                       Mean reward: 868.87
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8757
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7919
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 58.5833
--------------------------------------------------------------------------------
                   Total timesteps: 184320000
                    Iteration time: 0.14s
                      Time elapsed: 00:36:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1876/1 [0m                       

                       Computation: 857211 steps/s (collection: 0.033s, learning 0.082s)
                       Mean reward: 837.82
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.6326
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7575
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 184418304
                    Iteration time: 0.11s
                      Time elapsed: 00:36:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1877/1 [0m                       

                       Computation: 849983 steps/s (collection: 0.034s, learning 0.082s)
                       Mean reward: 839.95
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.9523
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7323
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 184516608
                    Iteration time: 0.12s
                      Time elapsed: 00:36:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1878/1 [0m                       

                       Computation: 869875 steps/s (collection: 0.034s, learning 0.079s)
                       Mean reward: 849.61
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.7973
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7502
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 184614912
                    Iteration time: 0.11s
                      Time elapsed: 00:36:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1879/1 [0m                       

                       Computation: 908244 steps/s (collection: 0.033s, learning 0.075s)
                       Mean reward: 849.72
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1598
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7564
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 184713216
                    Iteration time: 0.11s
                      Time elapsed: 00:36:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1880/1 [0m                       

                       Computation: 842210 steps/s (collection: 0.034s, learning 0.083s)
                       Mean reward: 854.87
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8002
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7582
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 184811520
                    Iteration time: 0.12s
                      Time elapsed: 00:36:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1881/1 [0m                       

                       Computation: 847222 steps/s (collection: 0.035s, learning 0.082s)
                       Mean reward: 855.62
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.3614
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 184909824
                    Iteration time: 0.12s
                      Time elapsed: 00:36:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1882/1 [0m                       

                       Computation: 859846 steps/s (collection: 0.034s, learning 0.080s)
                       Mean reward: 863.12
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4688
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7695
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 185008128
                    Iteration time: 0.11s
                      Time elapsed: 00:36:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1883/1 [0m                       

                       Computation: 678560 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 870.38
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5858
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 185106432
                    Iteration time: 0.14s
                      Time elapsed: 00:36:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1884/1 [0m                       

                       Computation: 905940 steps/s (collection: 0.034s, learning 0.075s)
                       Mean reward: 867.36
               Mean episode length: 248.18
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6547
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 185204736
                    Iteration time: 0.11s
                      Time elapsed: 00:36:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1885/1 [0m                       

                       Computation: 903023 steps/s (collection: 0.034s, learning 0.075s)
                       Mean reward: 863.22
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.1481
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 185303040
                    Iteration time: 0.11s
                      Time elapsed: 00:36:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1886/1 [0m                       

                       Computation: 748109 steps/s (collection: 0.034s, learning 0.097s)
                       Mean reward: 862.06
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1421
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7644
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 54.5833
--------------------------------------------------------------------------------
                   Total timesteps: 185401344
                    Iteration time: 0.13s
                      Time elapsed: 00:36:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1887/1 [0m                       

                       Computation: 835901 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 849.73
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.3694
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7651
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 185499648
                    Iteration time: 0.12s
                      Time elapsed: 00:36:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1888/1 [0m                       

                       Computation: 802332 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 822.74
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 164.0918
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7371
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 185597952
                    Iteration time: 0.12s
                      Time elapsed: 00:36:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1889/1 [0m                       

                       Computation: 883713 steps/s (collection: 0.034s, learning 0.077s)
                       Mean reward: 851.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8986
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 185696256
                    Iteration time: 0.11s
                      Time elapsed: 00:36:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1890/1 [0m                       

                       Computation: 833854 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 838.30
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.7247
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7513
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 185794560
                    Iteration time: 0.12s
                      Time elapsed: 00:36:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1891/1 [0m                       

                       Computation: 868437 steps/s (collection: 0.035s, learning 0.078s)
                       Mean reward: 853.14
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.0821
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7604
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 185892864
                    Iteration time: 0.11s
                      Time elapsed: 00:36:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1892/1 [0m                       

                       Computation: 808841 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 858.44
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0859
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7637
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 185991168
                    Iteration time: 0.12s
                      Time elapsed: 00:36:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1893/1 [0m                       

                       Computation: 768044 steps/s (collection: 0.032s, learning 0.095s)
                       Mean reward: 867.12
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.4415
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7807
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 186089472
                    Iteration time: 0.13s
                      Time elapsed: 00:36:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1894/1 [0m                       

                       Computation: 866208 steps/s (collection: 0.033s, learning 0.081s)
                       Mean reward: 872.91
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.8937
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 186187776
                    Iteration time: 0.11s
                      Time elapsed: 00:36:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1895/1 [0m                       

                       Computation: 716974 steps/s (collection: 0.034s, learning 0.103s)
                       Mean reward: 872.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6070
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 186286080
                    Iteration time: 0.14s
                      Time elapsed: 00:36:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1896/1 [0m                       

                       Computation: 710373 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 873.72
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.4467
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7882
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 57.3750
--------------------------------------------------------------------------------
                   Total timesteps: 186384384
                    Iteration time: 0.14s
                      Time elapsed: 00:36:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1897/1 [0m                       

                       Computation: 572535 steps/s (collection: 0.053s, learning 0.119s)
                       Mean reward: 863.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.0850
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7751
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 186482688
                    Iteration time: 0.17s
                      Time elapsed: 00:36:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1898/1 [0m                       

                       Computation: 782015 steps/s (collection: 0.035s, learning 0.091s)
                       Mean reward: 854.53
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.5879
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 186580992
                    Iteration time: 0.13s
                      Time elapsed: 00:36:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1899/1 [0m                       

                       Computation: 865408 steps/s (collection: 0.034s, learning 0.080s)
                       Mean reward: 858.35
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0924
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 186679296
                    Iteration time: 0.11s
                      Time elapsed: 00:36:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1900/1 [0m                       

                       Computation: 873726 steps/s (collection: 0.033s, learning 0.080s)
                       Mean reward: 860.11
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3688
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 186777600
                    Iteration time: 0.11s
                      Time elapsed: 00:36:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1901/1 [0m                       

                       Computation: 829034 steps/s (collection: 0.035s, learning 0.083s)
                       Mean reward: 854.79
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.6992
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 186875904
                    Iteration time: 0.12s
                      Time elapsed: 00:36:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1902/1 [0m                       

                       Computation: 890369 steps/s (collection: 0.036s, learning 0.075s)
                       Mean reward: 870.15
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0037
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1900
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7825
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 186974208
                    Iteration time: 0.11s
                      Time elapsed: 00:36:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1903/1 [0m                       

                       Computation: 764715 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 859.38
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.2966
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7723
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 187072512
                    Iteration time: 0.13s
                      Time elapsed: 00:36:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1904/1 [0m                       

                       Computation: 614169 steps/s (collection: 0.039s, learning 0.121s)
                       Mean reward: 873.11
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7692
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187170816
                    Iteration time: 0.16s
                      Time elapsed: 00:36:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1905/1 [0m                       

                       Computation: 665041 steps/s (collection: 0.054s, learning 0.094s)
                       Mean reward: 876.74
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.5545
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7871
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187269120
                    Iteration time: 0.15s
                      Time elapsed: 00:36:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1906/1 [0m                       

                       Computation: 570890 steps/s (collection: 0.036s, learning 0.136s)
                       Mean reward: 868.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0038
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0042
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 187367424
                    Iteration time: 0.17s
                      Time elapsed: 00:36:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1907/1 [0m                       

                       Computation: 529896 steps/s (collection: 0.050s, learning 0.136s)
                       Mean reward: 866.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0039
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.6096
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7624
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 53.3333
--------------------------------------------------------------------------------
                   Total timesteps: 187465728
                    Iteration time: 0.19s
                      Time elapsed: 00:36:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1908/1 [0m                       

                       Computation: 659542 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 844.35
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0039
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.8323
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7563
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 187564032
                    Iteration time: 0.15s
                      Time elapsed: 00:36:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1909/1 [0m                       

                       Computation: 840043 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 832.23
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0039
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.3740
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7464
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 187662336
                    Iteration time: 0.12s
                      Time elapsed: 00:36:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1910/1 [0m                       

                       Computation: 455458 steps/s (collection: 0.078s, learning 0.138s)
                       Mean reward: 849.04
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0040
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.8124
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187760640
                    Iteration time: 0.22s
                      Time elapsed: 00:36:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1911/1 [0m                       

                       Computation: 434282 steps/s (collection: 0.057s, learning 0.169s)
                       Mean reward: 859.50
               Mean episode length: 249.14
         Episode_Reward/action_rate -0.0039
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.4550
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 187858944
                    Iteration time: 0.23s
                      Time elapsed: 00:36:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1912/1 [0m                       

                       Computation: 691957 steps/s (collection: 0.042s, learning 0.100s)
                       Mean reward: 851.92
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0039
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.8666
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 187957248
                    Iteration time: 0.14s
                      Time elapsed: 00:36:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1913/1 [0m                       

                       Computation: 430063 steps/s (collection: 0.041s, learning 0.188s)
                       Mean reward: 857.49
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0039
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.8150
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7770
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 188055552
                    Iteration time: 0.23s
                      Time elapsed: 00:36:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1914/1 [0m                       

                       Computation: 309578 steps/s (collection: 0.102s, learning 0.216s)
                       Mean reward: 862.93
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0040
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1109
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7727
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 188153856
                    Iteration time: 0.32s
                      Time elapsed: 00:36:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1915/1 [0m                       

                       Computation: 415560 steps/s (collection: 0.061s, learning 0.176s)
                       Mean reward: 866.50
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0040
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8009
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 188252160
                    Iteration time: 0.24s
                      Time elapsed: 00:36:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1916/1 [0m                       

                       Computation: 688508 steps/s (collection: 0.037s, learning 0.106s)
                       Mean reward: 863.99
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0040
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.3143
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7788
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 188350464
                    Iteration time: 0.14s
                      Time elapsed: 00:36:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1917/1 [0m                       

                       Computation: 650489 steps/s (collection: 0.042s, learning 0.109s)
                       Mean reward: 863.66
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0040
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4843
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 55.2500
--------------------------------------------------------------------------------
                   Total timesteps: 188448768
                    Iteration time: 0.15s
                      Time elapsed: 00:36:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1918/1 [0m                       

                       Computation: 642301 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 848.79
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0041
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.8227
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 188547072
                    Iteration time: 0.15s
                      Time elapsed: 00:36:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1919/1 [0m                       

                       Computation: 668577 steps/s (collection: 0.043s, learning 0.104s)
                       Mean reward: 861.26
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0040
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.3393
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 188645376
                    Iteration time: 0.15s
                      Time elapsed: 00:36:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1920/1 [0m                       

                       Computation: 770414 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 864.57
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0041
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1772
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7783
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 188743680
                    Iteration time: 0.13s
                      Time elapsed: 00:36:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1921/1 [0m                       

                       Computation: 671409 steps/s (collection: 0.048s, learning 0.099s)
                       Mean reward: 865.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0041
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7696
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 188841984
                    Iteration time: 0.15s
                      Time elapsed: 00:37:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1922/1 [0m                       

                       Computation: 725276 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 870.91
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0041
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2983
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 188940288
                    Iteration time: 0.14s
                      Time elapsed: 00:37:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1923/1 [0m                       

                       Computation: 865833 steps/s (collection: 0.037s, learning 0.077s)
                       Mean reward: 868.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0041
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7445
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 189038592
                    Iteration time: 0.11s
                      Time elapsed: 00:37:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1924/1 [0m                       

                       Computation: 822638 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 867.70
               Mean episode length: 248.68
         Episode_Reward/action_rate -0.0041
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7567
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 189136896
                    Iteration time: 0.12s
                      Time elapsed: 00:37:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1925/1 [0m                       

                       Computation: 789615 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 871.36
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0042
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3288
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7857
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 189235200
                    Iteration time: 0.12s
                      Time elapsed: 00:37:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1926/1 [0m                       

                       Computation: 708517 steps/s (collection: 0.036s, learning 0.103s)
                       Mean reward: 875.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0042
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0319
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7878
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 189333504
                    Iteration time: 0.14s
                      Time elapsed: 00:37:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1927/1 [0m                       

                       Computation: 715619 steps/s (collection: 0.049s, learning 0.089s)
                       Mean reward: 874.98
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0042
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0444
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7870
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 189431808
                    Iteration time: 0.14s
                      Time elapsed: 00:37:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1928/1 [0m                       

                       Computation: 489040 steps/s (collection: 0.046s, learning 0.155s)
                       Mean reward: 872.59
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0041
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.8877
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 51.7917
--------------------------------------------------------------------------------
                   Total timesteps: 189530112
                    Iteration time: 0.20s
                      Time elapsed: 00:37:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1929/1 [0m                       

                       Computation: 573216 steps/s (collection: 0.038s, learning 0.134s)
                       Mean reward: 874.76
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0042
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.1107
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7973
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 189628416
                    Iteration time: 0.17s
                      Time elapsed: 00:37:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1930/1 [0m                       

                       Computation: 534154 steps/s (collection: 0.038s, learning 0.146s)
                       Mean reward: 876.78
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0042
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.2613
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7937
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 189726720
                    Iteration time: 0.18s
                      Time elapsed: 00:37:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1931/1 [0m                       

                       Computation: 657203 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 869.36
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0042
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.5859
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7857
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 189825024
                    Iteration time: 0.15s
                      Time elapsed: 00:37:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1932/1 [0m                       

                       Computation: 823898 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 871.09
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0042
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6646
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7958
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 189923328
                    Iteration time: 0.12s
                      Time elapsed: 00:37:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1933/1 [0m                       

                       Computation: 689305 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 876.83
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0042
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.4483
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7939
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 190021632
                    Iteration time: 0.14s
                      Time elapsed: 00:37:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1934/1 [0m                       

                       Computation: 604202 steps/s (collection: 0.041s, learning 0.122s)
                       Mean reward: 873.99
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0042
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.9443
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7957
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 190119936
                    Iteration time: 0.16s
                      Time elapsed: 00:37:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1935/1 [0m                       

                       Computation: 742366 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 881.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0043
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.5431
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.8025
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 190218240
                    Iteration time: 0.13s
                      Time elapsed: 00:37:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1936/1 [0m                       

                       Computation: 654411 steps/s (collection: 0.036s, learning 0.115s)
                       Mean reward: 875.87
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0043
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.3615
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7933
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 190316544
                    Iteration time: 0.15s
                      Time elapsed: 00:37:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1937/1 [0m                       

                       Computation: 689156 steps/s (collection: 0.038s, learning 0.105s)
                       Mean reward: 872.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0043
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7436
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7952
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 190414848
                    Iteration time: 0.14s
                      Time elapsed: 00:37:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1938/1 [0m                       

                       Computation: 686960 steps/s (collection: 0.043s, learning 0.101s)
                       Mean reward: 873.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0043
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.9057
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7893
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 54.1250
--------------------------------------------------------------------------------
                   Total timesteps: 190513152
                    Iteration time: 0.14s
                      Time elapsed: 00:37:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1939/1 [0m                       

                       Computation: 448816 steps/s (collection: 0.044s, learning 0.175s)
                       Mean reward: 880.26
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0043
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.7138
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7986
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 190611456
                    Iteration time: 0.22s
                      Time elapsed: 00:37:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1940/1 [0m                       

                       Computation: 764708 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 877.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0043
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.6791
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7933
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 190709760
                    Iteration time: 0.13s
                      Time elapsed: 00:37:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1941/1 [0m                       

                       Computation: 561235 steps/s (collection: 0.053s, learning 0.123s)
                       Mean reward: 869.36
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0044
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7899
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7904
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 190808064
                    Iteration time: 0.18s
                      Time elapsed: 00:37:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1942/1 [0m                       

                       Computation: 475040 steps/s (collection: 0.051s, learning 0.156s)
                       Mean reward: 860.90
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0044
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3421
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7888
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 190906368
                    Iteration time: 0.21s
                      Time elapsed: 00:37:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1943/1 [0m                       

                       Computation: 514627 steps/s (collection: 0.074s, learning 0.117s)
                       Mean reward: 868.79
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0044
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.5138
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7920
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 191004672
                    Iteration time: 0.19s
                      Time elapsed: 00:37:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1944/1 [0m                       

                       Computation: 721001 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 845.44
               Mean episode length: 245.41
         Episode_Reward/action_rate -0.0044
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.4728
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 191102976
                    Iteration time: 0.14s
                      Time elapsed: 00:37:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1945/1 [0m                       

                       Computation: 736977 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 852.83
               Mean episode length: 246.77
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.1089
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 191201280
                    Iteration time: 0.13s
                      Time elapsed: 00:37:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1946/1 [0m                       

                       Computation: 761301 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 844.49
               Mean episode length: 244.53
         Episode_Reward/action_rate -0.0044
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.4424
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7715
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 191299584
                    Iteration time: 0.13s
                      Time elapsed: 00:37:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1947/1 [0m                       

                       Computation: 650798 steps/s (collection: 0.045s, learning 0.106s)
                       Mean reward: 808.45
               Mean episode length: 242.79
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.2875
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7522
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 191397888
                    Iteration time: 0.15s
                      Time elapsed: 00:37:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1948/1 [0m                       

                       Computation: 659218 steps/s (collection: 0.046s, learning 0.104s)
                       Mean reward: 818.62
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.8036
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7409
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 56.7500
--------------------------------------------------------------------------------
                   Total timesteps: 191496192
                    Iteration time: 0.15s
                      Time elapsed: 00:37:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1949/1 [0m                       

                       Computation: 657967 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 296.03
               Mean episode length: 235.58
         Episode_Reward/action_rate -0.0053
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 57.5481
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.3750
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 191594496
                    Iteration time: 0.15s
                      Time elapsed: 00:37:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1950/1 [0m                       

                       Computation: 255500 steps/s (collection: 0.078s, learning 0.307s)
                       Mean reward: 51.23
               Mean episode length: 246.07
         Episode_Reward/action_rate -0.0060
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 10.9307
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2043
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 191692800
                    Iteration time: 0.38s
                      Time elapsed: 00:37:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1951/1 [0m                       

                       Computation: 654734 steps/s (collection: 0.046s, learning 0.105s)
                       Mean reward: 50.77
               Mean episode length: 239.68
         Episode_Reward/action_rate -0.0059
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 10.1391
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2004
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 191791104
                    Iteration time: 0.15s
                      Time elapsed: 00:37:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1952/1 [0m                       

                       Computation: 512756 steps/s (collection: 0.060s, learning 0.132s)
                       Mean reward: 41.37
               Mean episode length: 240.07
         Episode_Reward/action_rate -0.0060
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 7.8356
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.1893
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 191889408
                    Iteration time: 0.19s
                      Time elapsed: 00:37:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1953/1 [0m                       

                       Computation: 590134 steps/s (collection: 0.046s, learning 0.121s)
                       Mean reward: 59.62
               Mean episode length: 242.07
         Episode_Reward/action_rate -0.0060
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 12.3607
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2045
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 191987712
                    Iteration time: 0.17s
                      Time elapsed: 00:37:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1954/1 [0m                       

                       Computation: 614305 steps/s (collection: 0.039s, learning 0.122s)
                       Mean reward: 56.75
               Mean episode length: 242.63
         Episode_Reward/action_rate -0.0061
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 10.9385
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2075
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 192086016
                    Iteration time: 0.16s
                      Time elapsed: 00:37:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1955/1 [0m                       

                       Computation: 587382 steps/s (collection: 0.051s, learning 0.116s)
                       Mean reward: 59.16
               Mean episode length: 240.71
         Episode_Reward/action_rate -0.0060
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 11.8519
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.2043
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 192184320
                    Iteration time: 0.17s
                      Time elapsed: 00:37:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1956/1 [0m                       

                       Computation: 384121 steps/s (collection: 0.057s, learning 0.199s)
                       Mean reward: 70.53
               Mean episode length: 240.83
         Episode_Reward/action_rate -0.0060
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 13.9231
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.2242
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 192282624
                    Iteration time: 0.26s
                      Time elapsed: 00:37:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1957/1 [0m                       

                       Computation: 529748 steps/s (collection: 0.044s, learning 0.142s)
                       Mean reward: 97.21
               Mean episode length: 241.17
         Episode_Reward/action_rate -0.0059
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 19.6112
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.2463
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 192380928
                    Iteration time: 0.19s
                      Time elapsed: 00:37:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1958/1 [0m                       

                       Computation: 593910 steps/s (collection: 0.051s, learning 0.115s)
                       Mean reward: 96.97
               Mean episode length: 243.03
         Episode_Reward/action_rate -0.0059
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 18.9838
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.2471
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 192479232
                    Iteration time: 0.17s
                      Time elapsed: 00:37:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1959/1 [0m                       

                       Computation: 730922 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 108.09
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0058
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 18.8125
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.2464
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 49.3333
--------------------------------------------------------------------------------
                   Total timesteps: 192577536
                    Iteration time: 0.13s
                      Time elapsed: 00:37:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1960/1 [0m                       

                       Computation: 600675 steps/s (collection: 0.050s, learning 0.113s)
                       Mean reward: 105.65
               Mean episode length: 227.38
         Episode_Reward/action_rate -0.0055
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 21.9683
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.2477
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 192675840
                    Iteration time: 0.16s
                      Time elapsed: 00:37:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1961/1 [0m                       

                       Computation: 298754 steps/s (collection: 0.099s, learning 0.230s)
                       Mean reward: 161.63
               Mean episode length: 239.75
         Episode_Reward/action_rate -0.0056
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 32.2057
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.2930
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 192774144
                    Iteration time: 0.33s
                      Time elapsed: 00:37:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1962/1 [0m                       

                       Computation: 545819 steps/s (collection: 0.065s, learning 0.115s)
                       Mean reward: 162.06
               Mean episode length: 241.39
         Episode_Reward/action_rate -0.0057
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 32.3659
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3010
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 192872448
                    Iteration time: 0.18s
                      Time elapsed: 00:37:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1963/1 [0m                       

                       Computation: 446625 steps/s (collection: 0.043s, learning 0.178s)
                       Mean reward: 185.37
               Mean episode length: 237.40
         Episode_Reward/action_rate -0.0055
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 37.4161
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.3213
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 192970752
                    Iteration time: 0.22s
                      Time elapsed: 00:37:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1964/1 [0m                       

                       Computation: 439351 steps/s (collection: 0.051s, learning 0.173s)
                       Mean reward: 183.35
               Mean episode length: 238.71
         Episode_Reward/action_rate -0.0055
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 37.1002
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.3205
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 193069056
                    Iteration time: 0.22s
                      Time elapsed: 00:37:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1965/1 [0m                       

                       Computation: 334976 steps/s (collection: 0.083s, learning 0.210s)
                       Mean reward: 222.91
               Mean episode length: 238.98
         Episode_Reward/action_rate -0.0055
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 45.5338
       Episode_Reward/object_height 0.0041
     Episode_Reward/reaching_object 0.3569
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 193167360
                    Iteration time: 0.29s
                      Time elapsed: 00:37:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1966/1 [0m                       

                       Computation: 398522 steps/s (collection: 0.065s, learning 0.182s)
                       Mean reward: 269.32
               Mean episode length: 241.12
         Episode_Reward/action_rate -0.0054
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 51.6160
       Episode_Reward/object_height 0.0045
     Episode_Reward/reaching_object 0.3826
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 193265664
                    Iteration time: 0.25s
                      Time elapsed: 00:37:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1967/1 [0m                       

                       Computation: 780845 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 298.31
               Mean episode length: 243.49
         Episode_Reward/action_rate -0.0053
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 60.7523
       Episode_Reward/object_height 0.0050
     Episode_Reward/reaching_object 0.4072
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 193363968
                    Iteration time: 0.13s
                      Time elapsed: 00:37:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1968/1 [0m                       

                       Computation: 439579 steps/s (collection: 0.044s, learning 0.180s)
                       Mean reward: 323.43
               Mean episode length: 244.08
         Episode_Reward/action_rate -0.0053
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 64.5236
       Episode_Reward/object_height 0.0051
     Episode_Reward/reaching_object 0.4339
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 193462272
                    Iteration time: 0.22s
                      Time elapsed: 00:37:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1969/1 [0m                       

                       Computation: 327261 steps/s (collection: 0.051s, learning 0.249s)
                       Mean reward: 395.04
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0051
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 73.2472
       Episode_Reward/object_height 0.0054
     Episode_Reward/reaching_object 0.4519
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 49.4167
--------------------------------------------------------------------------------
                   Total timesteps: 193560576
                    Iteration time: 0.30s
                      Time elapsed: 00:38:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1970/1 [0m                       

                       Computation: 375650 steps/s (collection: 0.074s, learning 0.188s)
                       Mean reward: 401.81
               Mean episode length: 240.09
         Episode_Reward/action_rate -0.0049
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 80.8334
       Episode_Reward/object_height 0.0057
     Episode_Reward/reaching_object 0.4730
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 193658880
                    Iteration time: 0.26s
                      Time elapsed: 00:38:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1971/1 [0m                       

                       Computation: 448743 steps/s (collection: 0.050s, learning 0.169s)
                       Mean reward: 437.72
               Mean episode length: 235.77
         Episode_Reward/action_rate -0.0048
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 84.3290
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.4776
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 193757184
                    Iteration time: 0.22s
                      Time elapsed: 00:38:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1972/1 [0m                       

                       Computation: 653013 steps/s (collection: 0.038s, learning 0.113s)
                       Mean reward: 454.71
               Mean episode length: 240.47
         Episode_Reward/action_rate -0.0049
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 90.3676
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.5054
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 193855488
                    Iteration time: 0.15s
                      Time elapsed: 00:38:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1973/1 [0m                       

                       Computation: 610310 steps/s (collection: 0.044s, learning 0.118s)
                       Mean reward: 498.02
               Mean episode length: 243.43
         Episode_Reward/action_rate -0.0049
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 99.0349
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.5359
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 193953792
                    Iteration time: 0.16s
                      Time elapsed: 00:38:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1974/1 [0m                       

                       Computation: 390959 steps/s (collection: 0.077s, learning 0.175s)
                       Mean reward: 548.33
               Mean episode length: 240.70
         Episode_Reward/action_rate -0.0048
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 109.5262
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.5708
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 194052096
                    Iteration time: 0.25s
                      Time elapsed: 00:38:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1975/1 [0m                       

                       Computation: 510751 steps/s (collection: 0.049s, learning 0.144s)
                       Mean reward: 526.48
               Mean episode length: 242.96
         Episode_Reward/action_rate -0.0048
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 106.5981
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.5568
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 194150400
                    Iteration time: 0.19s
                      Time elapsed: 00:38:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1976/1 [0m                       

                       Computation: 648149 steps/s (collection: 0.038s, learning 0.114s)
                       Mean reward: 545.88
               Mean episode length: 242.02
         Episode_Reward/action_rate -0.0047
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 108.0691
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.5551
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 194248704
                    Iteration time: 0.15s
                      Time elapsed: 00:38:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1977/1 [0m                       

                       Computation: 749414 steps/s (collection: 0.036s, learning 0.095s)
                       Mean reward: 591.15
               Mean episode length: 243.56
         Episode_Reward/action_rate -0.0047
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 117.2506
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.5919
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 194347008
                    Iteration time: 0.13s
                      Time elapsed: 00:38:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1978/1 [0m                       

                       Computation: 584662 steps/s (collection: 0.046s, learning 0.122s)
                       Mean reward: 589.42
               Mean episode length: 244.29
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 119.1457
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.5919
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 194445312
                    Iteration time: 0.17s
                      Time elapsed: 00:38:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1979/1 [0m                       

                       Computation: 687232 steps/s (collection: 0.046s, learning 0.098s)
                       Mean reward: 598.47
               Mean episode length: 241.08
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 118.2769
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.5905
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 194543616
                    Iteration time: 0.14s
                      Time elapsed: 00:38:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1980/1 [0m                       

                       Computation: 472582 steps/s (collection: 0.043s, learning 0.166s)
                       Mean reward: 627.87
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 114.5909
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.5681
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 44.2083
--------------------------------------------------------------------------------
                   Total timesteps: 194641920
                    Iteration time: 0.21s
                      Time elapsed: 00:38:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1981/1 [0m                       

                       Computation: 437997 steps/s (collection: 0.041s, learning 0.183s)
                       Mean reward: 600.83
               Mean episode length: 242.01
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 119.2758
       Episode_Reward/object_height 0.0076
     Episode_Reward/reaching_object 0.5970
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 194740224
                    Iteration time: 0.22s
                      Time elapsed: 00:38:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1982/1 [0m                       

                       Computation: 693993 steps/s (collection: 0.049s, learning 0.093s)
                       Mean reward: 651.40
               Mean episode length: 242.01
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 130.0373
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.6268
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 194838528
                    Iteration time: 0.14s
                      Time elapsed: 00:38:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1983/1 [0m                       

                       Computation: 795484 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 667.07
               Mean episode length: 245.61
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 133.1972
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.6372
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 194936832
                    Iteration time: 0.12s
                      Time elapsed: 00:38:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1984/1 [0m                       

                       Computation: 654201 steps/s (collection: 0.038s, learning 0.113s)
                       Mean reward: 696.50
               Mean episode length: 246.08
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 138.1739
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.6598
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 195035136
                    Iteration time: 0.15s
                      Time elapsed: 00:38:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1985/1 [0m                       

                       Computation: 811114 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 687.11
               Mean episode length: 243.89
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 137.1082
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.6543
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 195133440
                    Iteration time: 0.12s
                      Time elapsed: 00:38:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1986/1 [0m                       

                       Computation: 664049 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 684.27
               Mean episode length: 242.97
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 136.1086
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.6499
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 195231744
                    Iteration time: 0.15s
                      Time elapsed: 00:38:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1987/1 [0m                       

                       Computation: 802671 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 679.36
               Mean episode length: 245.88
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 136.7841
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.6526
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 195330048
                    Iteration time: 0.12s
                      Time elapsed: 00:38:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1988/1 [0m                       

                       Computation: 690917 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 684.44
               Mean episode length: 244.13
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 134.9503
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.6445
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 195428352
                    Iteration time: 0.14s
                      Time elapsed: 00:38:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1989/1 [0m                       

                       Computation: 869795 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 688.73
               Mean episode length: 246.76
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 136.5841
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.6504
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 195526656
                    Iteration time: 0.11s
                      Time elapsed: 00:38:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1990/1 [0m                       

                       Computation: 557809 steps/s (collection: 0.039s, learning 0.137s)
                       Mean reward: 725.52
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 143.8408
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.6790
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 45.5000
--------------------------------------------------------------------------------
                   Total timesteps: 195624960
                    Iteration time: 0.18s
                      Time elapsed: 00:38:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1991/1 [0m                       

                       Computation: 774791 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 689.47
               Mean episode length: 236.33
         Episode_Reward/action_rate -0.0043
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 138.3174
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.6540
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 195723264
                    Iteration time: 0.13s
                      Time elapsed: 00:38:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1992/1 [0m                       

                       Computation: 730606 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 700.90
               Mean episode length: 244.07
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 139.8352
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.6590
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 195821568
                    Iteration time: 0.13s
                      Time elapsed: 00:38:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1993/1 [0m                       

                       Computation: 703363 steps/s (collection: 0.037s, learning 0.103s)
                       Mean reward: 724.28
               Mean episode length: 243.01
         Episode_Reward/action_rate -0.0045
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 144.4902
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.6791
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 195919872
                    Iteration time: 0.14s
                      Time elapsed: 00:38:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1994/1 [0m                       

                       Computation: 738748 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 730.08
               Mean episode length: 246.57
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 145.2415
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.6771
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 196018176
                    Iteration time: 0.13s
                      Time elapsed: 00:38:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1995/1 [0m                       

                       Computation: 751367 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 726.18
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 144.4648
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.6837
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 196116480
                    Iteration time: 0.13s
                      Time elapsed: 00:38:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1996/1 [0m                       

                       Computation: 783732 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 722.77
               Mean episode length: 245.56
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 143.5503
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.6755
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 196214784
                    Iteration time: 0.13s
                      Time elapsed: 00:38:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1997/1 [0m                       

                       Computation: 785346 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 728.96
               Mean episode length: 246.47
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 145.8685
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.6905
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 196313088
                    Iteration time: 0.13s
                      Time elapsed: 00:38:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1998/1 [0m                       

                       Computation: 629521 steps/s (collection: 0.040s, learning 0.116s)
                       Mean reward: 719.18
               Mean episode length: 245.73
         Episode_Reward/action_rate -0.0046
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 143.3047
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.6781
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 196411392
                    Iteration time: 0.16s
                      Time elapsed: 00:38:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1999/1 [0m                       

                       Computation: 667876 steps/s (collection: 0.043s, learning 0.104s)
                       Mean reward: 728.41
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0047
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 144.5326
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.6836
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 196509696
                    Iteration time: 0.15s
                      Time elapsed: 00:38:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 2000/1 [0m                       

                       Computation: 745925 steps/s (collection: 0.036s, learning 0.096s)
                       Mean reward: 745.30
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0047
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 144.0518
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.6771
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 46.7083
--------------------------------------------------------------------------------
                   Total timesteps: 196608000
                    Iteration time: 0.13s
                      Time elapsed: 00:38:37
                               ETA: 00:00:00

