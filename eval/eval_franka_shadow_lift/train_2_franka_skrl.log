################################################################################
                        [1m Learning iteration 1/1 [0m                        

                       Computation: 458999 steps/s (collection: 0.024s, learning 0.190s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 0.21s
                      Time elapsed: 00:00:01
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 2/1 [0m                        

                       Computation: 956793 steps/s (collection: 0.023s, learning 0.080s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 0.10s
                      Time elapsed: 00:00:02
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 3/1 [0m                        

                       Computation: 953373 steps/s (collection: 0.023s, learning 0.080s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 0.10s
                      Time elapsed: 00:00:03
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 4/1 [0m                        

                       Computation: 877620 steps/s (collection: 0.025s, learning 0.088s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 0.11s
                      Time elapsed: 00:00:03
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 5/1 [0m                        

                       Computation: 963629 steps/s (collection: 0.032s, learning 0.070s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 0.10s
                      Time elapsed: 00:00:04
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 6/1 [0m                        

                       Computation: 947443 steps/s (collection: 0.025s, learning 0.079s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 0.10s
                      Time elapsed: 00:00:05
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 7/1 [0m                        

                       Computation: 993197 steps/s (collection: 0.024s, learning 0.075s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 0.10s
                      Time elapsed: 00:00:05
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 8/1 [0m                        

                       Computation: 747439 steps/s (collection: 0.032s, learning 0.099s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 0.13s
                      Time elapsed: 00:00:06
                               ETA: 00:00:00

################################################################################
                        [1m Learning iteration 9/1 [0m                        

                       Computation: 725429 steps/s (collection: 0.033s, learning 0.103s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 0.14s
                      Time elapsed: 00:00:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 10/1 [0m                        

                       Computation: 702076 steps/s (collection: 0.035s, learning 0.105s)
                       Mean reward: 0.00
               Mean episode length: 0.00
         Episode_Reward/action_rate 0.0000
           Episode_Reward/joint_vel 0.0000
      Episode_Reward/lifting_object 0.0000
       Episode_Reward/object_height 0.0000
     Episode_Reward/reaching_object 0.0000
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 0.14s
                      Time elapsed: 00:00:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 11/1 [0m                        

                       Computation: 670438 steps/s (collection: 0.032s, learning 0.115s)
                       Mean reward: 0.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 0.0062
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.0291
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 2560.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 0.15s
                      Time elapsed: 00:00:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 12/1 [0m                        

                       Computation: 770012 steps/s (collection: 0.031s, learning 0.096s)
                       Mean reward: 0.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0100
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0465
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 0.13s
                      Time elapsed: 00:00:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 13/1 [0m                        

                       Computation: 830466 steps/s (collection: 0.029s, learning 0.089s)
                       Mean reward: 0.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0100
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0465
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 0.12s
                      Time elapsed: 00:00:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 14/1 [0m                        

                       Computation: 832973 steps/s (collection: 0.032s, learning 0.086s)
                       Mean reward: 0.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.0100
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.0465
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 4096.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 0.12s
                      Time elapsed: 00:00:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 15/1 [0m                        

                       Computation: 499064 steps/s (collection: 0.060s, learning 0.137s)
                       Mean reward: 0.91
               Mean episode length: 100.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0011
      Episode_Reward/lifting_object 0.0679
       Episode_Reward/object_height 0.0010
     Episode_Reward/reaching_object 0.0629
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 512.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 0.20s
                      Time elapsed: 00:00:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 16/1 [0m                        

                       Computation: 560150 steps/s (collection: 0.060s, learning 0.116s)
                       Mean reward: 22.58
               Mean episode length: 123.75
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0012
      Episode_Reward/lifting_object 5.4667
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.1234
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 0.18s
                      Time elapsed: 00:00:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 17/1 [0m                        

                       Computation: 705252 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 10.94
               Mean episode length: 147.79
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0014
      Episode_Reward/lifting_object 1.3333
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.1234
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 0.14s
                      Time elapsed: 00:00:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 18/1 [0m                        

                       Computation: 786534 steps/s (collection: 0.037s, learning 0.087s)
                       Mean reward: 7.40
               Mean episode length: 172.62
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 0.7333
       Episode_Reward/object_height 0.0015
     Episode_Reward/reaching_object 0.1412
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 0.12s
                      Time elapsed: 00:00:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 19/1 [0m                        

                       Computation: 733931 steps/s (collection: 0.036s, learning 0.098s)
                       Mean reward: 13.87
               Mean episode length: 194.00
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 2.3722
       Episode_Reward/object_height 0.0018
     Episode_Reward/reaching_object 0.1717
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 0.13s
                      Time elapsed: 00:00:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 20/1 [0m                        

                       Computation: 694658 steps/s (collection: 0.031s, learning 0.111s)
                       Mean reward: 10.19
               Mean episode length: 217.08
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 1.7961
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.1962
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 0.14s
                      Time elapsed: 00:00:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 21/1 [0m                        

                       Computation: 776852 steps/s (collection: 0.035s, learning 0.092s)
                       Mean reward: 3.71
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 1.6905
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2328
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 823.5417
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 0.13s
                      Time elapsed: 00:00:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 22/1 [0m                        

                       Computation: 811169 steps/s (collection: 0.031s, learning 0.090s)
                       Mean reward: 3.71
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0016
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.5013
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2269
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 3953.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 0.12s
                      Time elapsed: 00:00:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 23/1 [0m                        

                       Computation: 777508 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 68.88
               Mean episode length: 146.00
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0015
      Episode_Reward/lifting_object 11.9627
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.1826
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 494.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 0.13s
                      Time elapsed: 00:00:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 24/1 [0m                        

                       Computation: 824582 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 11.64
               Mean episode length: 66.45
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0006
      Episode_Reward/lifting_object 1.3083
       Episode_Reward/object_height 0.0006
     Episode_Reward/reaching_object 0.0507
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 0.12s
                      Time elapsed: 00:00:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 25/1 [0m                        

                       Computation: 852600 steps/s (collection: 0.037s, learning 0.079s)
                       Mean reward: 14.75
               Mean episode length: 103.31
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0010
      Episode_Reward/lifting_object 4.5194
       Episode_Reward/object_height 0.0011
     Episode_Reward/reaching_object 0.1078
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 0.12s
                      Time elapsed: 00:00:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 26/1 [0m                        

                       Computation: 783196 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 9.21
               Mean episode length: 142.28
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0014
      Episode_Reward/lifting_object 1.7000
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.1370
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 0.13s
                      Time elapsed: 00:00:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 27/1 [0m                        

                       Computation: 753031 steps/s (collection: 0.047s, learning 0.084s)
                       Mean reward: 2.68
               Mean episode length: 178.10
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 0.5667
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1598
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 0.13s
                      Time elapsed: 00:00:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 28/1 [0m                        

                       Computation: 836301 steps/s (collection: 0.033s, learning 0.085s)
                       Mean reward: 7.98
               Mean episode length: 212.16
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 1.1444
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2046
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 0.12s
                      Time elapsed: 00:00:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 29/1 [0m                        

                       Computation: 790565 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 13.04
               Mean episode length: 221.51
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 3.7306
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2295
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 0.12s
                      Time elapsed: 00:00:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 30/1 [0m                        

                       Computation: 755095 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 16.91
               Mean episode length: 233.71
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 3.3056
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2215
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 0.13s
                      Time elapsed: 00:00:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 31/1 [0m                        

                       Computation: 789968 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 17.48
               Mean episode length: 240.58
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 3.6222
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2529
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 0.12s
                      Time elapsed: 00:00:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 32/1 [0m                        

                       Computation: 876874 steps/s (collection: 0.027s, learning 0.085s)
                       Mean reward: 5.10
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 0.8903
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2371
Episode_Termination/object_dropping 2.6667
       Episode_Termination/time_out 2995.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 0.11s
                      Time elapsed: 00:00:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 33/1 [0m                        

                       Computation: 846879 steps/s (collection: 0.031s, learning 0.086s)
                       Mean reward: 32.77
               Mean episode length: 179.67
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 0.8646
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1238
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 315.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 0.12s
                      Time elapsed: 00:00:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 34/1 [0m                        

                       Computation: 778276 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 11.79
               Mean episode length: 117.46
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0011
      Episode_Reward/lifting_object 1.2628
       Episode_Reward/object_height 0.0011
     Episode_Reward/reaching_object 0.0939
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 0.13s
                      Time elapsed: 00:00:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 35/1 [0m                        

                       Computation: 814105 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 5.86
               Mean episode length: 149.63
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0014
      Episode_Reward/lifting_object 0.7470
       Episode_Reward/object_height 0.0013
     Episode_Reward/reaching_object 0.1440
Episode_Termination/object_dropping 2.2083
       Episode_Termination/time_out 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 0.12s
                      Time elapsed: 00:00:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 36/1 [0m                        

                       Computation: 733614 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 10.82
               Mean episode length: 172.54
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 2.2078
       Episode_Reward/object_height 0.0016
     Episode_Reward/reaching_object 0.1810
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 0.13s
                      Time elapsed: 00:00:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 37/1 [0m                        

                       Computation: 785078 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 13.69
               Mean episode length: 181.56
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0018
      Episode_Reward/lifting_object 1.8936
       Episode_Reward/object_height 0.0017
     Episode_Reward/reaching_object 0.1819
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 0.13s
                      Time elapsed: 00:00:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 38/1 [0m                        

                       Computation: 738793 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 17.76
               Mean episode length: 186.76
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 2.9417
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2014
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 0.13s
                      Time elapsed: 00:00:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 39/1 [0m                        

                       Computation: 751932 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 24.11
               Mean episode length: 213.39
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 4.7328
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2393
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 0.13s
                      Time elapsed: 00:00:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 40/1 [0m                        

                       Computation: 745117 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 18.51
               Mean episode length: 229.26
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 4.6456
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2439
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 0.13s
                      Time elapsed: 00:00:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 41/1 [0m                        

                       Computation: 737266 steps/s (collection: 0.037s, learning 0.096s)
                       Mean reward: 25.97
               Mean episode length: 237.76
         Episode_Reward/action_rate -0.0015
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 5.3838
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2622
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 0.13s
                      Time elapsed: 00:00:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 42/1 [0m                        

                       Computation: 836018 steps/s (collection: 0.033s, learning 0.085s)
                       Mean reward: 7.37
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 4.0865
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2300
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 439.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 0.12s
                      Time elapsed: 00:00:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 43/1 [0m                        

                       Computation: 709054 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 27.09
               Mean episode length: 159.11
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0012
      Episode_Reward/lifting_object 1.8500
       Episode_Reward/object_height 0.0012
     Episode_Reward/reaching_object 0.1145
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 0.14s
                      Time elapsed: 00:00:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 44/1 [0m                        

                       Computation: 822465 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 20.72
               Mean episode length: 169.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0013
      Episode_Reward/lifting_object 9.5489
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.1563
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 0.12s
                      Time elapsed: 00:00:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 45/1 [0m                        

                       Computation: 773175 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 19.28
               Mean episode length: 201.45
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 2.8834
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2192
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 0.13s
                      Time elapsed: 00:00:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 46/1 [0m                        

                       Computation: 672058 steps/s (collection: 0.052s, learning 0.094s)
                       Mean reward: 13.55
               Mean episode length: 200.42
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 2.6196
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2174
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 0.15s
                      Time elapsed: 00:00:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 47/1 [0m                        

                       Computation: 567973 steps/s (collection: 0.050s, learning 0.124s)
                       Mean reward: 16.21
               Mean episode length: 197.59
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 3.4766
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2086
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 0.17s
                      Time elapsed: 00:00:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 48/1 [0m                        

                       Computation: 597556 steps/s (collection: 0.050s, learning 0.115s)
                       Mean reward: 16.09
               Mean episode length: 205.93
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 3.1333
       Episode_Reward/object_height 0.0020
     Episode_Reward/reaching_object 0.2211
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 0.16s
                      Time elapsed: 00:00:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 49/1 [0m                        

                       Computation: 692212 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 22.58
               Mean episode length: 210.88
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 4.2155
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2273
Episode_Termination/object_dropping 2.0833
       Episode_Termination/time_out 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 0.14s
                      Time elapsed: 00:00:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 50/1 [0m                        

                       Computation: 700104 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 24.81
               Mean episode length: 223.81
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 4.7947
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2535
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 0.14s
                      Time elapsed: 00:00:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 51/1 [0m                        

                       Computation: 690542 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 15.77
               Mean episode length: 233.33
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 2.7288
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2581
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 0.14s
                      Time elapsed: 00:00:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 52/1 [0m                        

                       Computation: 769839 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 35.99
               Mean episode length: 237.39
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 5.8936
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2734
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 0.13s
                      Time elapsed: 00:00:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 53/1 [0m                        

                       Computation: 862021 steps/s (collection: 0.036s, learning 0.078s)
                       Mean reward: 11.91
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 7.2290
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2278
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 405.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 0.11s
                      Time elapsed: 00:00:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 54/1 [0m                        

                       Computation: 870153 steps/s (collection: 0.033s, learning 0.080s)
                       Mean reward: 41.08
               Mean episode length: 183.35
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0017
      Episode_Reward/lifting_object 6.6889
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2000
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 0.11s
                      Time elapsed: 00:00:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 55/1 [0m                        

                       Computation: 795817 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 19.68
               Mean episode length: 210.84
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 3.9966
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2126
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 0.12s
                      Time elapsed: 00:00:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 56/1 [0m                        

                       Computation: 768104 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 20.92
               Mean episode length: 215.03
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 3.7288
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2427
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 0.13s
                      Time elapsed: 00:00:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 57/1 [0m                        

                       Computation: 810339 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 16.50
               Mean episode length: 218.08
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 3.0953
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2331
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 0.12s
                      Time elapsed: 00:00:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 58/1 [0m                        

                       Computation: 744594 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 33.46
               Mean episode length: 212.66
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 6.3957
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2470
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 0.13s
                      Time elapsed: 00:00:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 59/1 [0m                        

                       Computation: 579829 steps/s (collection: 0.049s, learning 0.121s)
                       Mean reward: 20.66
               Mean episode length: 214.26
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 3.9127
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2352
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 0.17s
                      Time elapsed: 00:01:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 60/1 [0m                        

                       Computation: 605361 steps/s (collection: 0.049s, learning 0.114s)
                       Mean reward: 32.88
               Mean episode length: 230.00
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 8.1186
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2816
Episode_Termination/object_dropping 1.6250
       Episode_Termination/time_out 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 0.16s
                      Time elapsed: 00:01:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 61/1 [0m                        

                       Computation: 544421 steps/s (collection: 0.051s, learning 0.130s)
                       Mean reward: 30.18
               Mean episode length: 230.61
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 5.8712
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2650
Episode_Termination/object_dropping 1.9167
       Episode_Termination/time_out 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 0.18s
                      Time elapsed: 00:01:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 62/1 [0m                        

                       Computation: 620839 steps/s (collection: 0.055s, learning 0.104s)
                       Mean reward: 33.75
               Mean episode length: 239.12
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 6.6797
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.2981
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 0.16s
                      Time elapsed: 00:01:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 63/1 [0m                        

                       Computation: 772929 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 21.11
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 3.1547
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2649
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 126.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 0.13s
                      Time elapsed: 00:01:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 64/1 [0m                        

                       Computation: 829494 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 40.64
               Mean episode length: 204.96
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0019
      Episode_Reward/lifting_object 8.8333
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2484
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 0.12s
                      Time elapsed: 00:01:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 65/1 [0m                        

                       Computation: 833508 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 19.37
               Mean episode length: 193.90
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 3.7244
       Episode_Reward/object_height 0.0019
     Episode_Reward/reaching_object 0.2423
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 0.12s
                      Time elapsed: 00:01:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 66/1 [0m                        

                       Computation: 778223 steps/s (collection: 0.044s, learning 0.082s)
                       Mean reward: 20.77
               Mean episode length: 213.28
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 3.9287
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2559
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 0.13s
                      Time elapsed: 00:01:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 67/1 [0m                        

                       Computation: 782414 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 22.20
               Mean episode length: 221.68
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 3.9422
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2763
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 0.13s
                      Time elapsed: 00:01:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 68/1 [0m                        

                       Computation: 704551 steps/s (collection: 0.052s, learning 0.088s)
                       Mean reward: 22.65
               Mean episode length: 225.57
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 4.2031
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2799
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 0.14s
                      Time elapsed: 00:01:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 69/1 [0m                        

                       Computation: 740458 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 30.59
               Mean episode length: 226.76
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 5.5195
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2916
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 0.13s
                      Time elapsed: 00:01:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 70/1 [0m                        

                       Computation: 742009 steps/s (collection: 0.047s, learning 0.085s)
                       Mean reward: 26.76
               Mean episode length: 233.77
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 5.1550
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2992
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 0.13s
                      Time elapsed: 00:01:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 71/1 [0m                        

                       Computation: 728117 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 29.10
               Mean episode length: 236.99
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 5.5721
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2983
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 0.14s
                      Time elapsed: 00:01:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 72/1 [0m                        

                       Computation: 849514 steps/s (collection: 0.041s, learning 0.075s)
                       Mean reward: 30.99
               Mean episode length: 240.08
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 6.0210
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3017
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 0.12s
                      Time elapsed: 00:01:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 73/1 [0m                        

                       Computation: 895649 steps/s (collection: 0.031s, learning 0.078s)
                       Mean reward: 30.11
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0014
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 4.9399
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3088
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 120.7083
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 0.11s
                      Time elapsed: 00:01:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 74/1 [0m                        

                       Computation: 845232 steps/s (collection: 0.034s, learning 0.083s)
                       Mean reward: 22.20
               Mean episode length: 224.56
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 3.6511
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2775
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 0.12s
                      Time elapsed: 00:01:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 75/1 [0m                        

                       Computation: 618354 steps/s (collection: 0.042s, learning 0.117s)
                       Mean reward: 27.08
               Mean episode length: 206.42
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 6.5660
       Episode_Reward/object_height 0.0021
     Episode_Reward/reaching_object 0.2716
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 0.16s
                      Time elapsed: 00:01:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 76/1 [0m                        

                       Computation: 714285 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 31.78
               Mean episode length: 234.65
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 5.9660
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2925
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 0.14s
                      Time elapsed: 00:01:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 77/1 [0m                        

                       Computation: 629018 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 36.83
               Mean episode length: 225.99
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 6.6994
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2865
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 0.16s
                      Time elapsed: 00:01:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 78/1 [0m                        

                       Computation: 749220 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 37.44
               Mean episode length: 225.27
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 7.0612
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2905
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 0.13s
                      Time elapsed: 00:01:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 79/1 [0m                        

                       Computation: 717332 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 37.05
               Mean episode length: 222.63
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 7.1597
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2857
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 0.14s
                      Time elapsed: 00:01:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 80/1 [0m                        

                       Computation: 661881 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 39.75
               Mean episode length: 225.33
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 7.7100
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2907
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 0.15s
                      Time elapsed: 00:01:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 81/1 [0m                        

                       Computation: 719090 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 47.81
               Mean episode length: 234.19
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 9.6925
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3075
Episode_Termination/object_dropping 2.2083
       Episode_Termination/time_out 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 0.14s
                      Time elapsed: 00:01:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 82/1 [0m                        

                       Computation: 756401 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 41.16
               Mean episode length: 234.57
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 7.7239
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3035
Episode_Termination/object_dropping 2.2083
       Episode_Termination/time_out 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 0.13s
                      Time elapsed: 00:01:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 83/1 [0m                        

                       Computation: 690324 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 40.01
               Mean episode length: 235.76
         Episode_Reward/action_rate -0.0013
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 7.9903
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3044
Episode_Termination/object_dropping 1.9583
       Episode_Termination/time_out 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 0.14s
                      Time elapsed: 00:01:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 84/1 [0m                        

                       Computation: 782875 steps/s (collection: 0.035s, learning 0.091s)
                       Mean reward: 41.57
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 9.3850
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3049
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 108.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 0.13s
                      Time elapsed: 00:01:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 85/1 [0m                        

                       Computation: 715785 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 38.42
               Mean episode length: 207.90
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 8.9333
       Episode_Reward/object_height 0.0022
     Episode_Reward/reaching_object 0.2627
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 0.14s
                      Time elapsed: 00:01:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 86/1 [0m                        

                       Computation: 721792 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 47.57
               Mean episode length: 223.04
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 8.8192
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2797
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 0.14s
                      Time elapsed: 00:01:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 87/1 [0m                        

                       Computation: 664148 steps/s (collection: 0.044s, learning 0.105s)
                       Mean reward: 47.33
               Mean episode length: 229.22
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 9.1485
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3014
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 0.15s
                      Time elapsed: 00:01:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 88/1 [0m                        

                       Computation: 769252 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 47.81
               Mean episode length: 222.96
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 9.2157
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2926
Episode_Termination/object_dropping 1.8333
       Episode_Termination/time_out 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 0.13s
                      Time elapsed: 00:01:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 89/1 [0m                        

                       Computation: 789906 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 41.75
               Mean episode length: 220.47
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 7.7409
       Episode_Reward/object_height 0.0023
     Episode_Reward/reaching_object 0.2878
Episode_Termination/object_dropping 2.5000
       Episode_Termination/time_out 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 0.12s
                      Time elapsed: 00:01:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 90/1 [0m                        

                       Computation: 793588 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 41.99
               Mean episode length: 223.01
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 7.9784
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.2977
Episode_Termination/object_dropping 2.3750
       Episode_Termination/time_out 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 0.12s
                      Time elapsed: 00:01:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 91/1 [0m                        

                       Computation: 622202 steps/s (collection: 0.047s, learning 0.111s)
                       Mean reward: 44.30
               Mean episode length: 234.36
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 8.5259
       Episode_Reward/object_height 0.0024
     Episode_Reward/reaching_object 0.3110
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 0.16s
                      Time elapsed: 00:01:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 92/1 [0m                        

                       Computation: 599335 steps/s (collection: 0.053s, learning 0.112s)
                       Mean reward: 61.88
               Mean episode length: 237.63
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 11.8219
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3205
Episode_Termination/object_dropping 2.4167
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 0.16s
                      Time elapsed: 00:01:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 93/1 [0m                        

                       Computation: 630017 steps/s (collection: 0.048s, learning 0.109s)
                       Mean reward: 55.36
               Mean episode length: 239.44
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 10.6844
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3208
Episode_Termination/object_dropping 2.3750
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 0.16s
                      Time elapsed: 00:01:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 94/1 [0m                        

                       Computation: 670761 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 64.25
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 12.5167
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3139
Episode_Termination/object_dropping 2.4583
       Episode_Termination/time_out 99.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 0.15s
                      Time elapsed: 00:01:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 95/1 [0m                        

                       Computation: 616879 steps/s (collection: 0.053s, learning 0.106s)
                       Mean reward: 70.55
               Mean episode length: 207.36
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 15.3228
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2887
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 0.16s
                      Time elapsed: 00:01:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 96/1 [0m                        

                       Computation: 761765 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 62.17
               Mean episode length: 224.99
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 11.4518
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.3075
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 0.13s
                      Time elapsed: 00:01:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 97/1 [0m                        

                       Computation: 750607 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 66.10
               Mean episode length: 222.56
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 13.4907
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3036
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 0.13s
                      Time elapsed: 00:01:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 98/1 [0m                        

                       Computation: 780086 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 55.83
               Mean episode length: 224.40
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 10.6792
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2922
Episode_Termination/object_dropping 1.8750
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 0.13s
                      Time elapsed: 00:01:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 99/1 [0m                        

                       Computation: 777016 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 73.40
               Mean episode length: 231.35
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 13.7461
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3171
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 0.13s
                      Time elapsed: 00:01:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 100/1 [0m                       

                       Computation: 756232 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 85.10
               Mean episode length: 228.75
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 16.9936
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3223
Episode_Termination/object_dropping 2.2500
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 0.13s
                      Time elapsed: 00:01:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 101/1 [0m                       

                       Computation: 739035 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 71.00
               Mean episode length: 227.45
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 13.5247
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3120
Episode_Termination/object_dropping 2.6667
       Episode_Termination/time_out 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 0.13s
                      Time elapsed: 00:01:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 102/1 [0m                       

                       Computation: 691931 steps/s (collection: 0.049s, learning 0.093s)
                       Mean reward: 76.38
               Mean episode length: 231.67
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 15.2091
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3206
Episode_Termination/object_dropping 2.8333
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 0.14s
                      Time elapsed: 00:01:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 103/1 [0m                       

                       Computation: 642926 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 94.37
               Mean episode length: 234.49
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 17.5261
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3330
Episode_Termination/object_dropping 2.5417
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 0.15s
                      Time elapsed: 00:01:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 104/1 [0m                       

                       Computation: 646533 steps/s (collection: 0.045s, learning 0.107s)
                       Mean reward: 85.49
               Mean episode length: 244.04
         Episode_Reward/action_rate -0.0012
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 16.7851
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3442
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 0.15s
                      Time elapsed: 00:01:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 105/1 [0m                       

                       Computation: 632894 steps/s (collection: 0.047s, learning 0.109s)
                       Mean reward: 71.97
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 11.5469
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2901
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 86.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 0.16s
                      Time elapsed: 00:01:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 106/1 [0m                       

                       Computation: 569616 steps/s (collection: 0.052s, learning 0.121s)
                       Mean reward: 82.65
               Mean episode length: 219.38
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 15.6358
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3074
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 0.17s
                      Time elapsed: 00:01:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 107/1 [0m                       

                       Computation: 814367 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 64.55
               Mean episode length: 221.49
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 12.4688
       Episode_Reward/object_height 0.0025
     Episode_Reward/reaching_object 0.2951
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 0.12s
                      Time elapsed: 00:01:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 108/1 [0m                       

                       Computation: 725154 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 71.23
               Mean episode length: 226.06
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 14.3334
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3125
Episode_Termination/object_dropping 2.1250
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 0.14s
                      Time elapsed: 00:01:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 109/1 [0m                       

                       Computation: 783912 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 78.43
               Mean episode length: 228.44
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 16.1683
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3248
Episode_Termination/object_dropping 2.1250
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 0.13s
                      Time elapsed: 00:01:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 110/1 [0m                       

                       Computation: 560563 steps/s (collection: 0.058s, learning 0.118s)
                       Mean reward: 80.42
               Mean episode length: 223.71
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 15.8413
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3190
Episode_Termination/object_dropping 2.8333
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 0.18s
                      Time elapsed: 00:02:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 111/1 [0m                       

                       Computation: 620123 steps/s (collection: 0.057s, learning 0.102s)
                       Mean reward: 74.44
               Mean episode length: 229.46
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 14.5487
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3168
Episode_Termination/object_dropping 2.5833
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 0.16s
                      Time elapsed: 00:02:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 112/1 [0m                       

                       Computation: 544251 steps/s (collection: 0.054s, learning 0.127s)
                       Mean reward: 86.80
               Mean episode length: 235.72
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 18.2819
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3309
Episode_Termination/object_dropping 2.1667
       Episode_Termination/time_out 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 0.18s
                      Time elapsed: 00:02:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 113/1 [0m                       

                       Computation: 738166 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 85.86
               Mean episode length: 232.55
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 17.1280
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3289
Episode_Termination/object_dropping 3.5417
       Episode_Termination/time_out 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 0.13s
                      Time elapsed: 00:02:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 114/1 [0m                       

                       Computation: 649538 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 99.86
               Mean episode length: 234.68
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 20.1800
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3397
Episode_Termination/object_dropping 3.2917
       Episode_Termination/time_out 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 0.15s
                      Time elapsed: 00:02:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 115/1 [0m                       

                       Computation: 775629 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 82.67
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 17.0911
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3334
Episode_Termination/object_dropping 2.0000
       Episode_Termination/time_out 78.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 0.13s
                      Time elapsed: 00:02:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 116/1 [0m                       

                       Computation: 624557 steps/s (collection: 0.056s, learning 0.102s)
                       Mean reward: 74.44
               Mean episode length: 214.55
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 15.8156
       Episode_Reward/object_height 0.0026
     Episode_Reward/reaching_object 0.3063
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 0.16s
                      Time elapsed: 00:02:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 117/1 [0m                       

                       Computation: 621842 steps/s (collection: 0.049s, learning 0.110s)
                       Mean reward: 104.25
               Mean episode length: 227.91
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 19.7036
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3406
Episode_Termination/object_dropping 1.4167
       Episode_Termination/time_out 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 0.16s
                      Time elapsed: 00:02:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 118/1 [0m                       

                       Computation: 766619 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 92.25
               Mean episode length: 222.19
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 17.7739
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3219
Episode_Termination/object_dropping 2.3333
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 0.13s
                      Time elapsed: 00:02:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 119/1 [0m                       

                       Computation: 610681 steps/s (collection: 0.052s, learning 0.109s)
                       Mean reward: 104.86
               Mean episode length: 217.74
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 19.3659
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3263
Episode_Termination/object_dropping 3.0417
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 0.16s
                      Time elapsed: 00:02:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 120/1 [0m                       

                       Computation: 619785 steps/s (collection: 0.052s, learning 0.107s)
                       Mean reward: 78.82
               Mean episode length: 226.55
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 15.2724
       Episode_Reward/object_height 0.0027
     Episode_Reward/reaching_object 0.3267
Episode_Termination/object_dropping 2.7083
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 0.16s
                      Time elapsed: 00:02:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 121/1 [0m                       

                       Computation: 718695 steps/s (collection: 0.047s, learning 0.090s)
                       Mean reward: 94.81
               Mean episode length: 230.44
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 18.9477
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3382
Episode_Termination/object_dropping 2.8333
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 0.14s
                      Time elapsed: 00:02:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 122/1 [0m                       

                       Computation: 742748 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 98.11
               Mean episode length: 230.26
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 19.7879
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3412
Episode_Termination/object_dropping 2.7917
       Episode_Termination/time_out 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 0.13s
                      Time elapsed: 00:02:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 123/1 [0m                       

                       Computation: 745577 steps/s (collection: 0.045s, learning 0.086s)
                       Mean reward: 92.20
               Mean episode length: 232.82
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 17.5676
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3436
Episode_Termination/object_dropping 2.7500
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 0.13s
                      Time elapsed: 00:02:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 124/1 [0m                       

                       Computation: 735473 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 96.34
               Mean episode length: 240.15
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 19.4069
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3583
Episode_Termination/object_dropping 2.6250
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 0.13s
                      Time elapsed: 00:02:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 125/1 [0m                       

                       Computation: 739154 steps/s (collection: 0.050s, learning 0.083s)
                       Mean reward: 113.28
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 23.4653
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3669
Episode_Termination/object_dropping 2.1250
       Episode_Termination/time_out 71.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 0.13s
                      Time elapsed: 00:02:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 126/1 [0m                       

                       Computation: 738372 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 90.30
               Mean episode length: 221.05
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 19.3044
       Episode_Reward/object_height 0.0028
     Episode_Reward/reaching_object 0.3393
Episode_Termination/object_dropping 1.5833
       Episode_Termination/time_out 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 0.13s
                      Time elapsed: 00:02:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 127/1 [0m                       

                       Computation: 708864 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 119.19
               Mean episode length: 223.86
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 22.7867
       Episode_Reward/object_height 0.0029
     Episode_Reward/reaching_object 0.3400
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 0.14s
                      Time elapsed: 00:02:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 128/1 [0m                       

                       Computation: 638250 steps/s (collection: 0.039s, learning 0.115s)
                       Mean reward: 113.28
               Mean episode length: 232.13
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 22.1461
       Episode_Reward/object_height 0.0030
     Episode_Reward/reaching_object 0.3617
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 0.15s
                      Time elapsed: 00:02:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 129/1 [0m                       

                       Computation: 645796 steps/s (collection: 0.042s, learning 0.111s)
                       Mean reward: 130.91
               Mean episode length: 233.04
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 25.3910
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3719
Episode_Termination/object_dropping 2.1250
       Episode_Termination/time_out 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 0.15s
                      Time elapsed: 00:02:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 130/1 [0m                       

                       Computation: 688316 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 131.53
               Mean episode length: 232.60
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 27.1760
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3739
Episode_Termination/object_dropping 2.2083
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 0.14s
                      Time elapsed: 00:02:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 131/1 [0m                       

                       Computation: 658407 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 126.05
               Mean episode length: 235.45
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 24.4895
       Episode_Reward/object_height 0.0031
     Episode_Reward/reaching_object 0.3713
Episode_Termination/object_dropping 2.0417
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 0.15s
                      Time elapsed: 00:02:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 132/1 [0m                       

                       Computation: 662675 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 154.18
               Mean episode length: 238.75
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 31.3717
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3906
Episode_Termination/object_dropping 1.6667
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 0.15s
                      Time elapsed: 00:02:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 133/1 [0m                       

                       Computation: 774640 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 163.96
               Mean episode length: 238.63
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 32.7607
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3984
Episode_Termination/object_dropping 2.1667
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 0.13s
                      Time elapsed: 00:02:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 134/1 [0m                       

                       Computation: 822529 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 163.85
               Mean episode length: 241.24
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 33.0060
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3978
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 0.12s
                      Time elapsed: 00:02:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 135/1 [0m                       

                       Computation: 820518 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 149.25
               Mean episode length: 242.26
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.6424
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3902
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 0.12s
                      Time elapsed: 00:02:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 136/1 [0m                       

                       Computation: 815690 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 157.37
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 28.4721
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3776
Episode_Termination/object_dropping 1.3333
       Episode_Termination/time_out 63.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 0.12s
                      Time elapsed: 00:02:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 137/1 [0m                       

                       Computation: 816300 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 146.89
               Mean episode length: 233.20
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 27.4962
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3710
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 0.12s
                      Time elapsed: 00:02:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 138/1 [0m                       

                       Computation: 778593 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 157.49
               Mean episode length: 231.96
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 30.5561
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3822
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 0.13s
                      Time elapsed: 00:02:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 139/1 [0m                       

                       Computation: 637392 steps/s (collection: 0.046s, learning 0.108s)
                       Mean reward: 138.94
               Mean episode length: 235.09
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 27.3226
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3690
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 0.15s
                      Time elapsed: 00:02:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 140/1 [0m                       

                       Computation: 726186 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 141.78
               Mean episode length: 238.42
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 27.6336
       Episode_Reward/object_height 0.0032
     Episode_Reward/reaching_object 0.3769
Episode_Termination/object_dropping 1.3750
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 0.14s
                      Time elapsed: 00:02:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 141/1 [0m                       

                       Computation: 809299 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 142.53
               Mean episode length: 240.91
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 28.4003
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3788
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 0.12s
                      Time elapsed: 00:02:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 142/1 [0m                       

                       Computation: 777596 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 150.60
               Mean episode length: 238.41
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.1903
       Episode_Reward/object_height 0.0033
     Episode_Reward/reaching_object 0.3741
Episode_Termination/object_dropping 1.7917
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 0.13s
                      Time elapsed: 00:02:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 143/1 [0m                       

                       Computation: 789493 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 164.36
               Mean episode length: 239.03
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 30.9477
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3921
Episode_Termination/object_dropping 1.7083
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 0.12s
                      Time elapsed: 00:02:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 144/1 [0m                       

                       Computation: 829374 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 151.70
               Mean episode length: 242.52
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 29.6371
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3895
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 0.12s
                      Time elapsed: 00:02:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 145/1 [0m                       

                       Computation: 734883 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 170.66
               Mean episode length: 241.41
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 33.4565
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4020
Episode_Termination/object_dropping 1.7500
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 0.13s
                      Time elapsed: 00:02:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 146/1 [0m                       

                       Computation: 667181 steps/s (collection: 0.046s, learning 0.101s)
                       Mean reward: 165.25
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0011
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 31.0967
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.4001
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 62.0417
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 0.15s
                      Time elapsed: 00:02:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 147/1 [0m                       

                       Computation: 784236 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 146.81
               Mean episode length: 234.20
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 29.4320
       Episode_Reward/object_height 0.0034
     Episode_Reward/reaching_object 0.3867
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 0.13s
                      Time elapsed: 00:02:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 148/1 [0m                       

                       Computation: 644225 steps/s (collection: 0.054s, learning 0.098s)
                       Mean reward: 165.25
               Mean episode length: 236.40
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 32.6391
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3974
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 0.15s
                      Time elapsed: 00:02:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 149/1 [0m                       

                       Computation: 715728 steps/s (collection: 0.048s, learning 0.089s)
                       Mean reward: 155.72
               Mean episode length: 237.18
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 30.1053
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3903
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 0.14s
                      Time elapsed: 00:02:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 150/1 [0m                       

                       Computation: 763185 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 151.88
               Mean episode length: 239.76
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 30.4196
       Episode_Reward/object_height 0.0036
     Episode_Reward/reaching_object 0.3953
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 0.13s
                      Time elapsed: 00:02:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 151/1 [0m                       

                       Computation: 626816 steps/s (collection: 0.050s, learning 0.107s)
                       Mean reward: 159.01
               Mean episode length: 237.27
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 31.8914
       Episode_Reward/object_height 0.0035
     Episode_Reward/reaching_object 0.3971
Episode_Termination/object_dropping 1.4583
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 0.16s
                      Time elapsed: 00:02:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 152/1 [0m                       

                       Computation: 597841 steps/s (collection: 0.054s, learning 0.111s)
                       Mean reward: 173.67
               Mean episode length: 240.01
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 33.7865
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4034
Episode_Termination/object_dropping 1.5000
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 0.16s
                      Time elapsed: 00:02:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 153/1 [0m                       

                       Computation: 802703 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 175.86
               Mean episode length: 242.75
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 33.9155
       Episode_Reward/object_height 0.0037
     Episode_Reward/reaching_object 0.4072
Episode_Termination/object_dropping 1.1250
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 0.12s
                      Time elapsed: 00:02:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 154/1 [0m                       

                       Computation: 770456 steps/s (collection: 0.047s, learning 0.081s)
                       Mean reward: 183.31
               Mean episode length: 242.09
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 36.1930
       Episode_Reward/object_height 0.0038
     Episode_Reward/reaching_object 0.4133
Episode_Termination/object_dropping 1.5417
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 0.13s
                      Time elapsed: 00:02:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 155/1 [0m                       

                       Computation: 673163 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 218.31
               Mean episode length: 243.85
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 43.6345
       Episode_Reward/object_height 0.0042
     Episode_Reward/reaching_object 0.4407
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 0.15s
                      Time elapsed: 00:02:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 156/1 [0m                       

                       Computation: 760040 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 231.52
               Mean episode length: 244.26
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 46.1226
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4499
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 0.13s
                      Time elapsed: 00:02:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 157/1 [0m                       

                       Computation: 811168 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 241.87
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 47.5899
       Episode_Reward/object_height 0.0044
     Episode_Reward/reaching_object 0.4532
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 54.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 0.12s
                      Time elapsed: 00:02:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 158/1 [0m                       

                       Computation: 635697 steps/s (collection: 0.042s, learning 0.113s)
                       Mean reward: 279.45
               Mean episode length: 239.95
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.9356
       Episode_Reward/object_height 0.0048
     Episode_Reward/reaching_object 0.4759
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 0.15s
                      Time elapsed: 00:02:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 159/1 [0m                       

                       Computation: 657235 steps/s (collection: 0.045s, learning 0.105s)
                       Mean reward: 223.53
               Mean episode length: 236.21
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 44.2676
       Episode_Reward/object_height 0.0043
     Episode_Reward/reaching_object 0.4328
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 0.15s
                      Time elapsed: 00:02:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 160/1 [0m                       

                       Computation: 770903 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 282.71
               Mean episode length: 245.04
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.8412
       Episode_Reward/object_height 0.0049
     Episode_Reward/reaching_object 0.4744
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 0.13s
                      Time elapsed: 00:02:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 161/1 [0m                       

                       Computation: 746558 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 287.33
               Mean episode length: 240.38
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.4001
       Episode_Reward/object_height 0.0049
     Episode_Reward/reaching_object 0.4737
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 0.13s
                      Time elapsed: 00:02:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 162/1 [0m                       

                       Computation: 767228 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 277.92
               Mean episode length: 240.63
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 56.0859
       Episode_Reward/object_height 0.0048
     Episode_Reward/reaching_object 0.4736
Episode_Termination/object_dropping 1.2917
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 0.13s
                      Time elapsed: 00:03:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 163/1 [0m                       

                       Computation: 805100 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 273.43
               Mean episode length: 242.82
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 54.4492
       Episode_Reward/object_height 0.0048
     Episode_Reward/reaching_object 0.4723
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 0.12s
                      Time elapsed: 00:03:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 164/1 [0m                       

                       Computation: 783032 steps/s (collection: 0.045s, learning 0.081s)
                       Mean reward: 278.87
               Mean episode length: 244.30
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 55.1307
       Episode_Reward/object_height 0.0047
     Episode_Reward/reaching_object 0.4778
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 0.13s
                      Time elapsed: 00:03:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 165/1 [0m                       

                       Computation: 644327 steps/s (collection: 0.050s, learning 0.103s)
                       Mean reward: 288.53
               Mean episode length: 244.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 57.6110
       Episode_Reward/object_height 0.0048
     Episode_Reward/reaching_object 0.4921
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 0.15s
                      Time elapsed: 00:03:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 166/1 [0m                       

                       Computation: 619894 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 325.22
               Mean episode length: 242.65
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.8024
       Episode_Reward/object_height 0.0050
     Episode_Reward/reaching_object 0.5030
Episode_Termination/object_dropping 1.2083
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 0.16s
                      Time elapsed: 00:03:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 167/1 [0m                       

                       Computation: 584834 steps/s (collection: 0.045s, learning 0.123s)
                       Mean reward: 334.00
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 63.9587
       Episode_Reward/object_height 0.0050
     Episode_Reward/reaching_object 0.4968
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 55.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 0.17s
                      Time elapsed: 00:03:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 168/1 [0m                       

                       Computation: 626005 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 317.84
               Mean episode length: 240.45
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 62.7871
       Episode_Reward/object_height 0.0051
     Episode_Reward/reaching_object 0.4844
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 0.16s
                      Time elapsed: 00:03:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 169/1 [0m                       

                       Computation: 637662 steps/s (collection: 0.046s, learning 0.109s)
                       Mean reward: 340.04
               Mean episode length: 238.66
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 65.3131
       Episode_Reward/object_height 0.0052
     Episode_Reward/reaching_object 0.5002
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 0.15s
                      Time elapsed: 00:03:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 170/1 [0m                       

                       Computation: 547527 steps/s (collection: 0.058s, learning 0.122s)
                       Mean reward: 338.88
               Mean episode length: 239.62
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 66.2827
       Episode_Reward/object_height 0.0052
     Episode_Reward/reaching_object 0.5001
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 0.18s
                      Time elapsed: 00:03:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 171/1 [0m                       

                       Computation: 684830 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 358.28
               Mean episode length: 246.39
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 71.8000
       Episode_Reward/object_height 0.0056
     Episode_Reward/reaching_object 0.5246
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 0.14s
                      Time elapsed: 00:03:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 172/1 [0m                       

                       Computation: 670299 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 348.06
               Mean episode length: 245.56
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 68.7912
       Episode_Reward/object_height 0.0054
     Episode_Reward/reaching_object 0.5184
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 0.15s
                      Time elapsed: 00:03:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 173/1 [0m                       

                       Computation: 613690 steps/s (collection: 0.041s, learning 0.119s)
                       Mean reward: 336.42
               Mean episode length: 245.98
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 65.6957
       Episode_Reward/object_height 0.0053
     Episode_Reward/reaching_object 0.5147
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 0.16s
                      Time elapsed: 00:03:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 174/1 [0m                       

                       Computation: 701921 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 371.00
               Mean episode length: 246.30
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 73.2956
       Episode_Reward/object_height 0.0057
     Episode_Reward/reaching_object 0.5313
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 0.14s
                      Time elapsed: 00:03:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 175/1 [0m                       

                       Computation: 717524 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 393.41
               Mean episode length: 244.43
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 77.3129
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.5394
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 0.14s
                      Time elapsed: 00:03:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 176/1 [0m                       

                       Computation: 730042 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 392.38
               Mean episode length: 244.87
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 78.2416
       Episode_Reward/object_height 0.0058
     Episode_Reward/reaching_object 0.5433
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 0.13s
                      Time elapsed: 00:03:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 177/1 [0m                       

                       Computation: 755463 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 378.26
               Mean episode length: 246.52
         Episode_Reward/action_rate -0.0010
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 75.7433
       Episode_Reward/object_height 0.0057
     Episode_Reward/reaching_object 0.5335
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 0.13s
                      Time elapsed: 00:03:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 178/1 [0m                       

                       Computation: 672754 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 420.30
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 81.9104
       Episode_Reward/object_height 0.0058
     Episode_Reward/reaching_object 0.5341
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 49.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 0.15s
                      Time elapsed: 00:03:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 179/1 [0m                       

                       Computation: 690564 steps/s (collection: 0.052s, learning 0.090s)
                       Mean reward: 443.73
               Mean episode length: 244.89
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 87.2517
       Episode_Reward/object_height 0.0062
     Episode_Reward/reaching_object 0.5607
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 0.14s
                      Time elapsed: 00:03:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 180/1 [0m                       

                       Computation: 668252 steps/s (collection: 0.049s, learning 0.099s)
                       Mean reward: 432.14
               Mean episode length: 237.55
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 86.1845
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.5440
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 0.15s
                      Time elapsed: 00:03:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 181/1 [0m                       

                       Computation: 691590 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 416.12
               Mean episode length: 243.30
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 83.5324
       Episode_Reward/object_height 0.0059
     Episode_Reward/reaching_object 0.5539
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 0.14s
                      Time elapsed: 00:03:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 182/1 [0m                       

                       Computation: 696711 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 458.60
               Mean episode length: 243.55
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 90.0174
       Episode_Reward/object_height 0.0063
     Episode_Reward/reaching_object 0.5669
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 0.14s
                      Time elapsed: 00:03:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 183/1 [0m                       

                       Computation: 773431 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 481.49
               Mean episode length: 242.43
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 95.0223
       Episode_Reward/object_height 0.0065
     Episode_Reward/reaching_object 0.5728
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 0.13s
                      Time elapsed: 00:03:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 184/1 [0m                       

                       Computation: 761024 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 483.63
               Mean episode length: 244.40
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 95.8596
       Episode_Reward/object_height 0.0066
     Episode_Reward/reaching_object 0.5790
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 0.13s
                      Time elapsed: 00:03:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 185/1 [0m                       

                       Computation: 593336 steps/s (collection: 0.045s, learning 0.121s)
                       Mean reward: 454.74
               Mean episode length: 244.37
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 91.0650
       Episode_Reward/object_height 0.0064
     Episode_Reward/reaching_object 0.5639
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 0.17s
                      Time elapsed: 00:03:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 186/1 [0m                       

                       Computation: 696512 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 495.74
               Mean episode length: 241.27
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 98.8897
       Episode_Reward/object_height 0.0067
     Episode_Reward/reaching_object 0.5760
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 0.14s
                      Time elapsed: 00:03:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 187/1 [0m                       

                       Computation: 670823 steps/s (collection: 0.041s, learning 0.106s)
                       Mean reward: 513.09
               Mean episode length: 244.20
         Episode_Reward/action_rate -0.0009
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 101.3630
       Episode_Reward/object_height 0.0068
     Episode_Reward/reaching_object 0.5967
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 0.15s
                      Time elapsed: 00:03:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 188/1 [0m                       

                       Computation: 819140 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 550.01
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 104.5020
       Episode_Reward/object_height 0.0071
     Episode_Reward/reaching_object 0.5984
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 50.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 0.12s
                      Time elapsed: 00:03:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 189/1 [0m                       

                       Computation: 707048 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 554.16
               Mean episode length: 244.45
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 109.6112
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.6107
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 0.14s
                      Time elapsed: 00:03:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 190/1 [0m                       

                       Computation: 841993 steps/s (collection: 0.039s, learning 0.078s)
                       Mean reward: 546.73
               Mean episode length: 235.89
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 108.2414
       Episode_Reward/object_height 0.0070
     Episode_Reward/reaching_object 0.5868
Episode_Termination/object_dropping 0.9167
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 0.12s
                      Time elapsed: 00:03:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 191/1 [0m                       

                       Computation: 725295 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 561.21
               Mean episode length: 244.22
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 111.0410
       Episode_Reward/object_height 0.0072
     Episode_Reward/reaching_object 0.6096
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 0.14s
                      Time elapsed: 00:03:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 192/1 [0m                       

                       Computation: 741399 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 584.35
               Mean episode length: 243.25
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 116.3036
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.6267
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 0.13s
                      Time elapsed: 00:03:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 193/1 [0m                       

                       Computation: 722570 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 579.39
               Mean episode length: 246.35
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 114.3992
       Episode_Reward/object_height 0.0073
     Episode_Reward/reaching_object 0.6139
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 0.14s
                      Time elapsed: 00:03:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 194/1 [0m                       

                       Computation: 735582 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 613.79
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 121.3735
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.6354
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 0.13s
                      Time elapsed: 00:03:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 195/1 [0m                       

                       Computation: 659332 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 617.41
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 122.5587
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.6400
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 0.15s
                      Time elapsed: 00:03:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 196/1 [0m                       

                       Computation: 722712 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 593.91
               Mean episode length: 244.16
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 117.6353
       Episode_Reward/object_height 0.0075
     Episode_Reward/reaching_object 0.6204
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 0.14s
                      Time elapsed: 00:03:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 197/1 [0m                       

                       Computation: 676240 steps/s (collection: 0.053s, learning 0.092s)
                       Mean reward: 664.55
               Mean episode length: 245.84
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 132.1315
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.6570
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 0.15s
                      Time elapsed: 00:03:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 198/1 [0m                       

                       Computation: 779869 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 683.86
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 132.7837
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.6561
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 50.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 0.13s
                      Time elapsed: 00:03:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 199/1 [0m                       

                       Computation: 786267 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 651.42
               Mean episode length: 241.70
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 129.6904
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.6464
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 0.13s
                      Time elapsed: 00:03:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 200/1 [0m                       

                       Computation: 707531 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 658.50
               Mean episode length: 239.80
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 132.6620
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.6437
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 0.14s
                      Time elapsed: 00:03:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 201/1 [0m                       

                       Computation: 734851 steps/s (collection: 0.049s, learning 0.085s)
                       Mean reward: 674.39
               Mean episode length: 245.48
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 134.1349
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.6625
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 0.13s
                      Time elapsed: 00:03:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 202/1 [0m                       

                       Computation: 631941 steps/s (collection: 0.047s, learning 0.109s)
                       Mean reward: 692.72
               Mean episode length: 247.06
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 138.0169
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.6699
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 0.16s
                      Time elapsed: 00:03:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 203/1 [0m                       

                       Computation: 825938 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 695.67
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 137.8334
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.6743
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 0.12s
                      Time elapsed: 00:03:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 204/1 [0m                       

                       Computation: 779684 steps/s (collection: 0.047s, learning 0.079s)
                       Mean reward: 752.73
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 150.0499
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7144
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 0.13s
                      Time elapsed: 00:03:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 205/1 [0m                       

                       Computation: 771864 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 713.29
               Mean episode length: 247.90
         Episode_Reward/action_rate -0.0008
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 141.9854
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.6886
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 0.13s
                      Time elapsed: 00:03:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 206/1 [0m                       

                       Computation: 747339 steps/s (collection: 0.049s, learning 0.083s)
                       Mean reward: 724.83
               Mean episode length: 246.81
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 145.4427
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.6905
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 0.13s
                      Time elapsed: 00:03:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 207/1 [0m                       

                       Computation: 691775 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 716.99
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 143.0474
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.6867
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 0.14s
                      Time elapsed: 00:03:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 208/1 [0m                       

                       Computation: 799860 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 732.94
               Mean episode length: 247.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 145.3074
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.6975
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 0.12s
                      Time elapsed: 00:03:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 209/1 [0m                       

                       Computation: 733870 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 745.85
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 146.1362
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.6898
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 47.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 0.13s
                      Time elapsed: 00:03:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 210/1 [0m                       

                       Computation: 676297 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 757.27
               Mean episode length: 245.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 150.4627
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7082
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 0.15s
                      Time elapsed: 00:03:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 211/1 [0m                       

                       Computation: 592070 steps/s (collection: 0.058s, learning 0.108s)
                       Mean reward: 750.36
               Mean episode length: 247.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 148.7882
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7037
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 0.17s
                      Time elapsed: 00:03:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 212/1 [0m                       

                       Computation: 578026 steps/s (collection: 0.054s, learning 0.117s)
                       Mean reward: 762.85
               Mean episode length: 246.34
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 152.3659
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7109
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 0.17s
                      Time elapsed: 00:03:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 213/1 [0m                       

                       Computation: 597422 steps/s (collection: 0.039s, learning 0.126s)
                       Mean reward: 778.01
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 155.4058
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7275
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 0.16s
                      Time elapsed: 00:04:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 214/1 [0m                       

                       Computation: 624482 steps/s (collection: 0.038s, learning 0.120s)
                       Mean reward: 769.52
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 154.1952
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7206
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 0.16s
                      Time elapsed: 00:04:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 215/1 [0m                       

                       Computation: 776773 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 760.85
               Mean episode length: 245.72
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 150.7084
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7008
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 0.13s
                      Time elapsed: 00:04:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 216/1 [0m                       

                       Computation: 744629 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 774.56
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 154.6484
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7276
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 0.13s
                      Time elapsed: 00:04:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 217/1 [0m                       

                       Computation: 749305 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 774.93
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 153.4997
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7181
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 0.13s
                      Time elapsed: 00:04:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 218/1 [0m                       

                       Computation: 618860 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 780.85
               Mean episode length: 245.88
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 155.0528
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7154
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 0.16s
                      Time elapsed: 00:04:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 219/1 [0m                       

                       Computation: 732428 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 793.16
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.0916
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7279
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 49.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 0.13s
                      Time elapsed: 00:04:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 220/1 [0m                       

                       Computation: 741477 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 787.71
               Mean episode length: 246.47
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 156.7459
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7167
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 0.13s
                      Time elapsed: 00:04:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 221/1 [0m                       

                       Computation: 769588 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 761.22
               Mean episode length: 240.82
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 152.8322
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7071
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 0.13s
                      Time elapsed: 00:04:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 222/1 [0m                       

                       Computation: 770881 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 782.30
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 154.9390
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7168
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 0.13s
                      Time elapsed: 00:04:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 223/1 [0m                       

                       Computation: 772007 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 801.57
               Mean episode length: 246.80
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 158.0176
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7248
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 0.13s
                      Time elapsed: 00:04:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 224/1 [0m                       

                       Computation: 799142 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 778.57
               Mean episode length: 245.78
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 154.7585
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7146
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 0.12s
                      Time elapsed: 00:04:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 225/1 [0m                       

                       Computation: 788365 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 771.11
               Mean episode length: 246.03
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 153.6820
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7086
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 0.12s
                      Time elapsed: 00:04:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 226/1 [0m                       

                       Computation: 786183 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 809.58
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 160.9876
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7366
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 0.13s
                      Time elapsed: 00:04:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 227/1 [0m                       

                       Computation: 789862 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 809.59
               Mean episode length: 245.51
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.2116
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7323
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 0.12s
                      Time elapsed: 00:04:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 228/1 [0m                       

                       Computation: 789523 steps/s (collection: 0.047s, learning 0.077s)
                       Mean reward: 806.81
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 159.9385
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7260
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 0.12s
                      Time elapsed: 00:04:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 229/1 [0m                       

                       Computation: 750310 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 794.55
               Mean episode length: 245.16
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 157.8681
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7210
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 0.13s
                      Time elapsed: 00:04:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 230/1 [0m                       

                       Computation: 750268 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 814.93
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 159.3327
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7278
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 45.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 0.13s
                      Time elapsed: 00:04:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 231/1 [0m                       

                       Computation: 706996 steps/s (collection: 0.047s, learning 0.092s)
                       Mean reward: 775.84
               Mean episode length: 244.01
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 157.1598
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7209
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 0.14s
                      Time elapsed: 00:04:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 232/1 [0m                       

                       Computation: 839843 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 776.46
               Mean episode length: 239.74
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 154.3442
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7031
Episode_Termination/object_dropping 0.8750
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 0.12s
                      Time elapsed: 00:04:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 233/1 [0m                       

                       Computation: 798730 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 792.19
               Mean episode length: 244.90
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 157.2120
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7191
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 0.12s
                      Time elapsed: 00:04:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 234/1 [0m                       

                       Computation: 682493 steps/s (collection: 0.048s, learning 0.096s)
                       Mean reward: 808.13
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 161.1139
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7418
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 0.14s
                      Time elapsed: 00:04:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 235/1 [0m                       

                       Computation: 709704 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 826.07
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.6161
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7423
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 0.14s
                      Time elapsed: 00:04:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 236/1 [0m                       

                       Computation: 695719 steps/s (collection: 0.055s, learning 0.087s)
                       Mean reward: 806.25
               Mean episode length: 246.53
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 160.9134
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7288
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 0.14s
                      Time elapsed: 00:04:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 237/1 [0m                       

                       Computation: 763305 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 807.46
               Mean episode length: 245.98
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 159.8328
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7283
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 0.13s
                      Time elapsed: 00:04:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 238/1 [0m                       

                       Computation: 685785 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 814.64
               Mean episode length: 247.91
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.8967
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7399
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 0.14s
                      Time elapsed: 00:04:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 239/1 [0m                       

                       Computation: 794011 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 800.71
               Mean episode length: 246.65
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.6477
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7251
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 0.12s
                      Time elapsed: 00:04:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 240/1 [0m                       

                       Computation: 722361 steps/s (collection: 0.038s, learning 0.099s)
                       Mean reward: 825.01
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 159.1280
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7249
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 47.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 0.14s
                      Time elapsed: 00:04:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 241/1 [0m                       

                       Computation: 702188 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 826.94
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.6733
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7437
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 0.14s
                      Time elapsed: 00:04:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 242/1 [0m                       

                       Computation: 700923 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 820.81
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.9780
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7297
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 0.14s
                      Time elapsed: 00:04:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 243/1 [0m                       

                       Computation: 802510 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 806.86
               Mean episode length: 245.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.2258
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7251
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 0.12s
                      Time elapsed: 00:04:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 244/1 [0m                       

                       Computation: 756125 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 817.44
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.5916
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7391
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 0.13s
                      Time elapsed: 00:04:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 245/1 [0m                       

                       Computation: 711391 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 819.08
               Mean episode length: 247.25
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.7314
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7436
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 0.14s
                      Time elapsed: 00:04:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 246/1 [0m                       

                       Computation: 730818 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 824.06
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.6615
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7446
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 0.13s
                      Time elapsed: 00:04:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 247/1 [0m                       

                       Computation: 754991 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 823.74
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.1388
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7325
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 0.13s
                      Time elapsed: 00:04:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 248/1 [0m                       

                       Computation: 757851 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 848.72
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.1819
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7605
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 0.13s
                      Time elapsed: 00:04:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 249/1 [0m                       

                       Computation: 780182 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 844.39
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.8086
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7556
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 0.13s
                      Time elapsed: 00:04:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 250/1 [0m                       

                       Computation: 788371 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 835.07
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.3386
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7456
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 49.7917
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 0.12s
                      Time elapsed: 00:04:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 251/1 [0m                       

                       Computation: 799032 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 819.43
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.0551
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7455
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 0.12s
                      Time elapsed: 00:04:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 252/1 [0m                       

                       Computation: 784827 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 830.61
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.0555
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7480
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 0.13s
                      Time elapsed: 00:04:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 253/1 [0m                       

                       Computation: 742060 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 843.95
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.1006
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 0.13s
                      Time elapsed: 00:04:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 254/1 [0m                       

                       Computation: 751152 steps/s (collection: 0.051s, learning 0.080s)
                       Mean reward: 842.46
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.6976
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7551
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 0.13s
                      Time elapsed: 00:04:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 255/1 [0m                       

                       Computation: 655253 steps/s (collection: 0.050s, learning 0.100s)
                       Mean reward: 864.18
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0900
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 0.15s
                      Time elapsed: 00:04:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 256/1 [0m                       

                       Computation: 758037 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 844.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.1987
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 0.13s
                      Time elapsed: 00:04:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 257/1 [0m                       

                       Computation: 711708 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 842.08
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0007
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.2529
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 0.14s
                      Time elapsed: 00:04:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 258/1 [0m                       

                       Computation: 714255 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 865.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0783
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 0.14s
                      Time elapsed: 00:04:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 259/1 [0m                       

                       Computation: 779683 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 857.14
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.0340
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 0.13s
                      Time elapsed: 00:04:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 260/1 [0m                       

                       Computation: 666201 steps/s (collection: 0.046s, learning 0.102s)
                       Mean reward: 859.62
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9717
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 0.15s
                      Time elapsed: 00:04:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 261/1 [0m                       

                       Computation: 702216 steps/s (collection: 0.049s, learning 0.091s)
                       Mean reward: 864.21
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.1887
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7805
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 46.0000
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 0.14s
                      Time elapsed: 00:04:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 262/1 [0m                       

                       Computation: 695603 steps/s (collection: 0.048s, learning 0.093s)
                       Mean reward: 852.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.7298
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 0.14s
                      Time elapsed: 00:04:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 263/1 [0m                       

                       Computation: 745269 steps/s (collection: 0.050s, learning 0.082s)
                       Mean reward: 855.89
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.7371
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 0.13s
                      Time elapsed: 00:04:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 264/1 [0m                       

                       Computation: 782371 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 867.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9774
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7818
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 0.13s
                      Time elapsed: 00:04:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 265/1 [0m                       

                       Computation: 702860 steps/s (collection: 0.045s, learning 0.095s)
                       Mean reward: 856.18
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6843
       Episode_Reward/object_height 0.0105
     Episode_Reward/reaching_object 0.7730
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 0.14s
                      Time elapsed: 00:04:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 266/1 [0m                       

                       Computation: 739840 steps/s (collection: 0.047s, learning 0.086s)
                       Mean reward: 865.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.2423
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7791
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 0.13s
                      Time elapsed: 00:04:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 267/1 [0m                       

                       Computation: 663958 steps/s (collection: 0.042s, learning 0.106s)
                       Mean reward: 857.94
               Mean episode length: 249.03
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5225
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7707
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 0.15s
                      Time elapsed: 00:04:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 268/1 [0m                       

                       Computation: 777164 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 855.12
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.8570
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 0.13s
                      Time elapsed: 00:04:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 269/1 [0m                       

                       Computation: 640207 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 863.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8791
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 0.15s
                      Time elapsed: 00:05:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 270/1 [0m                       

                       Computation: 667750 steps/s (collection: 0.043s, learning 0.104s)
                       Mean reward: 869.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5344
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 0.15s
                      Time elapsed: 00:05:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 271/1 [0m                       

                       Computation: 722500 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 863.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7390
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7805
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 49.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 0.14s
                      Time elapsed: 00:05:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 272/1 [0m                       

                       Computation: 805600 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 847.24
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.4109
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7592
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 0.12s
                      Time elapsed: 00:05:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 273/1 [0m                       

                       Computation: 744486 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 854.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.2604
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 0.13s
                      Time elapsed: 00:05:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 274/1 [0m                       

                       Computation: 721322 steps/s (collection: 0.052s, learning 0.085s)
                       Mean reward: 860.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.0570
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 0.14s
                      Time elapsed: 00:05:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 275/1 [0m                       

                       Computation: 806295 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 859.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7419
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 0.12s
                      Time elapsed: 00:05:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 276/1 [0m                       

                       Computation: 819023 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 856.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.3689
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 0.12s
                      Time elapsed: 00:05:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 277/1 [0m                       

                       Computation: 836337 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 862.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4875
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 0.12s
                      Time elapsed: 00:05:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 278/1 [0m                       

                       Computation: 694401 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 861.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5229
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 0.14s
                      Time elapsed: 00:05:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 279/1 [0m                       

                       Computation: 742978 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 864.07
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.3594
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 0.13s
                      Time elapsed: 00:05:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 280/1 [0m                       

                       Computation: 642658 steps/s (collection: 0.048s, learning 0.105s)
                       Mean reward: 859.23
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6134
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7740
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 0.15s
                      Time elapsed: 00:05:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 281/1 [0m                       

                       Computation: 704555 steps/s (collection: 0.052s, learning 0.088s)
                       Mean reward: 870.07
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.0594
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 0.14s
                      Time elapsed: 00:05:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 282/1 [0m                       

                       Computation: 717494 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 868.46
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.8612
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 44.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 0.14s
                      Time elapsed: 00:05:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 283/1 [0m                       

                       Computation: 708632 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 859.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1046
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7627
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 0.14s
                      Time elapsed: 00:05:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 284/1 [0m                       

                       Computation: 766411 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 858.75
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.2928
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7600
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 0.13s
                      Time elapsed: 00:05:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 285/1 [0m                       

                       Computation: 731906 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 864.68
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1224
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 0.13s
                      Time elapsed: 00:05:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 286/1 [0m                       

                       Computation: 789219 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 860.95
               Mean episode length: 247.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1787
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 0.12s
                      Time elapsed: 00:05:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 287/1 [0m                       

                       Computation: 728063 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 868.32
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4522
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 0.14s
                      Time elapsed: 00:05:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 288/1 [0m                       

                       Computation: 729298 steps/s (collection: 0.051s, learning 0.084s)
                       Mean reward: 867.41
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4693
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7736
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 0.13s
                      Time elapsed: 00:05:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 289/1 [0m                       

                       Computation: 719977 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 859.38
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1881
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 0.14s
                      Time elapsed: 00:05:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 290/1 [0m                       

                       Computation: 767718 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 863.28
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7559
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 0.13s
                      Time elapsed: 00:05:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 291/1 [0m                       

                       Computation: 828306 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 853.45
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.9198
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 0.12s
                      Time elapsed: 00:05:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 292/1 [0m                       

                       Computation: 599623 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 860.56
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.0932
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7616
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 47.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 0.16s
                      Time elapsed: 00:05:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 293/1 [0m                       

                       Computation: 749652 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 859.56
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1719
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7541
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 0.13s
                      Time elapsed: 00:05:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 294/1 [0m                       

                       Computation: 777187 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 828.03
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.3243
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7255
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 0.13s
                      Time elapsed: 00:05:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 295/1 [0m                       

                       Computation: 719593 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 826.44
               Mean episode length: 247.17
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.8834
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7217
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 0.14s
                      Time elapsed: 00:05:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 296/1 [0m                       

                       Computation: 632070 steps/s (collection: 0.041s, learning 0.115s)
                       Mean reward: 839.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.0324
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7439
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 0.16s
                      Time elapsed: 00:05:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 297/1 [0m                       

                       Computation: 575152 steps/s (collection: 0.052s, learning 0.119s)
                       Mean reward: 849.03
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9977
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7407
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 0.17s
                      Time elapsed: 00:05:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 298/1 [0m                       

                       Computation: 626054 steps/s (collection: 0.041s, learning 0.116s)
                       Mean reward: 842.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.6888
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7413
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 0.16s
                      Time elapsed: 00:05:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 299/1 [0m                       

                       Computation: 622087 steps/s (collection: 0.047s, learning 0.111s)
                       Mean reward: 846.33
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.7349
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7372
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 0.16s
                      Time elapsed: 00:05:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 300/1 [0m                       

                       Computation: 678536 steps/s (collection: 0.040s, learning 0.105s)
                       Mean reward: 837.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.6829
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7396
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 0.14s
                      Time elapsed: 00:05:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 301/1 [0m                       

                       Computation: 708361 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 840.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.3147
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7391
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 0.14s
                      Time elapsed: 00:05:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 302/1 [0m                       

                       Computation: 666156 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 868.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7779
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7582
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 0.15s
                      Time elapsed: 00:05:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 303/1 [0m                       

                       Computation: 708498 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 857.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.0216
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 43.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 0.14s
                      Time elapsed: 00:05:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 304/1 [0m                       

                       Computation: 670910 steps/s (collection: 0.050s, learning 0.097s)
                       Mean reward: 854.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5187
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7429
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 0.15s
                      Time elapsed: 00:05:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 305/1 [0m                       

                       Computation: 764247 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 862.51
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.9378
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 0.13s
                      Time elapsed: 00:05:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 306/1 [0m                       

                       Computation: 824706 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 858.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9226
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 0.12s
                      Time elapsed: 00:05:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 307/1 [0m                       

                       Computation: 723380 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 868.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8448
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 0.14s
                      Time elapsed: 00:05:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 308/1 [0m                       

                       Computation: 785967 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 868.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7711
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7651
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 0.13s
                      Time elapsed: 00:05:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 309/1 [0m                       

                       Computation: 732814 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 871.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7479
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7632
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 0.13s
                      Time elapsed: 00:05:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 310/1 [0m                       

                       Computation: 812160 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 873.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7931
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 0.12s
                      Time elapsed: 00:05:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 311/1 [0m                       

                       Computation: 802946 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 878.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9854
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7726
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 0.12s
                      Time elapsed: 00:05:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 312/1 [0m                       

                       Computation: 742740 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 872.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2916
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 0.13s
                      Time elapsed: 00:05:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 313/1 [0m                       

                       Computation: 786903 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 876.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.7249
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 45.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 0.12s
                      Time elapsed: 00:05:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 314/1 [0m                       

                       Computation: 793910 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 876.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.6263
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7844
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 0.12s
                      Time elapsed: 00:05:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 315/1 [0m                       

                       Computation: 675404 steps/s (collection: 0.044s, learning 0.101s)
                       Mean reward: 877.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.7716
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7801
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 0.15s
                      Time elapsed: 00:05:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 316/1 [0m                       

                       Computation: 718588 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 874.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0795
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 0.14s
                      Time elapsed: 00:05:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 317/1 [0m                       

                       Computation: 806251 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 878.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5481
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 0.12s
                      Time elapsed: 00:05:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 318/1 [0m                       

                       Computation: 662513 steps/s (collection: 0.042s, learning 0.106s)
                       Mean reward: 875.46
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2313
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 0.15s
                      Time elapsed: 00:05:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 319/1 [0m                       

                       Computation: 737392 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 876.11
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5097
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7757
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 0.13s
                      Time elapsed: 00:05:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 320/1 [0m                       

                       Computation: 792569 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 872.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8140
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 0.12s
                      Time elapsed: 00:05:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 321/1 [0m                       

                       Computation: 836344 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 882.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.6837
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 0.12s
                      Time elapsed: 00:05:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 322/1 [0m                       

                       Computation: 845076 steps/s (collection: 0.040s, learning 0.076s)
                       Mean reward: 875.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2887
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7758
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 0.12s
                      Time elapsed: 00:05:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 323/1 [0m                       

                       Computation: 785640 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 871.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5505
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 48.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 0.13s
                      Time elapsed: 00:05:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 324/1 [0m                       

                       Computation: 698619 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 872.17
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.0592
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7770
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 0.14s
                      Time elapsed: 00:06:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 325/1 [0m                       

                       Computation: 612815 steps/s (collection: 0.042s, learning 0.119s)
                       Mean reward: 874.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.1702
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 0.16s
                      Time elapsed: 00:06:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 326/1 [0m                       

                       Computation: 698695 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 873.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.9828
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 0.14s
                      Time elapsed: 00:06:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 327/1 [0m                       

                       Computation: 633095 steps/s (collection: 0.053s, learning 0.102s)
                       Mean reward: 870.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.8115
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 0.16s
                      Time elapsed: 00:06:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 328/1 [0m                       

                       Computation: 715214 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 880.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.5454
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 0.14s
                      Time elapsed: 00:06:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 329/1 [0m                       

                       Computation: 626168 steps/s (collection: 0.041s, learning 0.116s)
                       Mean reward: 878.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.9673
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7679
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 0.16s
                      Time elapsed: 00:06:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 330/1 [0m                       

                       Computation: 672867 steps/s (collection: 0.052s, learning 0.094s)
                       Mean reward: 877.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.4555
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 0.15s
                      Time elapsed: 00:06:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 331/1 [0m                       

                       Computation: 785217 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 877.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.6603
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 0.13s
                      Time elapsed: 00:06:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 332/1 [0m                       

                       Computation: 767822 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 875.28
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.4742
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7598
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 0.13s
                      Time elapsed: 00:06:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 333/1 [0m                       

                       Computation: 747632 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 870.24
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.1682
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7630
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 0.13s
                      Time elapsed: 00:06:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 334/1 [0m                       

                       Computation: 752842 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 873.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.2644
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7570
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 45.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 0.13s
                      Time elapsed: 00:06:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 335/1 [0m                       

                       Computation: 747298 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 856.02
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.1166
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7416
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 0.13s
                      Time elapsed: 00:06:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 336/1 [0m                       

                       Computation: 809094 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 871.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.3603
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7545
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 0.12s
                      Time elapsed: 00:06:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 337/1 [0m                       

                       Computation: 776975 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 865.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.3934
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7448
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 0.13s
                      Time elapsed: 00:06:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 338/1 [0m                       

                       Computation: 710129 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 870.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2842
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7430
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 0.14s
                      Time elapsed: 00:06:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 339/1 [0m                       

                       Computation: 757162 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 862.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6828
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7401
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 0.13s
                      Time elapsed: 00:06:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 340/1 [0m                       

                       Computation: 682592 steps/s (collection: 0.051s, learning 0.094s)
                       Mean reward: 869.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.1730
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7529
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 0.14s
                      Time elapsed: 00:06:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 341/1 [0m                       

                       Computation: 774295 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 855.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.3732
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7418
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 0.13s
                      Time elapsed: 00:06:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 342/1 [0m                       

                       Computation: 782583 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 872.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7023
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7523
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 0.13s
                      Time elapsed: 00:06:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 343/1 [0m                       

                       Computation: 772306 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 876.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.7254
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 0.13s
                      Time elapsed: 00:06:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 344/1 [0m                       

                       Computation: 753149 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 874.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5528
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 47.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 0.13s
                      Time elapsed: 00:06:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 345/1 [0m                       

                       Computation: 751334 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 870.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5473
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 0.13s
                      Time elapsed: 00:06:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 346/1 [0m                       

                       Computation: 572980 steps/s (collection: 0.052s, learning 0.120s)
                       Mean reward: 878.20
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.6252
       Episode_Reward/object_height 0.0099
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 0.17s
                      Time elapsed: 00:06:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 347/1 [0m                       

                       Computation: 712298 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 873.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.0472
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 0.14s
                      Time elapsed: 00:06:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 348/1 [0m                       

                       Computation: 743167 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 873.31
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9408
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7675
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 0.13s
                      Time elapsed: 00:06:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 349/1 [0m                       

                       Computation: 750317 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 877.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9443
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 0.13s
                      Time elapsed: 00:06:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 350/1 [0m                       

                       Computation: 644666 steps/s (collection: 0.038s, learning 0.115s)
                       Mean reward: 878.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8367
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 0.15s
                      Time elapsed: 00:06:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 351/1 [0m                       

                       Computation: 729423 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 877.62
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8604
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 0.13s
                      Time elapsed: 00:06:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 352/1 [0m                       

                       Computation: 697849 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 873.93
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.1085
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 0.14s
                      Time elapsed: 00:06:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 353/1 [0m                       

                       Computation: 655390 steps/s (collection: 0.044s, learning 0.106s)
                       Mean reward: 874.80
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.2610
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7688
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 0.15s
                      Time elapsed: 00:06:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 354/1 [0m                       

                       Computation: 671967 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 880.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.3858
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 0.15s
                      Time elapsed: 00:06:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 355/1 [0m                       

                       Computation: 717077 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 878.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4745
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 44.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 0.14s
                      Time elapsed: 00:06:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 356/1 [0m                       

                       Computation: 691812 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 881.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.6090
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7849
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 0.14s
                      Time elapsed: 00:06:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 357/1 [0m                       

                       Computation: 651208 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 878.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.6932
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 0.15s
                      Time elapsed: 00:06:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 358/1 [0m                       

                       Computation: 728062 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 873.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.6206
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 0.14s
                      Time elapsed: 00:06:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 359/1 [0m                       

                       Computation: 745102 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 880.38
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.4177
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7815
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 0.13s
                      Time elapsed: 00:06:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 360/1 [0m                       

                       Computation: 744303 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 878.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.9415
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 0.13s
                      Time elapsed: 00:06:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 361/1 [0m                       

                       Computation: 758777 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 878.38
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.9127
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7877
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 0.13s
                      Time elapsed: 00:06:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 362/1 [0m                       

                       Computation: 733987 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 877.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.6950
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7859
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 0.13s
                      Time elapsed: 00:06:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 363/1 [0m                       

                       Computation: 719396 steps/s (collection: 0.037s, learning 0.100s)
                       Mean reward: 871.73
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.2463
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 0.14s
                      Time elapsed: 00:06:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 364/1 [0m                       

                       Computation: 659743 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 878.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.9617
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7827
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 0.15s
                      Time elapsed: 00:06:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 365/1 [0m                       

                       Computation: 765649 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 878.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.4550
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 46.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 0.13s
                      Time elapsed: 00:06:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 366/1 [0m                       

                       Computation: 748385 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 875.94
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.2305
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 0.13s
                      Time elapsed: 00:06:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 367/1 [0m                       

                       Computation: 760464 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 871.12
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.4041
       Episode_Reward/object_height 0.0077
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 0.13s
                      Time elapsed: 00:06:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 368/1 [0m                       

                       Computation: 686552 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 876.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.3560
       Episode_Reward/object_height 0.0078
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 0.14s
                      Time elapsed: 00:06:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 369/1 [0m                       

                       Computation: 707563 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 870.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.2220
       Episode_Reward/object_height 0.0079
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 0.14s
                      Time elapsed: 00:06:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 370/1 [0m                       

                       Computation: 731618 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 872.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.6007
       Episode_Reward/object_height 0.0080
     Episode_Reward/reaching_object 0.7783
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 0.13s
                      Time elapsed: 00:06:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 371/1 [0m                       

                       Computation: 704163 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 874.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.1862
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7799
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 0.14s
                      Time elapsed: 00:06:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 372/1 [0m                       

                       Computation: 716468 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 875.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.4266
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 0.14s
                      Time elapsed: 00:06:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 373/1 [0m                       

                       Computation: 737620 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 882.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.7324
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7873
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 0.13s
                      Time elapsed: 00:06:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 374/1 [0m                       

                       Computation: 727913 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 875.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.5458
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 0.14s
                      Time elapsed: 00:06:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 375/1 [0m                       

                       Computation: 740370 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 878.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.1318
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7855
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 49.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 0.13s
                      Time elapsed: 00:06:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 376/1 [0m                       

                       Computation: 789528 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 879.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.4515
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7831
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 0.12s
                      Time elapsed: 00:06:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 377/1 [0m                       

                       Computation: 819065 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 879.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.2069
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7869
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 0.12s
                      Time elapsed: 00:06:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 378/1 [0m                       

                       Computation: 794233 steps/s (collection: 0.035s, learning 0.089s)
                       Mean reward: 879.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.0520
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 0.12s
                      Time elapsed: 00:07:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 379/1 [0m                       

                       Computation: 709997 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 880.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.3132
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7891
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 0.14s
                      Time elapsed: 00:07:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 380/1 [0m                       

                       Computation: 718697 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 883.67
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 176.0010
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7904
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 0.14s
                      Time elapsed: 00:07:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 381/1 [0m                       

                       Computation: 662653 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 876.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2395
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7827
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 0.15s
                      Time elapsed: 00:07:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 382/1 [0m                       

                       Computation: 683871 steps/s (collection: 0.039s, learning 0.105s)
                       Mean reward: 880.83
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.1750
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 0.14s
                      Time elapsed: 00:07:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 383/1 [0m                       

                       Computation: 604811 steps/s (collection: 0.045s, learning 0.118s)
                       Mean reward: 879.35
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.2219
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 0.16s
                      Time elapsed: 00:07:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 384/1 [0m                       

                       Computation: 646124 steps/s (collection: 0.050s, learning 0.103s)
                       Mean reward: 883.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.8464
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7844
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 0.15s
                      Time elapsed: 00:07:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 385/1 [0m                       

                       Computation: 640010 steps/s (collection: 0.040s, learning 0.114s)
                       Mean reward: 883.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.9382
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7878
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 0.15s
                      Time elapsed: 00:07:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 386/1 [0m                       

                       Computation: 730782 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 881.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.3612
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7755
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 45.4583
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 0.13s
                      Time elapsed: 00:07:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 387/1 [0m                       

                       Computation: 715244 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 882.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.6620
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7847
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 0.14s
                      Time elapsed: 00:07:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 388/1 [0m                       

                       Computation: 714844 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 880.33
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.5582
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7843
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 0.14s
                      Time elapsed: 00:07:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 389/1 [0m                       

                       Computation: 762314 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 876.91
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.7940
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7826
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 0.13s
                      Time elapsed: 00:07:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 390/1 [0m                       

                       Computation: 757289 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 881.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.4612
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 0.13s
                      Time elapsed: 00:07:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 391/1 [0m                       

                       Computation: 805814 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 880.47
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.4333
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 0.12s
                      Time elapsed: 00:07:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 392/1 [0m                       

                       Computation: 758744 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 879.77
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.2105
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 0.13s
                      Time elapsed: 00:07:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 393/1 [0m                       

                       Computation: 670734 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 880.74
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.4902
       Episode_Reward/object_height 0.0091
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 0.15s
                      Time elapsed: 00:07:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 394/1 [0m                       

                       Computation: 708195 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 870.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4354
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 0.14s
                      Time elapsed: 00:07:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 395/1 [0m                       

                       Computation: 564527 steps/s (collection: 0.052s, learning 0.122s)
                       Mean reward: 874.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7644
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7578
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 0.17s
                      Time elapsed: 00:07:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 396/1 [0m                       

                       Computation: 725359 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 875.43
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0909
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 48.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 0.14s
                      Time elapsed: 00:07:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 397/1 [0m                       

                       Computation: 789404 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 868.38
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.4217
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7609
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 0.12s
                      Time elapsed: 00:07:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 398/1 [0m                       

                       Computation: 768907 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 871.17
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9898
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 0.13s
                      Time elapsed: 00:07:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 399/1 [0m                       

                       Computation: 735803 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 878.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.0274
       Episode_Reward/object_height 0.0090
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 0.13s
                      Time elapsed: 00:07:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 400/1 [0m                       

                       Computation: 679032 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 873.36
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.8410
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7668
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 0.14s
                      Time elapsed: 00:07:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 401/1 [0m                       

                       Computation: 725429 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 867.29
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7123
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7571
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 0.14s
                      Time elapsed: 00:07:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 402/1 [0m                       

                       Computation: 730343 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 868.69
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.9716
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 0.13s
                      Time elapsed: 00:07:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 403/1 [0m                       

                       Computation: 773852 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 878.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8530
       Episode_Reward/object_height 0.0088
     Episode_Reward/reaching_object 0.7620
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 0.13s
                      Time elapsed: 00:07:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 404/1 [0m                       

                       Computation: 775021 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 874.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3743
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 0.13s
                      Time elapsed: 00:07:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 405/1 [0m                       

                       Computation: 708023 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 868.98
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2320
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 0.14s
                      Time elapsed: 00:07:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 406/1 [0m                       

                       Computation: 802403 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 871.31
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.7091
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 0.12s
                      Time elapsed: 00:07:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 407/1 [0m                       

                       Computation: 728090 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 870.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.3348
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7736
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 44.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 0.14s
                      Time elapsed: 00:07:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 408/1 [0m                       

                       Computation: 666926 steps/s (collection: 0.044s, learning 0.103s)
                       Mean reward: 871.51
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.7431
       Episode_Reward/object_height 0.0082
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 0.15s
                      Time elapsed: 00:07:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 409/1 [0m                       

                       Computation: 717433 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 863.48
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1114
       Episode_Reward/object_height 0.0081
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 0.14s
                      Time elapsed: 00:07:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 410/1 [0m                       

                       Computation: 665524 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 856.34
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8284
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 0.15s
                      Time elapsed: 00:07:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 411/1 [0m                       

                       Computation: 678944 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 864.68
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7288
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 0.14s
                      Time elapsed: 00:07:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 412/1 [0m                       

                       Computation: 685686 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 860.60
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6425
       Episode_Reward/object_height 0.0085
     Episode_Reward/reaching_object 0.7662
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 0.14s
                      Time elapsed: 00:07:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 413/1 [0m                       

                       Computation: 741799 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 866.69
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.7510
       Episode_Reward/object_height 0.0083
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 0.13s
                      Time elapsed: 00:07:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 414/1 [0m                       

                       Computation: 716030 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 871.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.2415
       Episode_Reward/object_height 0.0084
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 0.14s
                      Time elapsed: 00:07:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 415/1 [0m                       

                       Computation: 659434 steps/s (collection: 0.043s, learning 0.106s)
                       Mean reward: 869.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3250
       Episode_Reward/object_height 0.0087
     Episode_Reward/reaching_object 0.7676
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 0.15s
                      Time elapsed: 00:07:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 416/1 [0m                       

                       Computation: 646652 steps/s (collection: 0.046s, learning 0.106s)
                       Mean reward: 867.09
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.6175
       Episode_Reward/object_height 0.0086
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 0.15s
                      Time elapsed: 00:07:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 417/1 [0m                       

                       Computation: 738442 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 874.26
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8421
       Episode_Reward/object_height 0.0089
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 46.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 0.13s
                      Time elapsed: 00:07:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 418/1 [0m                       

                       Computation: 806311 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 875.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2701
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7737
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 0.12s
                      Time elapsed: 00:07:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 419/1 [0m                       

                       Computation: 664972 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 867.94
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1776
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 0.15s
                      Time elapsed: 00:07:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 420/1 [0m                       

                       Computation: 746692 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 866.80
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.9755
       Episode_Reward/object_height 0.0098
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 0.13s
                      Time elapsed: 00:07:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 421/1 [0m                       

                       Computation: 764790 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 877.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6442
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 0.13s
                      Time elapsed: 00:07:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 422/1 [0m                       

                       Computation: 825740 steps/s (collection: 0.042s, learning 0.077s)
                       Mean reward: 862.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.8204
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 0.12s
                      Time elapsed: 00:07:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 423/1 [0m                       

                       Computation: 780900 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 871.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7409
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 0.13s
                      Time elapsed: 00:07:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 424/1 [0m                       

                       Computation: 708460 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 869.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8861
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 0.14s
                      Time elapsed: 00:07:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 425/1 [0m                       

                       Computation: 794349 steps/s (collection: 0.044s, learning 0.080s)
                       Mean reward: 875.50
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.5679
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7627
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 0.12s
                      Time elapsed: 00:07:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 426/1 [0m                       

                       Computation: 814277 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 871.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4527
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 0.12s
                      Time elapsed: 00:07:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 427/1 [0m                       

                       Computation: 770884 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 859.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2715
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7554
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 0.13s
                      Time elapsed: 00:07:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 428/1 [0m                       

                       Computation: 741726 steps/s (collection: 0.047s, learning 0.086s)
                       Mean reward: 847.81
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9401
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7569
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 42.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 0.13s
                      Time elapsed: 00:07:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 429/1 [0m                       

                       Computation: 713504 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 844.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.1862
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7444
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 0.14s
                      Time elapsed: 00:07:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 430/1 [0m                       

                       Computation: 764594 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 844.43
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.1534
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.7448
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 0.13s
                      Time elapsed: 00:08:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 431/1 [0m                       

                       Computation: 776124 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 855.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4969
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7484
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 0.13s
                      Time elapsed: 00:08:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 432/1 [0m                       

                       Computation: 766932 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 862.37
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0737
       Episode_Reward/object_height 0.0120
     Episode_Reward/reaching_object 0.7487
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 0.13s
                      Time elapsed: 00:08:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 433/1 [0m                       

                       Computation: 683027 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 870.94
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3433
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7493
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 0.14s
                      Time elapsed: 00:08:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 434/1 [0m                       

                       Computation: 750237 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 873.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9782
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 0.13s
                      Time elapsed: 00:08:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 435/1 [0m                       

                       Computation: 711559 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 868.12
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3953
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7436
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 0.14s
                      Time elapsed: 00:08:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 436/1 [0m                       

                       Computation: 636212 steps/s (collection: 0.043s, learning 0.112s)
                       Mean reward: 867.19
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8999
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7440
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 0.15s
                      Time elapsed: 00:08:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 437/1 [0m                       

                       Computation: 709809 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 871.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6075
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7438
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 0.14s
                      Time elapsed: 00:08:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 438/1 [0m                       

                       Computation: 620162 steps/s (collection: 0.048s, learning 0.111s)
                       Mean reward: 872.11
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0700
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7414
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 45.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 0.16s
                      Time elapsed: 00:08:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 439/1 [0m                       

                       Computation: 524894 steps/s (collection: 0.054s, learning 0.133s)
                       Mean reward: 863.60
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7667
       Episode_Reward/object_height 0.0120
     Episode_Reward/reaching_object 0.7450
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 0.19s
                      Time elapsed: 00:08:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 440/1 [0m                       

                       Computation: 748360 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 860.82
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1156
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7387
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 0.13s
                      Time elapsed: 00:08:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 441/1 [0m                       

                       Computation: 815672 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 868.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.7488
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7410
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 0.12s
                      Time elapsed: 00:08:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 442/1 [0m                       

                       Computation: 802625 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 869.14
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.0279
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7467
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 0.12s
                      Time elapsed: 00:08:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 443/1 [0m                       

                       Computation: 737867 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 878.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.9757
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7548
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 0.13s
                      Time elapsed: 00:08:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 444/1 [0m                       

                       Computation: 689065 steps/s (collection: 0.048s, learning 0.095s)
                       Mean reward: 874.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0325
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7502
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 0.14s
                      Time elapsed: 00:08:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 445/1 [0m                       

                       Computation: 691958 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 864.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.4445
       Episode_Reward/object_height 0.0120
     Episode_Reward/reaching_object 0.7490
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 0.14s
                      Time elapsed: 00:08:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 446/1 [0m                       

                       Computation: 724182 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 878.16
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.9424
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7570
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 0.14s
                      Time elapsed: 00:08:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 447/1 [0m                       

                       Computation: 767610 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 871.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.4961
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7535
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 0.13s
                      Time elapsed: 00:08:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 448/1 [0m                       

                       Computation: 711836 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 872.60
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.6266
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 48.1250
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 0.14s
                      Time elapsed: 00:08:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 449/1 [0m                       

                       Computation: 783081 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 878.20
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8859
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 0.13s
                      Time elapsed: 00:08:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 450/1 [0m                       

                       Computation: 802422 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 860.07
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.4968
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7451
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 0.12s
                      Time elapsed: 00:08:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 451/1 [0m                       

                       Computation: 638234 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 875.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.4504
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 0.15s
                      Time elapsed: 00:08:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 452/1 [0m                       

                       Computation: 789257 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 869.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0386
       Episode_Reward/object_height 0.0107
     Episode_Reward/reaching_object 0.7626
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 0.12s
                      Time elapsed: 00:08:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 453/1 [0m                       

                       Computation: 776767 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 873.13
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7103
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7602
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 0.13s
                      Time elapsed: 00:08:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 454/1 [0m                       

                       Computation: 808220 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 879.45
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.2936
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 0.12s
                      Time elapsed: 00:08:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 455/1 [0m                       

                       Computation: 792409 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 878.21
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9858
       Episode_Reward/object_height 0.0101
     Episode_Reward/reaching_object 0.7701
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 0.12s
                      Time elapsed: 00:08:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 456/1 [0m                       

                       Computation: 738491 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 875.78
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5250
       Episode_Reward/object_height 0.0100
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 0.13s
                      Time elapsed: 00:08:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 457/1 [0m                       

                       Computation: 765264 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 866.09
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3153
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7632
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 0.13s
                      Time elapsed: 00:08:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 458/1 [0m                       

                       Computation: 622007 steps/s (collection: 0.058s, learning 0.101s)
                       Mean reward: 868.12
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.9707
       Episode_Reward/object_height 0.0096
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 0.16s
                      Time elapsed: 00:08:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 459/1 [0m                       

                       Computation: 706244 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 872.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.8962
       Episode_Reward/object_height 0.0093
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 44.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 0.14s
                      Time elapsed: 00:08:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 460/1 [0m                       

                       Computation: 664158 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 871.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.7170
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7706
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 0.15s
                      Time elapsed: 00:08:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 461/1 [0m                       

                       Computation: 668058 steps/s (collection: 0.043s, learning 0.104s)
                       Mean reward: 859.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.5936
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 0.15s
                      Time elapsed: 00:08:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 462/1 [0m                       

                       Computation: 645888 steps/s (collection: 0.042s, learning 0.110s)
                       Mean reward: 869.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0715
       Episode_Reward/object_height 0.0092
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 0.15s
                      Time elapsed: 00:08:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 463/1 [0m                       

                       Computation: 732840 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 878.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9790
       Episode_Reward/object_height 0.0094
     Episode_Reward/reaching_object 0.7778
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 0.13s
                      Time elapsed: 00:08:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 464/1 [0m                       

                       Computation: 718038 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 876.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.4212
       Episode_Reward/object_height 0.0095
     Episode_Reward/reaching_object 0.7787
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 0.14s
                      Time elapsed: 00:08:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 465/1 [0m                       

                       Computation: 636548 steps/s (collection: 0.041s, learning 0.114s)
                       Mean reward: 865.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0006
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1441
       Episode_Reward/object_height 0.0097
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 0.15s
                      Time elapsed: 00:08:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 466/1 [0m                       

                       Computation: 691791 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 876.07
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.1541
       Episode_Reward/object_height 0.0102
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 0.14s
                      Time elapsed: 00:08:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 467/1 [0m                       

                       Computation: 642417 steps/s (collection: 0.049s, learning 0.105s)
                       Mean reward: 873.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0496
       Episode_Reward/object_height 0.0103
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 0.15s
                      Time elapsed: 00:08:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 468/1 [0m                       

                       Computation: 693867 steps/s (collection: 0.042s, learning 0.100s)
                       Mean reward: 880.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.2795
       Episode_Reward/object_height 0.0104
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 0.14s
                      Time elapsed: 00:08:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 469/1 [0m                       

                       Computation: 707109 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 878.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.0392
       Episode_Reward/object_height 0.0106
     Episode_Reward/reaching_object 0.7775
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 47.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 0.14s
                      Time elapsed: 00:08:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 470/1 [0m                       

                       Computation: 601079 steps/s (collection: 0.049s, learning 0.114s)
                       Mean reward: 882.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.8032
       Episode_Reward/object_height 0.0108
     Episode_Reward/reaching_object 0.7857
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 0.16s
                      Time elapsed: 00:08:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 471/1 [0m                       

                       Computation: 756451 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 883.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.8028
       Episode_Reward/object_height 0.0109
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 0.13s
                      Time elapsed: 00:08:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 472/1 [0m                       

                       Computation: 758428 steps/s (collection: 0.050s, learning 0.080s)
                       Mean reward: 876.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3092
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7737
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 0.13s
                      Time elapsed: 00:08:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 473/1 [0m                       

                       Computation: 745515 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 873.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2247
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7754
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 0.13s
                      Time elapsed: 00:08:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 474/1 [0m                       

                       Computation: 648670 steps/s (collection: 0.049s, learning 0.103s)
                       Mean reward: 876.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4360
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 0.15s
                      Time elapsed: 00:08:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 475/1 [0m                       

                       Computation: 661597 steps/s (collection: 0.052s, learning 0.097s)
                       Mean reward: 870.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3071
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7699
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 0.15s
                      Time elapsed: 00:08:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 476/1 [0m                       

                       Computation: 756206 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 872.61
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6647
       Episode_Reward/object_height 0.0115
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 0.13s
                      Time elapsed: 00:08:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 477/1 [0m                       

                       Computation: 630032 steps/s (collection: 0.047s, learning 0.110s)
                       Mean reward: 871.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.3794
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 0.16s
                      Time elapsed: 00:08:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 478/1 [0m                       

                       Computation: 706132 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 874.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.1652
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 0.14s
                      Time elapsed: 00:08:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 479/1 [0m                       

                       Computation: 798859 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 875.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.2110
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 0.12s
                      Time elapsed: 00:08:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 480/1 [0m                       

                       Computation: 701950 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 874.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.9236
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 43.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 0.14s
                      Time elapsed: 00:08:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 481/1 [0m                       

                       Computation: 750043 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 871.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.0671
       Episode_Reward/object_height 0.0120
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 0.13s
                      Time elapsed: 00:09:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 482/1 [0m                       

                       Computation: 727481 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 878.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.7372
       Episode_Reward/object_height 0.0120
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 0.14s
                      Time elapsed: 00:09:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 483/1 [0m                       

                       Computation: 619822 steps/s (collection: 0.047s, learning 0.112s)
                       Mean reward: 879.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.9886
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7668
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 0.16s
                      Time elapsed: 00:09:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 484/1 [0m                       

                       Computation: 733230 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 875.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.3719
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 0.13s
                      Time elapsed: 00:09:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 485/1 [0m                       

                       Computation: 744157 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 878.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.9675
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 0.13s
                      Time elapsed: 00:09:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 486/1 [0m                       

                       Computation: 733191 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 869.82
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.5069
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7624
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 0.13s
                      Time elapsed: 00:09:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 487/1 [0m                       

                       Computation: 705709 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 876.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.6076
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.7637
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 0.14s
                      Time elapsed: 00:09:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 488/1 [0m                       

                       Computation: 689527 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 878.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.9080
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.7698
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 0.14s
                      Time elapsed: 00:09:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 489/1 [0m                       

                       Computation: 743938 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 874.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.9373
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 0.13s
                      Time elapsed: 00:09:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 490/1 [0m                       

                       Computation: 563264 steps/s (collection: 0.052s, learning 0.123s)
                       Mean reward: 872.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.6399
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.7529
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 45.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 0.17s
                      Time elapsed: 00:09:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 491/1 [0m                       

                       Computation: 530927 steps/s (collection: 0.054s, learning 0.131s)
                       Mean reward: 862.38
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.7062
       Episode_Reward/object_height 0.0123
     Episode_Reward/reaching_object 0.7481
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 0.19s
                      Time elapsed: 00:09:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 492/1 [0m                       

                       Computation: 541124 steps/s (collection: 0.060s, learning 0.122s)
                       Mean reward: 875.83
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0101
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 0.18s
                      Time elapsed: 00:09:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 493/1 [0m                       

                       Computation: 644442 steps/s (collection: 0.051s, learning 0.102s)
                       Mean reward: 870.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.0537
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.7507
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 0.15s
                      Time elapsed: 00:09:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 494/1 [0m                       

                       Computation: 704494 steps/s (collection: 0.050s, learning 0.090s)
                       Mean reward: 874.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0649
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.7541
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 0.14s
                      Time elapsed: 00:09:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 495/1 [0m                       

                       Computation: 716899 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 879.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.2055
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 0.14s
                      Time elapsed: 00:09:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 496/1 [0m                       

                       Computation: 721586 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 876.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.7133
       Episode_Reward/object_height 0.0124
     Episode_Reward/reaching_object 0.7683
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 0.14s
                      Time elapsed: 00:09:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 497/1 [0m                       

                       Computation: 788812 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 880.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.5065
       Episode_Reward/object_height 0.0123
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 0.12s
                      Time elapsed: 00:09:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 498/1 [0m                       

                       Computation: 633889 steps/s (collection: 0.051s, learning 0.104s)
                       Mean reward: 877.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.8788
       Episode_Reward/object_height 0.0122
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 0.16s
                      Time elapsed: 00:09:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 499/1 [0m                       

                       Computation: 627558 steps/s (collection: 0.044s, learning 0.113s)
                       Mean reward: 880.32
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.3533
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7730
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 0.16s
                      Time elapsed: 00:09:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 500/1 [0m                       

                       Computation: 610379 steps/s (collection: 0.063s, learning 0.098s)
                       Mean reward: 877.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.9457
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 48.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 0.16s
                      Time elapsed: 00:09:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 501/1 [0m                       

                       Computation: 623897 steps/s (collection: 0.044s, learning 0.114s)
                       Mean reward: 878.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.5867
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 0.16s
                      Time elapsed: 00:09:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 502/1 [0m                       

                       Computation: 682606 steps/s (collection: 0.051s, learning 0.094s)
                       Mean reward: 880.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.2807
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7838
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 0.14s
                      Time elapsed: 00:09:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 503/1 [0m                       

                       Computation: 666075 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 876.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8293
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.7852
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 0.15s
                      Time elapsed: 00:09:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 504/1 [0m                       

                       Computation: 737173 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 882.26
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.6619
       Episode_Reward/object_height 0.0117
     Episode_Reward/reaching_object 0.7866
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 0.13s
                      Time elapsed: 00:09:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 505/1 [0m                       

                       Computation: 757991 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 879.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.9555
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7881
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 0.13s
                      Time elapsed: 00:09:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 506/1 [0m                       

                       Computation: 802091 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 879.40
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.1621
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7889
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 0.12s
                      Time elapsed: 00:09:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 507/1 [0m                       

                       Computation: 776924 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 879.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.4830
       Episode_Reward/object_height 0.0114
     Episode_Reward/reaching_object 0.7914
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 0.13s
                      Time elapsed: 00:09:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 508/1 [0m                       

                       Computation: 788361 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 885.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 176.0323
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7921
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 0.12s
                      Time elapsed: 00:09:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 509/1 [0m                       

                       Computation: 792205 steps/s (collection: 0.044s, learning 0.080s)
                       Mean reward: 884.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 176.1360
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7980
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 0.12s
                      Time elapsed: 00:09:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 510/1 [0m                       

                       Computation: 795890 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 884.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 176.0467
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7960
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 0.12s
                      Time elapsed: 00:09:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 511/1 [0m                       

                       Computation: 804246 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 880.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.7579
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7906
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 44.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 0.12s
                      Time elapsed: 00:09:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 512/1 [0m                       

                       Computation: 806069 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 882.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.9718
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7983
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 0.12s
                      Time elapsed: 00:09:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 513/1 [0m                       

                       Computation: 789519 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 876.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.6014
       Episode_Reward/object_height 0.0110
     Episode_Reward/reaching_object 0.7833
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 0.12s
                      Time elapsed: 00:09:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 514/1 [0m                       

                       Computation: 718620 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 880.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.5027
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 0.14s
                      Time elapsed: 00:09:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 515/1 [0m                       

                       Computation: 764869 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 882.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.3325
       Episode_Reward/object_height 0.0111
     Episode_Reward/reaching_object 0.7882
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 0.13s
                      Time elapsed: 00:09:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 516/1 [0m                       

                       Computation: 654852 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 879.59
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8616
       Episode_Reward/object_height 0.0112
     Episode_Reward/reaching_object 0.7916
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 0.15s
                      Time elapsed: 00:09:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 517/1 [0m                       

                       Computation: 632273 steps/s (collection: 0.041s, learning 0.114s)
                       Mean reward: 881.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.5272
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7941
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 0.16s
                      Time elapsed: 00:09:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 518/1 [0m                       

                       Computation: 693526 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 881.28
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.6184
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7922
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 0.14s
                      Time elapsed: 00:09:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 519/1 [0m                       

                       Computation: 623942 steps/s (collection: 0.041s, learning 0.117s)
                       Mean reward: 871.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3232
       Episode_Reward/object_height 0.0113
     Episode_Reward/reaching_object 0.7796
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 0.16s
                      Time elapsed: 00:09:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 520/1 [0m                       

                       Computation: 716229 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 881.98
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.5261
       Episode_Reward/object_height 0.0116
     Episode_Reward/reaching_object 0.7877
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 0.14s
                      Time elapsed: 00:09:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 521/1 [0m                       

                       Computation: 622005 steps/s (collection: 0.067s, learning 0.092s)
                       Mean reward: 883.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 176.3874
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7918
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 47.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 0.16s
                      Time elapsed: 00:09:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 522/1 [0m                       

                       Computation: 712442 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 870.80
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4253
       Episode_Reward/object_height 0.0118
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 0.14s
                      Time elapsed: 00:09:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 523/1 [0m                       

                       Computation: 672977 steps/s (collection: 0.050s, learning 0.096s)
                       Mean reward: 868.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7710
       Episode_Reward/object_height 0.0119
     Episode_Reward/reaching_object 0.7842
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 0.15s
                      Time elapsed: 00:09:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 524/1 [0m                       

                       Computation: 776022 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 874.46
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2735
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7847
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 0.13s
                      Time elapsed: 00:09:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 525/1 [0m                       

                       Computation: 739477 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 866.71
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2699
       Episode_Reward/object_height 0.0121
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 0.13s
                      Time elapsed: 00:09:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 526/1 [0m                       

                       Computation: 822500 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 880.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.4450
       Episode_Reward/object_height 0.0123
     Episode_Reward/reaching_object 0.7923
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 0.12s
                      Time elapsed: 00:09:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 527/1 [0m                       

                       Computation: 785265 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 880.53
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.3041
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.7920
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 0.13s
                      Time elapsed: 00:09:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 528/1 [0m                       

                       Computation: 779637 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 874.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0927
       Episode_Reward/object_height 0.0125
     Episode_Reward/reaching_object 0.7846
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 0.13s
                      Time elapsed: 00:09:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 529/1 [0m                       

                       Computation: 658362 steps/s (collection: 0.045s, learning 0.104s)
                       Mean reward: 875.52
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3162
       Episode_Reward/object_height 0.0127
     Episode_Reward/reaching_object 0.7881
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 0.15s
                      Time elapsed: 00:09:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 530/1 [0m                       

                       Computation: 778876 steps/s (collection: 0.045s, learning 0.081s)
                       Mean reward: 877.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3508
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 0.13s
                      Time elapsed: 00:09:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 531/1 [0m                       

                       Computation: 739010 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 876.31
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7369
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.7907
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 0.13s
                      Time elapsed: 00:09:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 532/1 [0m                       

                       Computation: 714733 steps/s (collection: 0.048s, learning 0.090s)
                       Mean reward: 875.56
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.9551
       Episode_Reward/object_height 0.0132
     Episode_Reward/reaching_object 0.7833
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 43.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 0.14s
                      Time elapsed: 00:09:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 533/1 [0m                       

                       Computation: 670518 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 877.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.3206
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 0.15s
                      Time elapsed: 00:10:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 534/1 [0m                       

                       Computation: 733473 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 874.41
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.2214
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 0.13s
                      Time elapsed: 00:10:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 535/1 [0m                       

                       Computation: 802110 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 880.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.5558
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7917
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 0.12s
                      Time elapsed: 00:10:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 536/1 [0m                       

                       Computation: 779780 steps/s (collection: 0.046s, learning 0.081s)
                       Mean reward: 874.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.8127
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7792
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 0.13s
                      Time elapsed: 00:10:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 537/1 [0m                       

                       Computation: 770959 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 876.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.2810
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7813
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 0.13s
                      Time elapsed: 00:10:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 538/1 [0m                       

                       Computation: 670281 steps/s (collection: 0.053s, learning 0.094s)
                       Mean reward: 873.52
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.1381
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7798
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 0.15s
                      Time elapsed: 00:10:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 539/1 [0m                       

                       Computation: 766489 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 882.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.6973
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7895
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 0.13s
                      Time elapsed: 00:10:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 540/1 [0m                       

                       Computation: 736136 steps/s (collection: 0.050s, learning 0.084s)
                       Mean reward: 875.90
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.3019
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7788
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 0.13s
                      Time elapsed: 00:10:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 541/1 [0m                       

                       Computation: 794558 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 879.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.1043
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7852
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 0.12s
                      Time elapsed: 00:10:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 542/1 [0m                       

                       Computation: 744614 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 878.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.1475
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 46.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 0.13s
                      Time elapsed: 00:10:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 543/1 [0m                       

                       Computation: 632587 steps/s (collection: 0.044s, learning 0.112s)
                       Mean reward: 869.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.9385
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7595
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 0.16s
                      Time elapsed: 00:10:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 544/1 [0m                       

                       Computation: 567337 steps/s (collection: 0.051s, learning 0.122s)
                       Mean reward: 855.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.0735
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7454
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 0.17s
                      Time elapsed: 00:10:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 545/1 [0m                       

                       Computation: 627976 steps/s (collection: 0.041s, learning 0.116s)
                       Mean reward: 864.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.0442
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7536
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 0.16s
                      Time elapsed: 00:10:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 546/1 [0m                       

                       Computation: 693765 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 863.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.3788
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 0.14s
                      Time elapsed: 00:10:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 547/1 [0m                       

                       Computation: 702479 steps/s (collection: 0.056s, learning 0.084s)
                       Mean reward: 872.52
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.9496
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7668
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 0.14s
                      Time elapsed: 00:10:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 548/1 [0m                       

                       Computation: 701029 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 870.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.2036
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 0.14s
                      Time elapsed: 00:10:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 549/1 [0m                       

                       Computation: 818655 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 869.06
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.2678
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 0.12s
                      Time elapsed: 00:10:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 550/1 [0m                       

                       Computation: 830900 steps/s (collection: 0.043s, learning 0.076s)
                       Mean reward: 867.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.9508
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 0.12s
                      Time elapsed: 00:10:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 551/1 [0m                       

                       Computation: 852526 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 862.66
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.9630
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 0.12s
                      Time elapsed: 00:10:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 552/1 [0m                       

                       Computation: 807644 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 849.86
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 169.2708
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.7588
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 0.12s
                      Time elapsed: 00:10:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 553/1 [0m                       

                       Computation: 807076 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 844.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 170.2430
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 42.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 0.12s
                      Time elapsed: 00:10:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 554/1 [0m                       

                       Computation: 722422 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 848.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 168.5435
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 0.14s
                      Time elapsed: 00:10:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 555/1 [0m                       

                       Computation: 788911 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 846.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 168.4671
       Episode_Reward/object_height 0.0127
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 0.12s
                      Time elapsed: 00:10:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 556/1 [0m                       

                       Computation: 701909 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 848.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 169.1201
       Episode_Reward/object_height 0.0127
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 0.14s
                      Time elapsed: 00:10:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 557/1 [0m                       

                       Computation: 789247 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 866.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.4209
       Episode_Reward/object_height 0.0129
     Episode_Reward/reaching_object 0.7680
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 0.12s
                      Time elapsed: 00:10:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 558/1 [0m                       

                       Computation: 816160 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 872.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.8694
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 0.12s
                      Time elapsed: 00:10:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 559/1 [0m                       

                       Computation: 792077 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 864.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.4422
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 0.12s
                      Time elapsed: 00:10:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 560/1 [0m                       

                       Computation: 700379 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 871.74
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.0234
       Episode_Reward/object_height 0.0128
     Episode_Reward/reaching_object 0.7782
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 0.14s
                      Time elapsed: 00:10:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 561/1 [0m                       

                       Computation: 842279 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 876.93
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.4827
       Episode_Reward/object_height 0.0129
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 0.12s
                      Time elapsed: 00:10:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 562/1 [0m                       

                       Computation: 790924 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 874.94
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0140
       Episode_Reward/object_height 0.0129
     Episode_Reward/reaching_object 0.7837
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 0.12s
                      Time elapsed: 00:10:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 563/1 [0m                       

                       Computation: 782842 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 874.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.7078
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.7851
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 45.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 0.13s
                      Time elapsed: 00:10:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 564/1 [0m                       

                       Computation: 761949 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 877.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.7980
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 0.13s
                      Time elapsed: 00:10:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 565/1 [0m                       

                       Computation: 755903 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 882.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.9012
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7912
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 0.13s
                      Time elapsed: 00:10:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 566/1 [0m                       

                       Computation: 754483 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 877.86
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.6973
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 0.13s
                      Time elapsed: 00:10:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 567/1 [0m                       

                       Computation: 723848 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 872.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.7283
       Episode_Reward/object_height 0.0132
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 0.14s
                      Time elapsed: 00:10:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 568/1 [0m                       

                       Computation: 640156 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 874.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.3850
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 0.15s
                      Time elapsed: 00:10:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 569/1 [0m                       

                       Computation: 689745 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 876.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.6579
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 0.14s
                      Time elapsed: 00:10:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 570/1 [0m                       

                       Computation: 799587 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 869.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.9807
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 0.12s
                      Time elapsed: 00:10:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 571/1 [0m                       

                       Computation: 690262 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 877.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.8831
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7842
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 0.14s
                      Time elapsed: 00:10:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 572/1 [0m                       

                       Computation: 719329 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 878.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.8187
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 0.14s
                      Time elapsed: 00:10:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 573/1 [0m                       

                       Computation: 595447 steps/s (collection: 0.054s, learning 0.111s)
                       Mean reward: 860.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0029
      Episode_Reward/lifting_object 173.2376
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 47.8333
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 0.17s
                      Time elapsed: 00:10:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 574/1 [0m                       

                       Computation: 540398 steps/s (collection: 0.053s, learning 0.129s)
                       Mean reward: 861.27
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.2183
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7598
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 0.18s
                      Time elapsed: 00:10:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 575/1 [0m                       

                       Computation: 563208 steps/s (collection: 0.054s, learning 0.121s)
                       Mean reward: 871.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.3479
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 0.17s
                      Time elapsed: 00:10:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 576/1 [0m                       

                       Computation: 604050 steps/s (collection: 0.050s, learning 0.113s)
                       Mean reward: 868.57
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.0263
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 0.16s
                      Time elapsed: 00:10:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 577/1 [0m                       

                       Computation: 682620 steps/s (collection: 0.055s, learning 0.089s)
                       Mean reward: 867.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.2418
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7585
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 0.14s
                      Time elapsed: 00:10:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 578/1 [0m                       

                       Computation: 716601 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 870.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0029
      Episode_Reward/lifting_object 173.1906
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 0.14s
                      Time elapsed: 00:10:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 579/1 [0m                       

                       Computation: 735141 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 870.67
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0029
      Episode_Reward/lifting_object 173.3816
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7803
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 0.13s
                      Time elapsed: 00:10:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 580/1 [0m                       

                       Computation: 736214 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 875.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.2904
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7794
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 0.13s
                      Time elapsed: 00:10:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 581/1 [0m                       

                       Computation: 811292 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 875.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.2288
       Episode_Reward/object_height 0.0132
     Episode_Reward/reaching_object 0.7849
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 0.12s
                      Time elapsed: 00:10:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 582/1 [0m                       

                       Computation: 764394 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 872.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0037
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7943
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 0.13s
                      Time elapsed: 00:10:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 583/1 [0m                       

                       Computation: 828313 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 874.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0710
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 0.12s
                      Time elapsed: 00:10:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 584/1 [0m                       

                       Computation: 813617 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 872.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.9526
       Episode_Reward/object_height 0.0132
     Episode_Reward/reaching_object 0.7736
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 43.9167
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 0.12s
                      Time elapsed: 00:11:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 585/1 [0m                       

                       Computation: 622018 steps/s (collection: 0.052s, learning 0.107s)
                       Mean reward: 868.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.1753
       Episode_Reward/object_height 0.0133
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 0.16s
                      Time elapsed: 00:11:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 586/1 [0m                       

                       Computation: 752184 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 852.16
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 169.5099
       Episode_Reward/object_height 0.0130
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 0.13s
                      Time elapsed: 00:11:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 587/1 [0m                       

                       Computation: 634304 steps/s (collection: 0.050s, learning 0.105s)
                       Mean reward: 865.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.6748
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 0.15s
                      Time elapsed: 00:11:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 588/1 [0m                       

                       Computation: 730616 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 863.12
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.5307
       Episode_Reward/object_height 0.0131
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 0.13s
                      Time elapsed: 00:11:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 589/1 [0m                       

                       Computation: 812286 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 871.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.3179
       Episode_Reward/object_height 0.0134
     Episode_Reward/reaching_object 0.7886
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 0.12s
                      Time elapsed: 00:11:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 590/1 [0m                       

                       Computation: 767952 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 873.90
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.4634
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7840
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 0.13s
                      Time elapsed: 00:11:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 591/1 [0m                       

                       Computation: 717751 steps/s (collection: 0.047s, learning 0.090s)
                       Mean reward: 876.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.4098
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 0.14s
                      Time elapsed: 00:11:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 592/1 [0m                       

                       Computation: 727937 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 879.50
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.2048
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7895
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 0.14s
                      Time elapsed: 00:11:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 593/1 [0m                       

                       Computation: 761369 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 874.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.0412
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7884
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 0.13s
                      Time elapsed: 00:11:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 594/1 [0m                       

                       Computation: 730698 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 865.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.7652
       Episode_Reward/object_height 0.0136
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 46.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 0.13s
                      Time elapsed: 00:11:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 595/1 [0m                       

                       Computation: 595490 steps/s (collection: 0.059s, learning 0.106s)
                       Mean reward: 864.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 171.7171
       Episode_Reward/object_height 0.0135
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 0.17s
                      Time elapsed: 00:11:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 596/1 [0m                       

                       Computation: 668512 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 872.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.4261
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7862
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 0.15s
                      Time elapsed: 00:11:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 597/1 [0m                       

                       Computation: 591393 steps/s (collection: 0.061s, learning 0.106s)
                       Mean reward: 875.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.5450
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7865
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 0.17s
                      Time elapsed: 00:11:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 598/1 [0m                       

                       Computation: 636115 steps/s (collection: 0.048s, learning 0.107s)
                       Mean reward: 871.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 173.0199
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 0.15s
                      Time elapsed: 00:11:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 599/1 [0m                       

                       Computation: 651813 steps/s (collection: 0.049s, learning 0.102s)
                       Mean reward: 874.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.2483
       Episode_Reward/object_height 0.0137
     Episode_Reward/reaching_object 0.7881
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 0.15s
                      Time elapsed: 00:11:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 600/1 [0m                       

                       Computation: 591078 steps/s (collection: 0.050s, learning 0.117s)
                       Mean reward: 880.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.4208
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7808
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 0.17s
                      Time elapsed: 00:11:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 601/1 [0m                       

                       Computation: 780028 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 875.28
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.1367
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 0.13s
                      Time elapsed: 00:11:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 602/1 [0m                       

                       Computation: 807666 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 879.34
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.1047
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7805
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 0.12s
                      Time elapsed: 00:11:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 603/1 [0m                       

                       Computation: 799238 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 877.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6752
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7792
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 0.12s
                      Time elapsed: 00:11:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 604/1 [0m                       

                       Computation: 719914 steps/s (collection: 0.048s, learning 0.088s)
                       Mean reward: 876.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4980
       Episode_Reward/object_height 0.0142
     Episode_Reward/reaching_object 0.7795
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 0.14s
                      Time elapsed: 00:11:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 605/1 [0m                       

                       Computation: 764637 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 876.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0927
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7801
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 42.8750
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 0.13s
                      Time elapsed: 00:11:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 606/1 [0m                       

                       Computation: 736306 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 863.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2450
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 0.13s
                      Time elapsed: 00:11:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 607/1 [0m                       

                       Computation: 723996 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 872.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9482
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7751
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 0.14s
                      Time elapsed: 00:11:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 608/1 [0m                       

                       Computation: 767458 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 866.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5068
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 0.13s
                      Time elapsed: 00:11:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 609/1 [0m                       

                       Computation: 683035 steps/s (collection: 0.044s, learning 0.100s)
                       Mean reward: 868.33
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9691
       Episode_Reward/object_height 0.0148
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 0.14s
                      Time elapsed: 00:11:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 610/1 [0m                       

                       Computation: 674770 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 861.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0949
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 0.15s
                      Time elapsed: 00:11:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 611/1 [0m                       

                       Computation: 622003 steps/s (collection: 0.043s, learning 0.115s)
                       Mean reward: 876.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5986
       Episode_Reward/object_height 0.0155
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 0.16s
                      Time elapsed: 00:11:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 612/1 [0m                       

                       Computation: 750186 steps/s (collection: 0.046s, learning 0.086s)
                       Mean reward: 872.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.8716
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 0.13s
                      Time elapsed: 00:11:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 613/1 [0m                       

                       Computation: 764786 steps/s (collection: 0.048s, learning 0.081s)
                       Mean reward: 874.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0717
       Episode_Reward/object_height 0.0163
     Episode_Reward/reaching_object 0.7541
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 0.13s
                      Time elapsed: 00:11:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 614/1 [0m                       

                       Computation: 794512 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 863.28
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.0857
       Episode_Reward/object_height 0.0165
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 0.12s
                      Time elapsed: 00:11:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 615/1 [0m                       

                       Computation: 703355 steps/s (collection: 0.051s, learning 0.089s)
                       Mean reward: 852.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.6185
       Episode_Reward/object_height 0.0165
     Episode_Reward/reaching_object 0.7437
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 45.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 0.14s
                      Time elapsed: 00:11:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 616/1 [0m                       

                       Computation: 676096 steps/s (collection: 0.050s, learning 0.095s)
                       Mean reward: 857.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0959
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7449
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 0.15s
                      Time elapsed: 00:11:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 617/1 [0m                       

                       Computation: 687396 steps/s (collection: 0.052s, learning 0.091s)
                       Mean reward: 851.48
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.3170
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7307
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 0.14s
                      Time elapsed: 00:11:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 618/1 [0m                       

                       Computation: 703981 steps/s (collection: 0.050s, learning 0.090s)
                       Mean reward: 854.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7109
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7253
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 0.14s
                      Time elapsed: 00:11:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 619/1 [0m                       

                       Computation: 740512 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 851.65
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.5250
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7266
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 0.13s
                      Time elapsed: 00:11:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 620/1 [0m                       

                       Computation: 766996 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 856.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.7839
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7249
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 0.13s
                      Time elapsed: 00:11:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 621/1 [0m                       

                       Computation: 751922 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 866.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.7156
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7345
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 0.13s
                      Time elapsed: 00:11:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 622/1 [0m                       

                       Computation: 670268 steps/s (collection: 0.045s, learning 0.101s)
                       Mean reward: 857.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5301
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7282
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 0.15s
                      Time elapsed: 00:11:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 623/1 [0m                       

                       Computation: 637515 steps/s (collection: 0.046s, learning 0.109s)
                       Mean reward: 859.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.6608
       Episode_Reward/object_height 0.0179
     Episode_Reward/reaching_object 0.7217
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 0.15s
                      Time elapsed: 00:11:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 624/1 [0m                       

                       Computation: 684628 steps/s (collection: 0.052s, learning 0.092s)
                       Mean reward: 863.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.9880
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7290
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 0.14s
                      Time elapsed: 00:11:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 625/1 [0m                       

                       Computation: 535641 steps/s (collection: 0.056s, learning 0.128s)
                       Mean reward: 858.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.1870
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7313
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 48.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 0.18s
                      Time elapsed: 00:11:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 626/1 [0m                       

                       Computation: 627429 steps/s (collection: 0.051s, learning 0.106s)
                       Mean reward: 863.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.5712
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7350
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 0.16s
                      Time elapsed: 00:11:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 627/1 [0m                       

                       Computation: 712605 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 858.86
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.3468
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7320
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 0.14s
                      Time elapsed: 00:11:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 628/1 [0m                       

                       Computation: 691835 steps/s (collection: 0.045s, learning 0.097s)
                       Mean reward: 857.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3140
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7330
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 0.14s
                      Time elapsed: 00:11:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 629/1 [0m                       

                       Computation: 684753 steps/s (collection: 0.051s, learning 0.093s)
                       Mean reward: 858.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1219
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7364
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 0.14s
                      Time elapsed: 00:11:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 630/1 [0m                       

                       Computation: 657097 steps/s (collection: 0.046s, learning 0.104s)
                       Mean reward: 868.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1393
       Episode_Reward/object_height 0.0166
     Episode_Reward/reaching_object 0.7411
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 0.15s
                      Time elapsed: 00:11:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 631/1 [0m                       

                       Computation: 560556 steps/s (collection: 0.058s, learning 0.118s)
                       Mean reward: 865.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8650
       Episode_Reward/object_height 0.0164
     Episode_Reward/reaching_object 0.7433
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 0.18s
                      Time elapsed: 00:11:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 632/1 [0m                       

                       Computation: 620009 steps/s (collection: 0.051s, learning 0.108s)
                       Mean reward: 875.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.3657
       Episode_Reward/object_height 0.0163
     Episode_Reward/reaching_object 0.7486
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 0.16s
                      Time elapsed: 00:11:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 633/1 [0m                       

                       Computation: 604668 steps/s (collection: 0.051s, learning 0.112s)
                       Mean reward: 863.11
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.5762
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7455
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 0.16s
                      Time elapsed: 00:11:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 634/1 [0m                       

                       Computation: 625396 steps/s (collection: 0.055s, learning 0.102s)
                       Mean reward: 868.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2758
       Episode_Reward/object_height 0.0161
     Episode_Reward/reaching_object 0.7500
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 0.16s
                      Time elapsed: 00:12:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 635/1 [0m                       

                       Computation: 571687 steps/s (collection: 0.062s, learning 0.110s)
                       Mean reward: 872.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7148
       Episode_Reward/object_height 0.0162
     Episode_Reward/reaching_object 0.7533
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 0.17s
                      Time elapsed: 00:12:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 636/1 [0m                       

                       Computation: 622017 steps/s (collection: 0.051s, learning 0.107s)
                       Mean reward: 872.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2429
       Episode_Reward/object_height 0.0163
     Episode_Reward/reaching_object 0.7533
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 44.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 0.16s
                      Time elapsed: 00:12:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 637/1 [0m                       

                       Computation: 733507 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 862.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1727
       Episode_Reward/object_height 0.0162
     Episode_Reward/reaching_object 0.7525
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 0.13s
                      Time elapsed: 00:12:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 638/1 [0m                       

                       Computation: 646547 steps/s (collection: 0.053s, learning 0.100s)
                       Mean reward: 861.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0447
       Episode_Reward/object_height 0.0165
     Episode_Reward/reaching_object 0.7369
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 0.15s
                      Time elapsed: 00:12:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 639/1 [0m                       

                       Computation: 756514 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 873.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9853
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 0.13s
                      Time elapsed: 00:12:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 640/1 [0m                       

                       Computation: 747741 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 863.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7351
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7525
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 0.13s
                      Time elapsed: 00:12:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 641/1 [0m                       

                       Computation: 728090 steps/s (collection: 0.045s, learning 0.090s)
                       Mean reward: 858.69
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4743
       Episode_Reward/object_height 0.0170
     Episode_Reward/reaching_object 0.7433
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 0.14s
                      Time elapsed: 00:12:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 642/1 [0m                       

                       Computation: 742799 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 866.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4459
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 0.13s
                      Time elapsed: 00:12:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 643/1 [0m                       

                       Computation: 777969 steps/s (collection: 0.049s, learning 0.077s)
                       Mean reward: 865.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0727
       Episode_Reward/object_height 0.0176
     Episode_Reward/reaching_object 0.7468
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 0.13s
                      Time elapsed: 00:12:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 644/1 [0m                       

                       Computation: 805479 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 875.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.1607
       Episode_Reward/object_height 0.0182
     Episode_Reward/reaching_object 0.7483
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 0.12s
                      Time elapsed: 00:12:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 645/1 [0m                       

                       Computation: 722859 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 866.83
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6370
       Episode_Reward/object_height 0.0182
     Episode_Reward/reaching_object 0.7476
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 0.14s
                      Time elapsed: 00:12:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 646/1 [0m                       

                       Computation: 758842 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 863.31
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3637
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7468
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 47.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 0.13s
                      Time elapsed: 00:12:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 647/1 [0m                       

                       Computation: 601814 steps/s (collection: 0.046s, learning 0.118s)
                       Mean reward: 865.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2718
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7511
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 0.16s
                      Time elapsed: 00:12:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 648/1 [0m                       

                       Computation: 638032 steps/s (collection: 0.055s, learning 0.099s)
                       Mean reward: 859.11
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0554
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7473
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 0.15s
                      Time elapsed: 00:12:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 649/1 [0m                       

                       Computation: 655512 steps/s (collection: 0.047s, learning 0.103s)
                       Mean reward: 857.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.7746
       Episode_Reward/object_height 0.0191
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 0.15s
                      Time elapsed: 00:12:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 650/1 [0m                       

                       Computation: 625929 steps/s (collection: 0.046s, learning 0.111s)
                       Mean reward: 854.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.7132
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7443
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 0.16s
                      Time elapsed: 00:12:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 651/1 [0m                       

                       Computation: 668752 steps/s (collection: 0.045s, learning 0.102s)
                       Mean reward: 866.58
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6429
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7459
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 0.15s
                      Time elapsed: 00:12:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 652/1 [0m                       

                       Computation: 675502 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 867.00
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7504
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7445
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 0.15s
                      Time elapsed: 00:12:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 653/1 [0m                       

                       Computation: 780087 steps/s (collection: 0.044s, learning 0.082s)
                       Mean reward: 859.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3791
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7463
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 0.13s
                      Time elapsed: 00:12:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 654/1 [0m                       

                       Computation: 742131 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 857.22
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5071
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7363
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 0.13s
                      Time elapsed: 00:12:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 655/1 [0m                       

                       Computation: 746935 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 854.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3644
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7451
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 0.13s
                      Time elapsed: 00:12:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 656/1 [0m                       

                       Computation: 747374 steps/s (collection: 0.049s, learning 0.083s)
                       Mean reward: 857.81
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.9164
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7470
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 0.13s
                      Time elapsed: 00:12:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 657/1 [0m                       

                       Computation: 745174 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 854.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.4684
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7383
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 43.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 0.13s
                      Time elapsed: 00:12:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 658/1 [0m                       

                       Computation: 736633 steps/s (collection: 0.048s, learning 0.086s)
                       Mean reward: 842.36
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.4333
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7352
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 0.13s
                      Time elapsed: 00:12:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 659/1 [0m                       

                       Computation: 709830 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 842.65
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.7457
       Episode_Reward/object_height 0.0201
     Episode_Reward/reaching_object 0.7373
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 0.14s
                      Time elapsed: 00:12:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 660/1 [0m                       

                       Computation: 717841 steps/s (collection: 0.049s, learning 0.088s)
                       Mean reward: 857.55
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.5008
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7536
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 0.14s
                      Time elapsed: 00:12:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 661/1 [0m                       

                       Computation: 700829 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 852.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.7152
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 0.14s
                      Time elapsed: 00:12:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 662/1 [0m                       

                       Computation: 767852 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 853.26
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.0881
       Episode_Reward/object_height 0.0212
     Episode_Reward/reaching_object 0.7474
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 0.13s
                      Time elapsed: 00:12:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 663/1 [0m                       

                       Computation: 779403 steps/s (collection: 0.044s, learning 0.082s)
                       Mean reward: 852.17
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.8691
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7450
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 0.13s
                      Time elapsed: 00:12:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 664/1 [0m                       

                       Computation: 772547 steps/s (collection: 0.045s, learning 0.082s)
                       Mean reward: 840.66
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.3349
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7387
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 0.13s
                      Time elapsed: 00:12:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 665/1 [0m                       

                       Computation: 760754 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 840.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.8146
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7355
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 0.13s
                      Time elapsed: 00:12:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 666/1 [0m                       

                       Computation: 822549 steps/s (collection: 0.044s, learning 0.076s)
                       Mean reward: 835.44
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.4392
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7275
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 0.12s
                      Time elapsed: 00:12:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 667/1 [0m                       

                       Computation: 698614 steps/s (collection: 0.051s, learning 0.090s)
                       Mean reward: 835.28
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.3808
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7358
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 46.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 0.14s
                      Time elapsed: 00:12:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 668/1 [0m                       

                       Computation: 685391 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 847.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3134
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7365
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 0.14s
                      Time elapsed: 00:12:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 669/1 [0m                       

                       Computation: 645547 steps/s (collection: 0.048s, learning 0.105s)
                       Mean reward: 839.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.3929
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7360
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 0.15s
                      Time elapsed: 00:12:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 670/1 [0m                       

                       Computation: 689674 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 844.71
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.8390
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7379
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 0.14s
                      Time elapsed: 00:12:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 671/1 [0m                       

                       Computation: 725164 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 834.51
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.1029
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7302
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 0.14s
                      Time elapsed: 00:12:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 672/1 [0m                       

                       Computation: 689775 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 856.22
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.3809
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7421
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 0.14s
                      Time elapsed: 00:12:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 673/1 [0m                       

                       Computation: 742749 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 835.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.4663
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7316
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 0.13s
                      Time elapsed: 00:12:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 674/1 [0m                       

                       Computation: 764131 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 840.56
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.2250
       Episode_Reward/object_height 0.0221
     Episode_Reward/reaching_object 0.7358
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 0.13s
                      Time elapsed: 00:12:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 675/1 [0m                       

                       Computation: 681298 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 849.31
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.8061
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7415
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 0.14s
                      Time elapsed: 00:12:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 676/1 [0m                       

                       Computation: 673629 steps/s (collection: 0.047s, learning 0.099s)
                       Mean reward: 837.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.7473
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7364
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 0.15s
                      Time elapsed: 00:12:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 677/1 [0m                       

                       Computation: 719754 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 851.32
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.0353
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7453
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 0.14s
                      Time elapsed: 00:12:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 678/1 [0m                       

                       Computation: 691730 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 852.72
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4466
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7588
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 41.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 0.14s
                      Time elapsed: 00:12:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 679/1 [0m                       

                       Computation: 774452 steps/s (collection: 0.047s, learning 0.080s)
                       Mean reward: 862.65
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1497
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7622
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 0.13s
                      Time elapsed: 00:12:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 680/1 [0m                       

                       Computation: 756734 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 862.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2264
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 0.13s
                      Time elapsed: 00:12:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 681/1 [0m                       

                       Computation: 642272 steps/s (collection: 0.049s, learning 0.104s)
                       Mean reward: 866.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4771
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 0.15s
                      Time elapsed: 00:12:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 682/1 [0m                       

                       Computation: 712521 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 863.17
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3093
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 0.14s
                      Time elapsed: 00:12:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 683/1 [0m                       

                       Computation: 675431 steps/s (collection: 0.055s, learning 0.091s)
                       Mean reward: 868.21
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7800
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 0.15s
                      Time elapsed: 00:12:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 684/1 [0m                       

                       Computation: 728965 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 860.55
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1503
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 0.13s
                      Time elapsed: 00:13:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 685/1 [0m                       

                       Computation: 770486 steps/s (collection: 0.045s, learning 0.083s)
                       Mean reward: 870.12
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0906
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 0.13s
                      Time elapsed: 00:13:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 686/1 [0m                       

                       Computation: 675433 steps/s (collection: 0.051s, learning 0.095s)
                       Mean reward: 865.86
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.3563
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7703
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 0.15s
                      Time elapsed: 00:13:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 687/1 [0m                       

                       Computation: 761942 steps/s (collection: 0.046s, learning 0.084s)
                       Mean reward: 863.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.0374
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 0.13s
                      Time elapsed: 00:13:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 688/1 [0m                       

                       Computation: 736247 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 866.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.8440
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 44.7917
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 0.13s
                      Time elapsed: 00:13:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 689/1 [0m                       

                       Computation: 691841 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 842.09
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.9416
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 0.14s
                      Time elapsed: 00:13:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 690/1 [0m                       

                       Computation: 729909 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 868.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8257
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7833
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 0.13s
                      Time elapsed: 00:13:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 691/1 [0m                       

                       Computation: 729899 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 860.81
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.5088
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7733
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 0.13s
                      Time elapsed: 00:13:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 692/1 [0m                       

                       Computation: 703413 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 870.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.9496
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 0.14s
                      Time elapsed: 00:13:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 693/1 [0m                       

                       Computation: 672917 steps/s (collection: 0.048s, learning 0.098s)
                       Mean reward: 867.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1398
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7796
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 0.15s
                      Time elapsed: 00:13:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 694/1 [0m                       

                       Computation: 640222 steps/s (collection: 0.047s, learning 0.107s)
                       Mean reward: 865.28
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8206
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 0.15s
                      Time elapsed: 00:13:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 695/1 [0m                       

                       Computation: 770230 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 860.48
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1836
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 0.13s
                      Time elapsed: 00:13:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 696/1 [0m                       

                       Computation: 761815 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 851.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.7907
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 0.13s
                      Time elapsed: 00:13:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 697/1 [0m                       

                       Computation: 809559 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 861.62
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4729
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7749
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 0.12s
                      Time elapsed: 00:13:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 698/1 [0m                       

                       Computation: 799049 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 864.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2555
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7880
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 47.5833
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 0.12s
                      Time elapsed: 00:13:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 699/1 [0m                       

                       Computation: 775480 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 869.32
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2358
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7849
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 0.13s
                      Time elapsed: 00:13:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 700/1 [0m                       

                       Computation: 655574 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 872.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5668
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7921
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 0.15s
                      Time elapsed: 00:13:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 701/1 [0m                       

                       Computation: 721735 steps/s (collection: 0.041s, learning 0.095s)
                       Mean reward: 854.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.7219
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 0.14s
                      Time elapsed: 00:13:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 702/1 [0m                       

                       Computation: 689687 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 866.68
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7392
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 0.14s
                      Time elapsed: 00:13:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 703/1 [0m                       

                       Computation: 679968 steps/s (collection: 0.039s, learning 0.106s)
                       Mean reward: 864.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9920
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7850
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 0.14s
                      Time elapsed: 00:13:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 704/1 [0m                       

                       Computation: 578063 steps/s (collection: 0.060s, learning 0.111s)
                       Mean reward: 871.33
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2896
       Episode_Reward/object_height 0.0185
     Episode_Reward/reaching_object 0.7901
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 0.17s
                      Time elapsed: 00:13:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 705/1 [0m                       

                       Computation: 616138 steps/s (collection: 0.049s, learning 0.111s)
                       Mean reward: 873.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7333
       Episode_Reward/object_height 0.0184
     Episode_Reward/reaching_object 0.7912
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 0.16s
                      Time elapsed: 00:13:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 706/1 [0m                       

                       Computation: 631257 steps/s (collection: 0.048s, learning 0.108s)
                       Mean reward: 864.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8215
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7856
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 0.16s
                      Time elapsed: 00:13:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 707/1 [0m                       

                       Computation: 706839 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 867.83
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8210
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7889
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 0.14s
                      Time elapsed: 00:13:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 708/1 [0m                       

                       Computation: 723793 steps/s (collection: 0.045s, learning 0.091s)
                       Mean reward: 854.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.1228
       Episode_Reward/object_height 0.0177
     Episode_Reward/reaching_object 0.7813
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 0.14s
                      Time elapsed: 00:13:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 709/1 [0m                       

                       Computation: 800160 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 850.26
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.7231
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 43.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 0.12s
                      Time elapsed: 00:13:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 710/1 [0m                       

                       Computation: 810728 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 864.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2604
       Episode_Reward/object_height 0.0176
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 0.12s
                      Time elapsed: 00:13:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 711/1 [0m                       

                       Computation: 704050 steps/s (collection: 0.050s, learning 0.090s)
                       Mean reward: 851.99
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.4340
       Episode_Reward/object_height 0.0173
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 0.14s
                      Time elapsed: 00:13:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 712/1 [0m                       

                       Computation: 696903 steps/s (collection: 0.047s, learning 0.094s)
                       Mean reward: 859.73
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9134
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 0.14s
                      Time elapsed: 00:13:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 713/1 [0m                       

                       Computation: 604674 steps/s (collection: 0.050s, learning 0.113s)
                       Mean reward: 878.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.9760
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7994
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 0.16s
                      Time elapsed: 00:13:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 714/1 [0m                       

                       Computation: 620940 steps/s (collection: 0.052s, learning 0.106s)
                       Mean reward: 870.70
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6757
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7891
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 0.16s
                      Time elapsed: 00:13:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 715/1 [0m                       

                       Computation: 590228 steps/s (collection: 0.051s, learning 0.116s)
                       Mean reward: 863.83
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.9085
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 0.17s
                      Time elapsed: 00:13:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 716/1 [0m                       

                       Computation: 618095 steps/s (collection: 0.050s, learning 0.110s)
                       Mean reward: 860.95
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6770
       Episode_Reward/object_height 0.0167
     Episode_Reward/reaching_object 0.7782
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 0.16s
                      Time elapsed: 00:13:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 717/1 [0m                       

                       Computation: 612357 steps/s (collection: 0.050s, learning 0.111s)
                       Mean reward: 848.22
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.7824
       Episode_Reward/object_height 0.0163
     Episode_Reward/reaching_object 0.7661
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 0.16s
                      Time elapsed: 00:13:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 718/1 [0m                       

                       Computation: 638117 steps/s (collection: 0.051s, learning 0.103s)
                       Mean reward: 854.39
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.9691
       Episode_Reward/object_height 0.0163
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 0.15s
                      Time elapsed: 00:13:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 719/1 [0m                       

                       Computation: 541220 steps/s (collection: 0.059s, learning 0.122s)
                       Mean reward: 827.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.3755
       Episode_Reward/object_height 0.0162
     Episode_Reward/reaching_object 0.7687
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 46.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 0.18s
                      Time elapsed: 00:13:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 720/1 [0m                       

                       Computation: 587694 steps/s (collection: 0.055s, learning 0.112s)
                       Mean reward: 792.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 157.0798
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7293
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 0.17s
                      Time elapsed: 00:13:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 721/1 [0m                       

                       Computation: 568134 steps/s (collection: 0.055s, learning 0.118s)
                       Mean reward: 790.65
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 156.8824
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7176
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 0.17s
                      Time elapsed: 00:13:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 722/1 [0m                       

                       Computation: 599147 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 791.28
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 158.6978
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7264
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 0.16s
                      Time elapsed: 00:13:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 723/1 [0m                       

                       Computation: 595690 steps/s (collection: 0.051s, learning 0.114s)
                       Mean reward: 821.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.5655
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7293
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 0.17s
                      Time elapsed: 00:13:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 724/1 [0m                       

                       Computation: 556835 steps/s (collection: 0.053s, learning 0.124s)
                       Mean reward: 831.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.4507
       Episode_Reward/object_height 0.0155
     Episode_Reward/reaching_object 0.7453
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 0.18s
                      Time elapsed: 00:13:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 725/1 [0m                       

                       Computation: 583192 steps/s (collection: 0.050s, learning 0.119s)
                       Mean reward: 849.34
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.9583
       Episode_Reward/object_height 0.0157
     Episode_Reward/reaching_object 0.7595
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 0.17s
                      Time elapsed: 00:13:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 726/1 [0m                       

                       Computation: 555243 steps/s (collection: 0.055s, learning 0.122s)
                       Mean reward: 847.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.9887
       Episode_Reward/object_height 0.0156
     Episode_Reward/reaching_object 0.7589
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 0.18s
                      Time elapsed: 00:13:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 727/1 [0m                       

                       Computation: 556644 steps/s (collection: 0.050s, learning 0.127s)
                       Mean reward: 846.86
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.4189
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7630
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 0.18s
                      Time elapsed: 00:13:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 728/1 [0m                       

                       Computation: 737346 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 847.54
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.5048
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 0.13s
                      Time elapsed: 00:13:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 729/1 [0m                       

                       Computation: 721888 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 839.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.3266
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 0.14s
                      Time elapsed: 00:13:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 730/1 [0m                       

                       Computation: 581484 steps/s (collection: 0.052s, learning 0.117s)
                       Mean reward: 819.18
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.8948
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7417
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 42.4583
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 0.17s
                      Time elapsed: 00:13:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 731/1 [0m                       

                       Computation: 681023 steps/s (collection: 0.045s, learning 0.100s)
                       Mean reward: 839.56
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.9861
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7586
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 0.14s
                      Time elapsed: 00:13:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 732/1 [0m                       

                       Computation: 709350 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 854.35
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.9066
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 0.14s
                      Time elapsed: 00:14:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 733/1 [0m                       

                       Computation: 736840 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 861.49
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.7939
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7771
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 0.13s
                      Time elapsed: 00:14:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 734/1 [0m                       

                       Computation: 693169 steps/s (collection: 0.039s, learning 0.103s)
                       Mean reward: 862.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6547
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 0.14s
                      Time elapsed: 00:14:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 735/1 [0m                       

                       Computation: 764047 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 859.72
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.4282
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7700
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 0.13s
                      Time elapsed: 00:14:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 736/1 [0m                       

                       Computation: 799542 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 856.81
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.7838
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 0.12s
                      Time elapsed: 00:14:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 737/1 [0m                       

                       Computation: 763616 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 860.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.9667
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7589
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 0.13s
                      Time elapsed: 00:14:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 738/1 [0m                       

                       Computation: 644410 steps/s (collection: 0.049s, learning 0.104s)
                       Mean reward: 870.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.4529
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7733
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 0.15s
                      Time elapsed: 00:14:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 739/1 [0m                       

                       Computation: 681541 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 853.27
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.4697
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7622
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 0.14s
                      Time elapsed: 00:14:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 740/1 [0m                       

                       Computation: 709728 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 857.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.8337
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 44.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 0.14s
                      Time elapsed: 00:14:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 741/1 [0m                       

                       Computation: 696914 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 860.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0803
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 0.14s
                      Time elapsed: 00:14:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 742/1 [0m                       

                       Computation: 567963 steps/s (collection: 0.051s, learning 0.123s)
                       Mean reward: 865.91
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1251
       Episode_Reward/object_height 0.0140
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 0.17s
                      Time elapsed: 00:14:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 743/1 [0m                       

                       Computation: 593452 steps/s (collection: 0.050s, learning 0.116s)
                       Mean reward: 857.10
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0812
       Episode_Reward/object_height 0.0138
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 0.17s
                      Time elapsed: 00:14:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 744/1 [0m                       

                       Computation: 565526 steps/s (collection: 0.060s, learning 0.114s)
                       Mean reward: 854.26
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.2785
       Episode_Reward/object_height 0.0139
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 0.17s
                      Time elapsed: 00:14:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 745/1 [0m                       

                       Computation: 591302 steps/s (collection: 0.051s, learning 0.115s)
                       Mean reward: 862.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.9357
       Episode_Reward/object_height 0.0141
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 0.17s
                      Time elapsed: 00:14:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 746/1 [0m                       

                       Computation: 612377 steps/s (collection: 0.052s, learning 0.109s)
                       Mean reward: 867.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7434
       Episode_Reward/object_height 0.0143
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 0.16s
                      Time elapsed: 00:14:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 747/1 [0m                       

                       Computation: 648745 steps/s (collection: 0.050s, learning 0.102s)
                       Mean reward: 872.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7303
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7765
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 0.15s
                      Time elapsed: 00:14:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 748/1 [0m                       

                       Computation: 559924 steps/s (collection: 0.067s, learning 0.109s)
                       Mean reward: 867.87
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6780
       Episode_Reward/object_height 0.0144
     Episode_Reward/reaching_object 0.7707
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 0.18s
                      Time elapsed: 00:14:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 749/1 [0m                       

                       Computation: 612061 steps/s (collection: 0.051s, learning 0.110s)
                       Mean reward: 863.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3943
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 0.16s
                      Time elapsed: 00:14:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 750/1 [0m                       

                       Computation: 548962 steps/s (collection: 0.051s, learning 0.128s)
                       Mean reward: 866.07
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.7011
       Episode_Reward/object_height 0.0148
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 47.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 0.18s
                      Time elapsed: 00:14:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 751/1 [0m                       

                       Computation: 543032 steps/s (collection: 0.050s, learning 0.131s)
                       Mean reward: 875.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.4368
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7834
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 0.18s
                      Time elapsed: 00:14:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 752/1 [0m                       

                       Computation: 517152 steps/s (collection: 0.061s, learning 0.130s)
                       Mean reward: 863.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.7734
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 0.19s
                      Time elapsed: 00:14:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 753/1 [0m                       

                       Computation: 577403 steps/s (collection: 0.060s, learning 0.111s)
                       Mean reward: 869.49
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0763
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7730
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 0.17s
                      Time elapsed: 00:14:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 754/1 [0m                       

                       Computation: 567976 steps/s (collection: 0.048s, learning 0.125s)
                       Mean reward: 870.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3043
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 0.17s
                      Time elapsed: 00:14:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 755/1 [0m                       

                       Computation: 608985 steps/s (collection: 0.054s, learning 0.108s)
                       Mean reward: 876.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.2877
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 0.16s
                      Time elapsed: 00:14:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 756/1 [0m                       

                       Computation: 593718 steps/s (collection: 0.050s, learning 0.116s)
                       Mean reward: 867.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.9459
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7773
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 0.17s
                      Time elapsed: 00:14:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 757/1 [0m                       

                       Computation: 638243 steps/s (collection: 0.050s, learning 0.104s)
                       Mean reward: 871.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.4249
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 0.15s
                      Time elapsed: 00:14:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 758/1 [0m                       

                       Computation: 590589 steps/s (collection: 0.051s, learning 0.115s)
                       Mean reward: 867.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.5562
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 0.17s
                      Time elapsed: 00:14:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 759/1 [0m                       

                       Computation: 633548 steps/s (collection: 0.054s, learning 0.101s)
                       Mean reward: 877.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.6285
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 0.16s
                      Time elapsed: 00:14:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 760/1 [0m                       

                       Computation: 775094 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 870.35
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3058
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7727
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 0.13s
                      Time elapsed: 00:14:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 761/1 [0m                       

                       Computation: 759023 steps/s (collection: 0.046s, learning 0.084s)
                       Mean reward: 871.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2500
       Episode_Reward/object_height 0.0148
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 43.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 0.13s
                      Time elapsed: 00:14:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 762/1 [0m                       

                       Computation: 766543 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 866.50
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7500
       Episode_Reward/object_height 0.0149
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 0.13s
                      Time elapsed: 00:14:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 763/1 [0m                       

                       Computation: 746762 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 869.05
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0663
       Episode_Reward/object_height 0.0148
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 0.13s
                      Time elapsed: 00:14:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 764/1 [0m                       

                       Computation: 759799 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 868.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3134
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 0.13s
                      Time elapsed: 00:14:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 765/1 [0m                       

                       Computation: 750286 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 877.15
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.7220
       Episode_Reward/object_height 0.0148
     Episode_Reward/reaching_object 0.7816
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 0.13s
                      Time elapsed: 00:14:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 766/1 [0m                       

                       Computation: 795920 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 874.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0730
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 0.12s
                      Time elapsed: 00:14:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 767/1 [0m                       

                       Computation: 717660 steps/s (collection: 0.053s, learning 0.084s)
                       Mean reward: 868.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8065
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 0.14s
                      Time elapsed: 00:14:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 768/1 [0m                       

                       Computation: 793125 steps/s (collection: 0.044s, learning 0.080s)
                       Mean reward: 878.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9489
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7810
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 0.12s
                      Time elapsed: 00:14:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 769/1 [0m                       

                       Computation: 805661 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 873.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2027
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 0.12s
                      Time elapsed: 00:14:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 770/1 [0m                       

                       Computation: 788444 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 866.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.3711
       Episode_Reward/object_height 0.0145
     Episode_Reward/reaching_object 0.7727
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 0.12s
                      Time elapsed: 00:14:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 771/1 [0m                       

                       Computation: 714192 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 869.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.1837
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7788
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 47.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 0.14s
                      Time elapsed: 00:14:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 772/1 [0m                       

                       Computation: 726646 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 863.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2583
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7696
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 0.14s
                      Time elapsed: 00:14:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 773/1 [0m                       

                       Computation: 653545 steps/s (collection: 0.044s, learning 0.106s)
                       Mean reward: 866.28
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1697
       Episode_Reward/object_height 0.0146
     Episode_Reward/reaching_object 0.7781
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 0.15s
                      Time elapsed: 00:14:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 774/1 [0m                       

                       Computation: 781803 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 868.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0399
       Episode_Reward/object_height 0.0147
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 0.13s
                      Time elapsed: 00:14:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 775/1 [0m                       

                       Computation: 633602 steps/s (collection: 0.043s, learning 0.112s)
                       Mean reward: 876.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.6168
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 0.16s
                      Time elapsed: 00:14:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 776/1 [0m                       

                       Computation: 676320 steps/s (collection: 0.042s, learning 0.103s)
                       Mean reward: 868.56
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8761
       Episode_Reward/object_height 0.0149
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 0.15s
                      Time elapsed: 00:14:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 777/1 [0m                       

                       Computation: 718586 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 866.33
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5250
       Episode_Reward/object_height 0.0149
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 0.14s
                      Time elapsed: 00:14:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 778/1 [0m                       

                       Computation: 764226 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 864.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1097
       Episode_Reward/object_height 0.0150
     Episode_Reward/reaching_object 0.7754
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 0.13s
                      Time elapsed: 00:14:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 779/1 [0m                       

                       Computation: 663337 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 870.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.3490
       Episode_Reward/object_height 0.0151
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 0.15s
                      Time elapsed: 00:14:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 780/1 [0m                       

                       Computation: 719229 steps/s (collection: 0.040s, learning 0.097s)
                       Mean reward: 868.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.0796
       Episode_Reward/object_height 0.0152
     Episode_Reward/reaching_object 0.7781
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 0.14s
                      Time elapsed: 00:14:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 781/1 [0m                       

                       Computation: 755876 steps/s (collection: 0.048s, learning 0.083s)
                       Mean reward: 868.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8194
       Episode_Reward/object_height 0.0154
     Episode_Reward/reaching_object 0.7854
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 0.13s
                      Time elapsed: 00:15:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 782/1 [0m                       

                       Computation: 761157 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 866.13
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.2964
       Episode_Reward/object_height 0.0156
     Episode_Reward/reaching_object 0.7874
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 42.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 0.13s
                      Time elapsed: 00:15:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 783/1 [0m                       

                       Computation: 727889 steps/s (collection: 0.045s, learning 0.090s)
                       Mean reward: 852.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3144
       Episode_Reward/object_height 0.0153
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 0.14s
                      Time elapsed: 00:15:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 784/1 [0m                       

                       Computation: 752761 steps/s (collection: 0.046s, learning 0.085s)
                       Mean reward: 864.03
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1554
       Episode_Reward/object_height 0.0158
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 0.13s
                      Time elapsed: 00:15:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 785/1 [0m                       

                       Computation: 704068 steps/s (collection: 0.042s, learning 0.098s)
                       Mean reward: 856.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.2573
       Episode_Reward/object_height 0.0157
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 0.14s
                      Time elapsed: 00:15:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 786/1 [0m                       

                       Computation: 534621 steps/s (collection: 0.054s, learning 0.130s)
                       Mean reward: 864.08
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.7633
       Episode_Reward/object_height 0.0160
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 0.18s
                      Time elapsed: 00:15:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 787/1 [0m                       

                       Computation: 591769 steps/s (collection: 0.054s, learning 0.112s)
                       Mean reward: 869.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8081
       Episode_Reward/object_height 0.0162
     Episode_Reward/reaching_object 0.7793
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 0.17s
                      Time elapsed: 00:15:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 788/1 [0m                       

                       Computation: 552112 steps/s (collection: 0.054s, learning 0.124s)
                       Mean reward: 871.44
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7824
       Episode_Reward/object_height 0.0166
     Episode_Reward/reaching_object 0.7823
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 0.18s
                      Time elapsed: 00:15:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 789/1 [0m                       

                       Computation: 578065 steps/s (collection: 0.055s, learning 0.115s)
                       Mean reward: 861.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.7848
       Episode_Reward/object_height 0.0166
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 0.17s
                      Time elapsed: 00:15:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 790/1 [0m                       

                       Computation: 635745 steps/s (collection: 0.051s, learning 0.104s)
                       Mean reward: 866.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.4025
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7782
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 0.15s
                      Time elapsed: 00:15:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 791/1 [0m                       

                       Computation: 741473 steps/s (collection: 0.045s, learning 0.088s)
                       Mean reward: 860.94
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4649
       Episode_Reward/object_height 0.0168
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 0.13s
                      Time elapsed: 00:15:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 792/1 [0m                       

                       Computation: 645980 steps/s (collection: 0.044s, learning 0.109s)
                       Mean reward: 860.79
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.1348
       Episode_Reward/object_height 0.0171
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 45.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 0.15s
                      Time elapsed: 00:15:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 793/1 [0m                       

                       Computation: 773552 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 861.38
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4737
       Episode_Reward/object_height 0.0172
     Episode_Reward/reaching_object 0.7673
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 0.13s
                      Time elapsed: 00:15:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 794/1 [0m                       

                       Computation: 643987 steps/s (collection: 0.058s, learning 0.095s)
                       Mean reward: 862.97
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6645
       Episode_Reward/object_height 0.0174
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 0.15s
                      Time elapsed: 00:15:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 795/1 [0m                       

                       Computation: 749101 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 864.52
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.7639
       Episode_Reward/object_height 0.0175
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 0.13s
                      Time elapsed: 00:15:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 796/1 [0m                       

                       Computation: 712222 steps/s (collection: 0.057s, learning 0.082s)
                       Mean reward: 872.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.6106
       Episode_Reward/object_height 0.0180
     Episode_Reward/reaching_object 0.7847
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 0.14s
                      Time elapsed: 00:15:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 797/1 [0m                       

                       Computation: 696863 steps/s (collection: 0.045s, learning 0.097s)
                       Mean reward: 865.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3566
       Episode_Reward/object_height 0.0181
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 0.14s
                      Time elapsed: 00:15:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 798/1 [0m                       

                       Computation: 776242 steps/s (collection: 0.046s, learning 0.081s)
                       Mean reward: 861.77
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.8895
       Episode_Reward/object_height 0.0183
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 0.13s
                      Time elapsed: 00:15:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 799/1 [0m                       

                       Computation: 755589 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 859.02
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6567
       Episode_Reward/object_height 0.0183
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 0.13s
                      Time elapsed: 00:15:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 800/1 [0m                       

                       Computation: 677358 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 872.07
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5463
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7788
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 0.15s
                      Time elapsed: 00:15:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 801/1 [0m                       

                       Computation: 648528 steps/s (collection: 0.040s, learning 0.112s)
                       Mean reward: 866.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3661
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 0.15s
                      Time elapsed: 00:15:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 802/1 [0m                       

                       Computation: 741574 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 858.77
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0243
       Episode_Reward/object_height 0.0187
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 0.13s
                      Time elapsed: 00:15:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 803/1 [0m                       

                       Computation: 745846 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 862.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3101
       Episode_Reward/object_height 0.0189
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 41.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 0.13s
                      Time elapsed: 00:15:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 804/1 [0m                       

                       Computation: 619434 steps/s (collection: 0.044s, learning 0.115s)
                       Mean reward: 872.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5189
       Episode_Reward/object_height 0.0190
     Episode_Reward/reaching_object 0.7588
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 0.16s
                      Time elapsed: 00:15:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 805/1 [0m                       

                       Computation: 758730 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 857.16
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.7524
       Episode_Reward/object_height 0.0188
     Episode_Reward/reaching_object 0.7599
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 0.13s
                      Time elapsed: 00:15:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 806/1 [0m                       

                       Computation: 745732 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 861.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4717
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7635
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 0.13s
                      Time elapsed: 00:15:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 807/1 [0m                       

                       Computation: 620052 steps/s (collection: 0.054s, learning 0.105s)
                       Mean reward: 870.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.7227
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7709
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 0.16s
                      Time elapsed: 00:15:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 808/1 [0m                       

                       Computation: 622475 steps/s (collection: 0.053s, learning 0.105s)
                       Mean reward: 850.01
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.7137
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7566
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 0.16s
                      Time elapsed: 00:15:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 809/1 [0m                       

                       Computation: 595954 steps/s (collection: 0.049s, learning 0.116s)
                       Mean reward: 857.63
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.2893
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 0.16s
                      Time elapsed: 00:15:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 810/1 [0m                       

                       Computation: 626387 steps/s (collection: 0.049s, learning 0.108s)
                       Mean reward: 858.81
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5794
       Episode_Reward/object_height 0.0200
     Episode_Reward/reaching_object 0.7548
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 0.16s
                      Time elapsed: 00:15:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 811/1 [0m                       

                       Computation: 583233 steps/s (collection: 0.052s, learning 0.117s)
                       Mean reward: 847.24
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0320
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7428
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 0.17s
                      Time elapsed: 00:15:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 812/1 [0m                       

                       Computation: 738850 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 829.11
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.1713
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7264
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 0.13s
                      Time elapsed: 00:15:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 813/1 [0m                       

                       Computation: 712294 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 838.99
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.6124
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7260
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 44.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 0.14s
                      Time elapsed: 00:15:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 814/1 [0m                       

                       Computation: 698165 steps/s (collection: 0.047s, learning 0.094s)
                       Mean reward: 829.10
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.7394
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7135
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 0.14s
                      Time elapsed: 00:15:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 815/1 [0m                       

                       Computation: 722328 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 832.97
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.1253
       Episode_Reward/object_height 0.0213
     Episode_Reward/reaching_object 0.7227
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 0.14s
                      Time elapsed: 00:15:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 816/1 [0m                       

                       Computation: 825953 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 811.02
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 161.2405
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7088
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 0.12s
                      Time elapsed: 00:15:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 817/1 [0m                       

                       Computation: 791516 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 836.21
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.7512
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7193
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 0.12s
                      Time elapsed: 00:15:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 818/1 [0m                       

                       Computation: 538454 steps/s (collection: 0.059s, learning 0.124s)
                       Mean reward: 829.04
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.4141
       Episode_Reward/object_height 0.0225
     Episode_Reward/reaching_object 0.7262
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 0.18s
                      Time elapsed: 00:15:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 819/1 [0m                       

                       Computation: 633587 steps/s (collection: 0.051s, learning 0.105s)
                       Mean reward: 850.91
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.6998
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7422
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 0.16s
                      Time elapsed: 00:15:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 820/1 [0m                       

                       Computation: 589849 steps/s (collection: 0.053s, learning 0.114s)
                       Mean reward: 832.68
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.8323
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7288
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 0.17s
                      Time elapsed: 00:15:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 821/1 [0m                       

                       Computation: 588525 steps/s (collection: 0.053s, learning 0.114s)
                       Mean reward: 828.71
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.2865
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7356
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 0.17s
                      Time elapsed: 00:15:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 822/1 [0m                       

                       Computation: 564806 steps/s (collection: 0.053s, learning 0.122s)
                       Mean reward: 836.53
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.8504
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7383
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 0.17s
                      Time elapsed: 00:15:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 823/1 [0m                       

                       Computation: 591394 steps/s (collection: 0.059s, learning 0.107s)
                       Mean reward: 850.41
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.3938
       Episode_Reward/object_height 0.0255
     Episode_Reward/reaching_object 0.7458
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 46.7500
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 0.17s
                      Time elapsed: 00:15:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 824/1 [0m                       

                       Computation: 610370 steps/s (collection: 0.053s, learning 0.108s)
                       Mean reward: 840.81
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.3413
       Episode_Reward/object_height 0.0261
     Episode_Reward/reaching_object 0.7498
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 0.16s
                      Time elapsed: 00:15:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 825/1 [0m                       

                       Computation: 752754 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 850.63
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.6002
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7522
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 0.13s
                      Time elapsed: 00:15:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 826/1 [0m                       

                       Computation: 560000 steps/s (collection: 0.052s, learning 0.123s)
                       Mean reward: 850.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.7537
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7536
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 0.18s
                      Time elapsed: 00:15:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 827/1 [0m                       

                       Computation: 755283 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 842.93
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.9402
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7476
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 0.13s
                      Time elapsed: 00:15:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 828/1 [0m                       

                       Computation: 694458 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 847.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.4240
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7564
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 0.14s
                      Time elapsed: 00:15:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 829/1 [0m                       

                       Computation: 560034 steps/s (collection: 0.055s, learning 0.121s)
                       Mean reward: 855.56
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6832
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7648
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 0.18s
                      Time elapsed: 00:16:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 830/1 [0m                       

                       Computation: 708674 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 844.26
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.4589
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 0.14s
                      Time elapsed: 00:16:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 831/1 [0m                       

                       Computation: 768311 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 861.78
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.5398
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 0.13s
                      Time elapsed: 00:16:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 832/1 [0m                       

                       Computation: 776990 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 851.20
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2302
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 0.13s
                      Time elapsed: 00:16:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 833/1 [0m                       

                       Computation: 755231 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 853.68
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.1276
       Episode_Reward/object_height 0.0261
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 0.13s
                      Time elapsed: 00:16:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 834/1 [0m                       

                       Computation: 714387 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 865.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.6304
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7782
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 42.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 0.14s
                      Time elapsed: 00:16:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 835/1 [0m                       

                       Computation: 559917 steps/s (collection: 0.051s, learning 0.124s)
                       Mean reward: 856.23
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2829
       Episode_Reward/object_height 0.0251
     Episode_Reward/reaching_object 0.7476
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 0.18s
                      Time elapsed: 00:16:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 836/1 [0m                       

                       Computation: 773936 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 859.42
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.1717
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7512
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 0.13s
                      Time elapsed: 00:16:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 837/1 [0m                       

                       Computation: 820444 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 847.90
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.4231
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 0.12s
                      Time elapsed: 00:16:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 838/1 [0m                       

                       Computation: 733499 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 857.38
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6280
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 0.13s
                      Time elapsed: 00:16:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 839/1 [0m                       

                       Computation: 736487 steps/s (collection: 0.049s, learning 0.085s)
                       Mean reward: 866.87
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.6366
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7685
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 0.13s
                      Time elapsed: 00:16:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 840/1 [0m                       

                       Computation: 744302 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 855.21
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.4102
       Episode_Reward/object_height 0.0256
     Episode_Reward/reaching_object 0.7543
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 0.13s
                      Time elapsed: 00:16:13
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 841/1 [0m                       

                       Computation: 692228 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 857.68
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8189
       Episode_Reward/object_height 0.0261
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 0.14s
                      Time elapsed: 00:16:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 842/1 [0m                       

                       Computation: 802442 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 858.77
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9301
       Episode_Reward/object_height 0.0263
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 0.12s
                      Time elapsed: 00:16:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 843/1 [0m                       

                       Computation: 783209 steps/s (collection: 0.044s, learning 0.082s)
                       Mean reward: 844.92
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.4933
       Episode_Reward/object_height 0.0260
     Episode_Reward/reaching_object 0.7496
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 0.13s
                      Time elapsed: 00:16:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 844/1 [0m                       

                       Computation: 801447 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 865.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0113
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7779
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 45.5417
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 0.12s
                      Time elapsed: 00:16:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 845/1 [0m                       

                       Computation: 736243 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 837.87
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.1561
       Episode_Reward/object_height 0.0260
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 0.13s
                      Time elapsed: 00:16:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 846/1 [0m                       

                       Computation: 606648 steps/s (collection: 0.055s, learning 0.108s)
                       Mean reward: 840.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.2882
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 0.16s
                      Time elapsed: 00:16:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 847/1 [0m                       

                       Computation: 766740 steps/s (collection: 0.048s, learning 0.080s)
                       Mean reward: 861.87
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4572
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7768
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 0.13s
                      Time elapsed: 00:16:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 848/1 [0m                       

                       Computation: 684812 steps/s (collection: 0.051s, learning 0.093s)
                       Mean reward: 854.34
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5352
       Episode_Reward/object_height 0.0285
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 0.14s
                      Time elapsed: 00:16:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 849/1 [0m                       

                       Computation: 576497 steps/s (collection: 0.057s, learning 0.113s)
                       Mean reward: 857.50
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5993
       Episode_Reward/object_height 0.0286
     Episode_Reward/reaching_object 0.7715
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 0.17s
                      Time elapsed: 00:16:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 850/1 [0m                       

                       Computation: 603376 steps/s (collection: 0.050s, learning 0.113s)
                       Mean reward: 863.38
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1419
       Episode_Reward/object_height 0.0296
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 0.16s
                      Time elapsed: 00:16:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 851/1 [0m                       

                       Computation: 626078 steps/s (collection: 0.050s, learning 0.107s)
                       Mean reward: 865.21
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.5839
       Episode_Reward/object_height 0.0299
     Episode_Reward/reaching_object 0.7705
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 0.16s
                      Time elapsed: 00:16:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 852/1 [0m                       

                       Computation: 538180 steps/s (collection: 0.055s, learning 0.128s)
                       Mean reward: 852.34
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.7366
       Episode_Reward/object_height 0.0299
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 0.18s
                      Time elapsed: 00:16:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 853/1 [0m                       

                       Computation: 527001 steps/s (collection: 0.048s, learning 0.138s)
                       Mean reward: 855.72
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.3547
       Episode_Reward/object_height 0.0295
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 0.19s
                      Time elapsed: 00:16:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 854/1 [0m                       

                       Computation: 532673 steps/s (collection: 0.053s, learning 0.132s)
                       Mean reward: 860.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.5403
       Episode_Reward/object_height 0.0294
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 0.18s
                      Time elapsed: 00:16:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 855/1 [0m                       

                       Computation: 565574 steps/s (collection: 0.052s, learning 0.122s)
                       Mean reward: 863.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7268
       Episode_Reward/object_height 0.0301
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 41.7083
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 0.17s
                      Time elapsed: 00:16:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 856/1 [0m                       

                       Computation: 650450 steps/s (collection: 0.053s, learning 0.098s)
                       Mean reward: 853.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.4720
       Episode_Reward/object_height 0.0299
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 0.15s
                      Time elapsed: 00:16:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 857/1 [0m                       

                       Computation: 630124 steps/s (collection: 0.051s, learning 0.105s)
                       Mean reward: 853.98
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8862
       Episode_Reward/object_height 0.0288
     Episode_Reward/reaching_object 0.7609
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 0.16s
                      Time elapsed: 00:16:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 858/1 [0m                       

                       Computation: 737329 steps/s (collection: 0.047s, learning 0.087s)
                       Mean reward: 860.46
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.4348
       Episode_Reward/object_height 0.0286
     Episode_Reward/reaching_object 0.7598
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 0.13s
                      Time elapsed: 00:16:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 859/1 [0m                       

                       Computation: 590261 steps/s (collection: 0.054s, learning 0.113s)
                       Mean reward: 854.65
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.1099
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 0.17s
                      Time elapsed: 00:16:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 860/1 [0m                       

                       Computation: 608588 steps/s (collection: 0.054s, learning 0.108s)
                       Mean reward: 863.61
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.1365
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7727
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 0.16s
                      Time elapsed: 00:16:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 861/1 [0m                       

                       Computation: 709102 steps/s (collection: 0.048s, learning 0.091s)
                       Mean reward: 862.13
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0781
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7755
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 0.14s
                      Time elapsed: 00:16:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 862/1 [0m                       

                       Computation: 806599 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 866.21
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.0115
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 0.12s
                      Time elapsed: 00:16:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 863/1 [0m                       

                       Computation: 668467 steps/s (collection: 0.051s, learning 0.097s)
                       Mean reward: 862.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4652
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 0.15s
                      Time elapsed: 00:16:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 864/1 [0m                       

                       Computation: 635919 steps/s (collection: 0.051s, learning 0.104s)
                       Mean reward: 855.29
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.5754
       Episode_Reward/object_height 0.0251
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 0.15s
                      Time elapsed: 00:16:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 865/1 [0m                       

                       Computation: 714812 steps/s (collection: 0.053s, learning 0.085s)
                       Mean reward: 859.83
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.1986
       Episode_Reward/object_height 0.0251
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 43.9167
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 0.14s
                      Time elapsed: 00:16:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 866/1 [0m                       

                       Computation: 773789 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 865.53
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.5643
       Episode_Reward/object_height 0.0257
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 0.13s
                      Time elapsed: 00:16:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 867/1 [0m                       

                       Computation: 712250 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 862.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.9127
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 0.14s
                      Time elapsed: 00:16:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 868/1 [0m                       

                       Computation: 672839 steps/s (collection: 0.044s, learning 0.103s)
                       Mean reward: 850.64
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.0269
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 0.15s
                      Time elapsed: 00:16:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 869/1 [0m                       

                       Computation: 683670 steps/s (collection: 0.063s, learning 0.081s)
                       Mean reward: 862.56
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.0231
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7629
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 0.14s
                      Time elapsed: 00:16:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 870/1 [0m                       

                       Computation: 789052 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 844.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.8197
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7637
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 0.12s
                      Time elapsed: 00:16:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 871/1 [0m                       

                       Computation: 753220 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 849.13
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.6252
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 0.13s
                      Time elapsed: 00:16:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 872/1 [0m                       

                       Computation: 717492 steps/s (collection: 0.046s, learning 0.091s)
                       Mean reward: 853.75
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.4497
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7604
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 0.14s
                      Time elapsed: 00:16:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 873/1 [0m                       

                       Computation: 615473 steps/s (collection: 0.052s, learning 0.108s)
                       Mean reward: 864.72
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.0862
       Episode_Reward/object_height 0.0248
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 0.16s
                      Time elapsed: 00:16:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 874/1 [0m                       

                       Computation: 564925 steps/s (collection: 0.058s, learning 0.116s)
                       Mean reward: 852.00
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9442
       Episode_Reward/object_height 0.0245
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 0.17s
                      Time elapsed: 00:16:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 875/1 [0m                       

                       Computation: 658226 steps/s (collection: 0.049s, learning 0.100s)
                       Mean reward: 846.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9626
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7522
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 46.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 0.15s
                      Time elapsed: 00:16:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 876/1 [0m                       

                       Computation: 695034 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 835.15
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.4219
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7450
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 0.14s
                      Time elapsed: 00:16:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 877/1 [0m                       

                       Computation: 780780 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 833.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.3538
       Episode_Reward/object_height 0.0237
     Episode_Reward/reaching_object 0.7347
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 0.13s
                      Time elapsed: 00:17:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 878/1 [0m                       

                       Computation: 668023 steps/s (collection: 0.052s, learning 0.095s)
                       Mean reward: 846.54
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.6932
       Episode_Reward/object_height 0.0240
     Episode_Reward/reaching_object 0.7441
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 0.15s
                      Time elapsed: 00:17:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 879/1 [0m                       

                       Computation: 650659 steps/s (collection: 0.051s, learning 0.100s)
                       Mean reward: 831.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.2470
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7241
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 0.15s
                      Time elapsed: 00:17:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 880/1 [0m                       

                       Computation: 710668 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 838.43
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.5489
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7348
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 0.14s
                      Time elapsed: 00:17:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 881/1 [0m                       

                       Computation: 788404 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 857.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5914
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 0.12s
                      Time elapsed: 00:17:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 882/1 [0m                       

                       Computation: 778983 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 850.81
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1423
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7509
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 0.13s
                      Time elapsed: 00:17:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 883/1 [0m                       

                       Computation: 730466 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 839.69
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.5602
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7315
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 0.13s
                      Time elapsed: 00:17:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 884/1 [0m                       

                       Computation: 795904 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 851.38
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0440
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 0.12s
                      Time elapsed: 00:17:09
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 885/1 [0m                       

                       Computation: 753031 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 839.64
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.0339
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7425
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 0.13s
                      Time elapsed: 00:17:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 886/1 [0m                       

                       Computation: 739779 steps/s (collection: 0.044s, learning 0.089s)
                       Mean reward: 846.76
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3299
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7481
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 43.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 0.13s
                      Time elapsed: 00:17:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 887/1 [0m                       

                       Computation: 628313 steps/s (collection: 0.055s, learning 0.102s)
                       Mean reward: 834.05
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.9326
       Episode_Reward/object_height 0.0193
     Episode_Reward/reaching_object 0.7311
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 0.16s
                      Time elapsed: 00:17:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 888/1 [0m                       

                       Computation: 664294 steps/s (collection: 0.054s, learning 0.094s)
                       Mean reward: 851.07
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3153
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7492
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 0.15s
                      Time elapsed: 00:17:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 889/1 [0m                       

                       Computation: 671100 steps/s (collection: 0.051s, learning 0.096s)
                       Mean reward: 851.51
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3986
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7423
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 0.15s
                      Time elapsed: 00:17:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 890/1 [0m                       

                       Computation: 670738 steps/s (collection: 0.051s, learning 0.096s)
                       Mean reward: 868.24
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8440
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7616
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 0.15s
                      Time elapsed: 00:17:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 891/1 [0m                       

                       Computation: 621847 steps/s (collection: 0.052s, learning 0.107s)
                       Mean reward: 853.02
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3465
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7510
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 0.16s
                      Time elapsed: 00:17:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 892/1 [0m                       

                       Computation: 549527 steps/s (collection: 0.063s, learning 0.116s)
                       Mean reward: 852.36
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3667
       Episode_Reward/object_height 0.0210
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 0.18s
                      Time elapsed: 00:17:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 893/1 [0m                       

                       Computation: 616495 steps/s (collection: 0.055s, learning 0.104s)
                       Mean reward: 850.78
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.5675
       Episode_Reward/object_height 0.0222
     Episode_Reward/reaching_object 0.7509
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 0.16s
                      Time elapsed: 00:17:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 894/1 [0m                       

                       Computation: 614331 steps/s (collection: 0.054s, learning 0.106s)
                       Mean reward: 847.31
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.8458
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7496
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 0.16s
                      Time elapsed: 00:17:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 895/1 [0m                       

                       Computation: 650725 steps/s (collection: 0.054s, learning 0.098s)
                       Mean reward: 844.15
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.2096
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7500
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 0.15s
                      Time elapsed: 00:17:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 896/1 [0m                       

                       Computation: 661542 steps/s (collection: 0.049s, learning 0.100s)
                       Mean reward: 841.36
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.5003
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7448
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 45.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 0.15s
                      Time elapsed: 00:17:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 897/1 [0m                       

                       Computation: 616181 steps/s (collection: 0.053s, learning 0.107s)
                       Mean reward: 825.54
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.4872
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7410
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 0.16s
                      Time elapsed: 00:17:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 898/1 [0m                       

                       Computation: 735977 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 829.96
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.1282
       Episode_Reward/object_height 0.0257
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 0.13s
                      Time elapsed: 00:17:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 899/1 [0m                       

                       Computation: 760045 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 826.47
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.7587
       Episode_Reward/object_height 0.0262
     Episode_Reward/reaching_object 0.7559
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 0.13s
                      Time elapsed: 00:17:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 900/1 [0m                       

                       Computation: 756197 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 827.39
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.8294
       Episode_Reward/object_height 0.0263
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 0.13s
                      Time elapsed: 00:17:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 901/1 [0m                       

                       Computation: 692072 steps/s (collection: 0.048s, learning 0.094s)
                       Mean reward: 837.97
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.0029
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7570
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 0.14s
                      Time elapsed: 00:17:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 902/1 [0m                       

                       Computation: 619393 steps/s (collection: 0.044s, learning 0.115s)
                       Mean reward: 844.58
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.0863
       Episode_Reward/object_height 0.0273
     Episode_Reward/reaching_object 0.7639
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 0.16s
                      Time elapsed: 00:17:31
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 903/1 [0m                       

                       Computation: 625961 steps/s (collection: 0.049s, learning 0.109s)
                       Mean reward: 827.78
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.4887
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7566
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 0.16s
                      Time elapsed: 00:17:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 904/1 [0m                       

                       Computation: 608890 steps/s (collection: 0.052s, learning 0.110s)
                       Mean reward: 841.69
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.6430
       Episode_Reward/object_height 0.0273
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 0.16s
                      Time elapsed: 00:17:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 905/1 [0m                       

                       Computation: 659412 steps/s (collection: 0.051s, learning 0.099s)
                       Mean reward: 854.74
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.2913
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 0.15s
                      Time elapsed: 00:17:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 906/1 [0m                       

                       Computation: 643933 steps/s (collection: 0.052s, learning 0.101s)
                       Mean reward: 851.17
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.1777
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 0.15s
                      Time elapsed: 00:17:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 907/1 [0m                       

                       Computation: 664096 steps/s (collection: 0.050s, learning 0.098s)
                       Mean reward: 837.30
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.3104
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 41.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 0.15s
                      Time elapsed: 00:17:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 908/1 [0m                       

                       Computation: 671419 steps/s (collection: 0.047s, learning 0.099s)
                       Mean reward: 839.86
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.1772
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 0.15s
                      Time elapsed: 00:17:39
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 909/1 [0m                       

                       Computation: 657291 steps/s (collection: 0.052s, learning 0.098s)
                       Mean reward: 849.79
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.6019
       Episode_Reward/object_height 0.0261
     Episode_Reward/reaching_object 0.7598
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 0.15s
                      Time elapsed: 00:17:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 910/1 [0m                       

                       Computation: 679720 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 842.01
               Mean episode length: 248.11
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.1001
       Episode_Reward/object_height 0.0262
     Episode_Reward/reaching_object 0.7537
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 0.14s
                      Time elapsed: 00:17:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 911/1 [0m                       

                       Computation: 644512 steps/s (collection: 0.052s, learning 0.101s)
                       Mean reward: 847.34
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.5400
       Episode_Reward/object_height 0.0263
     Episode_Reward/reaching_object 0.7620
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 0.15s
                      Time elapsed: 00:17:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 912/1 [0m                       

                       Computation: 684965 steps/s (collection: 0.051s, learning 0.093s)
                       Mean reward: 851.63
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.3136
       Episode_Reward/object_height 0.0262
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 0.14s
                      Time elapsed: 00:17:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 913/1 [0m                       

                       Computation: 575051 steps/s (collection: 0.060s, learning 0.111s)
                       Mean reward: 862.27
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.1887
       Episode_Reward/object_height 0.0264
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 0.17s
                      Time elapsed: 00:17:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 914/1 [0m                       

                       Computation: 638181 steps/s (collection: 0.051s, learning 0.103s)
                       Mean reward: 868.14
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.1511
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7796
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 0.15s
                      Time elapsed: 00:17:47
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 915/1 [0m                       

                       Computation: 528364 steps/s (collection: 0.059s, learning 0.128s)
                       Mean reward: 863.12
               Mean episode length: 249.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.4561
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 0.19s
                      Time elapsed: 00:17:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 916/1 [0m                       

                       Computation: 571451 steps/s (collection: 0.057s, learning 0.115s)
                       Mean reward: 856.11
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.1168
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 0.17s
                      Time elapsed: 00:17:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 917/1 [0m                       

                       Computation: 623460 steps/s (collection: 0.047s, learning 0.111s)
                       Mean reward: 857.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.3720
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7699
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 44.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 0.16s
                      Time elapsed: 00:17:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 918/1 [0m                       

                       Computation: 646521 steps/s (collection: 0.053s, learning 0.099s)
                       Mean reward: 871.56
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.5239
       Episode_Reward/object_height 0.0243
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 0.15s
                      Time elapsed: 00:17:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 919/1 [0m                       

                       Computation: 602895 steps/s (collection: 0.052s, learning 0.112s)
                       Mean reward: 864.72
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.0596
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 0.16s
                      Time elapsed: 00:17:54
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 920/1 [0m                       

                       Computation: 717011 steps/s (collection: 0.048s, learning 0.089s)
                       Mean reward: 879.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.1380
       Episode_Reward/object_height 0.0230
     Episode_Reward/reaching_object 0.7936
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 0.14s
                      Time elapsed: 00:17:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 921/1 [0m                       

                       Computation: 677816 steps/s (collection: 0.047s, learning 0.099s)
                       Mean reward: 869.90
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.0830
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 0.15s
                      Time elapsed: 00:17:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 922/1 [0m                       

                       Computation: 812259 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 864.94
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1241
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 0.12s
                      Time elapsed: 00:17:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 923/1 [0m                       

                       Computation: 788958 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 868.85
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.8274
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 0.12s
                      Time elapsed: 00:17:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 924/1 [0m                       

                       Computation: 776984 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 874.20
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.3696
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7791
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 0.13s
                      Time elapsed: 00:18:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 925/1 [0m                       

                       Computation: 778560 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 858.83
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0077
       Episode_Reward/object_height 0.0202
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 0.13s
                      Time elapsed: 00:18:02
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 926/1 [0m                       

                       Computation: 645818 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 866.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.7257
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 0.15s
                      Time elapsed: 00:18:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 927/1 [0m                       

                       Computation: 564772 steps/s (collection: 0.056s, learning 0.118s)
                       Mean reward: 859.66
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0444
       Episode_Reward/object_height 0.0198
     Episode_Reward/reaching_object 0.7581
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 0.17s
                      Time elapsed: 00:18:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 928/1 [0m                       

                       Computation: 604767 steps/s (collection: 0.050s, learning 0.113s)
                       Mean reward: 854.73
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.4595
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 40.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 0.16s
                      Time elapsed: 00:18:05
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 929/1 [0m                       

                       Computation: 604786 steps/s (collection: 0.052s, learning 0.111s)
                       Mean reward: 854.70
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.7421
       Episode_Reward/object_height 0.0195
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 0.16s
                      Time elapsed: 00:18:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 930/1 [0m                       

                       Computation: 553707 steps/s (collection: 0.056s, learning 0.122s)
                       Mean reward: 817.05
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0005
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 161.5052
       Episode_Reward/object_height 0.0186
     Episode_Reward/reaching_object 0.7470
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 0.18s
                      Time elapsed: 00:18:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 931/1 [0m                       

                       Computation: 573898 steps/s (collection: 0.052s, learning 0.119s)
                       Mean reward: 848.38
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.2904
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 0.17s
                      Time elapsed: 00:18:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 932/1 [0m                       

                       Computation: 593880 steps/s (collection: 0.051s, learning 0.115s)
                       Mean reward: 854.39
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5169
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 0.17s
                      Time elapsed: 00:18:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 933/1 [0m                       

                       Computation: 579830 steps/s (collection: 0.058s, learning 0.112s)
                       Mean reward: 851.28
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.0471
       Episode_Reward/object_height 0.0192
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 0.17s
                      Time elapsed: 00:18:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 934/1 [0m                       

                       Computation: 707258 steps/s (collection: 0.049s, learning 0.090s)
                       Mean reward: 863.66
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1280
       Episode_Reward/object_height 0.0197
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 0.14s
                      Time elapsed: 00:18:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 935/1 [0m                       

                       Computation: 704428 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 855.40
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.1342
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 0.14s
                      Time elapsed: 00:18:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 936/1 [0m                       

                       Computation: 772085 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 853.88
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8429
       Episode_Reward/object_height 0.0194
     Episode_Reward/reaching_object 0.7458
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 0.13s
                      Time elapsed: 00:18:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 937/1 [0m                       

                       Computation: 842982 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 865.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.4713
       Episode_Reward/object_height 0.0196
     Episode_Reward/reaching_object 0.7629
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 0.12s
                      Time elapsed: 00:18:17
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 938/1 [0m                       

                       Computation: 802296 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 861.20
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0843
       Episode_Reward/object_height 0.0199
     Episode_Reward/reaching_object 0.7557
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 42.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 0.12s
                      Time elapsed: 00:18:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 939/1 [0m                       

                       Computation: 764390 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 859.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.9998
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 0.13s
                      Time elapsed: 00:18:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 940/1 [0m                       

                       Computation: 648255 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 849.16
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1093
       Episode_Reward/object_height 0.0204
     Episode_Reward/reaching_object 0.7492
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 0.15s
                      Time elapsed: 00:18:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 941/1 [0m                       

                       Computation: 746983 steps/s (collection: 0.051s, learning 0.081s)
                       Mean reward: 840.04
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.0071
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7427
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 0.13s
                      Time elapsed: 00:18:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 942/1 [0m                       

                       Computation: 702058 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 852.01
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.2721
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7576
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 0.14s
                      Time elapsed: 00:18:23
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 943/1 [0m                       

                       Computation: 778288 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 864.11
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6817
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7620
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 0.13s
                      Time elapsed: 00:18:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 944/1 [0m                       

                       Computation: 633508 steps/s (collection: 0.056s, learning 0.100s)
                       Mean reward: 855.51
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.3198
       Episode_Reward/object_height 0.0216
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 0.16s
                      Time elapsed: 00:18:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 945/1 [0m                       

                       Computation: 693034 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 866.66
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5109
       Episode_Reward/object_height 0.0224
     Episode_Reward/reaching_object 0.7707
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 0.14s
                      Time elapsed: 00:18:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 946/1 [0m                       

                       Computation: 740496 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 865.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6342
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 0.13s
                      Time elapsed: 00:18:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 947/1 [0m                       

                       Computation: 789475 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 856.81
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.4395
       Episode_Reward/object_height 0.0228
     Episode_Reward/reaching_object 0.7526
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 0.12s
                      Time elapsed: 00:18:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 948/1 [0m                       

                       Computation: 812181 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 863.74
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6168
       Episode_Reward/object_height 0.0235
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 45.2917
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 0.12s
                      Time elapsed: 00:18:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 949/1 [0m                       

                       Computation: 731981 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 862.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8183
       Episode_Reward/object_height 0.0239
     Episode_Reward/reaching_object 0.7657
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 0.13s
                      Time elapsed: 00:18:30
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 950/1 [0m                       

                       Computation: 795491 steps/s (collection: 0.046s, learning 0.078s)
                       Mean reward: 878.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.9752
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7824
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 0.12s
                      Time elapsed: 00:18:32
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 951/1 [0m                       

                       Computation: 829322 steps/s (collection: 0.043s, learning 0.076s)
                       Mean reward: 869.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3618
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 0.12s
                      Time elapsed: 00:18:33
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 952/1 [0m                       

                       Computation: 713175 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 862.29
               Mean episode length: 249.36
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 172.1159
       Episode_Reward/object_height 0.0253
     Episode_Reward/reaching_object 0.7707
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 0.14s
                      Time elapsed: 00:18:34
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 953/1 [0m                       

                       Computation: 667470 steps/s (collection: 0.043s, learning 0.105s)
                       Mean reward: 859.25
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.0264
       Episode_Reward/object_height 0.0258
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 0.15s
                      Time elapsed: 00:18:35
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 954/1 [0m                       

                       Computation: 636256 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 866.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.9179
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7807
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 0.15s
                      Time elapsed: 00:18:36
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 955/1 [0m                       

                       Computation: 573446 steps/s (collection: 0.050s, learning 0.122s)
                       Mean reward: 859.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1333
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7679
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 0.17s
                      Time elapsed: 00:18:37
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 956/1 [0m                       

                       Computation: 746319 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 864.47
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.0283
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 0.13s
                      Time elapsed: 00:18:38
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 957/1 [0m                       

                       Computation: 682089 steps/s (collection: 0.045s, learning 0.100s)
                       Mean reward: 860.03
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1954
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 0.14s
                      Time elapsed: 00:18:40
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 958/1 [0m                       

                       Computation: 736134 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 864.72
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.7081
       Episode_Reward/object_height 0.0290
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 0.13s
                      Time elapsed: 00:18:41
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 959/1 [0m                       

                       Computation: 745322 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 867.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.4453
       Episode_Reward/object_height 0.0300
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 41.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 0.13s
                      Time elapsed: 00:18:42
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 960/1 [0m                       

                       Computation: 709693 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 857.47
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.3125
       Episode_Reward/object_height 0.0306
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 0.14s
                      Time elapsed: 00:18:43
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 961/1 [0m                       

                       Computation: 728820 steps/s (collection: 0.046s, learning 0.089s)
                       Mean reward: 851.92
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 169.1435
       Episode_Reward/object_height 0.0307
     Episode_Reward/reaching_object 0.7744
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 0.13s
                      Time elapsed: 00:18:44
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 962/1 [0m                       

                       Computation: 687087 steps/s (collection: 0.042s, learning 0.101s)
                       Mean reward: 856.38
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.4390
       Episode_Reward/object_height 0.0315
     Episode_Reward/reaching_object 0.7829
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 0.14s
                      Time elapsed: 00:18:45
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 963/1 [0m                       

                       Computation: 675406 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 846.81
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9687
       Episode_Reward/object_height 0.0317
     Episode_Reward/reaching_object 0.7689
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 0.15s
                      Time elapsed: 00:18:46
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 964/1 [0m                       

                       Computation: 560727 steps/s (collection: 0.045s, learning 0.131s)
                       Mean reward: 842.66
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.1110
       Episode_Reward/object_height 0.0332
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 0.18s
                      Time elapsed: 00:18:48
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 965/1 [0m                       

                       Computation: 689208 steps/s (collection: 0.048s, learning 0.095s)
                       Mean reward: 864.17
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 171.9552
       Episode_Reward/object_height 0.0342
     Episode_Reward/reaching_object 0.7863
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 0.14s
                      Time elapsed: 00:18:49
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 966/1 [0m                       

                       Computation: 768546 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 852.08
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.8839
       Episode_Reward/object_height 0.0344
     Episode_Reward/reaching_object 0.7743
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 0.13s
                      Time elapsed: 00:18:50
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 967/1 [0m                       

                       Computation: 716599 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 860.00
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 171.0028
       Episode_Reward/object_height 0.0352
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 0.14s
                      Time elapsed: 00:18:51
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 968/1 [0m                       

                       Computation: 756904 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 856.07
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.3575
       Episode_Reward/object_height 0.0355
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 0.13s
                      Time elapsed: 00:18:52
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 969/1 [0m                       

                       Computation: 717090 steps/s (collection: 0.047s, learning 0.090s)
                       Mean reward: 857.02
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.9776
       Episode_Reward/object_height 0.0356
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 44.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 0.14s
                      Time elapsed: 00:18:53
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 970/1 [0m                       

                       Computation: 771422 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 855.99
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.2494
       Episode_Reward/object_height 0.0362
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 0.13s
                      Time elapsed: 00:18:55
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 971/1 [0m                       

                       Computation: 815540 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 858.36
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 170.6528
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7777
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 0.12s
                      Time elapsed: 00:18:56
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 972/1 [0m                       

                       Computation: 718534 steps/s (collection: 0.051s, learning 0.086s)
                       Mean reward: 855.83
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 170.6196
       Episode_Reward/object_height 0.0364
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 0.14s
                      Time elapsed: 00:18:57
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 973/1 [0m                       

                       Computation: 786345 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 850.21
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.4580
       Episode_Reward/object_height 0.0359
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 0.13s
                      Time elapsed: 00:18:58
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 974/1 [0m                       

                       Computation: 714577 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 846.30
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.9078
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 0.14s
                      Time elapsed: 00:18:59
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 975/1 [0m                       

                       Computation: 665802 steps/s (collection: 0.041s, learning 0.107s)
                       Mean reward: 858.20
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 171.3151
       Episode_Reward/object_height 0.0367
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 0.15s
                      Time elapsed: 00:19:00
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 976/1 [0m                       

                       Computation: 667862 steps/s (collection: 0.039s, learning 0.108s)
                       Mean reward: 849.76
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.9547
       Episode_Reward/object_height 0.0363
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 0.15s
                      Time elapsed: 00:19:01
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 977/1 [0m                       

                       Computation: 597426 steps/s (collection: 0.054s, learning 0.111s)
                       Mean reward: 845.40
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 168.7673
       Episode_Reward/object_height 0.0364
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 0.16s
                      Time elapsed: 00:19:03
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 978/1 [0m                       

                       Computation: 608627 steps/s (collection: 0.053s, learning 0.109s)
                       Mean reward: 846.46
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.4392
       Episode_Reward/object_height 0.0366
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 0.16s
                      Time elapsed: 00:19:04
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 979/1 [0m                       

                       Computation: 591715 steps/s (collection: 0.049s, learning 0.117s)
                       Mean reward: 847.87
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.2026
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7582
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 0.17s
                      Time elapsed: 00:19:06
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 980/1 [0m                       

                       Computation: 592600 steps/s (collection: 0.049s, learning 0.117s)
                       Mean reward: 844.95
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.5304
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 40.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 0.17s
                      Time elapsed: 00:19:07
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 981/1 [0m                       

                       Computation: 561575 steps/s (collection: 0.050s, learning 0.126s)
                       Mean reward: 843.12
               Mean episode length: 248.32
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.0517
       Episode_Reward/object_height 0.0376
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 0.18s
                      Time elapsed: 00:19:08
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 982/1 [0m                       

                       Computation: 578066 steps/s (collection: 0.052s, learning 0.119s)
                       Mean reward: 842.26
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 166.5565
       Episode_Reward/object_height 0.0375
     Episode_Reward/reaching_object 0.7482
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 0.17s
                      Time elapsed: 00:19:10
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 983/1 [0m                       

                       Computation: 644293 steps/s (collection: 0.050s, learning 0.103s)
                       Mean reward: 846.90
               Mean episode length: 247.43
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.9618
       Episode_Reward/object_height 0.0384
     Episode_Reward/reaching_object 0.7611
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 0.15s
                      Time elapsed: 00:19:11
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 984/1 [0m                       

                       Computation: 668474 steps/s (collection: 0.054s, learning 0.094s)
                       Mean reward: 827.58
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.9033
       Episode_Reward/object_height 0.0379
     Episode_Reward/reaching_object 0.7437
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 0.15s
                      Time elapsed: 00:19:12
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 985/1 [0m                       

                       Computation: 604571 steps/s (collection: 0.059s, learning 0.104s)
                       Mean reward: 844.13
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.1133
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 0.16s
                      Time elapsed: 00:19:14
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 986/1 [0m                       

                       Computation: 672633 steps/s (collection: 0.047s, learning 0.099s)
                       Mean reward: 843.01
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.7722
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 0.15s
                      Time elapsed: 00:19:15
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 987/1 [0m                       

                       Computation: 663921 steps/s (collection: 0.049s, learning 0.100s)
                       Mean reward: 820.02
               Mean episode length: 248.43
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.6103
       Episode_Reward/object_height 0.0388
     Episode_Reward/reaching_object 0.7329
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 0.15s
                      Time elapsed: 00:19:16
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 988/1 [0m                       

                       Computation: 608398 steps/s (collection: 0.047s, learning 0.115s)
                       Mean reward: 829.13
               Mean episode length: 247.26
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.4375
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7331
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 0.16s
                      Time elapsed: 00:19:18
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 989/1 [0m                       

                       Computation: 586641 steps/s (collection: 0.049s, learning 0.119s)
                       Mean reward: 824.74
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 164.7229
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7330
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 0.17s
                      Time elapsed: 00:19:19
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 990/1 [0m                       

                       Computation: 725645 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 814.69
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 159.8452
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7094
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 41.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 0.14s
                      Time elapsed: 00:19:20
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 991/1 [0m                       

                       Computation: 787892 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 793.05
               Mean episode length: 244.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 158.6013
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.6976
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 0.12s
                      Time elapsed: 00:19:21
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 992/1 [0m                       

                       Computation: 677277 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 790.02
               Mean episode length: 246.40
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 158.0374
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.6906
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 0.15s
                      Time elapsed: 00:19:22
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 993/1 [0m                       

                       Computation: 729676 steps/s (collection: 0.040s, learning 0.095s)
                       Mean reward: 827.76
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.6591
       Episode_Reward/object_height 0.0416
     Episode_Reward/reaching_object 0.7232
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 0.13s
                      Time elapsed: 00:19:24
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 994/1 [0m                       

                       Computation: 641493 steps/s (collection: 0.043s, learning 0.110s)
                       Mean reward: 795.75
               Mean episode length: 246.99
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 158.6723
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7013
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 0.15s
                      Time elapsed: 00:19:25
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 995/1 [0m                       

                       Computation: 724448 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 819.22
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.4281
       Episode_Reward/object_height 0.0419
     Episode_Reward/reaching_object 0.7150
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 0.14s
                      Time elapsed: 00:19:26
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 996/1 [0m                       

                       Computation: 700956 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 823.28
               Mean episode length: 246.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 163.7007
       Episode_Reward/object_height 0.0422
     Episode_Reward/reaching_object 0.7252
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 0.14s
                      Time elapsed: 00:19:27
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 997/1 [0m                       

                       Computation: 696986 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 803.30
               Mean episode length: 247.01
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.5361
       Episode_Reward/object_height 0.0422
     Episode_Reward/reaching_object 0.7201
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 0.14s
                      Time elapsed: 00:19:28
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 998/1 [0m                       

                       Computation: 744371 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 819.28
               Mean episode length: 247.22
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.4606
       Episode_Reward/object_height 0.0430
     Episode_Reward/reaching_object 0.7218
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 0.13s
                      Time elapsed: 00:19:29
                               ETA: 00:00:00

################################################################################
                       [1m Learning iteration 999/1 [0m                       

                       Computation: 787460 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 809.97
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 161.8451
       Episode_Reward/object_height 0.0431
     Episode_Reward/reaching_object 0.7220
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 0.12s
                      Time elapsed: 00:19:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1000/1 [0m                       

                       Computation: 717333 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 819.90
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 160.7794
       Episode_Reward/object_height 0.0432
     Episode_Reward/reaching_object 0.7144
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 43.7083
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 0.14s
                      Time elapsed: 00:19:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1001/1 [0m                       

                       Computation: 660692 steps/s (collection: 0.048s, learning 0.101s)
                       Mean reward: 801.76
               Mean episode length: 246.63
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 159.8210
       Episode_Reward/object_height 0.0436
     Episode_Reward/reaching_object 0.7079
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 0.15s
                      Time elapsed: 00:19:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1002/1 [0m                       

                       Computation: 553581 steps/s (collection: 0.052s, learning 0.126s)
                       Mean reward: 821.75
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.9545
       Episode_Reward/object_height 0.0445
     Episode_Reward/reaching_object 0.7203
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 0.18s
                      Time elapsed: 00:19:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1003/1 [0m                       

                       Computation: 778486 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 808.96
               Mean episode length: 246.55
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 160.8230
       Episode_Reward/object_height 0.0443
     Episode_Reward/reaching_object 0.7166
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 0.13s
                      Time elapsed: 00:19:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1004/1 [0m                       

                       Computation: 824163 steps/s (collection: 0.043s, learning 0.076s)
                       Mean reward: 804.59
               Mean episode length: 246.21
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 159.9805
       Episode_Reward/object_height 0.0442
     Episode_Reward/reaching_object 0.7150
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 0.12s
                      Time elapsed: 00:19:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1005/1 [0m                       

                       Computation: 702075 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 817.48
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.5984
       Episode_Reward/object_height 0.0450
     Episode_Reward/reaching_object 0.7212
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 0.14s
                      Time elapsed: 00:19:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1006/1 [0m                       

                       Computation: 658256 steps/s (collection: 0.043s, learning 0.106s)
                       Mean reward: 785.05
               Mean episode length: 246.90
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 155.5481
       Episode_Reward/object_height 0.0429
     Episode_Reward/reaching_object 0.6972
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 0.15s
                      Time elapsed: 00:19:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1007/1 [0m                       

                       Computation: 683423 steps/s (collection: 0.041s, learning 0.103s)
                       Mean reward: 795.00
               Mean episode length: 246.76
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 157.8806
       Episode_Reward/object_height 0.0432
     Episode_Reward/reaching_object 0.7135
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 0.14s
                      Time elapsed: 00:19:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1008/1 [0m                       

                       Computation: 669785 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 810.56
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 160.3471
       Episode_Reward/object_height 0.0436
     Episode_Reward/reaching_object 0.7189
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 0.15s
                      Time elapsed: 00:19:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1009/1 [0m                       

                       Computation: 652552 steps/s (collection: 0.048s, learning 0.103s)
                       Mean reward: 833.38
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.4223
       Episode_Reward/object_height 0.0452
     Episode_Reward/reaching_object 0.7406
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 0.15s
                      Time elapsed: 00:19:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1010/1 [0m                       

                       Computation: 710493 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 825.32
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 164.3803
       Episode_Reward/object_height 0.0442
     Episode_Reward/reaching_object 0.7328
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 0.14s
                      Time elapsed: 00:19:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1011/1 [0m                       

                       Computation: 789432 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 838.09
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.0104
       Episode_Reward/object_height 0.0434
     Episode_Reward/reaching_object 0.7308
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 40.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 0.12s
                      Time elapsed: 00:19:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1012/1 [0m                       

                       Computation: 747300 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 820.18
               Mean episode length: 246.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.5985
       Episode_Reward/object_height 0.0432
     Episode_Reward/reaching_object 0.7348
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 0.13s
                      Time elapsed: 00:19:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1013/1 [0m                       

                       Computation: 764952 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 826.12
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 164.7896
       Episode_Reward/object_height 0.0434
     Episode_Reward/reaching_object 0.7317
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 0.13s
                      Time elapsed: 00:19:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1014/1 [0m                       

                       Computation: 756104 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 831.16
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.0794
       Episode_Reward/object_height 0.0436
     Episode_Reward/reaching_object 0.7384
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 0.13s
                      Time elapsed: 00:19:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1015/1 [0m                       

                       Computation: 715290 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 838.14
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.5789
       Episode_Reward/object_height 0.0440
     Episode_Reward/reaching_object 0.7494
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 0.14s
                      Time elapsed: 00:19:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1016/1 [0m                       

                       Computation: 670830 steps/s (collection: 0.040s, learning 0.107s)
                       Mean reward: 816.68
               Mean episode length: 246.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.1438
       Episode_Reward/object_height 0.0427
     Episode_Reward/reaching_object 0.7302
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 0.15s
                      Time elapsed: 00:19:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1017/1 [0m                       

                       Computation: 730619 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 817.38
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 161.9653
       Episode_Reward/object_height 0.0416
     Episode_Reward/reaching_object 0.7172
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 0.13s
                      Time elapsed: 00:19:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1018/1 [0m                       

                       Computation: 699241 steps/s (collection: 0.040s, learning 0.101s)
                       Mean reward: 820.38
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 163.6335
       Episode_Reward/object_height 0.0419
     Episode_Reward/reaching_object 0.7228
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 0.14s
                      Time elapsed: 00:19:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1019/1 [0m                       

                       Computation: 688996 steps/s (collection: 0.047s, learning 0.096s)
                       Mean reward: 827.05
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.3680
       Episode_Reward/object_height 0.0421
     Episode_Reward/reaching_object 0.7240
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 0.14s
                      Time elapsed: 00:19:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1020/1 [0m                       

                       Computation: 657349 steps/s (collection: 0.042s, learning 0.108s)
                       Mean reward: 838.17
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.9779
       Episode_Reward/object_height 0.0429
     Episode_Reward/reaching_object 0.7450
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 0.15s
                      Time elapsed: 00:19:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1021/1 [0m                       

                       Computation: 747401 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 844.30
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.9902
       Episode_Reward/object_height 0.0425
     Episode_Reward/reaching_object 0.7377
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 41.8750
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 0.13s
                      Time elapsed: 00:19:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1022/1 [0m                       

                       Computation: 763144 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 827.43
               Mean episode length: 246.49
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.6766
       Episode_Reward/object_height 0.0424
     Episode_Reward/reaching_object 0.7339
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 0.13s
                      Time elapsed: 00:19:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1023/1 [0m                       

                       Computation: 713591 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 820.22
               Mean episode length: 246.97
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.9375
       Episode_Reward/object_height 0.0421
     Episode_Reward/reaching_object 0.7295
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 0.14s
                      Time elapsed: 00:19:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1024/1 [0m                       

                       Computation: 719668 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 835.22
               Mean episode length: 247.31
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.4617
       Episode_Reward/object_height 0.0427
     Episode_Reward/reaching_object 0.7398
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 0.14s
                      Time elapsed: 00:19:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1025/1 [0m                       

                       Computation: 753434 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 842.35
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.4195
       Episode_Reward/object_height 0.0429
     Episode_Reward/reaching_object 0.7428
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 0.13s
                      Time elapsed: 00:20:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1026/1 [0m                       

                       Computation: 728175 steps/s (collection: 0.038s, learning 0.097s)
                       Mean reward: 822.44
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 164.2447
       Episode_Reward/object_height 0.0421
     Episode_Reward/reaching_object 0.7263
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 0.14s
                      Time elapsed: 00:20:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1027/1 [0m                       

                       Computation: 724422 steps/s (collection: 0.048s, learning 0.088s)
                       Mean reward: 815.84
               Mean episode length: 243.96
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.3437
       Episode_Reward/object_height 0.0418
     Episode_Reward/reaching_object 0.7178
Episode_Termination/object_dropping 1.0833
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 0.14s
                      Time elapsed: 00:20:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1028/1 [0m                       

                       Computation: 795545 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 832.14
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.2949
       Episode_Reward/object_height 0.0425
     Episode_Reward/reaching_object 0.7333
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 0.12s
                      Time elapsed: 00:20:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1029/1 [0m                       

                       Computation: 795600 steps/s (collection: 0.046s, learning 0.078s)
                       Mean reward: 836.31
               Mean episode length: 248.13
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.9318
       Episode_Reward/object_height 0.0432
     Episode_Reward/reaching_object 0.7302
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 0.12s
                      Time elapsed: 00:20:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1030/1 [0m                       

                       Computation: 675580 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 824.69
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 164.0899
       Episode_Reward/object_height 0.0424
     Episode_Reward/reaching_object 0.7164
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 0.15s
                      Time elapsed: 00:20:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1031/1 [0m                       

                       Computation: 757957 steps/s (collection: 0.047s, learning 0.083s)
                       Mean reward: 824.00
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 164.2521
       Episode_Reward/object_height 0.0425
     Episode_Reward/reaching_object 0.7185
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 0.13s
                      Time elapsed: 00:20:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1032/1 [0m                       

                       Computation: 748749 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 819.24
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 160.2068
       Episode_Reward/object_height 0.0417
     Episode_Reward/reaching_object 0.7085
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 37.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 0.13s
                      Time elapsed: 00:20:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1033/1 [0m                       

                       Computation: 737036 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 835.71
               Mean episode length: 245.77
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.7173
       Episode_Reward/object_height 0.0433
     Episode_Reward/reaching_object 0.7283
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 0.13s
                      Time elapsed: 00:20:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1034/1 [0m                       

                       Computation: 700697 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 848.81
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.8283
       Episode_Reward/object_height 0.0443
     Episode_Reward/reaching_object 0.7486
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 0.14s
                      Time elapsed: 00:20:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1035/1 [0m                       

                       Computation: 785922 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 842.98
               Mean episode length: 248.99
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.9214
       Episode_Reward/object_height 0.0442
     Episode_Reward/reaching_object 0.7453
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 0.13s
                      Time elapsed: 00:20:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1036/1 [0m                       

                       Computation: 595698 steps/s (collection: 0.048s, learning 0.118s)
                       Mean reward: 840.88
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.4702
       Episode_Reward/object_height 0.0443
     Episode_Reward/reaching_object 0.7404
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 0.17s
                      Time elapsed: 00:20:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1037/1 [0m                       

                       Computation: 693826 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 846.13
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.7502
       Episode_Reward/object_height 0.0447
     Episode_Reward/reaching_object 0.7443
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 0.14s
                      Time elapsed: 00:20:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1038/1 [0m                       

                       Computation: 695741 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 849.02
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.6168
       Episode_Reward/object_height 0.0451
     Episode_Reward/reaching_object 0.7569
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 0.14s
                      Time elapsed: 00:20:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1039/1 [0m                       

                       Computation: 737591 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 854.97
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.3867
       Episode_Reward/object_height 0.0450
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 0.13s
                      Time elapsed: 00:20:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1040/1 [0m                       

                       Computation: 640376 steps/s (collection: 0.043s, learning 0.111s)
                       Mean reward: 861.89
               Mean episode length: 247.75
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2063
       Episode_Reward/object_height 0.0454
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 0.15s
                      Time elapsed: 00:20:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1041/1 [0m                       

                       Computation: 736303 steps/s (collection: 0.047s, learning 0.087s)
                       Mean reward: 854.24
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.7941
       Episode_Reward/object_height 0.0447
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 0.13s
                      Time elapsed: 00:20:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1042/1 [0m                       

                       Computation: 707121 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 859.62
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0317
       Episode_Reward/object_height 0.0451
     Episode_Reward/reaching_object 0.7622
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 39.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 0.14s
                      Time elapsed: 00:20:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1043/1 [0m                       

                       Computation: 735448 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 845.58
               Mean episode length: 246.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.8513
       Episode_Reward/object_height 0.0441
     Episode_Reward/reaching_object 0.7457
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 0.13s
                      Time elapsed: 00:20:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1044/1 [0m                       

                       Computation: 697682 steps/s (collection: 0.047s, learning 0.094s)
                       Mean reward: 853.13
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8566
       Episode_Reward/object_height 0.0448
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 0.14s
                      Time elapsed: 00:20:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1045/1 [0m                       

                       Computation: 750526 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 857.84
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.9910
       Episode_Reward/object_height 0.0449
     Episode_Reward/reaching_object 0.7650
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 0.13s
                      Time elapsed: 00:20:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1046/1 [0m                       

                       Computation: 722373 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 857.15
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.2341
       Episode_Reward/object_height 0.0446
     Episode_Reward/reaching_object 0.7504
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 0.14s
                      Time elapsed: 00:20:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1047/1 [0m                       

                       Computation: 677754 steps/s (collection: 0.045s, learning 0.100s)
                       Mean reward: 851.34
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.3342
       Episode_Reward/object_height 0.0442
     Episode_Reward/reaching_object 0.7432
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.1667
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 0.15s
                      Time elapsed: 00:20:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1048/1 [0m                       

                       Computation: 699672 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 862.37
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.6667
       Episode_Reward/object_height 0.0449
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 0.14s
                      Time elapsed: 00:20:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1049/1 [0m                       

                       Computation: 792691 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 850.90
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1645
       Episode_Reward/object_height 0.0441
     Episode_Reward/reaching_object 0.7444
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 0.12s
                      Time elapsed: 00:20:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1050/1 [0m                       

                       Computation: 743655 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 867.14
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5997
       Episode_Reward/object_height 0.0450
     Episode_Reward/reaching_object 0.7676
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 0.13s
                      Time elapsed: 00:20:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1051/1 [0m                       

                       Computation: 753580 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 873.18
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8566
       Episode_Reward/object_height 0.0451
     Episode_Reward/reaching_object 0.7675
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 0.13s
                      Time elapsed: 00:20:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1052/1 [0m                       

                       Computation: 723703 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 876.32
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2668
       Episode_Reward/object_height 0.0453
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 0.14s
                      Time elapsed: 00:20:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1053/1 [0m                       

                       Computation: 666083 steps/s (collection: 0.053s, learning 0.095s)
                       Mean reward: 863.30
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.3661
       Episode_Reward/object_height 0.0434
     Episode_Reward/reaching_object 0.7578
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 35.8750
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 0.15s
                      Time elapsed: 00:20:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1054/1 [0m                       

                       Computation: 789381 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 864.62
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.8502
       Episode_Reward/object_height 0.0444
     Episode_Reward/reaching_object 0.7764
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 0.12s
                      Time elapsed: 00:20:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1055/1 [0m                       

                       Computation: 644517 steps/s (collection: 0.052s, learning 0.101s)
                       Mean reward: 855.60
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.6699
       Episode_Reward/object_height 0.0440
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 0.15s
                      Time elapsed: 00:20:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1056/1 [0m                       

                       Computation: 706589 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 865.41
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.5960
       Episode_Reward/object_height 0.0444
     Episode_Reward/reaching_object 0.7802
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 0.14s
                      Time elapsed: 00:20:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1057/1 [0m                       

                       Computation: 783095 steps/s (collection: 0.045s, learning 0.081s)
                       Mean reward: 870.14
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.2461
       Episode_Reward/object_height 0.0445
     Episode_Reward/reaching_object 0.7848
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 0.13s
                      Time elapsed: 00:20:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1058/1 [0m                       

                       Computation: 682809 steps/s (collection: 0.043s, learning 0.101s)
                       Mean reward: 862.57
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.5574
       Episode_Reward/object_height 0.0441
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 0.14s
                      Time elapsed: 00:20:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1059/1 [0m                       

                       Computation: 694593 steps/s (collection: 0.043s, learning 0.099s)
                       Mean reward: 863.70
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6535
       Episode_Reward/object_height 0.0440
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 0.14s
                      Time elapsed: 00:20:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1060/1 [0m                       

                       Computation: 679947 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 873.19
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5987
       Episode_Reward/object_height 0.0444
     Episode_Reward/reaching_object 0.7847
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 0.14s
                      Time elapsed: 00:20:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1061/1 [0m                       

                       Computation: 674696 steps/s (collection: 0.042s, learning 0.104s)
                       Mean reward: 863.14
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8456
       Episode_Reward/object_height 0.0438
     Episode_Reward/reaching_object 0.7749
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 0.15s
                      Time elapsed: 00:20:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1062/1 [0m                       

                       Computation: 661139 steps/s (collection: 0.042s, learning 0.107s)
                       Mean reward: 859.89
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8567
       Episode_Reward/object_height 0.0433
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 0.15s
                      Time elapsed: 00:20:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1063/1 [0m                       

                       Computation: 707886 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 860.85
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.1354
       Episode_Reward/object_height 0.0433
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 38.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 0.14s
                      Time elapsed: 00:20:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1064/1 [0m                       

                       Computation: 719407 steps/s (collection: 0.048s, learning 0.089s)
                       Mean reward: 848.33
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.6930
       Episode_Reward/object_height 0.0430
     Episode_Reward/reaching_object 0.7605
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 0.14s
                      Time elapsed: 00:20:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1065/1 [0m                       

                       Computation: 734015 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 847.52
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2262
       Episode_Reward/object_height 0.0427
     Episode_Reward/reaching_object 0.7568
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 0.13s
                      Time elapsed: 00:20:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1066/1 [0m                       

                       Computation: 763522 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 848.97
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.6481
       Episode_Reward/object_height 0.0428
     Episode_Reward/reaching_object 0.7616
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 0.13s
                      Time elapsed: 00:20:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1067/1 [0m                       

                       Computation: 756063 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 853.13
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.0735
       Episode_Reward/object_height 0.0427
     Episode_Reward/reaching_object 0.7624
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 0.13s
                      Time elapsed: 00:20:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1068/1 [0m                       

                       Computation: 711034 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 843.91
               Mean episode length: 248.22
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.3035
       Episode_Reward/object_height 0.0418
     Episode_Reward/reaching_object 0.7466
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 0.14s
                      Time elapsed: 00:20:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1069/1 [0m                       

                       Computation: 729778 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 854.20
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.7599
       Episode_Reward/object_height 0.0423
     Episode_Reward/reaching_object 0.7578
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 0.13s
                      Time elapsed: 00:20:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1070/1 [0m                       

                       Computation: 717864 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 859.13
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.0403
       Episode_Reward/object_height 0.0426
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 0.14s
                      Time elapsed: 00:20:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1071/1 [0m                       

                       Computation: 635826 steps/s (collection: 0.044s, learning 0.111s)
                       Mean reward: 861.07
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.0735
       Episode_Reward/object_height 0.0425
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 0.15s
                      Time elapsed: 00:20:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1072/1 [0m                       

                       Computation: 723577 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 852.47
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5961
       Episode_Reward/object_height 0.0421
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 0.14s
                      Time elapsed: 00:20:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1073/1 [0m                       

                       Computation: 699913 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 871.12
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.6926
       Episode_Reward/object_height 0.0431
     Episode_Reward/reaching_object 0.7804
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 39.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 0.14s
                      Time elapsed: 00:20:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1074/1 [0m                       

                       Computation: 734815 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 843.25
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.9839
       Episode_Reward/object_height 0.0411
     Episode_Reward/reaching_object 0.7520
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 0.13s
                      Time elapsed: 00:20:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1075/1 [0m                       

                       Computation: 752563 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 833.33
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.0044
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7325
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 0.13s
                      Time elapsed: 00:20:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1076/1 [0m                       

                       Computation: 610032 steps/s (collection: 0.044s, learning 0.117s)
                       Mean reward: 857.17
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.3125
       Episode_Reward/object_height 0.0412
     Episode_Reward/reaching_object 0.7559
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 0.16s
                      Time elapsed: 00:20:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1077/1 [0m                       

                       Computation: 732641 steps/s (collection: 0.051s, learning 0.084s)
                       Mean reward: 830.36
               Mean episode length: 246.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.8586
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7312
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 0.13s
                      Time elapsed: 00:21:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1078/1 [0m                       

                       Computation: 665957 steps/s (collection: 0.058s, learning 0.090s)
                       Mean reward: 850.84
               Mean episode length: 247.72
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.9692
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 0.15s
                      Time elapsed: 00:21:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1079/1 [0m                       

                       Computation: 714434 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 843.41
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.1147
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7390
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 0.14s
                      Time elapsed: 00:21:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1080/1 [0m                       

                       Computation: 593540 steps/s (collection: 0.053s, learning 0.113s)
                       Mean reward: 854.22
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 170.1242
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7417
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 0.17s
                      Time elapsed: 00:21:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1081/1 [0m                       

                       Computation: 625644 steps/s (collection: 0.049s, learning 0.108s)
                       Mean reward: 844.38
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.4043
       Episode_Reward/object_height 0.0385
     Episode_Reward/reaching_object 0.7369
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 0.16s
                      Time elapsed: 00:21:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1082/1 [0m                       

                       Computation: 758271 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 847.04
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.4261
       Episode_Reward/object_height 0.0383
     Episode_Reward/reaching_object 0.7363
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 0.13s
                      Time elapsed: 00:21:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1083/1 [0m                       

                       Computation: 804767 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 848.09
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.1995
       Episode_Reward/object_height 0.0381
     Episode_Reward/reaching_object 0.7415
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 0.12s
                      Time elapsed: 00:21:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1084/1 [0m                       

                       Computation: 556404 steps/s (collection: 0.057s, learning 0.120s)
                       Mean reward: 845.41
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.3913
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7163
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 36.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 0.18s
                      Time elapsed: 00:21:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1085/1 [0m                       

                       Computation: 597273 steps/s (collection: 0.051s, learning 0.113s)
                       Mean reward: 845.36
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 167.9557
       Episode_Reward/object_height 0.0371
     Episode_Reward/reaching_object 0.7306
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 0.16s
                      Time elapsed: 00:21:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1086/1 [0m                       

                       Computation: 616270 steps/s (collection: 0.053s, learning 0.106s)
                       Mean reward: 846.65
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 169.0770
       Episode_Reward/object_height 0.0379
     Episode_Reward/reaching_object 0.7398
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 0.16s
                      Time elapsed: 00:21:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1087/1 [0m                       

                       Computation: 784736 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 826.80
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 164.8532
       Episode_Reward/object_height 0.0371
     Episode_Reward/reaching_object 0.7219
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 0.13s
                      Time elapsed: 00:21:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1088/1 [0m                       

                       Computation: 714589 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 843.87
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 168.3389
       Episode_Reward/object_height 0.0382
     Episode_Reward/reaching_object 0.7338
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 0.14s
                      Time elapsed: 00:21:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1089/1 [0m                       

                       Computation: 665511 steps/s (collection: 0.048s, learning 0.100s)
                       Mean reward: 844.43
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.2087
       Episode_Reward/object_height 0.0383
     Episode_Reward/reaching_object 0.7341
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 0.15s
                      Time elapsed: 00:21:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1090/1 [0m                       

                       Computation: 673041 steps/s (collection: 0.048s, learning 0.098s)
                       Mean reward: 840.67
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.9643
       Episode_Reward/object_height 0.0382
     Episode_Reward/reaching_object 0.7272
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 0.15s
                      Time elapsed: 00:21:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1091/1 [0m                       

                       Computation: 709411 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 844.03
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 167.9694
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7346
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 0.14s
                      Time elapsed: 00:21:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1092/1 [0m                       

                       Computation: 746711 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 846.56
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 168.7912
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7393
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 0.13s
                      Time elapsed: 00:21:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1093/1 [0m                       

                       Computation: 744334 steps/s (collection: 0.048s, learning 0.085s)
                       Mean reward: 841.82
               Mean episode length: 249.08
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.0576
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7369
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 0.13s
                      Time elapsed: 00:21:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1094/1 [0m                       

                       Computation: 687278 steps/s (collection: 0.045s, learning 0.098s)
                       Mean reward: 859.96
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.9963
       Episode_Reward/object_height 0.0402
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 37.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 0.14s
                      Time elapsed: 00:21:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1095/1 [0m                       

                       Computation: 641819 steps/s (collection: 0.047s, learning 0.107s)
                       Mean reward: 844.17
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.9529
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7424
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 0.15s
                      Time elapsed: 00:21:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1096/1 [0m                       

                       Computation: 661359 steps/s (collection: 0.053s, learning 0.096s)
                       Mean reward: 853.13
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.8514
       Episode_Reward/object_height 0.0407
     Episode_Reward/reaching_object 0.7487
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 0.15s
                      Time elapsed: 00:21:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1097/1 [0m                       

                       Computation: 729795 steps/s (collection: 0.045s, learning 0.090s)
                       Mean reward: 844.93
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.8963
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7397
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 0.13s
                      Time elapsed: 00:21:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1098/1 [0m                       

                       Computation: 704036 steps/s (collection: 0.045s, learning 0.095s)
                       Mean reward: 836.69
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.7267
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7334
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 0.14s
                      Time elapsed: 00:21:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1099/1 [0m                       

                       Computation: 710877 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 852.70
               Mean episode length: 247.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.8403
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7521
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 0.14s
                      Time elapsed: 00:21:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1100/1 [0m                       

                       Computation: 761652 steps/s (collection: 0.046s, learning 0.084s)
                       Mean reward: 858.08
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.8036
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7513
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 0.13s
                      Time elapsed: 00:21:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1101/1 [0m                       

                       Computation: 682901 steps/s (collection: 0.045s, learning 0.099s)
                       Mean reward: 842.92
               Mean episode length: 248.06
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.3465
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7346
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 0.14s
                      Time elapsed: 00:21:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1102/1 [0m                       

                       Computation: 666260 steps/s (collection: 0.047s, learning 0.101s)
                       Mean reward: 845.89
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.3359
       Episode_Reward/object_height 0.0402
     Episode_Reward/reaching_object 0.7268
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 0.15s
                      Time elapsed: 00:21:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1103/1 [0m                       

                       Computation: 726926 steps/s (collection: 0.045s, learning 0.091s)
                       Mean reward: 854.95
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 170.0765
       Episode_Reward/object_height 0.0405
     Episode_Reward/reaching_object 0.7390
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 0.14s
                      Time elapsed: 00:21:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1104/1 [0m                       

                       Computation: 662436 steps/s (collection: 0.054s, learning 0.094s)
                       Mean reward: 839.00
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.7260
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7251
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 0.15s
                      Time elapsed: 00:21:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1105/1 [0m                       

                       Computation: 663304 steps/s (collection: 0.052s, learning 0.096s)
                       Mean reward: 838.12
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 162.4026
       Episode_Reward/object_height 0.0386
     Episode_Reward/reaching_object 0.7154
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 35.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 0.15s
                      Time elapsed: 00:21:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1106/1 [0m                       

                       Computation: 619929 steps/s (collection: 0.052s, learning 0.107s)
                       Mean reward: 829.50
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.6699
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7213
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 0.16s
                      Time elapsed: 00:21:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1107/1 [0m                       

                       Computation: 746274 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 843.34
               Mean episode length: 248.62
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.2500
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7298
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 0.13s
                      Time elapsed: 00:21:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1108/1 [0m                       

                       Computation: 718508 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 826.16
               Mean episode length: 248.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 164.4867
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7178
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 0.14s
                      Time elapsed: 00:21:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1109/1 [0m                       

                       Computation: 681739 steps/s (collection: 0.049s, learning 0.095s)
                       Mean reward: 832.22
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 165.9784
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7181
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 0.14s
                      Time elapsed: 00:21:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1110/1 [0m                       

                       Computation: 675815 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 841.59
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.5450
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7233
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 0.15s
                      Time elapsed: 00:21:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1111/1 [0m                       

                       Computation: 698139 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 851.21
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.9269
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7375
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 0.14s
                      Time elapsed: 00:21:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1112/1 [0m                       

                       Computation: 547502 steps/s (collection: 0.054s, learning 0.125s)
                       Mean reward: 847.59
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 168.8421
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7332
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 0.18s
                      Time elapsed: 00:21:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1113/1 [0m                       

                       Computation: 618352 steps/s (collection: 0.059s, learning 0.100s)
                       Mean reward: 858.98
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.1765
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7431
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 0.16s
                      Time elapsed: 00:21:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1114/1 [0m                       

                       Computation: 691673 steps/s (collection: 0.042s, learning 0.100s)
                       Mean reward: 851.21
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.6031
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7358
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 0.14s
                      Time elapsed: 00:21:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1115/1 [0m                       

                       Computation: 770985 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 849.38
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5333
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7367
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 36.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 0.13s
                      Time elapsed: 00:21:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1116/1 [0m                       

                       Computation: 790804 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 848.21
               Mean episode length: 247.88
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.3598
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7323
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 0.12s
                      Time elapsed: 00:21:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1117/1 [0m                       

                       Computation: 767058 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 836.77
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.6755
       Episode_Reward/object_height 0.0386
     Episode_Reward/reaching_object 0.7244
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 0.13s
                      Time elapsed: 00:21:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1118/1 [0m                       

                       Computation: 742680 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 843.25
               Mean episode length: 248.74
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 167.8911
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7321
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 0.13s
                      Time elapsed: 00:21:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1119/1 [0m                       

                       Computation: 795760 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 836.00
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 166.8627
       Episode_Reward/object_height 0.0386
     Episode_Reward/reaching_object 0.7179
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 0.12s
                      Time elapsed: 00:21:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1120/1 [0m                       

                       Computation: 667620 steps/s (collection: 0.048s, learning 0.100s)
                       Mean reward: 853.51
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.9041
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7302
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 0.15s
                      Time elapsed: 00:21:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1121/1 [0m                       

                       Computation: 610406 steps/s (collection: 0.059s, learning 0.103s)
                       Mean reward: 849.40
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 169.5288
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7248
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 0.16s
                      Time elapsed: 00:21:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1122/1 [0m                       

                       Computation: 683319 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 863.34
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 172.1094
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 0.14s
                      Time elapsed: 00:21:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1123/1 [0m                       

                       Computation: 749171 steps/s (collection: 0.049s, learning 0.083s)
                       Mean reward: 860.78
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.5382
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7464
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 0.13s
                      Time elapsed: 00:21:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1124/1 [0m                       

                       Computation: 673869 steps/s (collection: 0.049s, learning 0.097s)
                       Mean reward: 859.69
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 171.6817
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7486
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 0.15s
                      Time elapsed: 00:22:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1125/1 [0m                       

                       Computation: 736924 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 851.24
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 167.4050
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7366
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 38.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 0.13s
                      Time elapsed: 00:22:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1126/1 [0m                       

                       Computation: 761230 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 864.24
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.8445
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7548
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 0.13s
                      Time elapsed: 00:22:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1127/1 [0m                       

                       Computation: 843754 steps/s (collection: 0.044s, learning 0.073s)
                       Mean reward: 857.58
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6958
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7377
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 0.12s
                      Time elapsed: 00:22:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1128/1 [0m                       

                       Computation: 810465 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 862.22
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7462
       Episode_Reward/object_height 0.0400
     Episode_Reward/reaching_object 0.7443
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 0.12s
                      Time elapsed: 00:22:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1129/1 [0m                       

                       Computation: 787883 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 856.36
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.6991
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7407
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 0.12s
                      Time elapsed: 00:22:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1130/1 [0m                       

                       Computation: 741343 steps/s (collection: 0.046s, learning 0.087s)
                       Mean reward: 857.73
               Mean episode length: 249.22
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.8414
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7429
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 0.13s
                      Time elapsed: 00:22:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1131/1 [0m                       

                       Computation: 703754 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 861.15
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.6741
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7514
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 0.14s
                      Time elapsed: 00:22:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1132/1 [0m                       

                       Computation: 701956 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 859.06
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.7787
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7454
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 0.14s
                      Time elapsed: 00:22:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1133/1 [0m                       

                       Computation: 699641 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 863.34
               Mean episode length: 248.76
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 171.7905
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7510
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 0.14s
                      Time elapsed: 00:22:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1134/1 [0m                       

                       Computation: 812285 steps/s (collection: 0.043s, learning 0.078s)
                       Mean reward: 849.03
               Mean episode length: 247.96
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.2726
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7422
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 0.12s
                      Time elapsed: 00:22:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1135/1 [0m                       

                       Computation: 838638 steps/s (collection: 0.045s, learning 0.073s)
                       Mean reward: 853.03
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.4934
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7431
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 0.12s
                      Time elapsed: 00:22:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1136/1 [0m                       

                       Computation: 762976 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 856.60
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.8691
       Episode_Reward/object_height 0.0389
     Episode_Reward/reaching_object 0.7317
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 35.7917
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 0.13s
                      Time elapsed: 00:22:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1137/1 [0m                       

                       Computation: 689149 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 820.07
               Mean episode length: 248.21
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.4829
       Episode_Reward/object_height 0.0379
     Episode_Reward/reaching_object 0.7144
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 0.14s
                      Time elapsed: 00:22:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1138/1 [0m                       

                       Computation: 733546 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 832.59
               Mean episode length: 248.07
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.0186
       Episode_Reward/object_height 0.0385
     Episode_Reward/reaching_object 0.7199
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 0.13s
                      Time elapsed: 00:22:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1139/1 [0m                       

                       Computation: 761949 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 826.11
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.0271
       Episode_Reward/object_height 0.0386
     Episode_Reward/reaching_object 0.7149
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 0.13s
                      Time elapsed: 00:22:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1140/1 [0m                       

                       Computation: 672603 steps/s (collection: 0.046s, learning 0.101s)
                       Mean reward: 797.01
               Mean episode length: 248.01
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.1176
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.6881
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 0.15s
                      Time elapsed: 00:22:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1141/1 [0m                       

                       Computation: 820075 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 827.70
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.4474
       Episode_Reward/object_height 0.0386
     Episode_Reward/reaching_object 0.7031
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 0.12s
                      Time elapsed: 00:22:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1142/1 [0m                       

                       Computation: 713618 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 837.36
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.2554
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7148
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 0.14s
                      Time elapsed: 00:22:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1143/1 [0m                       

                       Computation: 744480 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 845.12
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.2952
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7202
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 0.13s
                      Time elapsed: 00:22:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1144/1 [0m                       

                       Computation: 737208 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 824.54
               Mean episode length: 248.55
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 163.8653
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7024
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 0.13s
                      Time elapsed: 00:22:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1145/1 [0m                       

                       Computation: 714749 steps/s (collection: 0.047s, learning 0.091s)
                       Mean reward: 818.28
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 162.5300
       Episode_Reward/object_height 0.0385
     Episode_Reward/reaching_object 0.7013
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 0.14s
                      Time elapsed: 00:22:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1146/1 [0m                       

                       Computation: 634508 steps/s (collection: 0.045s, learning 0.110s)
                       Mean reward: 841.54
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 165.7744
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7188
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 37.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 0.15s
                      Time elapsed: 00:22:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1147/1 [0m                       

                       Computation: 764192 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 837.39
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.0197
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7275
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 0.13s
                      Time elapsed: 00:22:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1148/1 [0m                       

                       Computation: 777620 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 845.81
               Mean episode length: 246.95
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.6317
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7405
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 0.13s
                      Time elapsed: 00:22:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1149/1 [0m                       

                       Computation: 712088 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 838.89
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.0386
       Episode_Reward/object_height 0.0400
     Episode_Reward/reaching_object 0.7396
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 0.14s
                      Time elapsed: 00:22:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1150/1 [0m                       

                       Computation: 810301 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 848.28
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.9639
       Episode_Reward/object_height 0.0405
     Episode_Reward/reaching_object 0.7429
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 0.12s
                      Time elapsed: 00:22:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1151/1 [0m                       

                       Computation: 735637 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 852.75
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.1793
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7541
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 0.13s
                      Time elapsed: 00:22:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1152/1 [0m                       

                       Computation: 809048 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 857.18
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.1798
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7483
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 0.12s
                      Time elapsed: 00:22:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1153/1 [0m                       

                       Computation: 763760 steps/s (collection: 0.044s, learning 0.085s)
                       Mean reward: 847.25
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.1729
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7445
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 0.13s
                      Time elapsed: 00:22:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1154/1 [0m                       

                       Computation: 819940 steps/s (collection: 0.046s, learning 0.074s)
                       Mean reward: 839.77
               Mean episode length: 249.01
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.3245
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7410
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 0.12s
                      Time elapsed: 00:22:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1155/1 [0m                       

                       Computation: 750349 steps/s (collection: 0.045s, learning 0.087s)
                       Mean reward: 829.50
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 164.9329
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7298
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 0.13s
                      Time elapsed: 00:22:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1156/1 [0m                       

                       Computation: 815176 steps/s (collection: 0.043s, learning 0.078s)
                       Mean reward: 834.20
               Mean episode length: 248.84
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.2567
       Episode_Reward/object_height 0.0402
     Episode_Reward/reaching_object 0.7266
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 0.12s
                      Time elapsed: 00:22:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1157/1 [0m                       

                       Computation: 740189 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 826.47
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.7613
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7128
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 34.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 0.13s
                      Time elapsed: 00:22:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1158/1 [0m                       

                       Computation: 786232 steps/s (collection: 0.045s, learning 0.081s)
                       Mean reward: 817.66
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.3094
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7076
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 0.13s
                      Time elapsed: 00:22:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1159/1 [0m                       

                       Computation: 771435 steps/s (collection: 0.047s, learning 0.081s)
                       Mean reward: 786.83
               Mean episode length: 246.05
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 157.7752
       Episode_Reward/object_height 0.0382
     Episode_Reward/reaching_object 0.6827
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 0.13s
                      Time elapsed: 00:22:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1160/1 [0m                       

                       Computation: 769160 steps/s (collection: 0.047s, learning 0.081s)
                       Mean reward: 813.91
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.3949
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7040
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 0.13s
                      Time elapsed: 00:22:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1161/1 [0m                       

                       Computation: 827032 steps/s (collection: 0.045s, learning 0.074s)
                       Mean reward: 816.39
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.3339
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7068
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 0.12s
                      Time elapsed: 00:22:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1162/1 [0m                       

                       Computation: 745654 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 816.77
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.2617
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7086
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 0.13s
                      Time elapsed: 00:22:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1163/1 [0m                       

                       Computation: 686432 steps/s (collection: 0.041s, learning 0.102s)
                       Mean reward: 811.17
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.4633
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7136
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 0.14s
                      Time elapsed: 00:22:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1164/1 [0m                       

                       Computation: 743799 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 816.78
               Mean episode length: 246.21
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.6761
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7177
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 0.13s
                      Time elapsed: 00:22:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1165/1 [0m                       

                       Computation: 732046 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 819.88
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.1306
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7209
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 0.13s
                      Time elapsed: 00:22:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1166/1 [0m                       

                       Computation: 606680 steps/s (collection: 0.045s, learning 0.117s)
                       Mean reward: 801.21
               Mean episode length: 248.64
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 159.6587
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7029
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 0.16s
                      Time elapsed: 00:22:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1167/1 [0m                       

                       Computation: 717458 steps/s (collection: 0.041s, learning 0.097s)
                       Mean reward: 813.93
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.6640
       Episode_Reward/object_height 0.0400
     Episode_Reward/reaching_object 0.7120
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 35.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 0.14s
                      Time elapsed: 00:22:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1168/1 [0m                       

                       Computation: 836629 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 803.81
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 159.5392
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7048
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 0.12s
                      Time elapsed: 00:22:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1169/1 [0m                       

                       Computation: 857400 steps/s (collection: 0.041s, learning 0.074s)
                       Mean reward: 814.09
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.4649
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7197
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 0.11s
                      Time elapsed: 00:22:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1170/1 [0m                       

                       Computation: 751654 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 792.56
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 157.8649
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.6978
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 0.13s
                      Time elapsed: 00:22:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1171/1 [0m                       

                       Computation: 805249 steps/s (collection: 0.044s, learning 0.079s)
                       Mean reward: 815.91
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.7131
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7172
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 0.12s
                      Time elapsed: 00:22:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1172/1 [0m                       

                       Computation: 699579 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 825.76
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.2885
       Episode_Reward/object_height 0.0417
     Episode_Reward/reaching_object 0.7363
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 0.14s
                      Time elapsed: 00:22:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1173/1 [0m                       

                       Computation: 805720 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 827.60
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.9514
       Episode_Reward/object_height 0.0413
     Episode_Reward/reaching_object 0.7305
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 0.12s
                      Time elapsed: 00:22:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1174/1 [0m                       

                       Computation: 756002 steps/s (collection: 0.048s, learning 0.082s)
                       Mean reward: 781.02
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 155.5558
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7004
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 0.13s
                      Time elapsed: 00:22:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1175/1 [0m                       

                       Computation: 839920 steps/s (collection: 0.043s, learning 0.075s)
                       Mean reward: 792.70
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 158.0151
       Episode_Reward/object_height 0.0400
     Episode_Reward/reaching_object 0.6957
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 0.12s
                      Time elapsed: 00:22:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1176/1 [0m                       

                       Computation: 796106 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 808.21
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 161.1305
       Episode_Reward/object_height 0.0411
     Episode_Reward/reaching_object 0.7139
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 0.12s
                      Time elapsed: 00:23:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1177/1 [0m                       

                       Computation: 798450 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 820.84
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.0706
       Episode_Reward/object_height 0.0416
     Episode_Reward/reaching_object 0.7292
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 0.12s
                      Time elapsed: 00:23:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1178/1 [0m                       

                       Computation: 764923 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 832.33
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.7524
       Episode_Reward/object_height 0.0419
     Episode_Reward/reaching_object 0.7386
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 32.0000
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 0.13s
                      Time elapsed: 00:23:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1179/1 [0m                       

                       Computation: 800758 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 806.95
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0004
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.8534
       Episode_Reward/object_height 0.0411
     Episode_Reward/reaching_object 0.7215
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 0.12s
                      Time elapsed: 00:23:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1180/1 [0m                       

                       Computation: 714807 steps/s (collection: 0.042s, learning 0.096s)
                       Mean reward: 837.13
               Mean episode length: 247.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.0717
       Episode_Reward/object_height 0.0420
     Episode_Reward/reaching_object 0.7374
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 0.14s
                      Time elapsed: 00:23:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1181/1 [0m                       

                       Computation: 752547 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 841.83
               Mean episode length: 248.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.4078
       Episode_Reward/object_height 0.0428
     Episode_Reward/reaching_object 0.7437
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 0.13s
                      Time elapsed: 00:23:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1182/1 [0m                       

                       Computation: 797764 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 839.40
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.5558
       Episode_Reward/object_height 0.0426
     Episode_Reward/reaching_object 0.7430
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 0.12s
                      Time elapsed: 00:23:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1183/1 [0m                       

                       Computation: 743992 steps/s (collection: 0.039s, learning 0.093s)
                       Mean reward: 834.14
               Mean episode length: 248.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.6050
       Episode_Reward/object_height 0.0425
     Episode_Reward/reaching_object 0.7343
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 0.13s
                      Time elapsed: 00:23:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1184/1 [0m                       

                       Computation: 727514 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 848.12
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.9167
       Episode_Reward/object_height 0.0435
     Episode_Reward/reaching_object 0.7445
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 0.14s
                      Time elapsed: 00:23:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1185/1 [0m                       

                       Computation: 751613 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 825.37
               Mean episode length: 247.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.8295
       Episode_Reward/object_height 0.0422
     Episode_Reward/reaching_object 0.7249
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 0.13s
                      Time elapsed: 00:23:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1186/1 [0m                       

                       Computation: 758378 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 828.06
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.7681
       Episode_Reward/object_height 0.0430
     Episode_Reward/reaching_object 0.7314
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 0.13s
                      Time elapsed: 00:23:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1187/1 [0m                       

                       Computation: 741654 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 845.56
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.3579
       Episode_Reward/object_height 0.0441
     Episode_Reward/reaching_object 0.7473
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 0.13s
                      Time elapsed: 00:23:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1188/1 [0m                       

                       Computation: 740948 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 833.88
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.7993
       Episode_Reward/object_height 0.0432
     Episode_Reward/reaching_object 0.7370
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 34.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 0.13s
                      Time elapsed: 00:23:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1189/1 [0m                       

                       Computation: 815485 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 797.13
               Mean episode length: 247.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 158.8031
       Episode_Reward/object_height 0.0427
     Episode_Reward/reaching_object 0.7256
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 0.12s
                      Time elapsed: 00:23:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1190/1 [0m                       

                       Computation: 774602 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 829.03
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.0562
       Episode_Reward/object_height 0.0447
     Episode_Reward/reaching_object 0.7521
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 0.13s
                      Time elapsed: 00:23:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1191/1 [0m                       

                       Computation: 664145 steps/s (collection: 0.045s, learning 0.103s)
                       Mean reward: 834.87
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.6212
       Episode_Reward/object_height 0.0456
     Episode_Reward/reaching_object 0.7499
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 0.15s
                      Time elapsed: 00:23:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1192/1 [0m                       

                       Computation: 733258 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 842.87
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.8261
       Episode_Reward/object_height 0.0465
     Episode_Reward/reaching_object 0.7533
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 0.13s
                      Time elapsed: 00:23:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1193/1 [0m                       

                       Computation: 769626 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 828.05
               Mean episode length: 248.81
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.2564
       Episode_Reward/object_height 0.0461
     Episode_Reward/reaching_object 0.7488
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 0.13s
                      Time elapsed: 00:23:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1194/1 [0m                       

                       Computation: 702137 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 812.36
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.4733
       Episode_Reward/object_height 0.0461
     Episode_Reward/reaching_object 0.7428
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 0.14s
                      Time elapsed: 00:23:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1195/1 [0m                       

                       Computation: 769945 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 826.93
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.7967
       Episode_Reward/object_height 0.0465
     Episode_Reward/reaching_object 0.7514
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 0.13s
                      Time elapsed: 00:23:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1196/1 [0m                       

                       Computation: 831087 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 828.81
               Mean episode length: 247.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.2965
       Episode_Reward/object_height 0.0475
     Episode_Reward/reaching_object 0.7499
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 0.12s
                      Time elapsed: 00:23:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1197/1 [0m                       

                       Computation: 822168 steps/s (collection: 0.038s, learning 0.081s)
                       Mean reward: 847.22
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.5498
       Episode_Reward/object_height 0.0489
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 0.12s
                      Time elapsed: 00:23:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1198/1 [0m                       

                       Computation: 758735 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 845.80
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.3747
       Episode_Reward/object_height 0.0492
     Episode_Reward/reaching_object 0.7627
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 36.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 0.13s
                      Time elapsed: 00:23:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1199/1 [0m                       

                       Computation: 809651 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 844.63
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.5963
       Episode_Reward/object_height 0.0487
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 0.12s
                      Time elapsed: 00:23:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1200/1 [0m                       

                       Computation: 755926 steps/s (collection: 0.037s, learning 0.094s)
                       Mean reward: 851.16
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.7709
       Episode_Reward/object_height 0.0494
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 0.13s
                      Time elapsed: 00:23:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1201/1 [0m                       

                       Computation: 704088 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 860.11
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.9350
       Episode_Reward/object_height 0.0496
     Episode_Reward/reaching_object 0.7649
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 0.14s
                      Time elapsed: 00:23:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1202/1 [0m                       

                       Computation: 778057 steps/s (collection: 0.046s, learning 0.080s)
                       Mean reward: 843.95
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.4613
       Episode_Reward/object_height 0.0488
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 0.13s
                      Time elapsed: 00:23:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1203/1 [0m                       

                       Computation: 776754 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 853.37
               Mean episode length: 248.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.8021
       Episode_Reward/object_height 0.0487
     Episode_Reward/reaching_object 0.7599
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 0.13s
                      Time elapsed: 00:23:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1204/1 [0m                       

                       Computation: 691696 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 853.62
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.0595
       Episode_Reward/object_height 0.0486
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 0.14s
                      Time elapsed: 00:23:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1205/1 [0m                       

                       Computation: 787552 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 855.21
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.3808
       Episode_Reward/object_height 0.0481
     Episode_Reward/reaching_object 0.7676
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 0.12s
                      Time elapsed: 00:23:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1206/1 [0m                       

                       Computation: 812389 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 838.60
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.6702
       Episode_Reward/object_height 0.0470
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 0.12s
                      Time elapsed: 00:23:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1207/1 [0m                       

                       Computation: 757264 steps/s (collection: 0.048s, learning 0.082s)
                       Mean reward: 862.47
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4180
       Episode_Reward/object_height 0.0479
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 0.13s
                      Time elapsed: 00:23:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1208/1 [0m                       

                       Computation: 786189 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 860.86
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3323
       Episode_Reward/object_height 0.0471
     Episode_Reward/reaching_object 0.7731
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 0.13s
                      Time elapsed: 00:23:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1209/1 [0m                       

                       Computation: 766921 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 851.64
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.2728
       Episode_Reward/object_height 0.0460
     Episode_Reward/reaching_object 0.7563
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 33.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 0.13s
                      Time elapsed: 00:23:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1210/1 [0m                       

                       Computation: 726530 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 864.70
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6655
       Episode_Reward/object_height 0.0464
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 0.14s
                      Time elapsed: 00:23:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1211/1 [0m                       

                       Computation: 830537 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 861.69
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7794
       Episode_Reward/object_height 0.0459
     Episode_Reward/reaching_object 0.7671
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 0.12s
                      Time elapsed: 00:23:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1212/1 [0m                       

                       Computation: 768393 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 860.94
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3936
       Episode_Reward/object_height 0.0460
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 0.13s
                      Time elapsed: 00:23:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1213/1 [0m                       

                       Computation: 833138 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 855.00
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8507
       Episode_Reward/object_height 0.0453
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 0.12s
                      Time elapsed: 00:23:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1214/1 [0m                       

                       Computation: 743752 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 861.36
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1973
       Episode_Reward/object_height 0.0456
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 0.13s
                      Time elapsed: 00:23:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1215/1 [0m                       

                       Computation: 730320 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 855.85
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6109
       Episode_Reward/object_height 0.0449
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 0.13s
                      Time elapsed: 00:23:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1216/1 [0m                       

                       Computation: 820140 steps/s (collection: 0.038s, learning 0.082s)
                       Mean reward: 848.18
               Mean episode length: 248.09
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.6038
       Episode_Reward/object_height 0.0439
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 0.12s
                      Time elapsed: 00:23:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1217/1 [0m                       

                       Computation: 767692 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 862.13
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6946
       Episode_Reward/object_height 0.0446
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 0.13s
                      Time elapsed: 00:23:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1218/1 [0m                       

                       Computation: 699584 steps/s (collection: 0.041s, learning 0.100s)
                       Mean reward: 856.63
               Mean episode length: 249.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3473
       Episode_Reward/object_height 0.0439
     Episode_Reward/reaching_object 0.7637
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 0.14s
                      Time elapsed: 00:23:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1219/1 [0m                       

                       Computation: 756439 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 854.02
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.2619
       Episode_Reward/object_height 0.0432
     Episode_Reward/reaching_object 0.7612
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 35.0417
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 0.13s
                      Time elapsed: 00:23:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1220/1 [0m                       

                       Computation: 721527 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 835.30
               Mean episode length: 247.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.4007
       Episode_Reward/object_height 0.0423
     Episode_Reward/reaching_object 0.7426
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 0.14s
                      Time elapsed: 00:23:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1221/1 [0m                       

                       Computation: 731254 steps/s (collection: 0.048s, learning 0.087s)
                       Mean reward: 849.80
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.5685
       Episode_Reward/object_height 0.0429
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 0.13s
                      Time elapsed: 00:23:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1222/1 [0m                       

                       Computation: 750927 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 858.93
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2070
       Episode_Reward/object_height 0.0427
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 0.13s
                      Time elapsed: 00:23:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1223/1 [0m                       

                       Computation: 701729 steps/s (collection: 0.043s, learning 0.097s)
                       Mean reward: 850.07
               Mean episode length: 247.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.3785
       Episode_Reward/object_height 0.0426
     Episode_Reward/reaching_object 0.7626
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 0.14s
                      Time elapsed: 00:23:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1224/1 [0m                       

                       Computation: 803069 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 842.80
               Mean episode length: 245.63
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.1824
       Episode_Reward/object_height 0.0422
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 0.12s
                      Time elapsed: 00:23:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1225/1 [0m                       

                       Computation: 835603 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 845.01
               Mean episode length: 248.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.4706
       Episode_Reward/object_height 0.0422
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 0.12s
                      Time elapsed: 00:23:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1226/1 [0m                       

                       Computation: 847396 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 831.45
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.8293
       Episode_Reward/object_height 0.0414
     Episode_Reward/reaching_object 0.7518
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 0.12s
                      Time elapsed: 00:23:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1227/1 [0m                       

                       Computation: 836661 steps/s (collection: 0.040s, learning 0.077s)
                       Mean reward: 858.01
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7726
       Episode_Reward/object_height 0.0425
     Episode_Reward/reaching_object 0.7705
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 17.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 0.12s
                      Time elapsed: 00:23:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1228/1 [0m                       

                       Computation: 795672 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 858.23
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8174
       Episode_Reward/object_height 0.0425
     Episode_Reward/reaching_object 0.7734
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 0.12s
                      Time elapsed: 00:23:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1229/1 [0m                       

                       Computation: 677901 steps/s (collection: 0.044s, learning 0.102s)
                       Mean reward: 848.60
               Mean episode length: 248.31
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.4717
       Episode_Reward/object_height 0.0421
     Episode_Reward/reaching_object 0.7683
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 0.15s
                      Time elapsed: 00:23:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1230/1 [0m                       

                       Computation: 602495 steps/s (collection: 0.055s, learning 0.108s)
                       Mean reward: 849.07
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.4658
       Episode_Reward/object_height 0.0411
     Episode_Reward/reaching_object 0.7533
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 31.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 0.16s
                      Time elapsed: 00:23:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1231/1 [0m                       

                       Computation: 719622 steps/s (collection: 0.039s, learning 0.098s)
                       Mean reward: 817.58
               Mean episode length: 246.51
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 162.2494
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7415
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 0.14s
                      Time elapsed: 00:24:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1232/1 [0m                       

                       Computation: 586426 steps/s (collection: 0.044s, learning 0.124s)
                       Mean reward: 836.03
               Mean episode length: 248.24
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.5835
       Episode_Reward/object_height 0.0411
     Episode_Reward/reaching_object 0.7634
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 0.17s
                      Time elapsed: 00:24:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1233/1 [0m                       

                       Computation: 805893 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 866.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1740
       Episode_Reward/object_height 0.0425
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 0.12s
                      Time elapsed: 00:24:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1234/1 [0m                       

                       Computation: 710540 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 863.54
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1700
       Episode_Reward/object_height 0.0425
     Episode_Reward/reaching_object 0.7819
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 0.14s
                      Time elapsed: 00:24:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1235/1 [0m                       

                       Computation: 802813 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 856.45
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4888
       Episode_Reward/object_height 0.0418
     Episode_Reward/reaching_object 0.7719
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 0.12s
                      Time elapsed: 00:24:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1236/1 [0m                       

                       Computation: 786342 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 854.63
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.6443
       Episode_Reward/object_height 0.0416
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 0.13s
                      Time elapsed: 00:24:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1237/1 [0m                       

                       Computation: 704432 steps/s (collection: 0.048s, learning 0.092s)
                       Mean reward: 856.51
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2640
       Episode_Reward/object_height 0.0419
     Episode_Reward/reaching_object 0.7755
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 0.14s
                      Time elapsed: 00:24:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1238/1 [0m                       

                       Computation: 843601 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 856.37
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6515
       Episode_Reward/object_height 0.0417
     Episode_Reward/reaching_object 0.7755
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 0.12s
                      Time elapsed: 00:24:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1239/1 [0m                       

                       Computation: 832712 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 845.42
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.5265
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7618
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 0.12s
                      Time elapsed: 00:24:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1240/1 [0m                       

                       Computation: 809869 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 853.94
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.6306
       Episode_Reward/object_height 0.0405
     Episode_Reward/reaching_object 0.7525
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 33.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 0.12s
                      Time elapsed: 00:24:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1241/1 [0m                       

                       Computation: 701918 steps/s (collection: 0.045s, learning 0.096s)
                       Mean reward: 849.72
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.7092
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 0.14s
                      Time elapsed: 00:24:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1242/1 [0m                       

                       Computation: 733904 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 836.75
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.7393
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7434
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 0.13s
                      Time elapsed: 00:24:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1243/1 [0m                       

                       Computation: 836525 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 860.15
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2504
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 0.12s
                      Time elapsed: 00:24:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1244/1 [0m                       

                       Computation: 823369 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 856.53
               Mean episode length: 248.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2102
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7745
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 0.12s
                      Time elapsed: 00:24:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1245/1 [0m                       

                       Computation: 806490 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 845.63
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.6699
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 0.12s
                      Time elapsed: 00:24:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1246/1 [0m                       

                       Computation: 767443 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 849.70
               Mean episode length: 248.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7820
       Episode_Reward/object_height 0.0402
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 0.13s
                      Time elapsed: 00:24:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1247/1 [0m                       

                       Computation: 720937 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 836.53
               Mean episode length: 248.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.3604
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7542
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 0.14s
                      Time elapsed: 00:24:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1248/1 [0m                       

                       Computation: 752863 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 826.62
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 164.5751
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 0.13s
                      Time elapsed: 00:24:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1249/1 [0m                       

                       Computation: 722737 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 829.13
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 164.8031
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7504
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 0.14s
                      Time elapsed: 00:24:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1250/1 [0m                       

                       Computation: 648861 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 842.72
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.2128
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7664
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 35.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 0.15s
                      Time elapsed: 00:24:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1251/1 [0m                       

                       Computation: 672279 steps/s (collection: 0.040s, learning 0.106s)
                       Mean reward: 833.53
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.4501
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 0.15s
                      Time elapsed: 00:24:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1252/1 [0m                       

                       Computation: 737953 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 814.05
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 161.7300
       Episode_Reward/object_height 0.0381
     Episode_Reward/reaching_object 0.7199
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 0.13s
                      Time elapsed: 00:24:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1253/1 [0m                       

                       Computation: 578579 steps/s (collection: 0.041s, learning 0.129s)
                       Mean reward: 800.66
               Mean episode length: 248.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 159.7986
       Episode_Reward/object_height 0.0377
     Episode_Reward/reaching_object 0.7084
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 0.17s
                      Time elapsed: 00:24:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1254/1 [0m                       

                       Computation: 787590 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 800.33
               Mean episode length: 248.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 158.7938
       Episode_Reward/object_height 0.0374
     Episode_Reward/reaching_object 0.7117
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 0.12s
                      Time elapsed: 00:24:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1255/1 [0m                       

                       Computation: 690512 steps/s (collection: 0.053s, learning 0.089s)
                       Mean reward: 812.21
               Mean episode length: 248.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 162.1272
       Episode_Reward/object_height 0.0384
     Episode_Reward/reaching_object 0.7215
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 0.14s
                      Time elapsed: 00:24:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1256/1 [0m                       

                       Computation: 731787 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 837.21
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.3118
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7435
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 0.13s
                      Time elapsed: 00:24:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1257/1 [0m                       

                       Computation: 819103 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 818.91
               Mean episode length: 247.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 163.5650
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7388
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 0.12s
                      Time elapsed: 00:24:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1258/1 [0m                       

                       Computation: 708576 steps/s (collection: 0.052s, learning 0.087s)
                       Mean reward: 841.34
               Mean episode length: 248.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.0336
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7437
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 0.14s
                      Time elapsed: 00:24:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1259/1 [0m                       

                       Computation: 764959 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 856.90
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4336
       Episode_Reward/object_height 0.0410
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 0.13s
                      Time elapsed: 00:24:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1260/1 [0m                       

                       Computation: 784160 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 864.40
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1945
       Episode_Reward/object_height 0.0415
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 0.13s
                      Time elapsed: 00:24:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1261/1 [0m                       

                       Computation: 780018 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 852.54
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1371
       Episode_Reward/object_height 0.0416
     Episode_Reward/reaching_object 0.7678
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 32.9167
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 0.13s
                      Time elapsed: 00:24:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1262/1 [0m                       

                       Computation: 814226 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 850.56
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.1951
       Episode_Reward/object_height 0.0407
     Episode_Reward/reaching_object 0.7552
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 0.12s
                      Time elapsed: 00:24:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1263/1 [0m                       

                       Computation: 550510 steps/s (collection: 0.043s, learning 0.135s)
                       Mean reward: 841.78
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.1537
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7551
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 0.18s
                      Time elapsed: 00:24:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1264/1 [0m                       

                       Computation: 765749 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 846.44
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.9461
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 0.13s
                      Time elapsed: 00:24:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1265/1 [0m                       

                       Computation: 784489 steps/s (collection: 0.046s, learning 0.079s)
                       Mean reward: 864.37
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4303
       Episode_Reward/object_height 0.0415
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 0.13s
                      Time elapsed: 00:24:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1266/1 [0m                       

                       Computation: 812189 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 858.67
               Mean episode length: 248.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8805
       Episode_Reward/object_height 0.0416
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 0.12s
                      Time elapsed: 00:24:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1267/1 [0m                       

                       Computation: 766066 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 844.82
               Mean episode length: 248.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.6919
       Episode_Reward/object_height 0.0412
     Episode_Reward/reaching_object 0.7596
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 0.13s
                      Time elapsed: 00:24:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1268/1 [0m                       

                       Computation: 821582 steps/s (collection: 0.043s, learning 0.077s)
                       Mean reward: 837.31
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.2569
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 0.12s
                      Time elapsed: 00:24:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1269/1 [0m                       

                       Computation: 608544 steps/s (collection: 0.047s, learning 0.115s)
                       Mean reward: 839.75
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.8934
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 0.16s
                      Time elapsed: 00:24:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1270/1 [0m                       

                       Computation: 608370 steps/s (collection: 0.042s, learning 0.119s)
                       Mean reward: 842.45
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.4050
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 0.16s
                      Time elapsed: 00:24:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1271/1 [0m                       

                       Computation: 812330 steps/s (collection: 0.045s, learning 0.076s)
                       Mean reward: 856.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.0545
       Episode_Reward/object_height 0.0414
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 34.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 0.12s
                      Time elapsed: 00:24:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1272/1 [0m                       

                       Computation: 767718 steps/s (collection: 0.045s, learning 0.083s)
                       Mean reward: 854.86
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2953
       Episode_Reward/object_height 0.0414
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 0.13s
                      Time elapsed: 00:24:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1273/1 [0m                       

                       Computation: 648644 steps/s (collection: 0.046s, learning 0.106s)
                       Mean reward: 862.83
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1062
       Episode_Reward/object_height 0.0419
     Episode_Reward/reaching_object 0.7835
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 0.15s
                      Time elapsed: 00:24:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1274/1 [0m                       

                       Computation: 683491 steps/s (collection: 0.047s, learning 0.097s)
                       Mean reward: 859.09
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.2759
       Episode_Reward/object_height 0.0415
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 0.14s
                      Time elapsed: 00:24:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1275/1 [0m                       

                       Computation: 598706 steps/s (collection: 0.058s, learning 0.106s)
                       Mean reward: 863.73
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0761
       Episode_Reward/object_height 0.0418
     Episode_Reward/reaching_object 0.7757
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 0.16s
                      Time elapsed: 00:24:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1276/1 [0m                       

                       Computation: 708153 steps/s (collection: 0.040s, learning 0.099s)
                       Mean reward: 870.98
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0086
       Episode_Reward/object_height 0.0419
     Episode_Reward/reaching_object 0.7825
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 0.14s
                      Time elapsed: 00:24:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1277/1 [0m                       

                       Computation: 750522 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 869.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5382
       Episode_Reward/object_height 0.0420
     Episode_Reward/reaching_object 0.7907
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 0.13s
                      Time elapsed: 00:24:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1278/1 [0m                       

                       Computation: 603043 steps/s (collection: 0.045s, learning 0.119s)
                       Mean reward: 864.31
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7920
       Episode_Reward/object_height 0.0417
     Episode_Reward/reaching_object 0.7846
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 0.16s
                      Time elapsed: 00:24:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1279/1 [0m                       

                       Computation: 773894 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 871.27
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4297
       Episode_Reward/object_height 0.0417
     Episode_Reward/reaching_object 0.7792
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 0.13s
                      Time elapsed: 00:24:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1280/1 [0m                       

                       Computation: 793260 steps/s (collection: 0.044s, learning 0.080s)
                       Mean reward: 855.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7155
       Episode_Reward/object_height 0.0413
     Episode_Reward/reaching_object 0.7747
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 0.12s
                      Time elapsed: 00:24:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1281/1 [0m                       

                       Computation: 775397 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 853.87
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.6216
       Episode_Reward/object_height 0.0412
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 0.13s
                      Time elapsed: 00:24:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1282/1 [0m                       

                       Computation: 768768 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 870.61
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9017
       Episode_Reward/object_height 0.0414
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 31.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 0.13s
                      Time elapsed: 00:24:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1283/1 [0m                       

                       Computation: 764265 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 873.54
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8508
       Episode_Reward/object_height 0.0416
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 0.13s
                      Time elapsed: 00:25:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1284/1 [0m                       

                       Computation: 764729 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 872.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8784
       Episode_Reward/object_height 0.0419
     Episode_Reward/reaching_object 0.7952
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 0.13s
                      Time elapsed: 00:25:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1285/1 [0m                       

                       Computation: 755405 steps/s (collection: 0.048s, learning 0.082s)
                       Mean reward: 869.63
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5055
       Episode_Reward/object_height 0.0415
     Episode_Reward/reaching_object 0.7909
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 0.13s
                      Time elapsed: 00:25:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1286/1 [0m                       

                       Computation: 670710 steps/s (collection: 0.043s, learning 0.104s)
                       Mean reward: 856.56
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4329
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7792
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 0.15s
                      Time elapsed: 00:25:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1287/1 [0m                       

                       Computation: 835127 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 872.67
               Mean episode length: 248.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6379
       Episode_Reward/object_height 0.0413
     Episode_Reward/reaching_object 0.7888
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 0.12s
                      Time elapsed: 00:25:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1288/1 [0m                       

                       Computation: 790090 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 857.17
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.7117
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7690
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 0.12s
                      Time elapsed: 00:25:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1289/1 [0m                       

                       Computation: 800486 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 843.42
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.5680
       Episode_Reward/object_height 0.0402
     Episode_Reward/reaching_object 0.7616
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 0.12s
                      Time elapsed: 00:25:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1290/1 [0m                       

                       Computation: 836125 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 845.66
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.2816
       Episode_Reward/object_height 0.0400
     Episode_Reward/reaching_object 0.7505
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 0.12s
                      Time elapsed: 00:25:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1291/1 [0m                       

                       Computation: 819179 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 824.31
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 163.8342
       Episode_Reward/object_height 0.0386
     Episode_Reward/reaching_object 0.7410
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 0.12s
                      Time elapsed: 00:25:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1292/1 [0m                       

                       Computation: 812890 steps/s (collection: 0.043s, learning 0.078s)
                       Mean reward: 848.66
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.6053
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 33.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 0.12s
                      Time elapsed: 00:25:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1293/1 [0m                       

                       Computation: 812003 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 843.47
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.3979
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7609
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 0.12s
                      Time elapsed: 00:25:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1294/1 [0m                       

                       Computation: 832526 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 863.40
               Mean episode length: 248.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8329
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7830
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 0.12s
                      Time elapsed: 00:25:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1295/1 [0m                       

                       Computation: 750973 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 865.84
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6050
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7748
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 0.13s
                      Time elapsed: 00:25:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1296/1 [0m                       

                       Computation: 777020 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 865.58
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5129
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 0.13s
                      Time elapsed: 00:25:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1297/1 [0m                       

                       Computation: 751317 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 866.32
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4368
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 0.13s
                      Time elapsed: 00:25:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1298/1 [0m                       

                       Computation: 796542 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 856.03
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.3395
       Episode_Reward/object_height 0.0400
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 0.12s
                      Time elapsed: 00:25:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1299/1 [0m                       

                       Computation: 708727 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 869.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2391
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 0.14s
                      Time elapsed: 00:25:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1300/1 [0m                       

                       Computation: 715617 steps/s (collection: 0.039s, learning 0.099s)
                       Mean reward: 870.36
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2988
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7786
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 0.14s
                      Time elapsed: 00:25:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1301/1 [0m                       

                       Computation: 777661 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 871.62
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7172
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 0.13s
                      Time elapsed: 00:25:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1302/1 [0m                       

                       Computation: 802489 steps/s (collection: 0.044s, learning 0.078s)
                       Mean reward: 858.22
               Mean episode length: 249.27
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7199
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 0.12s
                      Time elapsed: 00:25:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1303/1 [0m                       

                       Computation: 803287 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 865.91
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1221
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 30.0417
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 0.12s
                      Time elapsed: 00:25:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1304/1 [0m                       

                       Computation: 795079 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 866.70
               Mean episode length: 249.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6269
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7669
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 0.12s
                      Time elapsed: 00:25:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1305/1 [0m                       

                       Computation: 648687 steps/s (collection: 0.041s, learning 0.111s)
                       Mean reward: 867.64
               Mean episode length: 248.95
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5633
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 0.15s
                      Time elapsed: 00:25:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1306/1 [0m                       

                       Computation: 822454 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 871.55
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6375
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7696
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.6250
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 0.12s
                      Time elapsed: 00:25:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1307/1 [0m                       

                       Computation: 773867 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 866.23
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7231
       Episode_Reward/object_height 0.0405
     Episode_Reward/reaching_object 0.7707
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 0.13s
                      Time elapsed: 00:25:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1308/1 [0m                       

                       Computation: 766934 steps/s (collection: 0.053s, learning 0.075s)
                       Mean reward: 877.74
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4625
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 0.13s
                      Time elapsed: 00:25:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1309/1 [0m                       

                       Computation: 829763 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 873.03
               Mean episode length: 249.35
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0249
       Episode_Reward/object_height 0.0407
     Episode_Reward/reaching_object 0.7741
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 0.12s
                      Time elapsed: 00:25:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1310/1 [0m                       

                       Computation: 751983 steps/s (collection: 0.051s, learning 0.080s)
                       Mean reward: 873.87
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4673
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7812
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 0.13s
                      Time elapsed: 00:25:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1311/1 [0m                       

                       Computation: 775515 steps/s (collection: 0.046s, learning 0.081s)
                       Mean reward: 873.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9335
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7798
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 0.13s
                      Time elapsed: 00:25:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1312/1 [0m                       

                       Computation: 755085 steps/s (collection: 0.039s, learning 0.092s)
                       Mean reward: 871.51
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4847
       Episode_Reward/object_height 0.0407
     Episode_Reward/reaching_object 0.7785
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 0.13s
                      Time elapsed: 00:25:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1313/1 [0m                       

                       Computation: 738765 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 873.01
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4532
       Episode_Reward/object_height 0.0407
     Episode_Reward/reaching_object 0.7758
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 32.5417
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 0.13s
                      Time elapsed: 00:25:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1314/1 [0m                       

                       Computation: 805674 steps/s (collection: 0.041s, learning 0.082s)
                       Mean reward: 873.38
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7528
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7840
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 0.12s
                      Time elapsed: 00:25:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1315/1 [0m                       

                       Computation: 769107 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 877.94
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0451
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7924
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 0.13s
                      Time elapsed: 00:25:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1316/1 [0m                       

                       Computation: 802457 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 879.30
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8501
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7868
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 0.12s
                      Time elapsed: 00:25:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1317/1 [0m                       

                       Computation: 792187 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 880.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.1337
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7872
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 0.12s
                      Time elapsed: 00:25:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1318/1 [0m                       

                       Computation: 803147 steps/s (collection: 0.039s, learning 0.083s)
                       Mean reward: 865.55
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2791
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7781
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 0.12s
                      Time elapsed: 00:25:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1319/1 [0m                       

                       Computation: 776019 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 873.95
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8055
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 0.13s
                      Time elapsed: 00:25:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1320/1 [0m                       

                       Computation: 738882 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 871.53
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4375
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7735
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 0.13s
                      Time elapsed: 00:25:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1321/1 [0m                       

                       Computation: 705624 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 876.76
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8680
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7801
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 0.14s
                      Time elapsed: 00:25:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1322/1 [0m                       

                       Computation: 717247 steps/s (collection: 0.044s, learning 0.094s)
                       Mean reward: 877.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5027
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7860
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 0.14s
                      Time elapsed: 00:25:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1323/1 [0m                       

                       Computation: 808905 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 878.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6193
       Episode_Reward/object_height 0.0400
     Episode_Reward/reaching_object 0.7841
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 34.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 0.12s
                      Time elapsed: 00:25:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1324/1 [0m                       

                       Computation: 795672 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 870.07
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2008
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7809
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 0.12s
                      Time elapsed: 00:25:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1325/1 [0m                       

                       Computation: 847455 steps/s (collection: 0.039s, learning 0.077s)
                       Mean reward: 873.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0668
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 0.12s
                      Time elapsed: 00:25:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1326/1 [0m                       

                       Computation: 814860 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 878.50
               Mean episode length: 249.48
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5492
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7784
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 0.12s
                      Time elapsed: 00:25:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1327/1 [0m                       

                       Computation: 710709 steps/s (collection: 0.050s, learning 0.089s)
                       Mean reward: 877.84
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5184
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7747
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 0.14s
                      Time elapsed: 00:25:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1328/1 [0m                       

                       Computation: 741493 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 876.91
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7185
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 0.13s
                      Time elapsed: 00:25:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1329/1 [0m                       

                       Computation: 771693 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 876.43
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2433
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7749
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 0.13s
                      Time elapsed: 00:25:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1330/1 [0m                       

                       Computation: 642581 steps/s (collection: 0.050s, learning 0.103s)
                       Mean reward: 873.37
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2688
       Episode_Reward/object_height 0.0388
     Episode_Reward/reaching_object 0.7727
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 0.15s
                      Time elapsed: 00:25:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1331/1 [0m                       

                       Computation: 595738 steps/s (collection: 0.042s, learning 0.123s)
                       Mean reward: 879.09
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.1759
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 0.17s
                      Time elapsed: 00:25:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1332/1 [0m                       

                       Computation: 664887 steps/s (collection: 0.046s, learning 0.102s)
                       Mean reward: 875.88
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6162
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7767
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 0.15s
                      Time elapsed: 00:25:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1333/1 [0m                       

                       Computation: 676412 steps/s (collection: 0.041s, learning 0.104s)
                       Mean reward: 880.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.3913
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7864
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 0.15s
                      Time elapsed: 00:25:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1334/1 [0m                       

                       Computation: 818412 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 874.29
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1687
       Episode_Reward/object_height 0.0380
     Episode_Reward/reaching_object 0.7750
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 31.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 0.12s
                      Time elapsed: 00:25:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1335/1 [0m                       

                       Computation: 852732 steps/s (collection: 0.041s, learning 0.074s)
                       Mean reward: 873.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8472
       Episode_Reward/object_height 0.0382
     Episode_Reward/reaching_object 0.7770
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 0.12s
                      Time elapsed: 00:25:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1336/1 [0m                       

                       Computation: 815780 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 858.67
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9782
       Episode_Reward/object_height 0.0377
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 0.12s
                      Time elapsed: 00:25:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1337/1 [0m                       

                       Computation: 827751 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 875.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6279
       Episode_Reward/object_height 0.0384
     Episode_Reward/reaching_object 0.7853
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 0.12s
                      Time elapsed: 00:26:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1338/1 [0m                       

                       Computation: 767098 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 853.92
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.3011
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7559
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 0.13s
                      Time elapsed: 00:26:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1339/1 [0m                       

                       Computation: 777245 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 863.76
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1827
       Episode_Reward/object_height 0.0377
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 0.13s
                      Time elapsed: 00:26:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1340/1 [0m                       

                       Computation: 715068 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 857.72
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7269
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7482
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 0.14s
                      Time elapsed: 00:26:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1341/1 [0m                       

                       Computation: 714784 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 869.39
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9777
       Episode_Reward/object_height 0.0380
     Episode_Reward/reaching_object 0.7566
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 0.14s
                      Time elapsed: 00:26:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1342/1 [0m                       

                       Computation: 788846 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 864.94
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4306
       Episode_Reward/object_height 0.0374
     Episode_Reward/reaching_object 0.7556
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7917
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 0.12s
                      Time elapsed: 00:26:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1343/1 [0m                       

                       Computation: 675490 steps/s (collection: 0.038s, learning 0.108s)
                       Mean reward: 861.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0534
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7383
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 0.15s
                      Time elapsed: 00:26:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1344/1 [0m                       

                       Computation: 761921 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 867.12
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3259
       Episode_Reward/object_height 0.0374
     Episode_Reward/reaching_object 0.7408
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 33.6250
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 0.13s
                      Time elapsed: 00:26:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1345/1 [0m                       

                       Computation: 727407 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 862.52
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6717
       Episode_Reward/object_height 0.0374
     Episode_Reward/reaching_object 0.7482
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 0.14s
                      Time elapsed: 00:26:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1346/1 [0m                       

                       Computation: 795678 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 875.43
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9811
       Episode_Reward/object_height 0.0377
     Episode_Reward/reaching_object 0.7583
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 0.12s
                      Time elapsed: 00:26:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1347/1 [0m                       

                       Computation: 785615 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 866.17
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6085
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7416
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 0.13s
                      Time elapsed: 00:26:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1348/1 [0m                       

                       Computation: 858399 steps/s (collection: 0.038s, learning 0.077s)
                       Mean reward: 864.97
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0341
       Episode_Reward/object_height 0.0372
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 0.11s
                      Time elapsed: 00:26:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1349/1 [0m                       

                       Computation: 751125 steps/s (collection: 0.040s, learning 0.091s)
                       Mean reward: 865.06
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.0327
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 0.13s
                      Time elapsed: 00:26:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1350/1 [0m                       

                       Computation: 761851 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 855.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.8344
       Episode_Reward/object_height 0.0364
     Episode_Reward/reaching_object 0.7341
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 0.13s
                      Time elapsed: 00:26:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1351/1 [0m                       

                       Computation: 746431 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 869.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1637
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7595
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 0.13s
                      Time elapsed: 00:26:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1352/1 [0m                       

                       Computation: 843661 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 876.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5450
       Episode_Reward/object_height 0.0372
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 0.12s
                      Time elapsed: 00:26:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1353/1 [0m                       

                       Computation: 792511 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 878.70
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0952
       Episode_Reward/object_height 0.0371
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 0.12s
                      Time elapsed: 00:26:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1354/1 [0m                       

                       Computation: 825849 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 880.22
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.4944
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 0.12s
                      Time elapsed: 00:26:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1355/1 [0m                       

                       Computation: 786559 steps/s (collection: 0.040s, learning 0.085s)
                       Mean reward: 883.27
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 176.0033
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7912
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 30.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 0.12s
                      Time elapsed: 00:26:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1356/1 [0m                       

                       Computation: 837984 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 884.00
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 176.0359
       Episode_Reward/object_height 0.0366
     Episode_Reward/reaching_object 0.7995
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 0.12s
                      Time elapsed: 00:26:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1357/1 [0m                       

                       Computation: 779765 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 883.76
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.9224
       Episode_Reward/object_height 0.0366
     Episode_Reward/reaching_object 0.7998
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 0.13s
                      Time elapsed: 00:26:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1358/1 [0m                       

                       Computation: 861414 steps/s (collection: 0.040s, learning 0.075s)
                       Mean reward: 881.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.5573
       Episode_Reward/object_height 0.0366
     Episode_Reward/reaching_object 0.7976
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 0.11s
                      Time elapsed: 00:26:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1359/1 [0m                       

                       Computation: 759531 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 881.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.4127
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7922
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 0.13s
                      Time elapsed: 00:26:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1360/1 [0m                       

                       Computation: 814747 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 882.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.7836
       Episode_Reward/object_height 0.0367
     Episode_Reward/reaching_object 0.7943
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 0.12s
                      Time elapsed: 00:26:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1361/1 [0m                       

                       Computation: 771211 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 884.67
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 176.1895
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7955
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 0.13s
                      Time elapsed: 00:26:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1362/1 [0m                       

                       Computation: 751637 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 881.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.6251
       Episode_Reward/object_height 0.0367
     Episode_Reward/reaching_object 0.7966
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 0.13s
                      Time elapsed: 00:26:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1363/1 [0m                       

                       Computation: 687473 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 876.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5288
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7958
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 0.14s
                      Time elapsed: 00:26:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1364/1 [0m                       

                       Computation: 704485 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 884.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 176.0768
       Episode_Reward/object_height 0.0368
     Episode_Reward/reaching_object 0.8038
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 0.14s
                      Time elapsed: 00:26:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1365/1 [0m                       

                       Computation: 725328 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 883.06
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.4453
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7996
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 32.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 0.14s
                      Time elapsed: 00:26:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1366/1 [0m                       

                       Computation: 721499 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 884.59
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.9834
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7993
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 0.14s
                      Time elapsed: 00:26:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1367/1 [0m                       

                       Computation: 694554 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 886.81
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 176.5927
       Episode_Reward/object_height 0.0371
     Episode_Reward/reaching_object 0.8094
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 0.14s
                      Time elapsed: 00:26:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1368/1 [0m                       

                       Computation: 836527 steps/s (collection: 0.039s, learning 0.079s)
                       Mean reward: 883.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.9198
       Episode_Reward/object_height 0.0368
     Episode_Reward/reaching_object 0.8032
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 0.12s
                      Time elapsed: 00:26:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1369/1 [0m                       

                       Computation: 805663 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 879.98
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.3025
       Episode_Reward/object_height 0.0367
     Episode_Reward/reaching_object 0.8016
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 0.12s
                      Time elapsed: 00:26:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1370/1 [0m                       

                       Computation: 778063 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 872.84
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4260
       Episode_Reward/object_height 0.0361
     Episode_Reward/reaching_object 0.7923
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 0.13s
                      Time elapsed: 00:26:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1371/1 [0m                       

                       Computation: 789351 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 873.15
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4534
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7868
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 0.12s
                      Time elapsed: 00:26:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1372/1 [0m                       

                       Computation: 806978 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 866.80
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3261
       Episode_Reward/object_height 0.0355
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 0.12s
                      Time elapsed: 00:26:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1373/1 [0m                       

                       Computation: 764929 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 859.25
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.7939
       Episode_Reward/object_height 0.0348
     Episode_Reward/reaching_object 0.7820
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 0.13s
                      Time elapsed: 00:26:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1374/1 [0m                       

                       Computation: 821746 steps/s (collection: 0.037s, learning 0.082s)
                       Mean reward: 868.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4371
       Episode_Reward/object_height 0.0348
     Episode_Reward/reaching_object 0.7921
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 0.12s
                      Time elapsed: 00:26:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1375/1 [0m                       

                       Computation: 780000 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 867.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6719
       Episode_Reward/object_height 0.0343
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 34.9583
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 0.13s
                      Time elapsed: 00:26:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1376/1 [0m                       

                       Computation: 866046 steps/s (collection: 0.039s, learning 0.074s)
                       Mean reward: 868.55
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8660
       Episode_Reward/object_height 0.0339
     Episode_Reward/reaching_object 0.7790
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 0.11s
                      Time elapsed: 00:26:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1377/1 [0m                       

                       Computation: 786273 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 882.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.6128
       Episode_Reward/object_height 0.0343
     Episode_Reward/reaching_object 0.7852
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 0.13s
                      Time elapsed: 00:26:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1378/1 [0m                       

                       Computation: 805389 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 874.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0305
       Episode_Reward/object_height 0.0337
     Episode_Reward/reaching_object 0.7763
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 0.12s
                      Time elapsed: 00:26:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1379/1 [0m                       

                       Computation: 743372 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 871.09
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0013
       Episode_Reward/object_height 0.0332
     Episode_Reward/reaching_object 0.7712
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 0.13s
                      Time elapsed: 00:26:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1380/1 [0m                       

                       Computation: 735992 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 882.43
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.7522
       Episode_Reward/object_height 0.0341
     Episode_Reward/reaching_object 0.7828
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 0.13s
                      Time elapsed: 00:26:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1381/1 [0m                       

                       Computation: 768032 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 878.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.9846
       Episode_Reward/object_height 0.0334
     Episode_Reward/reaching_object 0.7789
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 0.13s
                      Time elapsed: 00:26:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1382/1 [0m                       

                       Computation: 774596 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 880.73
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.3586
       Episode_Reward/object_height 0.0338
     Episode_Reward/reaching_object 0.7832
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 0.13s
                      Time elapsed: 00:26:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1383/1 [0m                       

                       Computation: 773458 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 873.77
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8374
       Episode_Reward/object_height 0.0332
     Episode_Reward/reaching_object 0.7759
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 0.13s
                      Time elapsed: 00:26:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1384/1 [0m                       

                       Computation: 791490 steps/s (collection: 0.039s, learning 0.086s)
                       Mean reward: 877.18
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4681
       Episode_Reward/object_height 0.0336
     Episode_Reward/reaching_object 0.7813
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 0.12s
                      Time elapsed: 00:26:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1385/1 [0m                       

                       Computation: 618385 steps/s (collection: 0.044s, learning 0.115s)
                       Mean reward: 879.61
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0940
       Episode_Reward/object_height 0.0341
     Episode_Reward/reaching_object 0.7839
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 0.16s
                      Time elapsed: 00:26:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1386/1 [0m                       

                       Computation: 786597 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 869.91
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0243
       Episode_Reward/object_height 0.0337
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 32.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 0.12s
                      Time elapsed: 00:26:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1387/1 [0m                       

                       Computation: 667183 steps/s (collection: 0.054s, learning 0.094s)
                       Mean reward: 869.76
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2312
       Episode_Reward/object_height 0.0342
     Episode_Reward/reaching_object 0.7749
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 0.15s
                      Time elapsed: 00:26:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1388/1 [0m                       

                       Computation: 652178 steps/s (collection: 0.040s, learning 0.111s)
                       Mean reward: 872.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6229
       Episode_Reward/object_height 0.0350
     Episode_Reward/reaching_object 0.7774
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 0.15s
                      Time elapsed: 00:26:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1389/1 [0m                       

                       Computation: 710056 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 871.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6341
       Episode_Reward/object_height 0.0351
     Episode_Reward/reaching_object 0.7784
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 0.14s
                      Time elapsed: 00:26:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1390/1 [0m                       

                       Computation: 725057 steps/s (collection: 0.049s, learning 0.087s)
                       Mean reward: 866.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5465
       Episode_Reward/object_height 0.0348
     Episode_Reward/reaching_object 0.7726
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 0.14s
                      Time elapsed: 00:26:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1391/1 [0m                       

                       Computation: 773175 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 868.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1500
       Episode_Reward/object_height 0.0353
     Episode_Reward/reaching_object 0.7651
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 0.13s
                      Time elapsed: 00:27:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1392/1 [0m                       

                       Computation: 776463 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 874.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2642
       Episode_Reward/object_height 0.0356
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 0.13s
                      Time elapsed: 00:27:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1393/1 [0m                       

                       Computation: 727960 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 868.88
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6622
       Episode_Reward/object_height 0.0356
     Episode_Reward/reaching_object 0.7652
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 0.14s
                      Time elapsed: 00:27:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1394/1 [0m                       

                       Computation: 808632 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 874.40
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9390
       Episode_Reward/object_height 0.0361
     Episode_Reward/reaching_object 0.7690
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 0.12s
                      Time elapsed: 00:27:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1395/1 [0m                       

                       Computation: 822544 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 871.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7152
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 0.12s
                      Time elapsed: 00:27:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1396/1 [0m                       

                       Computation: 694616 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 878.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4030
       Episode_Reward/object_height 0.0362
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 34.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 0.14s
                      Time elapsed: 00:27:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1397/1 [0m                       

                       Computation: 640161 steps/s (collection: 0.046s, learning 0.108s)
                       Mean reward: 874.62
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0129
       Episode_Reward/object_height 0.0368
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 0.15s
                      Time elapsed: 00:27:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1398/1 [0m                       

                       Computation: 663877 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 881.27
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.2713
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7688
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 0.15s
                      Time elapsed: 00:27:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1399/1 [0m                       

                       Computation: 650504 steps/s (collection: 0.055s, learning 0.096s)
                       Mean reward: 876.42
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4039
       Episode_Reward/object_height 0.0372
     Episode_Reward/reaching_object 0.7629
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 0.15s
                      Time elapsed: 00:27:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1400/1 [0m                       

                       Computation: 606496 steps/s (collection: 0.048s, learning 0.115s)
                       Mean reward: 868.09
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8292
       Episode_Reward/object_height 0.0368
     Episode_Reward/reaching_object 0.7616
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 0.16s
                      Time elapsed: 00:27:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1401/1 [0m                       

                       Computation: 659383 steps/s (collection: 0.052s, learning 0.098s)
                       Mean reward: 872.70
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9141
       Episode_Reward/object_height 0.0367
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 0.15s
                      Time elapsed: 00:27:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1402/1 [0m                       

                       Computation: 764732 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 870.26
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8700
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7558
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 0.13s
                      Time elapsed: 00:27:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1403/1 [0m                       

                       Computation: 825682 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 869.45
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3632
       Episode_Reward/object_height 0.0358
     Episode_Reward/reaching_object 0.7539
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 0.12s
                      Time elapsed: 00:27:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1404/1 [0m                       

                       Computation: 780083 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 874.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2430
       Episode_Reward/object_height 0.0357
     Episode_Reward/reaching_object 0.7614
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 0.13s
                      Time elapsed: 00:27:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1405/1 [0m                       

                       Computation: 712010 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 880.64
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.1729
       Episode_Reward/object_height 0.0356
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 0.14s
                      Time elapsed: 00:27:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1406/1 [0m                       

                       Computation: 725212 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 865.73
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5986
       Episode_Reward/object_height 0.0345
     Episode_Reward/reaching_object 0.7396
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 0.14s
                      Time elapsed: 00:27:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1407/1 [0m                       

                       Computation: 818540 steps/s (collection: 0.043s, learning 0.077s)
                       Mean reward: 865.08
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5492
       Episode_Reward/object_height 0.0336
     Episode_Reward/reaching_object 0.7350
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 31.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 0.12s
                      Time elapsed: 00:27:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1408/1 [0m                       

                       Computation: 776915 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 861.38
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7959
       Episode_Reward/object_height 0.0324
     Episode_Reward/reaching_object 0.7406
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 0.13s
                      Time elapsed: 00:27:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1409/1 [0m                       

                       Computation: 749855 steps/s (collection: 0.047s, learning 0.085s)
                       Mean reward: 866.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5802
       Episode_Reward/object_height 0.0319
     Episode_Reward/reaching_object 0.7456
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 0.13s
                      Time elapsed: 00:27:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1410/1 [0m                       

                       Computation: 768008 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 856.78
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0950
       Episode_Reward/object_height 0.0313
     Episode_Reward/reaching_object 0.7531
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 0.13s
                      Time elapsed: 00:27:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1411/1 [0m                       

                       Computation: 780015 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 873.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2265
       Episode_Reward/object_height 0.0313
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 0.13s
                      Time elapsed: 00:27:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1412/1 [0m                       

                       Computation: 699342 steps/s (collection: 0.044s, learning 0.097s)
                       Mean reward: 864.71
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3311
       Episode_Reward/object_height 0.0302
     Episode_Reward/reaching_object 0.7665
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 0.14s
                      Time elapsed: 00:27:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1413/1 [0m                       

                       Computation: 799071 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 877.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6710
       Episode_Reward/object_height 0.0312
     Episode_Reward/reaching_object 0.7689
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 0.12s
                      Time elapsed: 00:27:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1414/1 [0m                       

                       Computation: 764722 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 874.28
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4663
       Episode_Reward/object_height 0.0307
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 0.13s
                      Time elapsed: 00:27:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1415/1 [0m                       

                       Computation: 767736 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 866.21
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6659
       Episode_Reward/object_height 0.0302
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 0.13s
                      Time elapsed: 00:27:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1416/1 [0m                       

                       Computation: 751276 steps/s (collection: 0.045s, learning 0.086s)
                       Mean reward: 866.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4282
       Episode_Reward/object_height 0.0306
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 0.13s
                      Time elapsed: 00:27:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1417/1 [0m                       

                       Computation: 740889 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 867.95
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6107
       Episode_Reward/object_height 0.0305
     Episode_Reward/reaching_object 0.7708
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 32.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 0.13s
                      Time elapsed: 00:27:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1418/1 [0m                       

                       Computation: 761360 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 854.96
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9082
       Episode_Reward/object_height 0.0306
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 0.13s
                      Time elapsed: 00:27:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1419/1 [0m                       

                       Computation: 759535 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 870.93
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1825
       Episode_Reward/object_height 0.0309
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 0.13s
                      Time elapsed: 00:27:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1420/1 [0m                       

                       Computation: 694478 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 861.83
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4435
       Episode_Reward/object_height 0.0311
     Episode_Reward/reaching_object 0.7690
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 0.14s
                      Time elapsed: 00:27:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1421/1 [0m                       

                       Computation: 776949 steps/s (collection: 0.045s, learning 0.082s)
                       Mean reward: 875.15
               Mean episode length: 249.49
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8313
       Episode_Reward/object_height 0.0318
     Episode_Reward/reaching_object 0.7739
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 0.13s
                      Time elapsed: 00:27:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1422/1 [0m                       

                       Computation: 815748 steps/s (collection: 0.045s, learning 0.075s)
                       Mean reward: 875.49
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2934
       Episode_Reward/object_height 0.0322
     Episode_Reward/reaching_object 0.7817
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 0.12s
                      Time elapsed: 00:27:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1423/1 [0m                       

                       Computation: 750709 steps/s (collection: 0.052s, learning 0.079s)
                       Mean reward: 873.12
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.1882
       Episode_Reward/object_height 0.0326
     Episode_Reward/reaching_object 0.7762
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 0.13s
                      Time elapsed: 00:27:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1424/1 [0m                       

                       Computation: 812166 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 867.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.4493
       Episode_Reward/object_height 0.0318
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 0.12s
                      Time elapsed: 00:27:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1425/1 [0m                       

                       Computation: 823010 steps/s (collection: 0.045s, learning 0.074s)
                       Mean reward: 867.60
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.6862
       Episode_Reward/object_height 0.0319
     Episode_Reward/reaching_object 0.7679
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 0.12s
                      Time elapsed: 00:27:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1426/1 [0m                       

                       Computation: 804456 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 864.48
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0683
       Episode_Reward/object_height 0.0322
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 0.12s
                      Time elapsed: 00:27:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1427/1 [0m                       

                       Computation: 761211 steps/s (collection: 0.052s, learning 0.077s)
                       Mean reward: 867.82
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8655
       Episode_Reward/object_height 0.0326
     Episode_Reward/reaching_object 0.7653
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 0.13s
                      Time elapsed: 00:27:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1428/1 [0m                       

                       Computation: 663288 steps/s (collection: 0.039s, learning 0.109s)
                       Mean reward: 870.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5232
       Episode_Reward/object_height 0.0322
     Episode_Reward/reaching_object 0.7551
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 29.6667
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 0.15s
                      Time elapsed: 00:27:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1429/1 [0m                       

                       Computation: 825855 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 860.81
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6255
       Episode_Reward/object_height 0.0320
     Episode_Reward/reaching_object 0.7490
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 0.12s
                      Time elapsed: 00:27:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1430/1 [0m                       

                       Computation: 733394 steps/s (collection: 0.049s, learning 0.086s)
                       Mean reward: 865.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7378
       Episode_Reward/object_height 0.0328
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 0.13s
                      Time elapsed: 00:27:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1431/1 [0m                       

                       Computation: 763388 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 856.33
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6126
       Episode_Reward/object_height 0.0323
     Episode_Reward/reaching_object 0.7561
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 0.13s
                      Time elapsed: 00:27:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1432/1 [0m                       

                       Computation: 709689 steps/s (collection: 0.046s, learning 0.092s)
                       Mean reward: 872.37
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7138
       Episode_Reward/object_height 0.0330
     Episode_Reward/reaching_object 0.7671
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 0.14s
                      Time elapsed: 00:27:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1433/1 [0m                       

                       Computation: 653007 steps/s (collection: 0.052s, learning 0.098s)
                       Mean reward: 870.75
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8440
       Episode_Reward/object_height 0.0329
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 0.15s
                      Time elapsed: 00:27:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1434/1 [0m                       

                       Computation: 752838 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 867.65
               Mean episode length: 249.39
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7036
       Episode_Reward/object_height 0.0331
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 0.13s
                      Time elapsed: 00:27:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1435/1 [0m                       

                       Computation: 808488 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 875.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.1425
       Episode_Reward/object_height 0.0330
     Episode_Reward/reaching_object 0.7756
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 0.12s
                      Time elapsed: 00:27:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1436/1 [0m                       

                       Computation: 848711 steps/s (collection: 0.042s, learning 0.073s)
                       Mean reward: 869.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2166
       Episode_Reward/object_height 0.0330
     Episode_Reward/reaching_object 0.7716
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 0.12s
                      Time elapsed: 00:27:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1437/1 [0m                       

                       Computation: 793336 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 872.05
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4116
       Episode_Reward/object_height 0.0331
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 0.12s
                      Time elapsed: 00:27:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1438/1 [0m                       

                       Computation: 785832 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 871.12
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5008
       Episode_Reward/object_height 0.0333
     Episode_Reward/reaching_object 0.7771
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 32.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 0.13s
                      Time elapsed: 00:27:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1439/1 [0m                       

                       Computation: 835242 steps/s (collection: 0.040s, learning 0.078s)
                       Mean reward: 878.00
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5711
       Episode_Reward/object_height 0.0334
     Episode_Reward/reaching_object 0.7870
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 0.12s
                      Time elapsed: 00:27:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1440/1 [0m                       

                       Computation: 715989 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 864.80
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7825
       Episode_Reward/object_height 0.0325
     Episode_Reward/reaching_object 0.7724
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 0.14s
                      Time elapsed: 00:27:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1441/1 [0m                       

                       Computation: 695326 steps/s (collection: 0.046s, learning 0.096s)
                       Mean reward: 872.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5693
       Episode_Reward/object_height 0.0329
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 0.14s
                      Time elapsed: 00:27:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1442/1 [0m                       

                       Computation: 704123 steps/s (collection: 0.044s, learning 0.096s)
                       Mean reward: 877.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5837
       Episode_Reward/object_height 0.0332
     Episode_Reward/reaching_object 0.7806
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 0.14s
                      Time elapsed: 00:27:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1443/1 [0m                       

                       Computation: 657854 steps/s (collection: 0.046s, learning 0.103s)
                       Mean reward: 866.22
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.2662
       Episode_Reward/object_height 0.0322
     Episode_Reward/reaching_object 0.7653
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 0.15s
                      Time elapsed: 00:27:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1444/1 [0m                       

                       Computation: 767158 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 870.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5080
       Episode_Reward/object_height 0.0324
     Episode_Reward/reaching_object 0.7769
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 0.13s
                      Time elapsed: 00:27:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1445/1 [0m                       

                       Computation: 692716 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 868.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.8913
       Episode_Reward/object_height 0.0314
     Episode_Reward/reaching_object 0.7818
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 0.14s
                      Time elapsed: 00:28:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1446/1 [0m                       

                       Computation: 778589 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 867.11
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5192
       Episode_Reward/object_height 0.0313
     Episode_Reward/reaching_object 0.7760
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 0.13s
                      Time elapsed: 00:28:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1447/1 [0m                       

                       Computation: 795789 steps/s (collection: 0.049s, learning 0.075s)
                       Mean reward: 871.92
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2895
       Episode_Reward/object_height 0.0310
     Episode_Reward/reaching_object 0.7716
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 0.12s
                      Time elapsed: 00:28:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1448/1 [0m                       

                       Computation: 833138 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 874.31
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7926
       Episode_Reward/object_height 0.0295
     Episode_Reward/reaching_object 0.7783
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 34.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 0.12s
                      Time elapsed: 00:28:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1449/1 [0m                       

                       Computation: 820544 steps/s (collection: 0.042s, learning 0.078s)
                       Mean reward: 877.97
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7700
       Episode_Reward/object_height 0.0291
     Episode_Reward/reaching_object 0.7707
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 0.12s
                      Time elapsed: 00:28:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1450/1 [0m                       

                       Computation: 791806 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 872.02
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5192
       Episode_Reward/object_height 0.0278
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 0.12s
                      Time elapsed: 00:28:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1451/1 [0m                       

                       Computation: 785194 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 873.70
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0805
       Episode_Reward/object_height 0.0284
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 0.13s
                      Time elapsed: 00:28:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1452/1 [0m                       

                       Computation: 776696 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 872.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9922
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 0.13s
                      Time elapsed: 00:28:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1453/1 [0m                       

                       Computation: 758960 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 866.08
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8301
       Episode_Reward/object_height 0.0255
     Episode_Reward/reaching_object 0.7585
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 0.13s
                      Time elapsed: 00:28:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1454/1 [0m                       

                       Computation: 783217 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 869.51
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0575
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7654
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 0.13s
                      Time elapsed: 00:28:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1455/1 [0m                       

                       Computation: 638240 steps/s (collection: 0.044s, learning 0.110s)
                       Mean reward: 868.44
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.5344
       Episode_Reward/object_height 0.0244
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 0.15s
                      Time elapsed: 00:28:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1456/1 [0m                       

                       Computation: 771007 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 880.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.5017
       Episode_Reward/object_height 0.0247
     Episode_Reward/reaching_object 0.7757
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 0.13s
                      Time elapsed: 00:28:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1457/1 [0m                       

                       Computation: 833589 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 872.96
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5026
       Episode_Reward/object_height 0.0236
     Episode_Reward/reaching_object 0.7675
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 0.12s
                      Time elapsed: 00:28:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1458/1 [0m                       

                       Computation: 796647 steps/s (collection: 0.045s, learning 0.079s)
                       Mean reward: 869.70
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2153
       Episode_Reward/object_height 0.0232
     Episode_Reward/reaching_object 0.7679
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 0.12s
                      Time elapsed: 00:28:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1459/1 [0m                       

                       Computation: 836870 steps/s (collection: 0.041s, learning 0.076s)
                       Mean reward: 874.67
               Mean episode length: 249.83
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1135
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7738
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 31.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 0.12s
                      Time elapsed: 00:28:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1460/1 [0m                       

                       Computation: 783248 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 872.35
               Mean episode length: 249.34
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8475
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7710
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 0.13s
                      Time elapsed: 00:28:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1461/1 [0m                       

                       Computation: 830384 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 874.45
               Mean episode length: 249.76
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3707
       Episode_Reward/object_height 0.0227
     Episode_Reward/reaching_object 0.7687
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 0.12s
                      Time elapsed: 00:28:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1462/1 [0m                       

                       Computation: 725216 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 876.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6245
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 0.14s
                      Time elapsed: 00:28:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1463/1 [0m                       

                       Computation: 834320 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 880.16
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0576
       Episode_Reward/object_height 0.0220
     Episode_Reward/reaching_object 0.7646
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 0.12s
                      Time elapsed: 00:28:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1464/1 [0m                       

                       Computation: 732459 steps/s (collection: 0.043s, learning 0.091s)
                       Mean reward: 877.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4105
       Episode_Reward/object_height 0.0219
     Episode_Reward/reaching_object 0.7638
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 0.13s
                      Time elapsed: 00:28:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1465/1 [0m                       

                       Computation: 740357 steps/s (collection: 0.050s, learning 0.083s)
                       Mean reward: 881.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.4619
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7688
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 0.13s
                      Time elapsed: 00:28:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1466/1 [0m                       

                       Computation: 806596 steps/s (collection: 0.045s, learning 0.077s)
                       Mean reward: 876.80
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8574
       Episode_Reward/object_height 0.0218
     Episode_Reward/reaching_object 0.7689
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 0.12s
                      Time elapsed: 00:28:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1467/1 [0m                       

                       Computation: 810795 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 878.33
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4077
       Episode_Reward/object_height 0.0209
     Episode_Reward/reaching_object 0.7749
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 0.12s
                      Time elapsed: 00:28:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1468/1 [0m                       

                       Computation: 677461 steps/s (collection: 0.043s, learning 0.102s)
                       Mean reward: 878.59
               Mean episode length: 249.45
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.1000
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7662
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 0.15s
                      Time elapsed: 00:28:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1469/1 [0m                       

                       Computation: 717175 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 879.19
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3983
       Episode_Reward/object_height 0.0208
     Episode_Reward/reaching_object 0.7690
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 33.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 0.14s
                      Time elapsed: 00:28:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1470/1 [0m                       

                       Computation: 709081 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 875.17
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7462
       Episode_Reward/object_height 0.0203
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 0.14s
                      Time elapsed: 00:28:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1471/1 [0m                       

                       Computation: 730423 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 877.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.6522
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7671
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 0.13s
                      Time elapsed: 00:28:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1472/1 [0m                       

                       Computation: 807669 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 875.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 174.4610
       Episode_Reward/object_height 0.0205
     Episode_Reward/reaching_object 0.7564
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 0.12s
                      Time elapsed: 00:28:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1473/1 [0m                       

                       Computation: 732757 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 877.98
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 175.1212
       Episode_Reward/object_height 0.0211
     Episode_Reward/reaching_object 0.7635
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 0.13s
                      Time elapsed: 00:28:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1474/1 [0m                       

                       Computation: 761829 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 865.96
               Mean episode length: 249.99
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0028
      Episode_Reward/lifting_object 172.9323
       Episode_Reward/object_height 0.0207
     Episode_Reward/reaching_object 0.7557
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 0.13s
                      Time elapsed: 00:28:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1475/1 [0m                       

                       Computation: 736302 steps/s (collection: 0.041s, learning 0.093s)
                       Mean reward: 876.10
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5017
       Episode_Reward/object_height 0.0215
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 0.13s
                      Time elapsed: 00:28:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1476/1 [0m                       

                       Computation: 707217 steps/s (collection: 0.048s, learning 0.091s)
                       Mean reward: 869.54
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.3941
       Episode_Reward/object_height 0.0214
     Episode_Reward/reaching_object 0.7511
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 0.14s
                      Time elapsed: 00:28:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1477/1 [0m                       

                       Computation: 749462 steps/s (collection: 0.043s, learning 0.089s)
                       Mean reward: 878.58
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0165
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7597
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 0.13s
                      Time elapsed: 00:28:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1478/1 [0m                       

                       Computation: 780283 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 869.91
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4053
       Episode_Reward/object_height 0.0223
     Episode_Reward/reaching_object 0.7527
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 0.13s
                      Time elapsed: 00:28:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1479/1 [0m                       

                       Computation: 823554 steps/s (collection: 0.043s, learning 0.077s)
                       Mean reward: 880.72
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.3839
       Episode_Reward/object_height 0.0226
     Episode_Reward/reaching_object 0.7681
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 0.12s
                      Time elapsed: 00:28:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1480/1 [0m                       

                       Computation: 779985 steps/s (collection: 0.046s, learning 0.081s)
                       Mean reward: 878.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.2614
       Episode_Reward/object_height 0.0234
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 30.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 0.13s
                      Time elapsed: 00:28:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1481/1 [0m                       

                       Computation: 808919 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 871.62
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9324
       Episode_Reward/object_height 0.0229
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 0.12s
                      Time elapsed: 00:28:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1482/1 [0m                       

                       Computation: 789407 steps/s (collection: 0.045s, learning 0.080s)
                       Mean reward: 876.07
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8878
       Episode_Reward/object_height 0.0242
     Episode_Reward/reaching_object 0.7634
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 0.12s
                      Time elapsed: 00:28:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1483/1 [0m                       

                       Computation: 780462 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 885.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 176.0487
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7693
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.6667
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 0.13s
                      Time elapsed: 00:28:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1484/1 [0m                       

                       Computation: 800865 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 877.74
               Mean episode length: 249.12
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6466
       Episode_Reward/object_height 0.0250
     Episode_Reward/reaching_object 0.7676
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 0.12s
                      Time elapsed: 00:28:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1485/1 [0m                       

                       Computation: 773753 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 878.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.1651
       Episode_Reward/object_height 0.0252
     Episode_Reward/reaching_object 0.7683
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 0.13s
                      Time elapsed: 00:28:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1486/1 [0m                       

                       Computation: 773489 steps/s (collection: 0.041s, learning 0.086s)
                       Mean reward: 875.27
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4171
       Episode_Reward/object_height 0.0254
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 0.13s
                      Time elapsed: 00:28:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1487/1 [0m                       

                       Computation: 824838 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 876.24
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7207
       Episode_Reward/object_height 0.0259
     Episode_Reward/reaching_object 0.7691
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 0.12s
                      Time elapsed: 00:28:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1488/1 [0m                       

                       Computation: 728706 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 878.57
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8259
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7692
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 0.13s
                      Time elapsed: 00:28:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1489/1 [0m                       

                       Computation: 847224 steps/s (collection: 0.041s, learning 0.075s)
                       Mean reward: 881.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.5634
       Episode_Reward/object_height 0.0275
     Episode_Reward/reaching_object 0.7721
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 0.12s
                      Time elapsed: 00:28:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1490/1 [0m                       

                       Computation: 755030 steps/s (collection: 0.045s, learning 0.086s)
                       Mean reward: 877.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.1917
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7605
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 32.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 0.13s
                      Time elapsed: 00:28:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1491/1 [0m                       

                       Computation: 786279 steps/s (collection: 0.046s, learning 0.080s)
                       Mean reward: 883.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.8901
       Episode_Reward/object_height 0.0293
     Episode_Reward/reaching_object 0.7728
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 0.13s
                      Time elapsed: 00:28:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1492/1 [0m                       

                       Computation: 812261 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 875.53
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7599
       Episode_Reward/object_height 0.0312
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 0.12s
                      Time elapsed: 00:28:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1493/1 [0m                       

                       Computation: 825310 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 876.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.9294
       Episode_Reward/object_height 0.0317
     Episode_Reward/reaching_object 0.7686
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 0.12s
                      Time elapsed: 00:28:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1494/1 [0m                       

                       Computation: 783233 steps/s (collection: 0.050s, learning 0.076s)
                       Mean reward: 878.23
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7583
       Episode_Reward/object_height 0.0332
     Episode_Reward/reaching_object 0.7720
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 0.13s
                      Time elapsed: 00:28:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1495/1 [0m                       

                       Computation: 814523 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 872.43
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.5910
       Episode_Reward/object_height 0.0345
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 0.12s
                      Time elapsed: 00:28:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1496/1 [0m                       

                       Computation: 692938 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 879.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0508
       Episode_Reward/object_height 0.0350
     Episode_Reward/reaching_object 0.7814
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 0.14s
                      Time elapsed: 00:28:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1497/1 [0m                       

                       Computation: 651627 steps/s (collection: 0.043s, learning 0.108s)
                       Mean reward: 870.14
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0030
       Episode_Reward/object_height 0.0359
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 0.15s
                      Time elapsed: 00:28:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1498/1 [0m                       

                       Computation: 648782 steps/s (collection: 0.043s, learning 0.108s)
                       Mean reward: 875.66
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3619
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7729
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 0.15s
                      Time elapsed: 00:28:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1499/1 [0m                       

                       Computation: 699621 steps/s (collection: 0.048s, learning 0.093s)
                       Mean reward: 872.72
               Mean episode length: 248.05
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.1390
       Episode_Reward/object_height 0.0379
     Episode_Reward/reaching_object 0.7688
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 0.14s
                      Time elapsed: 00:28:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1500/1 [0m                       

                       Computation: 730084 steps/s (collection: 0.049s, learning 0.086s)
                       Mean reward: 873.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9604
       Episode_Reward/object_height 0.0384
     Episode_Reward/reaching_object 0.7677
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 34.5000
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 0.13s
                      Time elapsed: 00:29:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1501/1 [0m                       

                       Computation: 798972 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 862.87
               Mean episode length: 249.18
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6539
       Episode_Reward/object_height 0.0383
     Episode_Reward/reaching_object 0.7468
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 147554304
                    Iteration time: 0.12s
                      Time elapsed: 00:29:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1502/1 [0m                       

                       Computation: 737743 steps/s (collection: 0.042s, learning 0.091s)
                       Mean reward: 855.85
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.4741
       Episode_Reward/object_height 0.0389
     Episode_Reward/reaching_object 0.7278
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147652608
                    Iteration time: 0.13s
                      Time elapsed: 00:29:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1503/1 [0m                       

                       Computation: 808195 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 842.82
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.1779
       Episode_Reward/object_height 0.0377
     Episode_Reward/reaching_object 0.7352
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 147750912
                    Iteration time: 0.12s
                      Time elapsed: 00:29:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1504/1 [0m                       

                       Computation: 802385 steps/s (collection: 0.046s, learning 0.077s)
                       Mean reward: 838.71
               Mean episode length: 247.59
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.6240
       Episode_Reward/object_height 0.0377
     Episode_Reward/reaching_object 0.7327
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 147849216
                    Iteration time: 0.12s
                      Time elapsed: 00:29:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1505/1 [0m                       

                       Computation: 778858 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 835.48
               Mean episode length: 249.02
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.3666
       Episode_Reward/object_height 0.0375
     Episode_Reward/reaching_object 0.7274
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 147947520
                    Iteration time: 0.13s
                      Time elapsed: 00:29:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1506/1 [0m                       

                       Computation: 826816 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 847.15
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.8972
       Episode_Reward/object_height 0.0384
     Episode_Reward/reaching_object 0.7260
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 148045824
                    Iteration time: 0.12s
                      Time elapsed: 00:29:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1507/1 [0m                       

                       Computation: 803992 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 826.73
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.0166
       Episode_Reward/object_height 0.0377
     Episode_Reward/reaching_object 0.7117
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 148144128
                    Iteration time: 0.12s
                      Time elapsed: 00:29:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1508/1 [0m                       

                       Computation: 834566 steps/s (collection: 0.041s, learning 0.077s)
                       Mean reward: 832.06
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 165.5954
       Episode_Reward/object_height 0.0379
     Episode_Reward/reaching_object 0.7158
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 148242432
                    Iteration time: 0.12s
                      Time elapsed: 00:29:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1509/1 [0m                       

                       Computation: 817876 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 841.29
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.8245
       Episode_Reward/object_height 0.0389
     Episode_Reward/reaching_object 0.7212
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 148340736
                    Iteration time: 0.12s
                      Time elapsed: 00:29:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1510/1 [0m                       

                       Computation: 865939 steps/s (collection: 0.038s, learning 0.076s)
                       Mean reward: 846.17
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7240
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7249
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 148439040
                    Iteration time: 0.11s
                      Time elapsed: 00:29:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1511/1 [0m                       

                       Computation: 843627 steps/s (collection: 0.042s, learning 0.075s)
                       Mean reward: 843.02
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.6437
       Episode_Reward/object_height 0.0384
     Episode_Reward/reaching_object 0.7085
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 31.7500
--------------------------------------------------------------------------------
                   Total timesteps: 148537344
                    Iteration time: 0.12s
                      Time elapsed: 00:29:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1512/1 [0m                       

                       Computation: 840459 steps/s (collection: 0.038s, learning 0.079s)
                       Mean reward: 806.88
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 160.7715
       Episode_Reward/object_height 0.0378
     Episode_Reward/reaching_object 0.6849
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 148635648
                    Iteration time: 0.12s
                      Time elapsed: 00:29:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1513/1 [0m                       

                       Computation: 747854 steps/s (collection: 0.049s, learning 0.083s)
                       Mean reward: 810.07
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 160.1712
       Episode_Reward/object_height 0.0371
     Episode_Reward/reaching_object 0.6816
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 148733952
                    Iteration time: 0.13s
                      Time elapsed: 00:29:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1514/1 [0m                       

                       Computation: 766002 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 824.78
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 163.3465
       Episode_Reward/object_height 0.0380
     Episode_Reward/reaching_object 0.6976
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 148832256
                    Iteration time: 0.13s
                      Time elapsed: 00:29:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1515/1 [0m                       

                       Computation: 802378 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 842.79
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.1309
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7188
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 148930560
                    Iteration time: 0.12s
                      Time elapsed: 00:29:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1516/1 [0m                       

                       Computation: 715038 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 853.91
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.1808
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7360
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 149028864
                    Iteration time: 0.14s
                      Time elapsed: 00:29:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1517/1 [0m                       

                       Computation: 825846 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 862.83
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6346
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7376
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 149127168
                    Iteration time: 0.12s
                      Time elapsed: 00:29:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1518/1 [0m                       

                       Computation: 789516 steps/s (collection: 0.047s, learning 0.078s)
                       Mean reward: 870.21
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.5679
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7505
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 149225472
                    Iteration time: 0.12s
                      Time elapsed: 00:29:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1519/1 [0m                       

                       Computation: 773987 steps/s (collection: 0.045s, learning 0.082s)
                       Mean reward: 870.58
               Mean episode length: 249.80
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6788
       Episode_Reward/object_height 0.0405
     Episode_Reward/reaching_object 0.7524
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 149323776
                    Iteration time: 0.13s
                      Time elapsed: 00:29:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1520/1 [0m                       

                       Computation: 690609 steps/s (collection: 0.043s, learning 0.100s)
                       Mean reward: 865.64
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8101
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 149422080
                    Iteration time: 0.14s
                      Time elapsed: 00:29:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1521/1 [0m                       

                       Computation: 772049 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 879.92
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.9275
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 33.7083
--------------------------------------------------------------------------------
                   Total timesteps: 149520384
                    Iteration time: 0.13s
                      Time elapsed: 00:29:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1522/1 [0m                       

                       Computation: 767492 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 873.12
               Mean episode length: 249.75
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7161
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7752
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 149618688
                    Iteration time: 0.13s
                      Time elapsed: 00:29:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1523/1 [0m                       

                       Computation: 767459 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 878.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8394
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7751
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 149716992
                    Iteration time: 0.13s
                      Time elapsed: 00:29:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1524/1 [0m                       

                       Computation: 757733 steps/s (collection: 0.039s, learning 0.090s)
                       Mean reward: 861.29
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.0390
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7670
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 149815296
                    Iteration time: 0.13s
                      Time elapsed: 00:29:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1525/1 [0m                       

                       Computation: 794056 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 865.18
               Mean episode length: 248.82
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1760
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 149913600
                    Iteration time: 0.12s
                      Time elapsed: 00:29:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1526/1 [0m                       

                       Computation: 724500 steps/s (collection: 0.046s, learning 0.090s)
                       Mean reward: 873.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5912
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7737
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 150011904
                    Iteration time: 0.14s
                      Time elapsed: 00:29:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1527/1 [0m                       

                       Computation: 803543 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 859.63
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6009
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 150110208
                    Iteration time: 0.12s
                      Time elapsed: 00:29:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1528/1 [0m                       

                       Computation: 799491 steps/s (collection: 0.043s, learning 0.079s)
                       Mean reward: 854.97
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.7532
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7637
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 150208512
                    Iteration time: 0.12s
                      Time elapsed: 00:29:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1529/1 [0m                       

                       Computation: 806536 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 878.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.0169
       Episode_Reward/object_height 0.0410
     Episode_Reward/reaching_object 0.7800
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 150306816
                    Iteration time: 0.12s
                      Time elapsed: 00:29:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1530/1 [0m                       

                       Computation: 850964 steps/s (collection: 0.041s, learning 0.075s)
                       Mean reward: 866.50
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6665
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 150405120
                    Iteration time: 0.12s
                      Time elapsed: 00:29:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1531/1 [0m                       

                       Computation: 761934 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 857.71
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1436
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7662
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 150503424
                    Iteration time: 0.13s
                      Time elapsed: 00:29:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1532/1 [0m                       

                       Computation: 664553 steps/s (collection: 0.040s, learning 0.108s)
                       Mean reward: 873.12
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.1233
       Episode_Reward/object_height 0.0405
     Episode_Reward/reaching_object 0.7781
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 30.1250
--------------------------------------------------------------------------------
                   Total timesteps: 150601728
                    Iteration time: 0.15s
                      Time elapsed: 00:29:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1533/1 [0m                       

                       Computation: 802118 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 860.98
               Mean episode length: 248.58
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3100
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7671
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 150700032
                    Iteration time: 0.12s
                      Time elapsed: 00:29:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1534/1 [0m                       

                       Computation: 793542 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 867.67
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6722
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 150798336
                    Iteration time: 0.12s
                      Time elapsed: 00:29:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1535/1 [0m                       

                       Computation: 714868 steps/s (collection: 0.045s, learning 0.093s)
                       Mean reward: 867.01
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.0488
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7662
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.8750
--------------------------------------------------------------------------------
                   Total timesteps: 150896640
                    Iteration time: 0.14s
                      Time elapsed: 00:29:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1536/1 [0m                       

                       Computation: 827342 steps/s (collection: 0.041s, learning 0.078s)
                       Mean reward: 877.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.7615
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7591
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 150994944
                    Iteration time: 0.12s
                      Time elapsed: 00:29:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1537/1 [0m                       

                       Computation: 808152 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 862.84
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.7917
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7589
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 151093248
                    Iteration time: 0.12s
                      Time elapsed: 00:29:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1538/1 [0m                       

                       Computation: 796592 steps/s (collection: 0.042s, learning 0.081s)
                       Mean reward: 869.01
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.9006
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7690
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 151191552
                    Iteration time: 0.12s
                      Time elapsed: 00:29:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1539/1 [0m                       

                       Computation: 767048 steps/s (collection: 0.048s, learning 0.081s)
                       Mean reward: 866.75
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1784
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7714
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 151289856
                    Iteration time: 0.13s
                      Time elapsed: 00:29:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1540/1 [0m                       

                       Computation: 782251 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 866.00
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6005
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7725
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 151388160
                    Iteration time: 0.13s
                      Time elapsed: 00:29:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1541/1 [0m                       

                       Computation: 767535 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 869.23
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6895
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7663
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 151486464
                    Iteration time: 0.13s
                      Time elapsed: 00:29:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1542/1 [0m                       

                       Computation: 714797 steps/s (collection: 0.043s, learning 0.095s)
                       Mean reward: 868.64
               Mean episode length: 249.88
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6625
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 32.3333
--------------------------------------------------------------------------------
                   Total timesteps: 151584768
                    Iteration time: 0.14s
                      Time elapsed: 00:29:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1543/1 [0m                       

                       Computation: 753167 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 876.52
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0488
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7726
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 151683072
                    Iteration time: 0.13s
                      Time elapsed: 00:29:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1544/1 [0m                       

                       Computation: 770913 steps/s (collection: 0.045s, learning 0.083s)
                       Mean reward: 874.24
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.3649
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7689
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 151781376
                    Iteration time: 0.13s
                      Time elapsed: 00:29:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1545/1 [0m                       

                       Computation: 653044 steps/s (collection: 0.041s, learning 0.109s)
                       Mean reward: 862.39
               Mean episode length: 249.04
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.4696
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7551
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 151879680
                    Iteration time: 0.15s
                      Time elapsed: 00:29:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1546/1 [0m                       

                       Computation: 736268 steps/s (collection: 0.049s, learning 0.085s)
                       Mean reward: 873.06
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.9802
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7656
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 151977984
                    Iteration time: 0.13s
                      Time elapsed: 00:29:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1547/1 [0m                       

                       Computation: 808970 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 870.97
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3872
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 152076288
                    Iteration time: 0.12s
                      Time elapsed: 00:29:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1548/1 [0m                       

                       Computation: 807136 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 871.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2991
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 152174592
                    Iteration time: 0.12s
                      Time elapsed: 00:29:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1549/1 [0m                       

                       Computation: 779953 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 867.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3756
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7672
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 152272896
                    Iteration time: 0.13s
                      Time elapsed: 00:29:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1550/1 [0m                       

                       Computation: 697400 steps/s (collection: 0.039s, learning 0.102s)
                       Mean reward: 872.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.8187
       Episode_Reward/object_height 0.0398
     Episode_Reward/reaching_object 0.7772
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 152371200
                    Iteration time: 0.14s
                      Time elapsed: 00:29:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1551/1 [0m                       

                       Computation: 717178 steps/s (collection: 0.051s, learning 0.086s)
                       Mean reward: 878.29
               Mean episode length: 248.90
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.9503
       Episode_Reward/object_height 0.0400
     Episode_Reward/reaching_object 0.7751
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 152469504
                    Iteration time: 0.14s
                      Time elapsed: 00:29:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1552/1 [0m                       

                       Computation: 784540 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 872.42
               Mean episode length: 249.77
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3776
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7694
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 152567808
                    Iteration time: 0.13s
                      Time elapsed: 00:29:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1553/1 [0m                       

                       Computation: 697771 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 876.52
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8033
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 28.7917
--------------------------------------------------------------------------------
                   Total timesteps: 152666112
                    Iteration time: 0.14s
                      Time elapsed: 00:29:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1554/1 [0m                       

                       Computation: 693239 steps/s (collection: 0.054s, learning 0.088s)
                       Mean reward: 860.82
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3521
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 152764416
                    Iteration time: 0.14s
                      Time elapsed: 00:29:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1555/1 [0m                       

                       Computation: 709489 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 873.00
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5428
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 152862720
                    Iteration time: 0.14s
                      Time elapsed: 00:30:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1556/1 [0m                       

                       Computation: 706895 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 867.76
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7129
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 152961024
                    Iteration time: 0.14s
                      Time elapsed: 00:30:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1557/1 [0m                       

                       Computation: 744649 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 875.17
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.5920
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7586
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 153059328
                    Iteration time: 0.13s
                      Time elapsed: 00:30:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1558/1 [0m                       

                       Computation: 861552 steps/s (collection: 0.039s, learning 0.076s)
                       Mean reward: 870.44
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4665
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 153157632
                    Iteration time: 0.11s
                      Time elapsed: 00:30:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1559/1 [0m                       

                       Computation: 775680 steps/s (collection: 0.043s, learning 0.083s)
                       Mean reward: 871.56
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4773
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7625
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 153255936
                    Iteration time: 0.13s
                      Time elapsed: 00:30:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1560/1 [0m                       

                       Computation: 810087 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 869.41
               Mean episode length: 249.69
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6651
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7559
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 153354240
                    Iteration time: 0.12s
                      Time elapsed: 00:30:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1561/1 [0m                       

                       Computation: 805446 steps/s (collection: 0.040s, learning 0.083s)
                       Mean reward: 856.67
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2469
       Episode_Reward/object_height 0.0388
     Episode_Reward/reaching_object 0.7488
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 153452544
                    Iteration time: 0.12s
                      Time elapsed: 00:30:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1562/1 [0m                       

                       Computation: 766430 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 865.97
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3185
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 153550848
                    Iteration time: 0.13s
                      Time elapsed: 00:30:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1563/1 [0m                       

                       Computation: 765528 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 865.74
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4010
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7606
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 31.7500
--------------------------------------------------------------------------------
                   Total timesteps: 153649152
                    Iteration time: 0.13s
                      Time elapsed: 00:30:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1564/1 [0m                       

                       Computation: 724267 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 862.07
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.8555
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7659
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 153747456
                    Iteration time: 0.14s
                      Time elapsed: 00:30:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1565/1 [0m                       

                       Computation: 696501 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 872.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4019
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7628
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 153845760
                    Iteration time: 0.14s
                      Time elapsed: 00:30:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1566/1 [0m                       

                       Computation: 684801 steps/s (collection: 0.047s, learning 0.097s)
                       Mean reward: 865.19
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7796
       Episode_Reward/object_height 0.0388
     Episode_Reward/reaching_object 0.7494
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 153944064
                    Iteration time: 0.14s
                      Time elapsed: 00:30:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1567/1 [0m                       

                       Computation: 672700 steps/s (collection: 0.046s, learning 0.101s)
                       Mean reward: 867.15
               Mean episode length: 249.96
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1027
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 154042368
                    Iteration time: 0.15s
                      Time elapsed: 00:30:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1568/1 [0m                       

                       Computation: 735805 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 864.53
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1406
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7544
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 154140672
                    Iteration time: 0.13s
                      Time elapsed: 00:30:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1569/1 [0m                       

                       Computation: 760328 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 854.62
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.9132
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7438
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 154238976
                    Iteration time: 0.13s
                      Time elapsed: 00:30:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1570/1 [0m                       

                       Computation: 781963 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 864.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.1283
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7553
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 154337280
                    Iteration time: 0.13s
                      Time elapsed: 00:30:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1571/1 [0m                       

                       Computation: 789467 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 866.28
               Mean episode length: 249.94
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.0222
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7538
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 154435584
                    Iteration time: 0.12s
                      Time elapsed: 00:30:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1572/1 [0m                       

                       Computation: 784801 steps/s (collection: 0.044s, learning 0.082s)
                       Mean reward: 857.29
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0386
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7465
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 154533888
                    Iteration time: 0.13s
                      Time elapsed: 00:30:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1573/1 [0m                       

                       Computation: 736976 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 865.49
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.3308
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7505
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 33.9583
--------------------------------------------------------------------------------
                   Total timesteps: 154632192
                    Iteration time: 0.13s
                      Time elapsed: 00:30:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1574/1 [0m                       

                       Computation: 679630 steps/s (collection: 0.047s, learning 0.098s)
                       Mean reward: 856.78
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.3093
       Episode_Reward/object_height 0.0385
     Episode_Reward/reaching_object 0.7495
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 154730496
                    Iteration time: 0.14s
                      Time elapsed: 00:30:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1575/1 [0m                       

                       Computation: 795479 steps/s (collection: 0.043s, learning 0.081s)
                       Mean reward: 859.41
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.2098
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7388
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 154828800
                    Iteration time: 0.12s
                      Time elapsed: 00:30:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1576/1 [0m                       

                       Computation: 824625 steps/s (collection: 0.044s, learning 0.075s)
                       Mean reward: 859.28
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0772
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7478
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 154927104
                    Iteration time: 0.12s
                      Time elapsed: 00:30:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1577/1 [0m                       

                       Computation: 781452 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 853.94
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.8208
       Episode_Reward/object_height 0.0388
     Episode_Reward/reaching_object 0.7304
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 155025408
                    Iteration time: 0.13s
                      Time elapsed: 00:30:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1578/1 [0m                       

                       Computation: 741401 steps/s (collection: 0.049s, learning 0.084s)
                       Mean reward: 849.53
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.4031
       Episode_Reward/object_height 0.0388
     Episode_Reward/reaching_object 0.7318
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 155123712
                    Iteration time: 0.13s
                      Time elapsed: 00:30:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1579/1 [0m                       

                       Computation: 811083 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 848.68
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.6474
       Episode_Reward/object_height 0.0382
     Episode_Reward/reaching_object 0.7343
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 155222016
                    Iteration time: 0.12s
                      Time elapsed: 00:30:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1580/1 [0m                       

                       Computation: 772697 steps/s (collection: 0.042s, learning 0.085s)
                       Mean reward: 862.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.2649
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7340
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 155320320
                    Iteration time: 0.13s
                      Time elapsed: 00:30:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1581/1 [0m                       

                       Computation: 706618 steps/s (collection: 0.042s, learning 0.097s)
                       Mean reward: 855.77
               Mean episode length: 248.12
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.5119
       Episode_Reward/object_height 0.0386
     Episode_Reward/reaching_object 0.7267
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 155418624
                    Iteration time: 0.14s
                      Time elapsed: 00:30:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1582/1 [0m                       

                       Computation: 716030 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 860.71
               Mean episode length: 248.92
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.8269
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7378
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 155516928
                    Iteration time: 0.14s
                      Time elapsed: 00:30:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1583/1 [0m                       

                       Computation: 741279 steps/s (collection: 0.049s, learning 0.084s)
                       Mean reward: 860.95
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6302
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7500
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 155615232
                    Iteration time: 0.13s
                      Time elapsed: 00:30:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1584/1 [0m                       

                       Computation: 761534 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 858.25
               Mean episode length: 249.24
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0857
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7441
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 30.4583
--------------------------------------------------------------------------------
                   Total timesteps: 155713536
                    Iteration time: 0.13s
                      Time elapsed: 00:30:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1585/1 [0m                       

                       Computation: 666691 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 864.22
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4147
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7438
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 155811840
                    Iteration time: 0.15s
                      Time elapsed: 00:30:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1586/1 [0m                       

                       Computation: 763682 steps/s (collection: 0.045s, learning 0.084s)
                       Mean reward: 839.12
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.8219
       Episode_Reward/object_height 0.0383
     Episode_Reward/reaching_object 0.7262
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 155910144
                    Iteration time: 0.13s
                      Time elapsed: 00:30:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1587/1 [0m                       

                       Computation: 758712 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 863.14
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3908
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7309
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 156008448
                    Iteration time: 0.13s
                      Time elapsed: 00:30:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1588/1 [0m                       

                       Computation: 750465 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 855.90
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.4380
       Episode_Reward/object_height 0.0389
     Episode_Reward/reaching_object 0.7344
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 156106752
                    Iteration time: 0.13s
                      Time elapsed: 00:30:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1589/1 [0m                       

                       Computation: 730453 steps/s (collection: 0.045s, learning 0.090s)
                       Mean reward: 859.64
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.0034
       Episode_Reward/object_height 0.0391
     Episode_Reward/reaching_object 0.7368
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 156205056
                    Iteration time: 0.13s
                      Time elapsed: 00:30:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1590/1 [0m                       

                       Computation: 720258 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 856.21
               Mean episode length: 248.49
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.7328
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7339
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 156303360
                    Iteration time: 0.14s
                      Time elapsed: 00:30:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1591/1 [0m                       

                       Computation: 730894 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 854.97
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.2112
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7304
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 156401664
                    Iteration time: 0.13s
                      Time elapsed: 00:30:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1592/1 [0m                       

                       Computation: 736751 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 853.27
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.1178
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7320
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 156499968
                    Iteration time: 0.13s
                      Time elapsed: 00:30:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1593/1 [0m                       

                       Computation: 756993 steps/s (collection: 0.050s, learning 0.080s)
                       Mean reward: 858.26
               Mean episode length: 249.26
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.0097
       Episode_Reward/object_height 0.0393
     Episode_Reward/reaching_object 0.7273
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 156598272
                    Iteration time: 0.13s
                      Time elapsed: 00:30:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1594/1 [0m                       

                       Computation: 627614 steps/s (collection: 0.048s, learning 0.108s)
                       Mean reward: 853.86
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.6148
       Episode_Reward/object_height 0.0388
     Episode_Reward/reaching_object 0.7194
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 32.4583
--------------------------------------------------------------------------------
                   Total timesteps: 156696576
                    Iteration time: 0.16s
                      Time elapsed: 00:30:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1595/1 [0m                       

                       Computation: 784227 steps/s (collection: 0.044s, learning 0.082s)
                       Mean reward: 840.52
               Mean episode length: 248.34
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.2257
       Episode_Reward/object_height 0.0388
     Episode_Reward/reaching_object 0.7165
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 156794880
                    Iteration time: 0.13s
                      Time elapsed: 00:30:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1596/1 [0m                       

                       Computation: 772126 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 830.49
               Mean episode length: 248.53
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.6161
       Episode_Reward/object_height 0.0380
     Episode_Reward/reaching_object 0.7052
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 156893184
                    Iteration time: 0.13s
                      Time elapsed: 00:30:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1597/1 [0m                       

                       Computation: 786312 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 815.91
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 163.2678
       Episode_Reward/object_height 0.0376
     Episode_Reward/reaching_object 0.7032
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 156991488
                    Iteration time: 0.13s
                      Time elapsed: 00:30:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1598/1 [0m                       

                       Computation: 763616 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 832.28
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.4373
       Episode_Reward/object_height 0.0383
     Episode_Reward/reaching_object 0.7146
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 157089792
                    Iteration time: 0.13s
                      Time elapsed: 00:30:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1599/1 [0m                       

                       Computation: 825029 steps/s (collection: 0.040s, learning 0.079s)
                       Mean reward: 854.74
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.1272
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7323
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 157188096
                    Iteration time: 0.12s
                      Time elapsed: 00:30:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1600/1 [0m                       

                       Computation: 759496 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 841.94
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.7250
       Episode_Reward/object_height 0.0389
     Episode_Reward/reaching_object 0.7228
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 157286400
                    Iteration time: 0.13s
                      Time elapsed: 00:30:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1601/1 [0m                       

                       Computation: 819088 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 831.44
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.3103
       Episode_Reward/object_height 0.0381
     Episode_Reward/reaching_object 0.7124
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 157384704
                    Iteration time: 0.12s
                      Time elapsed: 00:30:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1602/1 [0m                       

                       Computation: 697204 steps/s (collection: 0.048s, learning 0.093s)
                       Mean reward: 838.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.9318
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7176
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 157483008
                    Iteration time: 0.14s
                      Time elapsed: 00:30:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1603/1 [0m                       

                       Computation: 768862 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 816.23
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.3627
       Episode_Reward/object_height 0.0375
     Episode_Reward/reaching_object 0.7029
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 157581312
                    Iteration time: 0.13s
                      Time elapsed: 00:30:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1604/1 [0m                       

                       Computation: 799124 steps/s (collection: 0.045s, learning 0.078s)
                       Mean reward: 825.05
               Mean episode length: 248.80
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.8039
       Episode_Reward/object_height 0.0381
     Episode_Reward/reaching_object 0.7060
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 157679616
                    Iteration time: 0.12s
                      Time elapsed: 00:30:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1605/1 [0m                       

                       Computation: 779547 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 829.44
               Mean episode length: 249.71
         Episode_Reward/action_rate -0.0003
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 162.6664
       Episode_Reward/object_height 0.0376
     Episode_Reward/reaching_object 0.7120
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 29.1250
--------------------------------------------------------------------------------
                   Total timesteps: 157777920
                    Iteration time: 0.13s
                      Time elapsed: 00:30:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1606/1 [0m                       

                       Computation: 812285 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 847.94
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.7140
       Episode_Reward/object_height 0.0387
     Episode_Reward/reaching_object 0.7187
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 157876224
                    Iteration time: 0.12s
                      Time elapsed: 00:30:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1607/1 [0m                       

                       Computation: 759064 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 841.65
               Mean episode length: 248.72
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.9836
       Episode_Reward/object_height 0.0384
     Episode_Reward/reaching_object 0.7316
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 157974528
                    Iteration time: 0.13s
                      Time elapsed: 00:30:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1608/1 [0m                       

                       Computation: 774129 steps/s (collection: 0.044s, learning 0.083s)
                       Mean reward: 849.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.0470
       Episode_Reward/object_height 0.0383
     Episode_Reward/reaching_object 0.7301
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 158072832
                    Iteration time: 0.13s
                      Time elapsed: 00:30:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1609/1 [0m                       

                       Computation: 695433 steps/s (collection: 0.040s, learning 0.102s)
                       Mean reward: 840.46
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.4671
       Episode_Reward/object_height 0.0379
     Episode_Reward/reaching_object 0.7355
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 158171136
                    Iteration time: 0.14s
                      Time elapsed: 00:31:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1610/1 [0m                       

                       Computation: 624338 steps/s (collection: 0.044s, learning 0.113s)
                       Mean reward: 843.45
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.6811
       Episode_Reward/object_height 0.0379
     Episode_Reward/reaching_object 0.7198
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 158269440
                    Iteration time: 0.16s
                      Time elapsed: 00:31:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1611/1 [0m                       

                       Computation: 591107 steps/s (collection: 0.051s, learning 0.116s)
                       Mean reward: 843.03
               Mean episode length: 248.27
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 168.0898
       Episode_Reward/object_height 0.0381
     Episode_Reward/reaching_object 0.7317
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 158367744
                    Iteration time: 0.17s
                      Time elapsed: 00:31:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1612/1 [0m                       

                       Computation: 655296 steps/s (collection: 0.050s, learning 0.100s)
                       Mean reward: 846.99
               Mean episode length: 248.97
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.1391
       Episode_Reward/object_height 0.0380
     Episode_Reward/reaching_object 0.7298
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 158466048
                    Iteration time: 0.15s
                      Time elapsed: 00:31:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1613/1 [0m                       

                       Computation: 743893 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 847.49
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.7086
       Episode_Reward/object_height 0.0376
     Episode_Reward/reaching_object 0.7310
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 158564352
                    Iteration time: 0.13s
                      Time elapsed: 00:31:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1614/1 [0m                       

                       Computation: 789543 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 848.96
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.3200
       Episode_Reward/object_height 0.0375
     Episode_Reward/reaching_object 0.7277
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 158662656
                    Iteration time: 0.12s
                      Time elapsed: 00:31:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1615/1 [0m                       

                       Computation: 783702 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 842.98
               Mean episode length: 249.64
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.7372
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7248
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 31.2500
--------------------------------------------------------------------------------
                   Total timesteps: 158760960
                    Iteration time: 0.13s
                      Time elapsed: 00:31:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1616/1 [0m                       

                       Computation: 712293 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 853.93
               Mean episode length: 249.29
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.9750
       Episode_Reward/object_height 0.0375
     Episode_Reward/reaching_object 0.7254
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 158859264
                    Iteration time: 0.14s
                      Time elapsed: 00:31:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1617/1 [0m                       

                       Computation: 795858 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 838.95
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.9015
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7244
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 158957568
                    Iteration time: 0.12s
                      Time elapsed: 00:31:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1618/1 [0m                       

                       Computation: 826733 steps/s (collection: 0.043s, learning 0.076s)
                       Mean reward: 849.47
               Mean episode length: 249.19
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.5244
       Episode_Reward/object_height 0.0367
     Episode_Reward/reaching_object 0.7253
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 159055872
                    Iteration time: 0.12s
                      Time elapsed: 00:31:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1619/1 [0m                       

                       Computation: 725439 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 857.54
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.7882
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7377
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 159154176
                    Iteration time: 0.14s
                      Time elapsed: 00:31:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1620/1 [0m                       

                       Computation: 725391 steps/s (collection: 0.050s, learning 0.086s)
                       Mean reward: 861.41
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.7077
       Episode_Reward/object_height 0.0368
     Episode_Reward/reaching_object 0.7439
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 159252480
                    Iteration time: 0.14s
                      Time elapsed: 00:31:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1621/1 [0m                       

                       Computation: 683896 steps/s (collection: 0.046s, learning 0.098s)
                       Mean reward: 864.82
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4889
       Episode_Reward/object_height 0.0371
     Episode_Reward/reaching_object 0.7468
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 159350784
                    Iteration time: 0.14s
                      Time elapsed: 00:31:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1622/1 [0m                       

                       Computation: 753102 steps/s (collection: 0.042s, learning 0.089s)
                       Mean reward: 855.26
               Mean episode length: 249.15
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.1325
       Episode_Reward/object_height 0.0368
     Episode_Reward/reaching_object 0.7433
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 159449088
                    Iteration time: 0.13s
                      Time elapsed: 00:31:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1623/1 [0m                       

                       Computation: 768490 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 847.63
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.3994
       Episode_Reward/object_height 0.0361
     Episode_Reward/reaching_object 0.7285
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 159547392
                    Iteration time: 0.13s
                      Time elapsed: 00:31:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1624/1 [0m                       

                       Computation: 748406 steps/s (collection: 0.049s, learning 0.083s)
                       Mean reward: 858.29
               Mean episode length: 249.28
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.8757
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7329
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 159645696
                    Iteration time: 0.13s
                      Time elapsed: 00:31:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1625/1 [0m                       

                       Computation: 793310 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 860.28
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.8873
       Episode_Reward/object_height 0.0359
     Episode_Reward/reaching_object 0.7391
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 33.6250
--------------------------------------------------------------------------------
                   Total timesteps: 159744000
                    Iteration time: 0.12s
                      Time elapsed: 00:31:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1626/1 [0m                       

                       Computation: 814432 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 869.18
               Mean episode length: 248.57
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3062
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 159842304
                    Iteration time: 0.12s
                      Time elapsed: 00:31:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1627/1 [0m                       

                       Computation: 791685 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 873.03
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.9004
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7668
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 159940608
                    Iteration time: 0.12s
                      Time elapsed: 00:31:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1628/1 [0m                       

                       Computation: 835967 steps/s (collection: 0.042s, learning 0.076s)
                       Mean reward: 859.15
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1692
       Episode_Reward/object_height 0.0349
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 160038912
                    Iteration time: 0.12s
                      Time elapsed: 00:31:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1629/1 [0m                       

                       Computation: 819046 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 877.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.1049
       Episode_Reward/object_height 0.0354
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 160137216
                    Iteration time: 0.12s
                      Time elapsed: 00:31:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1630/1 [0m                       

                       Computation: 765177 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 869.97
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1265
       Episode_Reward/object_height 0.0339
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 160235520
                    Iteration time: 0.13s
                      Time elapsed: 00:31:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1631/1 [0m                       

                       Computation: 722582 steps/s (collection: 0.049s, learning 0.087s)
                       Mean reward: 865.65
               Mean episode length: 249.56
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.1459
       Episode_Reward/object_height 0.0327
     Episode_Reward/reaching_object 0.7488
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 160333824
                    Iteration time: 0.14s
                      Time elapsed: 00:31:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1632/1 [0m                       

                       Computation: 620291 steps/s (collection: 0.051s, learning 0.107s)
                       Mean reward: 863.84
               Mean episode length: 249.84
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.2324
       Episode_Reward/object_height 0.0323
     Episode_Reward/reaching_object 0.7423
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 160432128
                    Iteration time: 0.16s
                      Time elapsed: 00:31:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1633/1 [0m                       

                       Computation: 783827 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 874.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.4443
       Episode_Reward/object_height 0.0312
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 160530432
                    Iteration time: 0.13s
                      Time elapsed: 00:31:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1634/1 [0m                       

                       Computation: 727676 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 869.22
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7979
       Episode_Reward/object_height 0.0294
     Episode_Reward/reaching_object 0.7460
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 160628736
                    Iteration time: 0.14s
                      Time elapsed: 00:31:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1635/1 [0m                       

                       Computation: 676329 steps/s (collection: 0.046s, learning 0.099s)
                       Mean reward: 854.52
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4513
       Episode_Reward/object_height 0.0293
     Episode_Reward/reaching_object 0.7317
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 160727040
                    Iteration time: 0.15s
                      Time elapsed: 00:31:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1636/1 [0m                       

                       Computation: 739937 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 867.37
               Mean episode length: 249.92
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.5836
       Episode_Reward/object_height 0.0278
     Episode_Reward/reaching_object 0.7446
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 31.3333
--------------------------------------------------------------------------------
                   Total timesteps: 160825344
                    Iteration time: 0.13s
                      Time elapsed: 00:31:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1637/1 [0m                       

                       Computation: 621562 steps/s (collection: 0.052s, learning 0.106s)
                       Mean reward: 871.89
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4671
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7420
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 160923648
                    Iteration time: 0.16s
                      Time elapsed: 00:31:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1638/1 [0m                       

                       Computation: 616138 steps/s (collection: 0.054s, learning 0.106s)
                       Mean reward: 874.46
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2410
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7507
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 161021952
                    Iteration time: 0.16s
                      Time elapsed: 00:31:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1639/1 [0m                       

                       Computation: 651909 steps/s (collection: 0.040s, learning 0.111s)
                       Mean reward: 873.41
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.7127
       Episode_Reward/object_height 0.0273
     Episode_Reward/reaching_object 0.7484
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 161120256
                    Iteration time: 0.15s
                      Time elapsed: 00:31:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1640/1 [0m                       

                       Computation: 723248 steps/s (collection: 0.040s, learning 0.096s)
                       Mean reward: 874.54
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.1865
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7544
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 161218560
                    Iteration time: 0.14s
                      Time elapsed: 00:31:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1641/1 [0m                       

                       Computation: 649459 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 877.47
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8859
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 161316864
                    Iteration time: 0.15s
                      Time elapsed: 00:31:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1642/1 [0m                       

                       Computation: 752394 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 883.44
               Mean episode length: 249.62
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 176.0470
       Episode_Reward/object_height 0.0264
     Episode_Reward/reaching_object 0.7580
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 161415168
                    Iteration time: 0.13s
                      Time elapsed: 00:31:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1643/1 [0m                       

                       Computation: 694434 steps/s (collection: 0.041s, learning 0.101s)
                       Mean reward: 877.17
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7396
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7603
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 161513472
                    Iteration time: 0.14s
                      Time elapsed: 00:31:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1644/1 [0m                       

                       Computation: 736277 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 873.94
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3306
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7582
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 161611776
                    Iteration time: 0.13s
                      Time elapsed: 00:31:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1645/1 [0m                       

                       Computation: 779029 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 876.41
               Mean episode length: 249.65
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7071
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7597
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 161710080
                    Iteration time: 0.13s
                      Time elapsed: 00:31:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1646/1 [0m                       

                       Computation: 813792 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 877.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2697
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7544
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 33.1667
--------------------------------------------------------------------------------
                   Total timesteps: 161808384
                    Iteration time: 0.12s
                      Time elapsed: 00:31:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1647/1 [0m                       

                       Computation: 735872 steps/s (collection: 0.042s, learning 0.092s)
                       Mean reward: 870.37
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.2246
       Episode_Reward/object_height 0.0263
     Episode_Reward/reaching_object 0.7502
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 161906688
                    Iteration time: 0.13s
                      Time elapsed: 00:31:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1648/1 [0m                       

                       Computation: 781203 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 872.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.6690
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7490
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 162004992
                    Iteration time: 0.13s
                      Time elapsed: 00:31:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1649/1 [0m                       

                       Computation: 581422 steps/s (collection: 0.048s, learning 0.121s)
                       Mean reward: 870.48
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8800
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7568
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 162103296
                    Iteration time: 0.17s
                      Time elapsed: 00:31:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1650/1 [0m                       

                       Computation: 559745 steps/s (collection: 0.063s, learning 0.113s)
                       Mean reward: 873.64
               Mean episode length: 249.67
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9090
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 162201600
                    Iteration time: 0.18s
                      Time elapsed: 00:31:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1651/1 [0m                       

                       Computation: 608521 steps/s (collection: 0.049s, learning 0.113s)
                       Mean reward: 869.04
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4105
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 162299904
                    Iteration time: 0.16s
                      Time elapsed: 00:31:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1652/1 [0m                       

                       Computation: 624887 steps/s (collection: 0.048s, learning 0.109s)
                       Mean reward: 869.42
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9730
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7462
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.1667
--------------------------------------------------------------------------------
                   Total timesteps: 162398208
                    Iteration time: 0.16s
                      Time elapsed: 00:31:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1653/1 [0m                       

                       Computation: 525906 steps/s (collection: 0.055s, learning 0.132s)
                       Mean reward: 879.11
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8349
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7568
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 162496512
                    Iteration time: 0.19s
                      Time elapsed: 00:31:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1654/1 [0m                       

                       Computation: 769612 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 877.24
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6657
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7529
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 162594816
                    Iteration time: 0.13s
                      Time elapsed: 00:31:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1655/1 [0m                       

                       Computation: 761896 steps/s (collection: 0.038s, learning 0.091s)
                       Mean reward: 879.42
               Mean episode length: 249.54
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.4520
       Episode_Reward/object_height 0.0272
     Episode_Reward/reaching_object 0.7532
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 162693120
                    Iteration time: 0.13s
                      Time elapsed: 00:31:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1656/1 [0m                       

                       Computation: 792574 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 870.32
               Mean episode length: 249.16
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1719
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7558
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 162791424
                    Iteration time: 0.12s
                      Time elapsed: 00:31:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1657/1 [0m                       

                       Computation: 708286 steps/s (collection: 0.038s, learning 0.101s)
                       Mean reward: 875.06
               Mean episode length: 249.74
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.9708
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7512
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 29.5000
--------------------------------------------------------------------------------
                   Total timesteps: 162889728
                    Iteration time: 0.14s
                      Time elapsed: 00:31:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1658/1 [0m                       

                       Computation: 576337 steps/s (collection: 0.058s, learning 0.113s)
                       Mean reward: 876.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8449
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7655
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 162988032
                    Iteration time: 0.17s
                      Time elapsed: 00:31:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1659/1 [0m                       

                       Computation: 601189 steps/s (collection: 0.052s, learning 0.112s)
                       Mean reward: 869.77
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.1215
       Episode_Reward/object_height 0.0265
     Episode_Reward/reaching_object 0.7493
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 163086336
                    Iteration time: 0.16s
                      Time elapsed: 00:31:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1660/1 [0m                       

                       Computation: 669603 steps/s (collection: 0.044s, learning 0.103s)
                       Mean reward: 877.20
               Mean episode length: 249.86
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0065
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7533
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 163184640
                    Iteration time: 0.15s
                      Time elapsed: 00:31:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1661/1 [0m                       

                       Computation: 730597 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 874.98
               Mean episode length: 248.83
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.3966
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7493
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 163282944
                    Iteration time: 0.13s
                      Time elapsed: 00:31:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1662/1 [0m                       

                       Computation: 574737 steps/s (collection: 0.048s, learning 0.124s)
                       Mean reward: 880.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.0199
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7549
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 163381248
                    Iteration time: 0.17s
                      Time elapsed: 00:32:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1663/1 [0m                       

                       Computation: 564797 steps/s (collection: 0.054s, learning 0.120s)
                       Mean reward: 877.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7072
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7526
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 163479552
                    Iteration time: 0.17s
                      Time elapsed: 00:32:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1664/1 [0m                       

                       Computation: 566375 steps/s (collection: 0.055s, learning 0.119s)
                       Mean reward: 877.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.7890
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 163577856
                    Iteration time: 0.17s
                      Time elapsed: 00:32:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1665/1 [0m                       

                       Computation: 531196 steps/s (collection: 0.053s, learning 0.132s)
                       Mean reward: 874.88
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.0917
       Episode_Reward/object_height 0.0264
     Episode_Reward/reaching_object 0.7555
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 163676160
                    Iteration time: 0.19s
                      Time elapsed: 00:32:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1666/1 [0m                       

                       Computation: 683752 steps/s (collection: 0.043s, learning 0.101s)
                       Mean reward: 884.20
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.6729
       Episode_Reward/object_height 0.0266
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 163774464
                    Iteration time: 0.14s
                      Time elapsed: 00:32:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1667/1 [0m                       

                       Computation: 698534 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 875.36
               Mean episode length: 249.81
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.2046
       Episode_Reward/object_height 0.0264
     Episode_Reward/reaching_object 0.7514
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 31.5833
--------------------------------------------------------------------------------
                   Total timesteps: 163872768
                    Iteration time: 0.14s
                      Time elapsed: 00:32:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1668/1 [0m                       

                       Computation: 814081 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 873.33
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.9061
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7375
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 163971072
                    Iteration time: 0.12s
                      Time elapsed: 00:32:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1669/1 [0m                       

                       Computation: 795815 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 881.03
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.2856
       Episode_Reward/object_height 0.0268
     Episode_Reward/reaching_object 0.7514
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 164069376
                    Iteration time: 0.12s
                      Time elapsed: 00:32:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1670/1 [0m                       

                       Computation: 795781 steps/s (collection: 0.041s, learning 0.083s)
                       Mean reward: 879.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.9178
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7515
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 164167680
                    Iteration time: 0.12s
                      Time elapsed: 00:32:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1671/1 [0m                       

                       Computation: 565143 steps/s (collection: 0.068s, learning 0.106s)
                       Mean reward: 872.51
               Mean episode length: 249.89
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.8081
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7502
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 164265984
                    Iteration time: 0.17s
                      Time elapsed: 00:32:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1672/1 [0m                       

                       Computation: 758923 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 875.54
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0751
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7481
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 164364288
                    Iteration time: 0.13s
                      Time elapsed: 00:32:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1673/1 [0m                       

                       Computation: 684473 steps/s (collection: 0.052s, learning 0.092s)
                       Mean reward: 877.87
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.7095
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7572
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 164462592
                    Iteration time: 0.14s
                      Time elapsed: 00:32:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1674/1 [0m                       

                       Computation: 728074 steps/s (collection: 0.042s, learning 0.093s)
                       Mean reward: 878.64
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.0004
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7525
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 164560896
                    Iteration time: 0.14s
                      Time elapsed: 00:32:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1675/1 [0m                       

                       Computation: 773148 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 879.14
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.2052
       Episode_Reward/object_height 0.0267
     Episode_Reward/reaching_object 0.7545
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 164659200
                    Iteration time: 0.13s
                      Time elapsed: 00:32:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1676/1 [0m                       

                       Computation: 657433 steps/s (collection: 0.037s, learning 0.113s)
                       Mean reward: 884.64
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 176.1052
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7561
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 164757504
                    Iteration time: 0.15s
                      Time elapsed: 00:32:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1677/1 [0m                       

                       Computation: 808887 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 881.74
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.4959
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 164855808
                    Iteration time: 0.12s
                      Time elapsed: 00:32:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1678/1 [0m                       

                       Computation: 808519 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 873.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.5406
       Episode_Reward/object_height 0.0269
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 28.0417
--------------------------------------------------------------------------------
                   Total timesteps: 164954112
                    Iteration time: 0.12s
                      Time elapsed: 00:32:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1679/1 [0m                       

                       Computation: 731330 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 884.39
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.8269
       Episode_Reward/object_height 0.0273
     Episode_Reward/reaching_object 0.7667
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 165052416
                    Iteration time: 0.13s
                      Time elapsed: 00:32:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1680/1 [0m                       

                       Computation: 778974 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 876.41
               Mean episode length: 249.52
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8489
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7599
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 165150720
                    Iteration time: 0.13s
                      Time elapsed: 00:32:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1681/1 [0m                       

                       Computation: 756057 steps/s (collection: 0.041s, learning 0.089s)
                       Mean reward: 876.86
               Mean episode length: 249.59
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8127
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7538
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 165249024
                    Iteration time: 0.13s
                      Time elapsed: 00:32:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1682/1 [0m                       

                       Computation: 790825 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 875.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.4247
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7529
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 165347328
                    Iteration time: 0.12s
                      Time elapsed: 00:32:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1683/1 [0m                       

                       Computation: 809485 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 879.73
               Mean episode length: 249.51
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.4197
       Episode_Reward/object_height 0.0273
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 165445632
                    Iteration time: 0.12s
                      Time elapsed: 00:32:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1684/1 [0m                       

                       Computation: 738584 steps/s (collection: 0.038s, learning 0.095s)
                       Mean reward: 878.86
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.1687
       Episode_Reward/object_height 0.0272
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 165543936
                    Iteration time: 0.13s
                      Time elapsed: 00:32:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1685/1 [0m                       

                       Computation: 766877 steps/s (collection: 0.038s, learning 0.090s)
                       Mean reward: 879.12
               Mean episode length: 249.78
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.0070
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7513
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 165642240
                    Iteration time: 0.13s
                      Time elapsed: 00:32:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1686/1 [0m                       

                       Computation: 620113 steps/s (collection: 0.040s, learning 0.119s)
                       Mean reward: 867.38
               Mean episode length: 249.25
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.5659
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 165740544
                    Iteration time: 0.16s
                      Time elapsed: 00:32:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1687/1 [0m                       

                       Computation: 653846 steps/s (collection: 0.064s, learning 0.086s)
                       Mean reward: 871.11
               Mean episode length: 249.05
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5853
       Episode_Reward/object_height 0.0270
     Episode_Reward/reaching_object 0.7520
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 165838848
                    Iteration time: 0.15s
                      Time elapsed: 00:32:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1688/1 [0m                       

                       Computation: 792903 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 880.09
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.2670
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7565
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 31.2083
--------------------------------------------------------------------------------
                   Total timesteps: 165937152
                    Iteration time: 0.12s
                      Time elapsed: 00:32:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1689/1 [0m                       

                       Computation: 781441 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 880.63
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.4156
       Episode_Reward/object_height 0.0272
     Episode_Reward/reaching_object 0.7635
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 166035456
                    Iteration time: 0.13s
                      Time elapsed: 00:32:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1690/1 [0m                       

                       Computation: 788068 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 879.67
               Mean episode length: 249.37
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.2756
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7512
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 166133760
                    Iteration time: 0.12s
                      Time elapsed: 00:32:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1691/1 [0m                       

                       Computation: 704360 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 878.38
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.2117
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7479
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 166232064
                    Iteration time: 0.14s
                      Time elapsed: 00:32:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1692/1 [0m                       

                       Computation: 811815 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 876.60
               Mean episode length: 249.43
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.6130
       Episode_Reward/object_height 0.0272
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 166330368
                    Iteration time: 0.12s
                      Time elapsed: 00:32:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1693/1 [0m                       

                       Computation: 775949 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 871.89
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 173.4087
       Episode_Reward/object_height 0.0273
     Episode_Reward/reaching_object 0.7507
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 166428672
                    Iteration time: 0.13s
                      Time elapsed: 00:32:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1694/1 [0m                       

                       Computation: 819572 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 878.11
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.8020
       Episode_Reward/object_height 0.0275
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 166526976
                    Iteration time: 0.12s
                      Time elapsed: 00:32:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1695/1 [0m                       

                       Computation: 728185 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 875.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.2575
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7468
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 166625280
                    Iteration time: 0.13s
                      Time elapsed: 00:32:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1696/1 [0m                       

                       Computation: 745973 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 879.30
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 174.6665
       Episode_Reward/object_height 0.0278
     Episode_Reward/reaching_object 0.7519
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 166723584
                    Iteration time: 0.13s
                      Time elapsed: 00:32:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1697/1 [0m                       

                       Computation: 799784 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 881.78
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 175.8676
       Episode_Reward/object_height 0.0278
     Episode_Reward/reaching_object 0.7557
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 166821888
                    Iteration time: 0.12s
                      Time elapsed: 00:32:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1698/1 [0m                       

                       Computation: 697403 steps/s (collection: 0.046s, learning 0.095s)
                       Mean reward: 876.75
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7967
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7418
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 33.2083
--------------------------------------------------------------------------------
                   Total timesteps: 166920192
                    Iteration time: 0.14s
                      Time elapsed: 00:32:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1699/1 [0m                       

                       Computation: 715065 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 871.56
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3844
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7391
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 167018496
                    Iteration time: 0.14s
                      Time elapsed: 00:32:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1700/1 [0m                       

                       Computation: 684821 steps/s (collection: 0.037s, learning 0.107s)
                       Mean reward: 876.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.4630
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7465
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 167116800
                    Iteration time: 0.14s
                      Time elapsed: 00:32:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1701/1 [0m                       

                       Computation: 766755 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 874.66
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.2445
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7416
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 167215104
                    Iteration time: 0.13s
                      Time elapsed: 00:32:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1702/1 [0m                       

                       Computation: 815708 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 879.75
               Mean episode length: 249.58
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.0603
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7439
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 167313408
                    Iteration time: 0.12s
                      Time elapsed: 00:32:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1703/1 [0m                       

                       Computation: 819020 steps/s (collection: 0.039s, learning 0.082s)
                       Mean reward: 869.63
               Mean episode length: 249.47
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.4583
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7407
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 167411712
                    Iteration time: 0.12s
                      Time elapsed: 00:32:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1704/1 [0m                       

                       Computation: 740675 steps/s (collection: 0.040s, learning 0.093s)
                       Mean reward: 871.07
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2230
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7434
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.2917
--------------------------------------------------------------------------------
                   Total timesteps: 167510016
                    Iteration time: 0.13s
                      Time elapsed: 00:32:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1705/1 [0m                       

                       Computation: 813466 steps/s (collection: 0.036s, learning 0.085s)
                       Mean reward: 878.55
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.9339
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7485
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 167608320
                    Iteration time: 0.12s
                      Time elapsed: 00:32:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1706/1 [0m                       

                       Computation: 813195 steps/s (collection: 0.038s, learning 0.083s)
                       Mean reward: 875.74
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.4739
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 167706624
                    Iteration time: 0.12s
                      Time elapsed: 00:32:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1707/1 [0m                       

                       Computation: 796627 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 863.26
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.2691
       Episode_Reward/object_height 0.0271
     Episode_Reward/reaching_object 0.7411
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 167804928
                    Iteration time: 0.12s
                      Time elapsed: 00:32:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1708/1 [0m                       

                       Computation: 801846 steps/s (collection: 0.037s, learning 0.086s)
                       Mean reward: 870.58
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2566
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7414
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 167903232
                    Iteration time: 0.12s
                      Time elapsed: 00:32:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1709/1 [0m                       

                       Computation: 788904 steps/s (collection: 0.038s, learning 0.086s)
                       Mean reward: 871.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.2651
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7540
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 29.9583
--------------------------------------------------------------------------------
                   Total timesteps: 168001536
                    Iteration time: 0.12s
                      Time elapsed: 00:32:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1710/1 [0m                       

                       Computation: 786610 steps/s (collection: 0.043s, learning 0.082s)
                       Mean reward: 869.80
               Mean episode length: 248.87
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.3216
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7433
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 168099840
                    Iteration time: 0.12s
                      Time elapsed: 00:32:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1711/1 [0m                       

                       Computation: 758183 steps/s (collection: 0.035s, learning 0.095s)
                       Mean reward: 882.65
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.7325
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7562
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 168198144
                    Iteration time: 0.13s
                      Time elapsed: 00:32:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1712/1 [0m                       

                       Computation: 785021 steps/s (collection: 0.038s, learning 0.087s)
                       Mean reward: 875.99
               Mean episode length: 249.42
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.3172
       Episode_Reward/object_height 0.0281
     Episode_Reward/reaching_object 0.7497
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 168296448
                    Iteration time: 0.13s
                      Time elapsed: 00:32:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1713/1 [0m                       

                       Computation: 779748 steps/s (collection: 0.036s, learning 0.090s)
                       Mean reward: 872.18
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7390
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7500
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 168394752
                    Iteration time: 0.13s
                      Time elapsed: 00:32:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1714/1 [0m                       

                       Computation: 785556 steps/s (collection: 0.039s, learning 0.087s)
                       Mean reward: 871.03
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6845
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7463
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 168493056
                    Iteration time: 0.13s
                      Time elapsed: 00:32:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1715/1 [0m                       

                       Computation: 770688 steps/s (collection: 0.039s, learning 0.089s)
                       Mean reward: 872.25
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6642
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7523
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 168591360
                    Iteration time: 0.13s
                      Time elapsed: 00:32:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1716/1 [0m                       

                       Computation: 818659 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 874.94
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.9609
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7520
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 168689664
                    Iteration time: 0.12s
                      Time elapsed: 00:33:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1717/1 [0m                       

                       Computation: 795548 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 872.77
               Mean episode length: 249.57
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.0176
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7556
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 168787968
                    Iteration time: 0.12s
                      Time elapsed: 00:33:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1718/1 [0m                       

                       Computation: 822198 steps/s (collection: 0.040s, learning 0.080s)
                       Mean reward: 873.06
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.8250
       Episode_Reward/object_height 0.0278
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 168886272
                    Iteration time: 0.12s
                      Time elapsed: 00:33:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1719/1 [0m                       

                       Computation: 821950 steps/s (collection: 0.037s, learning 0.083s)
                       Mean reward: 875.86
               Mean episode length: 249.98
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.2331
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 31.9167
--------------------------------------------------------------------------------
                   Total timesteps: 168984576
                    Iteration time: 0.12s
                      Time elapsed: 00:33:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1720/1 [0m                       

                       Computation: 808310 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 881.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.7286
       Episode_Reward/object_height 0.0278
     Episode_Reward/reaching_object 0.7703
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 169082880
                    Iteration time: 0.12s
                      Time elapsed: 00:33:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1721/1 [0m                       

                       Computation: 724888 steps/s (collection: 0.038s, learning 0.098s)
                       Mean reward: 874.27
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.7509
       Episode_Reward/object_height 0.0274
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 169181184
                    Iteration time: 0.14s
                      Time elapsed: 00:33:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1722/1 [0m                       

                       Computation: 763875 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 882.54
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.7485
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7732
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 169279488
                    Iteration time: 0.13s
                      Time elapsed: 00:33:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1723/1 [0m                       

                       Computation: 752263 steps/s (collection: 0.038s, learning 0.093s)
                       Mean reward: 879.79
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.2085
       Episode_Reward/object_height 0.0278
     Episode_Reward/reaching_object 0.7797
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 169377792
                    Iteration time: 0.13s
                      Time elapsed: 00:33:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1724/1 [0m                       

                       Computation: 822656 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 875.85
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.4061
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7761
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 169476096
                    Iteration time: 0.12s
                      Time elapsed: 00:33:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1725/1 [0m                       

                       Computation: 770377 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 879.51
               Mean episode length: 249.91
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.0369
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7796
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 169574400
                    Iteration time: 0.13s
                      Time elapsed: 00:33:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1726/1 [0m                       

                       Computation: 767566 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 879.47
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.8900
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7718
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 169672704
                    Iteration time: 0.13s
                      Time elapsed: 00:33:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1727/1 [0m                       

                       Computation: 792398 steps/s (collection: 0.046s, learning 0.078s)
                       Mean reward: 884.04
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 176.0288
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7776
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 169771008
                    Iteration time: 0.12s
                      Time elapsed: 00:33:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1728/1 [0m                       

                       Computation: 706645 steps/s (collection: 0.051s, learning 0.089s)
                       Mean reward: 877.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 174.9556
       Episode_Reward/object_height 0.0279
     Episode_Reward/reaching_object 0.7713
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 169869312
                    Iteration time: 0.14s
                      Time elapsed: 00:33:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1729/1 [0m                       

                       Computation: 824955 steps/s (collection: 0.041s, learning 0.079s)
                       Mean reward: 867.69
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.6076
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7697
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 169967616
                    Iteration time: 0.12s
                      Time elapsed: 00:33:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1730/1 [0m                       

                       Computation: 727874 steps/s (collection: 0.039s, learning 0.096s)
                       Mean reward: 876.82
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.4191
       Episode_Reward/object_height 0.0276
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 28.5417
--------------------------------------------------------------------------------
                   Total timesteps: 170065920
                    Iteration time: 0.14s
                      Time elapsed: 00:33:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1731/1 [0m                       

                       Computation: 756114 steps/s (collection: 0.038s, learning 0.092s)
                       Mean reward: 874.16
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.0745
       Episode_Reward/object_height 0.0277
     Episode_Reward/reaching_object 0.7766
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 170164224
                    Iteration time: 0.13s
                      Time elapsed: 00:33:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1732/1 [0m                       

                       Computation: 729720 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 877.77
               Mean episode length: 249.66
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.9177
       Episode_Reward/object_height 0.0282
     Episode_Reward/reaching_object 0.7756
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 170262528
                    Iteration time: 0.13s
                      Time elapsed: 00:33:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1733/1 [0m                       

                       Computation: 726837 steps/s (collection: 0.037s, learning 0.098s)
                       Mean reward: 877.10
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.7776
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7746
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 170360832
                    Iteration time: 0.14s
                      Time elapsed: 00:33:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1734/1 [0m                       

                       Computation: 760892 steps/s (collection: 0.042s, learning 0.088s)
                       Mean reward: 881.98
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 175.3904
       Episode_Reward/object_height 0.0280
     Episode_Reward/reaching_object 0.7784
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 170459136
                    Iteration time: 0.13s
                      Time elapsed: 00:33:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1735/1 [0m                       

                       Computation: 654866 steps/s (collection: 0.041s, learning 0.110s)
                       Mean reward: 879.25
               Mean episode length: 249.93
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.0312
       Episode_Reward/object_height 0.0283
     Episode_Reward/reaching_object 0.7702
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 170557440
                    Iteration time: 0.15s
                      Time elapsed: 00:33:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1736/1 [0m                       

                       Computation: 670601 steps/s (collection: 0.043s, learning 0.104s)
                       Mean reward: 874.02
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.8312
       Episode_Reward/object_height 0.0282
     Episode_Reward/reaching_object 0.7632
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 170655744
                    Iteration time: 0.15s
                      Time elapsed: 00:33:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1737/1 [0m                       

                       Computation: 749262 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 879.33
               Mean episode length: 249.70
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.0978
       Episode_Reward/object_height 0.0285
     Episode_Reward/reaching_object 0.7671
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 170754048
                    Iteration time: 0.13s
                      Time elapsed: 00:33:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1738/1 [0m                       

                       Computation: 730371 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 876.93
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.8759
       Episode_Reward/object_height 0.0285
     Episode_Reward/reaching_object 0.7621
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 170852352
                    Iteration time: 0.13s
                      Time elapsed: 00:33:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1739/1 [0m                       

                       Computation: 832793 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 877.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.6810
       Episode_Reward/object_height 0.0285
     Episode_Reward/reaching_object 0.7682
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 170950656
                    Iteration time: 0.12s
                      Time elapsed: 00:33:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1740/1 [0m                       

                       Computation: 797936 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 875.11
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.7485
       Episode_Reward/object_height 0.0284
     Episode_Reward/reaching_object 0.7599
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 31.1250
--------------------------------------------------------------------------------
                   Total timesteps: 171048960
                    Iteration time: 0.12s
                      Time elapsed: 00:33:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1741/1 [0m                       

                       Computation: 807321 steps/s (collection: 0.038s, learning 0.084s)
                       Mean reward: 871.68
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.1554
       Episode_Reward/object_height 0.0281
     Episode_Reward/reaching_object 0.7588
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 171147264
                    Iteration time: 0.12s
                      Time elapsed: 00:33:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1742/1 [0m                       

                       Computation: 763834 steps/s (collection: 0.037s, learning 0.092s)
                       Mean reward: 873.26
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.2541
       Episode_Reward/object_height 0.0284
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 12.6250
--------------------------------------------------------------------------------
                   Total timesteps: 171245568
                    Iteration time: 0.13s
                      Time elapsed: 00:33:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1743/1 [0m                       

                       Computation: 753476 steps/s (collection: 0.040s, learning 0.090s)
                       Mean reward: 879.77
               Mean episode length: 249.68
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.0031
       Episode_Reward/object_height 0.0286
     Episode_Reward/reaching_object 0.7613
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 171343872
                    Iteration time: 0.13s
                      Time elapsed: 00:33:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1744/1 [0m                       

                       Computation: 730167 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 880.96
               Mean episode length: 249.85
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 175.4765
       Episode_Reward/object_height 0.0287
     Episode_Reward/reaching_object 0.7647
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 171442176
                    Iteration time: 0.13s
                      Time elapsed: 00:33:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1745/1 [0m                       

                       Computation: 734697 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 882.35
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.6182
       Episode_Reward/object_height 0.0288
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 171540480
                    Iteration time: 0.13s
                      Time elapsed: 00:33:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1746/1 [0m                       

                       Computation: 755222 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 883.20
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.9028
       Episode_Reward/object_height 0.0289
     Episode_Reward/reaching_object 0.7704
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 171638784
                    Iteration time: 0.13s
                      Time elapsed: 00:33:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1747/1 [0m                       

                       Computation: 704875 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 880.99
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.2525
       Episode_Reward/object_height 0.0288
     Episode_Reward/reaching_object 0.7666
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 171737088
                    Iteration time: 0.14s
                      Time elapsed: 00:33:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1748/1 [0m                       

                       Computation: 793979 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 883.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.8813
       Episode_Reward/object_height 0.0291
     Episode_Reward/reaching_object 0.7619
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 171835392
                    Iteration time: 0.12s
                      Time elapsed: 00:33:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1749/1 [0m                       

                       Computation: 662427 steps/s (collection: 0.048s, learning 0.100s)
                       Mean reward: 876.86
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.3653
       Episode_Reward/object_height 0.0292
     Episode_Reward/reaching_object 0.7545
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 171933696
                    Iteration time: 0.15s
                      Time elapsed: 00:33:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1750/1 [0m                       

                       Computation: 817534 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 881.13
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 175.3067
       Episode_Reward/object_height 0.0292
     Episode_Reward/reaching_object 0.7602
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 33.5000
--------------------------------------------------------------------------------
                   Total timesteps: 172032000
                    Iteration time: 0.12s
                      Time elapsed: 00:33:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1751/1 [0m                       

                       Computation: 704515 steps/s (collection: 0.038s, learning 0.102s)
                       Mean reward: 878.19
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 174.8864
       Episode_Reward/object_height 0.0294
     Episode_Reward/reaching_object 0.7585
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 172130304
                    Iteration time: 0.14s
                      Time elapsed: 00:33:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1752/1 [0m                       

                       Computation: 745244 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 877.81
               Mean episode length: 249.61
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.5312
       Episode_Reward/object_height 0.0293
     Episode_Reward/reaching_object 0.7584
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 172228608
                    Iteration time: 0.13s
                      Time elapsed: 00:33:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1753/1 [0m                       

                       Computation: 701838 steps/s (collection: 0.038s, learning 0.103s)
                       Mean reward: 874.33
               Mean episode length: 249.06
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 174.2651
       Episode_Reward/object_height 0.0291
     Episode_Reward/reaching_object 0.7567
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 172326912
                    Iteration time: 0.14s
                      Time elapsed: 00:33:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1754/1 [0m                       

                       Computation: 701103 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 885.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 176.2309
       Episode_Reward/object_height 0.0295
     Episode_Reward/reaching_object 0.7660
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 172425216
                    Iteration time: 0.14s
                      Time elapsed: 00:33:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1755/1 [0m                       

                       Computation: 780244 steps/s (collection: 0.038s, learning 0.088s)
                       Mean reward: 884.92
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 176.2371
       Episode_Reward/object_height 0.0297
     Episode_Reward/reaching_object 0.7593
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 172523520
                    Iteration time: 0.13s
                      Time elapsed: 00:33:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1756/1 [0m                       

                       Computation: 808638 steps/s (collection: 0.037s, learning 0.085s)
                       Mean reward: 880.18
               Mean episode length: 249.72
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.2019
       Episode_Reward/object_height 0.0296
     Episode_Reward/reaching_object 0.7579
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 172621824
                    Iteration time: 0.12s
                      Time elapsed: 00:33:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1757/1 [0m                       

                       Computation: 792500 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 886.14
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 176.5052
       Episode_Reward/object_height 0.0301
     Episode_Reward/reaching_object 0.7640
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 172720128
                    Iteration time: 0.12s
                      Time elapsed: 00:33:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1758/1 [0m                       

                       Computation: 799060 steps/s (collection: 0.039s, learning 0.084s)
                       Mean reward: 881.01
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.4187
       Episode_Reward/object_height 0.0301
     Episode_Reward/reaching_object 0.7599
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 172818432
                    Iteration time: 0.12s
                      Time elapsed: 00:33:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1759/1 [0m                       

                       Computation: 813294 steps/s (collection: 0.037s, learning 0.084s)
                       Mean reward: 874.70
               Mean episode length: 249.55
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.9469
       Episode_Reward/object_height 0.0302
     Episode_Reward/reaching_object 0.7544
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 172916736
                    Iteration time: 0.12s
                      Time elapsed: 00:33:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1760/1 [0m                       

                       Computation: 754149 steps/s (collection: 0.037s, learning 0.093s)
                       Mean reward: 881.49
               Mean episode length: 249.63
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 175.4912
       Episode_Reward/object_height 0.0303
     Episode_Reward/reaching_object 0.7624
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 173015040
                    Iteration time: 0.13s
                      Time elapsed: 00:33:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1761/1 [0m                       

                       Computation: 784236 steps/s (collection: 0.036s, learning 0.089s)
                       Mean reward: 880.69
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 175.8696
       Episode_Reward/object_height 0.0302
     Episode_Reward/reaching_object 0.7717
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 30.9167
--------------------------------------------------------------------------------
                   Total timesteps: 173113344
                    Iteration time: 0.13s
                      Time elapsed: 00:33:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1762/1 [0m                       

                       Computation: 831252 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 871.50
               Mean episode length: 248.93
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.8345
       Episode_Reward/object_height 0.0300
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 173211648
                    Iteration time: 0.12s
                      Time elapsed: 00:33:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1763/1 [0m                       

                       Computation: 828228 steps/s (collection: 0.036s, learning 0.083s)
                       Mean reward: 882.28
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 175.5379
       Episode_Reward/object_height 0.0303
     Episode_Reward/reaching_object 0.7674
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 173309952
                    Iteration time: 0.12s
                      Time elapsed: 00:33:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1764/1 [0m                       

                       Computation: 762110 steps/s (collection: 0.036s, learning 0.093s)
                       Mean reward: 883.94
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 176.0462
       Episode_Reward/object_height 0.0305
     Episode_Reward/reaching_object 0.7753
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 173408256
                    Iteration time: 0.13s
                      Time elapsed: 00:33:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1765/1 [0m                       

                       Computation: 783917 steps/s (collection: 0.041s, learning 0.085s)
                       Mean reward: 873.20
               Mean episode length: 249.20
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.7667
       Episode_Reward/object_height 0.0302
     Episode_Reward/reaching_object 0.7636
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 173506560
                    Iteration time: 0.13s
                      Time elapsed: 00:33:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1766/1 [0m                       

                       Computation: 801676 steps/s (collection: 0.036s, learning 0.087s)
                       Mean reward: 878.44
               Mean episode length: 249.53
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 174.8998
       Episode_Reward/object_height 0.0303
     Episode_Reward/reaching_object 0.7641
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 173604864
                    Iteration time: 0.12s
                      Time elapsed: 00:33:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1767/1 [0m                       

                       Computation: 770475 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 877.34
               Mean episode length: 249.09
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.3700
       Episode_Reward/object_height 0.0304
     Episode_Reward/reaching_object 0.7617
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 173703168
                    Iteration time: 0.13s
                      Time elapsed: 00:33:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1768/1 [0m                       

                       Computation: 773103 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 878.98
               Mean episode length: 249.95
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 175.0769
       Episode_Reward/object_height 0.0307
     Episode_Reward/reaching_object 0.7583
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 173801472
                    Iteration time: 0.13s
                      Time elapsed: 00:33:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1769/1 [0m                       

                       Computation: 780428 steps/s (collection: 0.037s, learning 0.089s)
                       Mean reward: 875.80
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 174.4984
       Episode_Reward/object_height 0.0307
     Episode_Reward/reaching_object 0.7523
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 173899776
                    Iteration time: 0.13s
                      Time elapsed: 00:33:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1770/1 [0m                       

                       Computation: 786837 steps/s (collection: 0.041s, learning 0.084s)
                       Mean reward: 880.84
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 175.2797
       Episode_Reward/object_height 0.0308
     Episode_Reward/reaching_object 0.7569
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 173998080
                    Iteration time: 0.12s
                      Time elapsed: 00:33:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1771/1 [0m                       

                       Computation: 687809 steps/s (collection: 0.040s, learning 0.103s)
                       Mean reward: 881.62
               Mean episode length: 249.90
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 175.4890
       Episode_Reward/object_height 0.0310
     Episode_Reward/reaching_object 0.7571
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 32.7500
--------------------------------------------------------------------------------
                   Total timesteps: 174096384
                    Iteration time: 0.14s
                      Time elapsed: 00:34:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1772/1 [0m                       

                       Computation: 830533 steps/s (collection: 0.037s, learning 0.081s)
                       Mean reward: 878.12
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.8597
       Episode_Reward/object_height 0.0308
     Episode_Reward/reaching_object 0.7630
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 174194688
                    Iteration time: 0.12s
                      Time elapsed: 00:34:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1773/1 [0m                       

                       Computation: 831874 steps/s (collection: 0.036s, learning 0.082s)
                       Mean reward: 878.05
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 175.1296
       Episode_Reward/object_height 0.0308
     Episode_Reward/reaching_object 0.7684
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 174292992
                    Iteration time: 0.12s
                      Time elapsed: 00:34:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1774/1 [0m                       

                       Computation: 819392 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 881.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 175.4270
       Episode_Reward/object_height 0.0310
     Episode_Reward/reaching_object 0.7722
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 174391296
                    Iteration time: 0.12s
                      Time elapsed: 00:34:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1775/1 [0m                       

                       Computation: 802742 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 875.21
               Mean episode length: 249.21
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 174.6194
       Episode_Reward/object_height 0.0310
     Episode_Reward/reaching_object 0.7648
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 174489600
                    Iteration time: 0.12s
                      Time elapsed: 00:34:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1776/1 [0m                       

                       Computation: 733474 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 880.12
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 175.3684
       Episode_Reward/object_height 0.0314
     Episode_Reward/reaching_object 0.7629
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 174587904
                    Iteration time: 0.13s
                      Time elapsed: 00:34:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1777/1 [0m                       

                       Computation: 826831 steps/s (collection: 0.039s, learning 0.080s)
                       Mean reward: 878.32
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 174.8067
       Episode_Reward/object_height 0.0314
     Episode_Reward/reaching_object 0.7577
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 174686208
                    Iteration time: 0.12s
                      Time elapsed: 00:34:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1778/1 [0m                       

                       Computation: 736715 steps/s (collection: 0.040s, learning 0.094s)
                       Mean reward: 874.53
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.3984
       Episode_Reward/object_height 0.0313
     Episode_Reward/reaching_object 0.7550
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 174784512
                    Iteration time: 0.13s
                      Time elapsed: 00:34:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1779/1 [0m                       

                       Computation: 775823 steps/s (collection: 0.038s, learning 0.089s)
                       Mean reward: 875.25
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 173.6139
       Episode_Reward/object_height 0.0314
     Episode_Reward/reaching_object 0.7506
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 174882816
                    Iteration time: 0.13s
                      Time elapsed: 00:34:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1780/1 [0m                       

                       Computation: 804754 steps/s (collection: 0.038s, learning 0.085s)
                       Mean reward: 877.29
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.5281
       Episode_Reward/object_height 0.0318
     Episode_Reward/reaching_object 0.7546
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 174981120
                    Iteration time: 0.12s
                      Time elapsed: 00:34:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1781/1 [0m                       

                       Computation: 735599 steps/s (collection: 0.038s, learning 0.096s)
                       Mean reward: 883.36
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 176.0744
       Episode_Reward/object_height 0.0321
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 175079424
                    Iteration time: 0.13s
                      Time elapsed: 00:34:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1782/1 [0m                       

                       Computation: 714778 steps/s (collection: 0.038s, learning 0.100s)
                       Mean reward: 878.90
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 175.6934
       Episode_Reward/object_height 0.0321
     Episode_Reward/reaching_object 0.7578
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 29.1250
--------------------------------------------------------------------------------
                   Total timesteps: 175177728
                    Iteration time: 0.14s
                      Time elapsed: 00:34:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1783/1 [0m                       

                       Computation: 761769 steps/s (collection: 0.039s, learning 0.091s)
                       Mean reward: 883.92
               Mean episode length: 249.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 176.2328
       Episode_Reward/object_height 0.0322
     Episode_Reward/reaching_object 0.7627
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 175276032
                    Iteration time: 0.13s
                      Time elapsed: 00:34:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1784/1 [0m                       

                       Computation: 799049 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 882.73
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 175.7096
       Episode_Reward/object_height 0.0323
     Episode_Reward/reaching_object 0.7605
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 175374336
                    Iteration time: 0.12s
                      Time elapsed: 00:34:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1785/1 [0m                       

                       Computation: 852565 steps/s (collection: 0.036s, learning 0.079s)
                       Mean reward: 880.74
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 175.3536
       Episode_Reward/object_height 0.0323
     Episode_Reward/reaching_object 0.7569
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 175472640
                    Iteration time: 0.12s
                      Time elapsed: 00:34:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1786/1 [0m                       

                       Computation: 785401 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 880.43
               Mean episode length: 248.91
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 175.1881
       Episode_Reward/object_height 0.0324
     Episode_Reward/reaching_object 0.7615
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 175570944
                    Iteration time: 0.13s
                      Time elapsed: 00:34:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1787/1 [0m                       

                       Computation: 785750 steps/s (collection: 0.037s, learning 0.088s)
                       Mean reward: 880.91
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 175.5033
       Episode_Reward/object_height 0.0324
     Episode_Reward/reaching_object 0.7623
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 175669248
                    Iteration time: 0.13s
                      Time elapsed: 00:34:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1788/1 [0m                       

                       Computation: 737602 steps/s (collection: 0.039s, learning 0.094s)
                       Mean reward: 885.90
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 176.1627
       Episode_Reward/object_height 0.0327
     Episode_Reward/reaching_object 0.7607
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 175767552
                    Iteration time: 0.13s
                      Time elapsed: 00:34:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1789/1 [0m                       

                       Computation: 814375 steps/s (collection: 0.036s, learning 0.084s)
                       Mean reward: 875.18
               Mean episode length: 249.79
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 174.0574
       Episode_Reward/object_height 0.0325
     Episode_Reward/reaching_object 0.7594
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 175865856
                    Iteration time: 0.12s
                      Time elapsed: 00:34:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1790/1 [0m                       

                       Computation: 750242 steps/s (collection: 0.037s, learning 0.095s)
                       Mean reward: 881.90
               Mean episode length: 249.97
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 175.5289
       Episode_Reward/object_height 0.0331
     Episode_Reward/reaching_object 0.7513
Episode_Termination/object_dropping 0.0417
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 175964160
                    Iteration time: 0.13s
                      Time elapsed: 00:34:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1791/1 [0m                       

                       Computation: 795465 steps/s (collection: 0.036s, learning 0.088s)
                       Mean reward: 877.65
               Mean episode length: 249.73
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 174.9428
       Episode_Reward/object_height 0.0332
     Episode_Reward/reaching_object 0.7450
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 176062464
                    Iteration time: 0.12s
                      Time elapsed: 00:34:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1792/1 [0m                       

                       Computation: 766858 steps/s (collection: 0.037s, learning 0.091s)
                       Mean reward: 880.56
               Mean episode length: 250.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 175.2742
       Episode_Reward/object_height 0.0335
     Episode_Reward/reaching_object 0.7437
Episode_Termination/object_dropping 0.0000
       Episode_Termination/time_out 31.1250
--------------------------------------------------------------------------------
                   Total timesteps: 176160768
                    Iteration time: 0.13s
                      Time elapsed: 00:34:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1793/1 [0m                       

                       Computation: 701666 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 872.19
               Mean episode length: 249.13
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0020
      Episode_Reward/lifting_object 173.3863
       Episode_Reward/object_height 0.0335
     Episode_Reward/reaching_object 0.7442
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 176259072
                    Iteration time: 0.14s
                      Time elapsed: 00:34:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1794/1 [0m                       

                       Computation: 756953 steps/s (collection: 0.045s, learning 0.085s)
                       Mean reward: 871.02
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 172.9731
       Episode_Reward/object_height 0.0334
     Episode_Reward/reaching_object 0.7416
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 176357376
                    Iteration time: 0.13s
                      Time elapsed: 00:34:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1795/1 [0m                       

                       Computation: 768492 steps/s (collection: 0.043s, learning 0.085s)
                       Mean reward: 876.93
               Mean episode length: 249.87
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 174.6906
       Episode_Reward/object_height 0.0343
     Episode_Reward/reaching_object 0.7447
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 176455680
                    Iteration time: 0.13s
                      Time elapsed: 00:34:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1796/1 [0m                       

                       Computation: 823041 steps/s (collection: 0.039s, learning 0.081s)
                       Mean reward: 878.73
               Mean episode length: 249.41
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 175.0806
       Episode_Reward/object_height 0.0343
     Episode_Reward/reaching_object 0.7452
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 176553984
                    Iteration time: 0.12s
                      Time elapsed: 00:34:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1797/1 [0m                       

                       Computation: 793206 steps/s (collection: 0.039s, learning 0.085s)
                       Mean reward: 867.37
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.0138
       Episode_Reward/object_height 0.0341
     Episode_Reward/reaching_object 0.7416
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 176652288
                    Iteration time: 0.12s
                      Time elapsed: 00:34:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1798/1 [0m                       

                       Computation: 769279 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 874.31
               Mean episode length: 249.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 173.9103
       Episode_Reward/object_height 0.0344
     Episode_Reward/reaching_object 0.7528
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 176750592
                    Iteration time: 0.13s
                      Time elapsed: 00:34:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1799/1 [0m                       

                       Computation: 707129 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 872.27
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 173.8627
       Episode_Reward/object_height 0.0346
     Episode_Reward/reaching_object 0.7583
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 176848896
                    Iteration time: 0.14s
                      Time elapsed: 00:34:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1800/1 [0m                       

                       Computation: 699596 steps/s (collection: 0.042s, learning 0.099s)
                       Mean reward: 880.19
               Mean episode length: 249.17
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 175.3886
       Episode_Reward/object_height 0.0352
     Episode_Reward/reaching_object 0.7597
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 176947200
                    Iteration time: 0.14s
                      Time elapsed: 00:34:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1801/1 [0m                       

                       Computation: 746443 steps/s (collection: 0.040s, learning 0.092s)
                       Mean reward: 875.37
               Mean episode length: 248.71
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.9957
       Episode_Reward/object_height 0.0352
     Episode_Reward/reaching_object 0.7561
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 177045504
                    Iteration time: 0.13s
                      Time elapsed: 00:34:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1802/1 [0m                       

                       Computation: 757929 steps/s (collection: 0.043s, learning 0.087s)
                       Mean reward: 871.32
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 173.3965
       Episode_Reward/object_height 0.0358
     Episode_Reward/reaching_object 0.7622
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.5417
--------------------------------------------------------------------------------
                   Total timesteps: 177143808
                    Iteration time: 0.13s
                      Time elapsed: 00:34:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1803/1 [0m                       

                       Computation: 720309 steps/s (collection: 0.039s, learning 0.097s)
                       Mean reward: 866.99
               Mean episode length: 249.50
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.9997
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7564
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 27.5417
--------------------------------------------------------------------------------
                   Total timesteps: 177242112
                    Iteration time: 0.14s
                      Time elapsed: 00:34:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1804/1 [0m                       

                       Computation: 711027 steps/s (collection: 0.040s, learning 0.098s)
                       Mean reward: 861.50
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4477
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7570
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 177340416
                    Iteration time: 0.14s
                      Time elapsed: 00:34:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1805/1 [0m                       

                       Computation: 776824 steps/s (collection: 0.045s, learning 0.082s)
                       Mean reward: 869.28
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.5028
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7633
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 177438720
                    Iteration time: 0.13s
                      Time elapsed: 00:34:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1806/1 [0m                       

                       Computation: 734771 steps/s (collection: 0.039s, learning 0.095s)
                       Mean reward: 854.43
               Mean episode length: 246.74
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.8830
       Episode_Reward/object_height 0.0364
     Episode_Reward/reaching_object 0.7453
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 177537024
                    Iteration time: 0.13s
                      Time elapsed: 00:34:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1807/1 [0m                       

                       Computation: 727151 steps/s (collection: 0.047s, learning 0.088s)
                       Mean reward: 866.92
               Mean episode length: 247.83
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3287
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 177635328
                    Iteration time: 0.14s
                      Time elapsed: 00:34:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1808/1 [0m                       

                       Computation: 766242 steps/s (collection: 0.040s, learning 0.089s)
                       Mean reward: 876.10
               Mean episode length: 248.89
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 174.5725
       Episode_Reward/object_height 0.0376
     Episode_Reward/reaching_object 0.7648
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 177733632
                    Iteration time: 0.13s
                      Time elapsed: 00:34:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1809/1 [0m                       

                       Computation: 768595 steps/s (collection: 0.041s, learning 0.087s)
                       Mean reward: 859.43
               Mean episode length: 247.42
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.0582
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7559
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 177831936
                    Iteration time: 0.13s
                      Time elapsed: 00:34:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1810/1 [0m                       

                       Computation: 618888 steps/s (collection: 0.042s, learning 0.117s)
                       Mean reward: 872.60
               Mean episode length: 247.77
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6005
       Episode_Reward/object_height 0.0376
     Episode_Reward/reaching_object 0.7631
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 177930240
                    Iteration time: 0.16s
                      Time elapsed: 00:34:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1811/1 [0m                       

                       Computation: 741990 steps/s (collection: 0.041s, learning 0.092s)
                       Mean reward: 862.86
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.5234
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7536
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 178028544
                    Iteration time: 0.13s
                      Time elapsed: 00:34:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1812/1 [0m                       

                       Computation: 748953 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 868.09
               Mean episode length: 248.23
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.8289
       Episode_Reward/object_height 0.0374
     Episode_Reward/reaching_object 0.7590
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 178126848
                    Iteration time: 0.13s
                      Time elapsed: 00:34:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1813/1 [0m                       

                       Computation: 775197 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 868.14
               Mean episode length: 249.31
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.5783
       Episode_Reward/object_height 0.0375
     Episode_Reward/reaching_object 0.7587
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 30.2500
--------------------------------------------------------------------------------
                   Total timesteps: 178225152
                    Iteration time: 0.13s
                      Time elapsed: 00:34:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1814/1 [0m                       

                       Computation: 747107 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 869.72
               Mean episode length: 247.92
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.2539
       Episode_Reward/object_height 0.0377
     Episode_Reward/reaching_object 0.7658
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 178323456
                    Iteration time: 0.13s
                      Time elapsed: 00:34:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1815/1 [0m                       

                       Computation: 703698 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 867.47
               Mean episode length: 248.56
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.1722
       Episode_Reward/object_height 0.0376
     Episode_Reward/reaching_object 0.7645
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 178421760
                    Iteration time: 0.14s
                      Time elapsed: 00:34:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1816/1 [0m                       

                       Computation: 773875 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 855.36
               Mean episode length: 246.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.1194
       Episode_Reward/object_height 0.0372
     Episode_Reward/reaching_object 0.7493
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 178520064
                    Iteration time: 0.13s
                      Time elapsed: 00:34:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1817/1 [0m                       

                       Computation: 772777 steps/s (collection: 0.039s, learning 0.088s)
                       Mean reward: 864.22
               Mean episode length: 247.32
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.8687
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7546
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 178618368
                    Iteration time: 0.13s
                      Time elapsed: 00:34:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1818/1 [0m                       

                       Computation: 704618 steps/s (collection: 0.039s, learning 0.101s)
                       Mean reward: 863.89
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.4711
       Episode_Reward/object_height 0.0371
     Episode_Reward/reaching_object 0.7573
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 178716672
                    Iteration time: 0.14s
                      Time elapsed: 00:34:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1819/1 [0m                       

                       Computation: 771022 steps/s (collection: 0.040s, learning 0.087s)
                       Mean reward: 867.14
               Mean episode length: 247.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.6478
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7597
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 178814976
                    Iteration time: 0.13s
                      Time elapsed: 00:34:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1820/1 [0m                       

                       Computation: 704900 steps/s (collection: 0.039s, learning 0.100s)
                       Mean reward: 862.48
               Mean episode length: 248.30
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6276
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7571
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 178913280
                    Iteration time: 0.14s
                      Time elapsed: 00:34:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1821/1 [0m                       

                       Computation: 767603 steps/s (collection: 0.041s, learning 0.088s)
                       Mean reward: 870.46
               Mean episode length: 249.32
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.4025
       Episode_Reward/object_height 0.0374
     Episode_Reward/reaching_object 0.7608
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 179011584
                    Iteration time: 0.13s
                      Time elapsed: 00:34:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1822/1 [0m                       

                       Computation: 736809 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 856.34
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.6696
       Episode_Reward/object_height 0.0366
     Episode_Reward/reaching_object 0.7510
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 179109888
                    Iteration time: 0.13s
                      Time elapsed: 00:34:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1823/1 [0m                       

                       Computation: 709508 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 863.19
               Mean episode length: 249.44
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7959
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7642
Episode_Termination/object_dropping 0.1250
       Episode_Termination/time_out 32.1250
--------------------------------------------------------------------------------
                   Total timesteps: 179208192
                    Iteration time: 0.14s
                      Time elapsed: 00:34:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1824/1 [0m                       

                       Computation: 692474 steps/s (collection: 0.047s, learning 0.095s)
                       Mean reward: 862.55
               Mean episode length: 249.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.0270
       Episode_Reward/object_height 0.0368
     Episode_Reward/reaching_object 0.7534
Episode_Termination/object_dropping 0.0833
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 179306496
                    Iteration time: 0.14s
                      Time elapsed: 00:34:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1825/1 [0m                       

                       Computation: 767585 steps/s (collection: 0.044s, learning 0.084s)
                       Mean reward: 865.99
               Mean episode length: 247.73
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 172.7685
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7517
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 179404800
                    Iteration time: 0.13s
                      Time elapsed: 00:34:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1826/1 [0m                       

                       Computation: 676305 steps/s (collection: 0.050s, learning 0.095s)
                       Mean reward: 859.87
               Mean episode length: 248.54
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.0603
       Episode_Reward/object_height 0.0366
     Episode_Reward/reaching_object 0.7486
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 179503104
                    Iteration time: 0.15s
                      Time elapsed: 00:35:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1827/1 [0m                       

                       Computation: 674701 steps/s (collection: 0.046s, learning 0.100s)
                       Mean reward: 859.03
               Mean episode length: 248.10
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.9528
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7445
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 179601408
                    Iteration time: 0.15s
                      Time elapsed: 00:35:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1828/1 [0m                       

                       Computation: 645462 steps/s (collection: 0.048s, learning 0.104s)
                       Mean reward: 858.53
               Mean episode length: 247.62
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.8829
       Episode_Reward/object_height 0.0362
     Episode_Reward/reaching_object 0.7347
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 179699712
                    Iteration time: 0.15s
                      Time elapsed: 00:35:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1829/1 [0m                       

                       Computation: 638317 steps/s (collection: 0.053s, learning 0.101s)
                       Mean reward: 863.45
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.3838
       Episode_Reward/object_height 0.0363
     Episode_Reward/reaching_object 0.7424
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 179798016
                    Iteration time: 0.15s
                      Time elapsed: 00:35:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1830/1 [0m                       

                       Computation: 795757 steps/s (collection: 0.040s, learning 0.084s)
                       Mean reward: 855.63
               Mean episode length: 247.65
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2439
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7416
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 179896320
                    Iteration time: 0.12s
                      Time elapsed: 00:35:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1831/1 [0m                       

                       Computation: 725100 steps/s (collection: 0.041s, learning 0.094s)
                       Mean reward: 868.34
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.7719
       Episode_Reward/object_height 0.0362
     Episode_Reward/reaching_object 0.7457
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 179994624
                    Iteration time: 0.14s
                      Time elapsed: 00:35:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1832/1 [0m                       

                       Computation: 782585 steps/s (collection: 0.040s, learning 0.086s)
                       Mean reward: 860.96
               Mean episode length: 247.13
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4188
       Episode_Reward/object_height 0.0358
     Episode_Reward/reaching_object 0.7402
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 180092928
                    Iteration time: 0.13s
                      Time elapsed: 00:35:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1833/1 [0m                       

                       Computation: 744575 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 861.46
               Mean episode length: 247.19
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7094
       Episode_Reward/object_height 0.0358
     Episode_Reward/reaching_object 0.7391
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 180191232
                    Iteration time: 0.13s
                      Time elapsed: 00:35:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1834/1 [0m                       

                       Computation: 627975 steps/s (collection: 0.047s, learning 0.110s)
                       Mean reward: 861.04
               Mean episode length: 249.07
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 172.9550
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7387
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 28.2917
--------------------------------------------------------------------------------
                   Total timesteps: 180289536
                    Iteration time: 0.16s
                      Time elapsed: 00:35:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1835/1 [0m                       

                       Computation: 759149 steps/s (collection: 0.044s, learning 0.086s)
                       Mean reward: 860.33
               Mean episode length: 246.85
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.1962
       Episode_Reward/object_height 0.0357
     Episode_Reward/reaching_object 0.7371
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 180387840
                    Iteration time: 0.13s
                      Time elapsed: 00:35:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1836/1 [0m                       

                       Computation: 556882 steps/s (collection: 0.052s, learning 0.125s)
                       Mean reward: 837.37
               Mean episode length: 244.59
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.2948
       Episode_Reward/object_height 0.0349
     Episode_Reward/reaching_object 0.7213
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 180486144
                    Iteration time: 0.18s
                      Time elapsed: 00:35:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1837/1 [0m                       

                       Computation: 564938 steps/s (collection: 0.061s, learning 0.113s)
                       Mean reward: 855.21
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.2268
       Episode_Reward/object_height 0.0355
     Episode_Reward/reaching_object 0.7317
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 180584448
                    Iteration time: 0.17s
                      Time elapsed: 00:35:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1838/1 [0m                       

                       Computation: 583127 steps/s (collection: 0.054s, learning 0.115s)
                       Mean reward: 858.49
               Mean episode length: 247.05
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.4925
       Episode_Reward/object_height 0.0357
     Episode_Reward/reaching_object 0.7350
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 180682752
                    Iteration time: 0.17s
                      Time elapsed: 00:35:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1839/1 [0m                       

                       Computation: 732453 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 857.51
               Mean episode length: 248.16
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.6547
       Episode_Reward/object_height 0.0356
     Episode_Reward/reaching_object 0.7298
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 180781056
                    Iteration time: 0.13s
                      Time elapsed: 00:35:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1840/1 [0m                       

                       Computation: 608479 steps/s (collection: 0.051s, learning 0.111s)
                       Mean reward: 844.51
               Mean episode length: 245.90
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.2918
       Episode_Reward/object_height 0.0350
     Episode_Reward/reaching_object 0.7198
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 180879360
                    Iteration time: 0.16s
                      Time elapsed: 00:35:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1841/1 [0m                       

                       Computation: 747619 steps/s (collection: 0.050s, learning 0.082s)
                       Mean reward: 849.85
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.0822
       Episode_Reward/object_height 0.0354
     Episode_Reward/reaching_object 0.7222
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 180977664
                    Iteration time: 0.13s
                      Time elapsed: 00:35:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1842/1 [0m                       

                       Computation: 778913 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 840.61
               Mean episode length: 246.50
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.3894
       Episode_Reward/object_height 0.0349
     Episode_Reward/reaching_object 0.7234
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 181075968
                    Iteration time: 0.13s
                      Time elapsed: 00:35:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1843/1 [0m                       

                       Computation: 567039 steps/s (collection: 0.060s, learning 0.113s)
                       Mean reward: 858.77
               Mean episode length: 247.80
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.9616
       Episode_Reward/object_height 0.0357
     Episode_Reward/reaching_object 0.7359
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 181174272
                    Iteration time: 0.17s
                      Time elapsed: 00:35:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1844/1 [0m                       

                       Computation: 720128 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 854.33
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.8287
       Episode_Reward/object_height 0.0353
     Episode_Reward/reaching_object 0.7287
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 30.2083
--------------------------------------------------------------------------------
                   Total timesteps: 181272576
                    Iteration time: 0.14s
                      Time elapsed: 00:35:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1845/1 [0m                       

                       Computation: 747893 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 852.46
               Mean episode length: 247.53
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5130
       Episode_Reward/object_height 0.0356
     Episode_Reward/reaching_object 0.7363
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 181370880
                    Iteration time: 0.13s
                      Time elapsed: 00:35:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1846/1 [0m                       

                       Computation: 803999 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 841.05
               Mean episode length: 246.48
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.4814
       Episode_Reward/object_height 0.0349
     Episode_Reward/reaching_object 0.7261
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 181469184
                    Iteration time: 0.12s
                      Time elapsed: 00:35:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1847/1 [0m                       

                       Computation: 744637 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 859.17
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8144
       Episode_Reward/object_height 0.0357
     Episode_Reward/reaching_object 0.7430
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 181567488
                    Iteration time: 0.13s
                      Time elapsed: 00:35:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1848/1 [0m                       

                       Computation: 808843 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 854.57
               Mean episode length: 246.30
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.4268
       Episode_Reward/object_height 0.0355
     Episode_Reward/reaching_object 0.7395
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 181665792
                    Iteration time: 0.12s
                      Time elapsed: 00:35:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1849/1 [0m                       

                       Computation: 720009 steps/s (collection: 0.042s, learning 0.095s)
                       Mean reward: 855.60
               Mean episode length: 245.62
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.8652
       Episode_Reward/object_height 0.0356
     Episode_Reward/reaching_object 0.7409
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 181764096
                    Iteration time: 0.14s
                      Time elapsed: 00:35:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1850/1 [0m                       

                       Computation: 690198 steps/s (collection: 0.052s, learning 0.090s)
                       Mean reward: 861.59
               Mean episode length: 248.41
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.7792
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7445
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 181862400
                    Iteration time: 0.14s
                      Time elapsed: 00:35:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1851/1 [0m                       

                       Computation: 807128 steps/s (collection: 0.040s, learning 0.082s)
                       Mean reward: 862.70
               Mean episode length: 248.25
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.9615
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7426
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 181960704
                    Iteration time: 0.12s
                      Time elapsed: 00:35:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1852/1 [0m                       

                       Computation: 760615 steps/s (collection: 0.042s, learning 0.087s)
                       Mean reward: 860.81
               Mean episode length: 247.97
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.3667
       Episode_Reward/object_height 0.0359
     Episode_Reward/reaching_object 0.7417
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 182059008
                    Iteration time: 0.13s
                      Time elapsed: 00:35:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1853/1 [0m                       

                       Computation: 702071 steps/s (collection: 0.040s, learning 0.100s)
                       Mean reward: 851.04
               Mean episode length: 248.36
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.3477
       Episode_Reward/object_height 0.0354
     Episode_Reward/reaching_object 0.7388
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 182157312
                    Iteration time: 0.14s
                      Time elapsed: 00:35:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1854/1 [0m                       

                       Computation: 815629 steps/s (collection: 0.041s, learning 0.080s)
                       Mean reward: 850.74
               Mean episode length: 246.48
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.5031
       Episode_Reward/object_height 0.0357
     Episode_Reward/reaching_object 0.7388
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 182255616
                    Iteration time: 0.12s
                      Time elapsed: 00:35:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1855/1 [0m                       

                       Computation: 725381 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 861.77
               Mean episode length: 248.37
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.0978
       Episode_Reward/object_height 0.0359
     Episode_Reward/reaching_object 0.7381
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 26.4583
--------------------------------------------------------------------------------
                   Total timesteps: 182353920
                    Iteration time: 0.14s
                      Time elapsed: 00:35:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1856/1 [0m                       

                       Computation: 693739 steps/s (collection: 0.044s, learning 0.098s)
                       Mean reward: 844.70
               Mean episode length: 244.99
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.7434
       Episode_Reward/object_height 0.0358
     Episode_Reward/reaching_object 0.7286
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 182452224
                    Iteration time: 0.14s
                      Time elapsed: 00:35:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1857/1 [0m                       

                       Computation: 739792 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 845.99
               Mean episode length: 244.72
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.3158
       Episode_Reward/object_height 0.0357
     Episode_Reward/reaching_object 0.7245
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 182550528
                    Iteration time: 0.13s
                      Time elapsed: 00:35:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1858/1 [0m                       

                       Computation: 693627 steps/s (collection: 0.048s, learning 0.094s)
                       Mean reward: 832.36
               Mean episode length: 244.36
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.4895
       Episode_Reward/object_height 0.0352
     Episode_Reward/reaching_object 0.7198
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 182648832
                    Iteration time: 0.14s
                      Time elapsed: 00:35:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1859/1 [0m                       

                       Computation: 695598 steps/s (collection: 0.050s, learning 0.091s)
                       Mean reward: 835.54
               Mean episode length: 245.95
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 166.8425
       Episode_Reward/object_height 0.0354
     Episode_Reward/reaching_object 0.7240
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 182747136
                    Iteration time: 0.14s
                      Time elapsed: 00:35:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1860/1 [0m                       

                       Computation: 764960 steps/s (collection: 0.043s, learning 0.086s)
                       Mean reward: 826.11
               Mean episode length: 241.93
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.2317
       Episode_Reward/object_height 0.0350
     Episode_Reward/reaching_object 0.7097
Episode_Termination/object_dropping 1.2500
       Episode_Termination/time_out 17.0417
--------------------------------------------------------------------------------
                   Total timesteps: 182845440
                    Iteration time: 0.13s
                      Time elapsed: 00:35:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1861/1 [0m                       

                       Computation: 597433 steps/s (collection: 0.049s, learning 0.116s)
                       Mean reward: 835.68
               Mean episode length: 242.23
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 166.9483
       Episode_Reward/object_height 0.0357
     Episode_Reward/reaching_object 0.7323
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 182943744
                    Iteration time: 0.16s
                      Time elapsed: 00:35:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1862/1 [0m                       

                       Computation: 712197 steps/s (collection: 0.041s, learning 0.098s)
                       Mean reward: 831.61
               Mean episode length: 244.73
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.4056
       Episode_Reward/object_height 0.0354
     Episode_Reward/reaching_object 0.7224
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 183042048
                    Iteration time: 0.14s
                      Time elapsed: 00:35:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1863/1 [0m                       

                       Computation: 726128 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 831.48
               Mean episode length: 244.34
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.4471
       Episode_Reward/object_height 0.0355
     Episode_Reward/reaching_object 0.7248
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 183140352
                    Iteration time: 0.14s
                      Time elapsed: 00:35:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1864/1 [0m                       

                       Computation: 643955 steps/s (collection: 0.048s, learning 0.104s)
                       Mean reward: 828.22
               Mean episode length: 245.18
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 164.8959
       Episode_Reward/object_height 0.0355
     Episode_Reward/reaching_object 0.7231
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 183238656
                    Iteration time: 0.15s
                      Time elapsed: 00:35:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1865/1 [0m                       

                       Computation: 687489 steps/s (collection: 0.046s, learning 0.097s)
                       Mean reward: 838.11
               Mean episode length: 246.99
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 165.8734
       Episode_Reward/object_height 0.0359
     Episode_Reward/reaching_object 0.7308
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 28.0417
--------------------------------------------------------------------------------
                   Total timesteps: 183336960
                    Iteration time: 0.14s
                      Time elapsed: 00:35:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1866/1 [0m                       

                       Computation: 676832 steps/s (collection: 0.049s, learning 0.097s)
                       Mean reward: 842.46
               Mean episode length: 245.81
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.3089
       Episode_Reward/object_height 0.0363
     Episode_Reward/reaching_object 0.7397
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 183435264
                    Iteration time: 0.15s
                      Time elapsed: 00:35:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1867/1 [0m                       

                       Computation: 762432 steps/s (collection: 0.040s, learning 0.088s)
                       Mean reward: 838.64
               Mean episode length: 247.37
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 167.7730
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7471
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 183533568
                    Iteration time: 0.13s
                      Time elapsed: 00:35:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1868/1 [0m                       

                       Computation: 737023 steps/s (collection: 0.047s, learning 0.086s)
                       Mean reward: 840.36
               Mean episode length: 245.27
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.5214
       Episode_Reward/object_height 0.0365
     Episode_Reward/reaching_object 0.7447
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 183631872
                    Iteration time: 0.13s
                      Time elapsed: 00:35:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1869/1 [0m                       

                       Computation: 728204 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 842.11
               Mean episode length: 245.02
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.2117
       Episode_Reward/object_height 0.0367
     Episode_Reward/reaching_object 0.7323
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 183730176
                    Iteration time: 0.13s
                      Time elapsed: 00:35:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1870/1 [0m                       

                       Computation: 600136 steps/s (collection: 0.054s, learning 0.110s)
                       Mean reward: 863.19
               Mean episode length: 248.39
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 171.6282
       Episode_Reward/object_height 0.0381
     Episode_Reward/reaching_object 0.7547
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 183828480
                    Iteration time: 0.16s
                      Time elapsed: 00:35:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1871/1 [0m                       

                       Computation: 629021 steps/s (collection: 0.050s, learning 0.107s)
                       Mean reward: 848.87
               Mean episode length: 246.01
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 168.8528
       Episode_Reward/object_height 0.0375
     Episode_Reward/reaching_object 0.7426
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 16.8333
--------------------------------------------------------------------------------
                   Total timesteps: 183926784
                    Iteration time: 0.16s
                      Time elapsed: 00:35:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1872/1 [0m                       

                       Computation: 614233 steps/s (collection: 0.054s, learning 0.107s)
                       Mean reward: 856.16
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 170.5872
       Episode_Reward/object_height 0.0383
     Episode_Reward/reaching_object 0.7509
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 184025088
                    Iteration time: 0.16s
                      Time elapsed: 00:35:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1873/1 [0m                       

                       Computation: 605083 steps/s (collection: 0.054s, learning 0.108s)
                       Mean reward: 853.23
               Mean episode length: 248.04
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0027
      Episode_Reward/lifting_object 169.7822
       Episode_Reward/object_height 0.0383
     Episode_Reward/reaching_object 0.7441
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 184123392
                    Iteration time: 0.16s
                      Time elapsed: 00:35:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1874/1 [0m                       

                       Computation: 658933 steps/s (collection: 0.049s, learning 0.101s)
                       Mean reward: 848.17
               Mean episode length: 246.88
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.0264
       Episode_Reward/object_height 0.0382
     Episode_Reward/reaching_object 0.7347
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 184221696
                    Iteration time: 0.15s
                      Time elapsed: 00:35:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1875/1 [0m                       

                       Computation: 578175 steps/s (collection: 0.053s, learning 0.118s)
                       Mean reward: 854.83
               Mean episode length: 248.35
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.4167
       Episode_Reward/object_height 0.0385
     Episode_Reward/reaching_object 0.7358
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 30.2083
--------------------------------------------------------------------------------
                   Total timesteps: 184320000
                    Iteration time: 0.17s
                      Time elapsed: 00:35:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1876/1 [0m                       

                       Computation: 576370 steps/s (collection: 0.053s, learning 0.118s)
                       Mean reward: 847.79
               Mean episode length: 243.57
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 168.5425
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7284
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 184418304
                    Iteration time: 0.17s
                      Time elapsed: 00:36:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1877/1 [0m                       

                       Computation: 588514 steps/s (collection: 0.050s, learning 0.117s)
                       Mean reward: 852.72
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.7569
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7423
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 184516608
                    Iteration time: 0.17s
                      Time elapsed: 00:36:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1878/1 [0m                       

                       Computation: 574698 steps/s (collection: 0.059s, learning 0.112s)
                       Mean reward: 856.09
               Mean episode length: 244.82
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.2535
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7415
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 184614912
                    Iteration time: 0.17s
                      Time elapsed: 00:36:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1879/1 [0m                       

                       Computation: 561614 steps/s (collection: 0.063s, learning 0.112s)
                       Mean reward: 861.02
               Mean episode length: 245.32
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.2749
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7440
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 184713216
                    Iteration time: 0.18s
                      Time elapsed: 00:36:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1880/1 [0m                       

                       Computation: 592057 steps/s (collection: 0.055s, learning 0.112s)
                       Mean reward: 873.53
               Mean episode length: 248.51
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 173.6935
       Episode_Reward/object_height 0.0411
     Episode_Reward/reaching_object 0.7561
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 16.1250
--------------------------------------------------------------------------------
                   Total timesteps: 184811520
                    Iteration time: 0.17s
                      Time elapsed: 00:36:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1881/1 [0m                       

                       Computation: 585020 steps/s (collection: 0.054s, learning 0.114s)
                       Mean reward: 859.71
               Mean episode length: 245.63
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 171.6372
       Episode_Reward/object_height 0.0409
     Episode_Reward/reaching_object 0.7486
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 17.5417
--------------------------------------------------------------------------------
                   Total timesteps: 184909824
                    Iteration time: 0.17s
                      Time elapsed: 00:36:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1882/1 [0m                       

                       Computation: 644394 steps/s (collection: 0.051s, learning 0.102s)
                       Mean reward: 858.70
               Mean episode length: 246.50
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.8257
       Episode_Reward/object_height 0.0407
     Episode_Reward/reaching_object 0.7421
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 185008128
                    Iteration time: 0.15s
                      Time elapsed: 00:36:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1883/1 [0m                       

                       Computation: 627852 steps/s (collection: 0.052s, learning 0.105s)
                       Mean reward: 852.77
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 169.4764
       Episode_Reward/object_height 0.0405
     Episode_Reward/reaching_object 0.7461
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 185106432
                    Iteration time: 0.16s
                      Time elapsed: 00:36:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1884/1 [0m                       

                       Computation: 554243 steps/s (collection: 0.054s, learning 0.123s)
                       Mean reward: 857.54
               Mean episode length: 246.64
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.4130
       Episode_Reward/object_height 0.0410
     Episode_Reward/reaching_object 0.7514
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 185204736
                    Iteration time: 0.18s
                      Time elapsed: 00:36:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1885/1 [0m                       

                       Computation: 608574 steps/s (collection: 0.061s, learning 0.101s)
                       Mean reward: 858.64
               Mean episode length: 246.75
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.5782
       Episode_Reward/object_height 0.0411
     Episode_Reward/reaching_object 0.7487
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 185303040
                    Iteration time: 0.16s
                      Time elapsed: 00:36:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1886/1 [0m                       

                       Computation: 541538 steps/s (collection: 0.060s, learning 0.122s)
                       Mean reward: 866.48
               Mean episode length: 247.86
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.6144
       Episode_Reward/object_height 0.0412
     Episode_Reward/reaching_object 0.7467
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 27.4167
--------------------------------------------------------------------------------
                   Total timesteps: 185401344
                    Iteration time: 0.18s
                      Time elapsed: 00:36:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1887/1 [0m                       

                       Computation: 745256 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 843.38
               Mean episode length: 244.74
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 167.4199
       Episode_Reward/object_height 0.0404
     Episode_Reward/reaching_object 0.7344
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 185499648
                    Iteration time: 0.13s
                      Time elapsed: 00:36:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1888/1 [0m                       

                       Computation: 720038 steps/s (collection: 0.044s, learning 0.093s)
                       Mean reward: 862.42
               Mean episode length: 247.84
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 170.9836
       Episode_Reward/object_height 0.0413
     Episode_Reward/reaching_object 0.7506
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 13.7500
--------------------------------------------------------------------------------
                   Total timesteps: 185597952
                    Iteration time: 0.14s
                      Time elapsed: 00:36:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1889/1 [0m                       

                       Computation: 638122 steps/s (collection: 0.045s, learning 0.109s)
                       Mean reward: 836.64
               Mean episode length: 245.52
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 166.9313
       Episode_Reward/object_height 0.0403
     Episode_Reward/reaching_object 0.7340
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 185696256
                    Iteration time: 0.15s
                      Time elapsed: 00:36:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1890/1 [0m                       

                       Computation: 622050 steps/s (collection: 0.050s, learning 0.108s)
                       Mean reward: 842.84
               Mean episode length: 247.42
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0026
      Episode_Reward/lifting_object 167.7335
       Episode_Reward/object_height 0.0405
     Episode_Reward/reaching_object 0.7380
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 185794560
                    Iteration time: 0.16s
                      Time elapsed: 00:36:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1891/1 [0m                       

                       Computation: 728069 steps/s (collection: 0.054s, learning 0.082s)
                       Mean reward: 819.58
               Mean episode length: 245.45
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 163.3556
       Episode_Reward/object_height 0.0395
     Episode_Reward/reaching_object 0.7172
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 185892864
                    Iteration time: 0.14s
                      Time elapsed: 00:36:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1892/1 [0m                       

                       Computation: 730848 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 852.71
               Mean episode length: 246.91
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.6053
       Episode_Reward/object_height 0.0410
     Episode_Reward/reaching_object 0.7491
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 185991168
                    Iteration time: 0.13s
                      Time elapsed: 00:36:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1893/1 [0m                       

                       Computation: 712962 steps/s (collection: 0.051s, learning 0.087s)
                       Mean reward: 859.44
               Mean episode length: 248.50
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.1356
       Episode_Reward/object_height 0.0416
     Episode_Reward/reaching_object 0.7518
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.3333
--------------------------------------------------------------------------------
                   Total timesteps: 186089472
                    Iteration time: 0.14s
                      Time elapsed: 00:36:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1894/1 [0m                       

                       Computation: 792692 steps/s (collection: 0.047s, learning 0.077s)
                       Mean reward: 854.07
               Mean episode length: 249.10
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9972
       Episode_Reward/object_height 0.0410
     Episode_Reward/reaching_object 0.7515
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 186187776
                    Iteration time: 0.12s
                      Time elapsed: 00:36:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1895/1 [0m                       

                       Computation: 608614 steps/s (collection: 0.046s, learning 0.116s)
                       Mean reward: 856.76
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5690
       Episode_Reward/object_height 0.0413
     Episode_Reward/reaching_object 0.7524
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 15.1667
--------------------------------------------------------------------------------
                   Total timesteps: 186286080
                    Iteration time: 0.16s
                      Time elapsed: 00:36:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1896/1 [0m                       

                       Computation: 656846 steps/s (collection: 0.048s, learning 0.101s)
                       Mean reward: 862.55
               Mean episode length: 248.73
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.2252
       Episode_Reward/object_height 0.0411
     Episode_Reward/reaching_object 0.7442
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 28.7500
--------------------------------------------------------------------------------
                   Total timesteps: 186384384
                    Iteration time: 0.15s
                      Time elapsed: 00:36:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1897/1 [0m                       

                       Computation: 728161 steps/s (collection: 0.043s, learning 0.092s)
                       Mean reward: 855.34
               Mean episode length: 247.30
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9695
       Episode_Reward/object_height 0.0410
     Episode_Reward/reaching_object 0.7412
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 186482688
                    Iteration time: 0.14s
                      Time elapsed: 00:36:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1898/1 [0m                       

                       Computation: 696597 steps/s (collection: 0.047s, learning 0.094s)
                       Mean reward: 864.45
               Mean episode length: 246.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.5767
       Episode_Reward/object_height 0.0413
     Episode_Reward/reaching_object 0.7422
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 186580992
                    Iteration time: 0.14s
                      Time elapsed: 00:36:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1899/1 [0m                       

                       Computation: 570002 steps/s (collection: 0.055s, learning 0.118s)
                       Mean reward: 872.71
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.4225
       Episode_Reward/object_height 0.0417
     Episode_Reward/reaching_object 0.7485
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 186679296
                    Iteration time: 0.17s
                      Time elapsed: 00:36:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1900/1 [0m                       

                       Computation: 706891 steps/s (collection: 0.047s, learning 0.093s)
                       Mean reward: 863.86
               Mean episode length: 247.48
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.5574
       Episode_Reward/object_height 0.0413
     Episode_Reward/reaching_object 0.7392
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 186777600
                    Iteration time: 0.14s
                      Time elapsed: 00:36:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1901/1 [0m                       

                       Computation: 786265 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 854.76
               Mean episode length: 245.41
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.5167
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7370
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 186875904
                    Iteration time: 0.13s
                      Time elapsed: 00:36:33
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1902/1 [0m                       

                       Computation: 810683 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 868.42
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.2678
       Episode_Reward/object_height 0.0414
     Episode_Reward/reaching_object 0.7515
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 17.7917
--------------------------------------------------------------------------------
                   Total timesteps: 186974208
                    Iteration time: 0.12s
                      Time elapsed: 00:36:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1903/1 [0m                       

                       Computation: 717916 steps/s (collection: 0.045s, learning 0.092s)
                       Mean reward: 865.71
               Mean episode length: 249.11
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.2390
       Episode_Reward/object_height 0.0410
     Episode_Reward/reaching_object 0.7505
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 187072512
                    Iteration time: 0.14s
                      Time elapsed: 00:36:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1904/1 [0m                       

                       Computation: 686242 steps/s (collection: 0.044s, learning 0.099s)
                       Mean reward: 859.08
               Mean episode length: 247.93
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 170.7433
       Episode_Reward/object_height 0.0408
     Episode_Reward/reaching_object 0.7428
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 187170816
                    Iteration time: 0.14s
                      Time elapsed: 00:36:36
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1905/1 [0m                       

                       Computation: 586685 steps/s (collection: 0.042s, learning 0.125s)
                       Mean reward: 862.81
               Mean episode length: 247.63
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.8412
       Episode_Reward/object_height 0.0406
     Episode_Reward/reaching_object 0.7492
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 187269120
                    Iteration time: 0.17s
                      Time elapsed: 00:36:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1906/1 [0m                       

                       Computation: 755872 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 867.31
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.7301
       Episode_Reward/object_height 0.0407
     Episode_Reward/reaching_object 0.7478
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 187367424
                    Iteration time: 0.13s
                      Time elapsed: 00:36:39
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1907/1 [0m                       

                       Computation: 737195 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 864.68
               Mean episode length: 248.29
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 169.9840
       Episode_Reward/object_height 0.0400
     Episode_Reward/reaching_object 0.7393
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 24.7917
--------------------------------------------------------------------------------
                   Total timesteps: 187465728
                    Iteration time: 0.13s
                      Time elapsed: 00:36:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1908/1 [0m                       

                       Computation: 599188 steps/s (collection: 0.059s, learning 0.105s)
                       Mean reward: 858.56
               Mean episode length: 245.58
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.7429
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7382
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187564032
                    Iteration time: 0.16s
                      Time elapsed: 00:36:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1909/1 [0m                       

                       Computation: 588504 steps/s (collection: 0.058s, learning 0.110s)
                       Mean reward: 863.85
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.8290
       Episode_Reward/object_height 0.0399
     Episode_Reward/reaching_object 0.7529
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 187662336
                    Iteration time: 0.17s
                      Time elapsed: 00:36:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1910/1 [0m                       

                       Computation: 595707 steps/s (collection: 0.052s, learning 0.113s)
                       Mean reward: 869.47
               Mean episode length: 248.88
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 173.0971
       Episode_Reward/object_height 0.0401
     Episode_Reward/reaching_object 0.7554
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.2917
--------------------------------------------------------------------------------
                   Total timesteps: 187760640
                    Iteration time: 0.17s
                      Time elapsed: 00:36:44
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1911/1 [0m                       

                       Computation: 604743 steps/s (collection: 0.052s, learning 0.111s)
                       Mean reward: 863.34
               Mean episode length: 247.35
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.7411
       Episode_Reward/object_height 0.0397
     Episode_Reward/reaching_object 0.7486
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 187858944
                    Iteration time: 0.16s
                      Time elapsed: 00:36:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1912/1 [0m                       

                       Computation: 649026 steps/s (collection: 0.043s, learning 0.108s)
                       Mean reward: 863.66
               Mean episode length: 246.87
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1627
       Episode_Reward/object_height 0.0396
     Episode_Reward/reaching_object 0.7503
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 17.9583
--------------------------------------------------------------------------------
                   Total timesteps: 187957248
                    Iteration time: 0.15s
                      Time elapsed: 00:36:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1913/1 [0m                       

                       Computation: 718881 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 866.07
               Mean episode length: 247.82
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.3678
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7483
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 188055552
                    Iteration time: 0.14s
                      Time elapsed: 00:36:48
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1914/1 [0m                       

                       Computation: 718761 steps/s (collection: 0.041s, learning 0.096s)
                       Mean reward: 865.71
               Mean episode length: 249.40
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 172.1019
       Episode_Reward/object_height 0.0394
     Episode_Reward/reaching_object 0.7477
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 188153856
                    Iteration time: 0.14s
                      Time elapsed: 00:36:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1915/1 [0m                       

                       Computation: 708962 steps/s (collection: 0.053s, learning 0.085s)
                       Mean reward: 861.06
               Mean episode length: 247.99
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0025
      Episode_Reward/lifting_object 171.4134
       Episode_Reward/object_height 0.0392
     Episode_Reward/reaching_object 0.7440
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.2917
--------------------------------------------------------------------------------
                   Total timesteps: 188252160
                    Iteration time: 0.14s
                      Time elapsed: 00:36:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1916/1 [0m                       

                       Computation: 677640 steps/s (collection: 0.047s, learning 0.098s)
                       Mean reward: 856.62
               Mean episode length: 246.76
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 170.9347
       Episode_Reward/object_height 0.0390
     Episode_Reward/reaching_object 0.7337
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 188350464
                    Iteration time: 0.15s
                      Time elapsed: 00:36:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1917/1 [0m                       

                       Computation: 730837 steps/s (collection: 0.044s, learning 0.090s)
                       Mean reward: 862.82
               Mean episode length: 248.69
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.8754
       Episode_Reward/object_height 0.0386
     Episode_Reward/reaching_object 0.7338
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 27.1667
--------------------------------------------------------------------------------
                   Total timesteps: 188448768
                    Iteration time: 0.13s
                      Time elapsed: 00:36:53
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1918/1 [0m                       

                       Computation: 547881 steps/s (collection: 0.043s, learning 0.136s)
                       Mean reward: 848.26
               Mean episode length: 247.27
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.8285
       Episode_Reward/object_height 0.0381
     Episode_Reward/reaching_object 0.7291
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 188547072
                    Iteration time: 0.18s
                      Time elapsed: 00:36:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1919/1 [0m                       

                       Computation: 748801 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 846.82
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.4452
       Episode_Reward/object_height 0.0379
     Episode_Reward/reaching_object 0.7315
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 188645376
                    Iteration time: 0.13s
                      Time elapsed: 00:36:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1920/1 [0m                       

                       Computation: 740515 steps/s (collection: 0.048s, learning 0.085s)
                       Mean reward: 846.90
               Mean episode length: 247.02
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.0595
       Episode_Reward/object_height 0.0380
     Episode_Reward/reaching_object 0.7286
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 188743680
                    Iteration time: 0.13s
                      Time elapsed: 00:36:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1921/1 [0m                       

                       Computation: 707778 steps/s (collection: 0.043s, learning 0.096s)
                       Mean reward: 852.57
               Mean episode length: 247.50
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 169.8361
       Episode_Reward/object_height 0.0383
     Episode_Reward/reaching_object 0.7343
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 188841984
                    Iteration time: 0.14s
                      Time elapsed: 00:36:58
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1922/1 [0m                       

                       Computation: 730775 steps/s (collection: 0.044s, learning 0.091s)
                       Mean reward: 844.70
               Mean episode length: 247.14
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.3256
       Episode_Reward/object_height 0.0380
     Episode_Reward/reaching_object 0.7236
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 188940288
                    Iteration time: 0.13s
                      Time elapsed: 00:36:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1923/1 [0m                       

                       Computation: 805515 steps/s (collection: 0.042s, learning 0.080s)
                       Mean reward: 847.14
               Mean episode length: 248.14
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 168.6942
       Episode_Reward/object_height 0.0381
     Episode_Reward/reaching_object 0.7260
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 189038592
                    Iteration time: 0.12s
                      Time elapsed: 00:37:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1924/1 [0m                       

                       Computation: 792339 steps/s (collection: 0.042s, learning 0.083s)
                       Mean reward: 835.41
               Mean episode length: 247.56
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.4803
       Episode_Reward/object_height 0.0379
     Episode_Reward/reaching_object 0.7163
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 189136896
                    Iteration time: 0.12s
                      Time elapsed: 00:37:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1925/1 [0m                       

                       Computation: 734751 steps/s (collection: 0.046s, learning 0.088s)
                       Mean reward: 839.20
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.9436
       Episode_Reward/object_height 0.0380
     Episode_Reward/reaching_object 0.7177
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 189235200
                    Iteration time: 0.13s
                      Time elapsed: 00:37:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1926/1 [0m                       

                       Computation: 715832 steps/s (collection: 0.043s, learning 0.094s)
                       Mean reward: 831.00
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.4114
       Episode_Reward/object_height 0.0374
     Episode_Reward/reaching_object 0.7124
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 189333504
                    Iteration time: 0.14s
                      Time elapsed: 00:37:03
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1927/1 [0m                       

                       Computation: 746600 steps/s (collection: 0.044s, learning 0.087s)
                       Mean reward: 833.00
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 166.0124
       Episode_Reward/object_height 0.0376
     Episode_Reward/reaching_object 0.7196
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 189431808
                    Iteration time: 0.13s
                      Time elapsed: 00:37:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1928/1 [0m                       

                       Computation: 732633 steps/s (collection: 0.045s, learning 0.089s)
                       Mean reward: 833.60
               Mean episode length: 248.03
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.8369
       Episode_Reward/object_height 0.0375
     Episode_Reward/reaching_object 0.7202
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 24.0417
--------------------------------------------------------------------------------
                   Total timesteps: 189530112
                    Iteration time: 0.13s
                      Time elapsed: 00:37:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1929/1 [0m                       

                       Computation: 770881 steps/s (collection: 0.046s, learning 0.082s)
                       Mean reward: 820.76
               Mean episode length: 245.62
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 163.7154
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7166
Episode_Termination/object_dropping 0.6667
       Episode_Termination/time_out 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 189628416
                    Iteration time: 0.13s
                      Time elapsed: 00:37:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1930/1 [0m                       

                       Computation: 577949 steps/s (collection: 0.047s, learning 0.123s)
                       Mean reward: 830.40
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.6457
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7224
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.0000
--------------------------------------------------------------------------------
                   Total timesteps: 189726720
                    Iteration time: 0.17s
                      Time elapsed: 00:37:08
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1931/1 [0m                       

                       Computation: 653579 steps/s (collection: 0.043s, learning 0.108s)
                       Mean reward: 828.79
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.8180
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7189
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 15.8750
--------------------------------------------------------------------------------
                   Total timesteps: 189825024
                    Iteration time: 0.15s
                      Time elapsed: 00:37:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1932/1 [0m                       

                       Computation: 625303 steps/s (collection: 0.058s, learning 0.099s)
                       Mean reward: 816.26
               Mean episode length: 247.04
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 162.3694
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7123
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 189923328
                    Iteration time: 0.16s
                      Time elapsed: 00:37:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1933/1 [0m                       

                       Computation: 591984 steps/s (collection: 0.056s, learning 0.111s)
                       Mean reward: 823.85
               Mean episode length: 247.39
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.1791
       Episode_Reward/object_height 0.0372
     Episode_Reward/reaching_object 0.7234
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 17.6667
--------------------------------------------------------------------------------
                   Total timesteps: 190021632
                    Iteration time: 0.17s
                      Time elapsed: 00:37:12
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1934/1 [0m                       

                       Computation: 576687 steps/s (collection: 0.055s, learning 0.115s)
                       Mean reward: 831.64
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 165.1315
       Episode_Reward/object_height 0.0372
     Episode_Reward/reaching_object 0.7293
Episode_Termination/object_dropping 0.2083
       Episode_Termination/time_out 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 190119936
                    Iteration time: 0.17s
                      Time elapsed: 00:37:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1935/1 [0m                       

                       Computation: 616254 steps/s (collection: 0.052s, learning 0.108s)
                       Mean reward: 828.10
               Mean episode length: 248.38
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 164.9685
       Episode_Reward/object_height 0.0378
     Episode_Reward/reaching_object 0.7371
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.6250
--------------------------------------------------------------------------------
                   Total timesteps: 190218240
                    Iteration time: 0.16s
                      Time elapsed: 00:37:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1936/1 [0m                       

                       Computation: 547654 steps/s (collection: 0.053s, learning 0.127s)
                       Mean reward: 796.53
               Mean episode length: 247.85
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.6667
       Episode_Reward/object_height 0.0364
     Episode_Reward/reaching_object 0.7159
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 190316544
                    Iteration time: 0.18s
                      Time elapsed: 00:37:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1937/1 [0m                       

                       Computation: 649737 steps/s (collection: 0.044s, learning 0.107s)
                       Mean reward: 812.48
               Mean episode length: 247.87
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 161.7550
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7267
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.7500
--------------------------------------------------------------------------------
                   Total timesteps: 190414848
                    Iteration time: 0.15s
                      Time elapsed: 00:37:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1938/1 [0m                       

                       Computation: 599224 steps/s (collection: 0.044s, learning 0.121s)
                       Mean reward: 807.79
               Mean episode length: 248.96
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 159.9237
       Episode_Reward/object_height 0.0373
     Episode_Reward/reaching_object 0.7250
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 25.7917
--------------------------------------------------------------------------------
                   Total timesteps: 190513152
                    Iteration time: 0.16s
                      Time elapsed: 00:37:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1939/1 [0m                       

                       Computation: 594809 steps/s (collection: 0.049s, learning 0.117s)
                       Mean reward: 792.18
               Mean episode length: 247.04
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 158.0268
       Episode_Reward/object_height 0.0370
     Episode_Reward/reaching_object 0.7251
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 190611456
                    Iteration time: 0.17s
                      Time elapsed: 00:37:20
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1940/1 [0m                       

                       Computation: 724785 steps/s (collection: 0.047s, learning 0.089s)
                       Mean reward: 791.39
               Mean episode length: 246.28
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 157.6584
       Episode_Reward/object_height 0.0369
     Episode_Reward/reaching_object 0.7264
Episode_Termination/object_dropping 0.7500
       Episode_Termination/time_out 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 190709760
                    Iteration time: 0.14s
                      Time elapsed: 00:37:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1941/1 [0m                       

                       Computation: 650905 steps/s (collection: 0.057s, learning 0.094s)
                       Mean reward: 780.21
               Mean episode length: 244.73
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 155.1847
       Episode_Reward/object_height 0.0363
     Episode_Reward/reaching_object 0.7108
Episode_Termination/object_dropping 1.0000
       Episode_Termination/time_out 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 190808064
                    Iteration time: 0.15s
                      Time elapsed: 00:37:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1942/1 [0m                       

                       Computation: 707970 steps/s (collection: 0.047s, learning 0.092s)
                       Mean reward: 785.21
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0024
      Episode_Reward/lifting_object 156.2988
       Episode_Reward/object_height 0.0367
     Episode_Reward/reaching_object 0.7195
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 190906368
                    Iteration time: 0.14s
                      Time elapsed: 00:37:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1943/1 [0m                       

                       Computation: 503991 steps/s (collection: 0.044s, learning 0.152s)
                       Mean reward: 780.72
               Mean episode length: 247.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 155.5993
       Episode_Reward/object_height 0.0364
     Episode_Reward/reaching_object 0.7248
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 191004672
                    Iteration time: 0.20s
                      Time elapsed: 00:37:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1944/1 [0m                       

                       Computation: 805669 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 783.45
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 155.2474
       Episode_Reward/object_height 0.0361
     Episode_Reward/reaching_object 0.7230
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 17.0833
--------------------------------------------------------------------------------
                   Total timesteps: 191102976
                    Iteration time: 0.12s
                      Time elapsed: 00:37:26
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1945/1 [0m                       

                       Computation: 759331 steps/s (collection: 0.048s, learning 0.082s)
                       Mean reward: 763.04
               Mean episode length: 246.64
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 152.1365
       Episode_Reward/object_height 0.0360
     Episode_Reward/reaching_object 0.7181
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 191201280
                    Iteration time: 0.13s
                      Time elapsed: 00:37:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1946/1 [0m                       

                       Computation: 727441 steps/s (collection: 0.044s, learning 0.092s)
                       Mean reward: 769.09
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 153.2995
       Episode_Reward/object_height 0.0364
     Episode_Reward/reaching_object 0.7273
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 191299584
                    Iteration time: 0.14s
                      Time elapsed: 00:37:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1947/1 [0m                       

                       Computation: 756057 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 748.19
               Mean episode length: 246.44
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 148.2889
       Episode_Reward/object_height 0.0355
     Episode_Reward/reaching_object 0.7119
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 191397888
                    Iteration time: 0.13s
                      Time elapsed: 00:37:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1948/1 [0m                       

                       Computation: 702099 steps/s (collection: 0.041s, learning 0.099s)
                       Mean reward: 742.60
               Mean episode length: 248.60
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 147.6036
       Episode_Reward/object_height 0.0352
     Episode_Reward/reaching_object 0.7111
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 26.8333
--------------------------------------------------------------------------------
                   Total timesteps: 191496192
                    Iteration time: 0.14s
                      Time elapsed: 00:37:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1949/1 [0m                       

                       Computation: 597117 steps/s (collection: 0.054s, learning 0.111s)
                       Mean reward: 717.82
               Mean episode length: 247.64
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 143.0419
       Episode_Reward/object_height 0.0350
     Episode_Reward/reaching_object 0.7060
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 191594496
                    Iteration time: 0.16s
                      Time elapsed: 00:37:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1950/1 [0m                       

                       Computation: 569712 steps/s (collection: 0.055s, learning 0.118s)
                       Mean reward: 733.25
               Mean episode length: 247.40
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 145.4473
       Episode_Reward/object_height 0.0347
     Episode_Reward/reaching_object 0.7067
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 191692800
                    Iteration time: 0.17s
                      Time elapsed: 00:37:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1951/1 [0m                       

                       Computation: 632848 steps/s (collection: 0.050s, learning 0.106s)
                       Mean reward: 743.68
               Mean episode length: 247.71
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 148.8086
       Episode_Reward/object_height 0.0354
     Episode_Reward/reaching_object 0.7161
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 16.4167
--------------------------------------------------------------------------------
                   Total timesteps: 191791104
                    Iteration time: 0.16s
                      Time elapsed: 00:37:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1952/1 [0m                       

                       Computation: 530887 steps/s (collection: 0.058s, learning 0.127s)
                       Mean reward: 735.24
               Mean episode length: 246.79
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 146.7661
       Episode_Reward/object_height 0.0352
     Episode_Reward/reaching_object 0.7186
Episode_Termination/object_dropping 0.7083
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 191889408
                    Iteration time: 0.19s
                      Time elapsed: 00:37:37
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1953/1 [0m                       

                       Computation: 591958 steps/s (collection: 0.053s, learning 0.114s)
                       Mean reward: 732.59
               Mean episode length: 248.45
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 145.9185
       Episode_Reward/object_height 0.0349
     Episode_Reward/reaching_object 0.7175
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 191987712
                    Iteration time: 0.17s
                      Time elapsed: 00:37:38
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1954/1 [0m                       

                       Computation: 612297 steps/s (collection: 0.053s, learning 0.107s)
                       Mean reward: 732.86
               Mean episode length: 246.94
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 145.5367
       Episode_Reward/object_height 0.0353
     Episode_Reward/reaching_object 0.7219
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 192086016
                    Iteration time: 0.16s
                      Time elapsed: 00:37:40
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1955/1 [0m                       

                       Computation: 677894 steps/s (collection: 0.047s, learning 0.099s)
                       Mean reward: 700.84
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 138.4030
       Episode_Reward/object_height 0.0348
     Episode_Reward/reaching_object 0.7031
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 192184320
                    Iteration time: 0.15s
                      Time elapsed: 00:37:41
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1956/1 [0m                       

                       Computation: 657457 steps/s (collection: 0.048s, learning 0.102s)
                       Mean reward: 699.34
               Mean episode length: 247.47
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 139.6957
       Episode_Reward/object_height 0.0353
     Episode_Reward/reaching_object 0.7148
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 192282624
                    Iteration time: 0.15s
                      Time elapsed: 00:37:42
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1957/1 [0m                       

                       Computation: 712278 steps/s (collection: 0.044s, learning 0.095s)
                       Mean reward: 709.90
               Mean episode length: 247.60
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 141.8245
       Episode_Reward/object_height 0.0349
     Episode_Reward/reaching_object 0.7071
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 13.7083
--------------------------------------------------------------------------------
                   Total timesteps: 192380928
                    Iteration time: 0.14s
                      Time elapsed: 00:37:43
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1958/1 [0m                       

                       Computation: 711301 steps/s (collection: 0.048s, learning 0.090s)
                       Mean reward: 712.61
               Mean episode length: 248.33
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0023
      Episode_Reward/lifting_object 141.9911
       Episode_Reward/object_height 0.0352
     Episode_Reward/reaching_object 0.7146
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 192479232
                    Iteration time: 0.14s
                      Time elapsed: 00:37:45
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1959/1 [0m                       

                       Computation: 747510 steps/s (collection: 0.041s, learning 0.091s)
                       Mean reward: 705.11
               Mean episode length: 248.52
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 139.1523
       Episode_Reward/object_height 0.0347
     Episode_Reward/reaching_object 0.7106
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 23.4167
--------------------------------------------------------------------------------
                   Total timesteps: 192577536
                    Iteration time: 0.13s
                      Time elapsed: 00:37:46
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1960/1 [0m                       

                       Computation: 566072 steps/s (collection: 0.053s, learning 0.121s)
                       Mean reward: 689.91
               Mean episode length: 246.95
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 137.6003
       Episode_Reward/object_height 0.0348
     Episode_Reward/reaching_object 0.7140
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 192675840
                    Iteration time: 0.17s
                      Time elapsed: 00:37:47
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1961/1 [0m                       

                       Computation: 606644 steps/s (collection: 0.050s, learning 0.113s)
                       Mean reward: 689.07
               Mean episode length: 246.59
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 137.0289
       Episode_Reward/object_height 0.0348
     Episode_Reward/reaching_object 0.7108
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 192774144
                    Iteration time: 0.16s
                      Time elapsed: 00:37:49
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1962/1 [0m                       

                       Computation: 741543 steps/s (collection: 0.042s, learning 0.090s)
                       Mean reward: 699.34
               Mean episode length: 247.55
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 138.3842
       Episode_Reward/object_height 0.0352
     Episode_Reward/reaching_object 0.7213
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 192872448
                    Iteration time: 0.13s
                      Time elapsed: 00:37:50
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1963/1 [0m                       

                       Computation: 599294 steps/s (collection: 0.049s, learning 0.115s)
                       Mean reward: 712.82
               Mean episode length: 246.88
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 142.1113
       Episode_Reward/object_height 0.0351
     Episode_Reward/reaching_object 0.7220
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 192970752
                    Iteration time: 0.16s
                      Time elapsed: 00:37:51
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1964/1 [0m                       

                       Computation: 667729 steps/s (collection: 0.042s, learning 0.105s)
                       Mean reward: 708.55
               Mean episode length: 246.95
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 140.7350
       Episode_Reward/object_height 0.0344
     Episode_Reward/reaching_object 0.7153
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 193069056
                    Iteration time: 0.15s
                      Time elapsed: 00:37:52
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1965/1 [0m                       

                       Computation: 704927 steps/s (collection: 0.051s, learning 0.089s)
                       Mean reward: 709.18
               Mean episode length: 249.30
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 141.6213
       Episode_Reward/object_height 0.0348
     Episode_Reward/reaching_object 0.7224
Episode_Termination/object_dropping 0.1667
       Episode_Termination/time_out 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 193167360
                    Iteration time: 0.14s
                      Time elapsed: 00:37:54
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1966/1 [0m                       

                       Computation: 763604 steps/s (collection: 0.048s, learning 0.081s)
                       Mean reward: 719.44
               Mean episode length: 248.08
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 142.9105
       Episode_Reward/object_height 0.0343
     Episode_Reward/reaching_object 0.7197
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 14.8333
--------------------------------------------------------------------------------
                   Total timesteps: 193265664
                    Iteration time: 0.13s
                      Time elapsed: 00:37:55
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1967/1 [0m                       

                       Computation: 592301 steps/s (collection: 0.057s, learning 0.109s)
                       Mean reward: 693.71
               Mean episode length: 244.65
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 138.7228
       Episode_Reward/object_height 0.0336
     Episode_Reward/reaching_object 0.7047
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 193363968
                    Iteration time: 0.17s
                      Time elapsed: 00:37:56
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1968/1 [0m                       

                       Computation: 628004 steps/s (collection: 0.054s, learning 0.103s)
                       Mean reward: 698.32
               Mean episode length: 243.96
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 138.9657
       Episode_Reward/object_height 0.0333
     Episode_Reward/reaching_object 0.7084
Episode_Termination/object_dropping 0.9583
       Episode_Termination/time_out 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 193462272
                    Iteration time: 0.16s
                      Time elapsed: 00:37:57
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1969/1 [0m                       

                       Computation: 608495 steps/s (collection: 0.058s, learning 0.104s)
                       Mean reward: 707.60
               Mean episode length: 246.07
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 139.5655
       Episode_Reward/object_height 0.0328
     Episode_Reward/reaching_object 0.6973
Episode_Termination/object_dropping 1.1667
       Episode_Termination/time_out 25.2917
--------------------------------------------------------------------------------
                   Total timesteps: 193560576
                    Iteration time: 0.16s
                      Time elapsed: 00:37:59
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1970/1 [0m                       

                       Computation: 617760 steps/s (collection: 0.046s, learning 0.114s)
                       Mean reward: 702.25
               Mean episode length: 245.08
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 139.4337
       Episode_Reward/object_height 0.0331
     Episode_Reward/reaching_object 0.6993
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 193658880
                    Iteration time: 0.16s
                      Time elapsed: 00:38:00
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1971/1 [0m                       

                       Computation: 786304 steps/s (collection: 0.044s, learning 0.081s)
                       Mean reward: 686.54
               Mean episode length: 243.92
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 136.3473
       Episode_Reward/object_height 0.0328
     Episode_Reward/reaching_object 0.6956
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 193757184
                    Iteration time: 0.13s
                      Time elapsed: 00:38:01
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1972/1 [0m                       

                       Computation: 763974 steps/s (collection: 0.046s, learning 0.083s)
                       Mean reward: 697.42
               Mean episode length: 245.26
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 138.3811
       Episode_Reward/object_height 0.0329
     Episode_Reward/reaching_object 0.6940
Episode_Termination/object_dropping 0.8333
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 193855488
                    Iteration time: 0.13s
                      Time elapsed: 00:38:02
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1973/1 [0m                       

                       Computation: 773881 steps/s (collection: 0.042s, learning 0.086s)
                       Mean reward: 698.44
               Mean episode length: 245.43
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 138.9665
       Episode_Reward/object_height 0.0326
     Episode_Reward/reaching_object 0.6973
Episode_Termination/object_dropping 0.7917
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 193953792
                    Iteration time: 0.13s
                      Time elapsed: 00:38:04
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1974/1 [0m                       

                       Computation: 708372 steps/s (collection: 0.046s, learning 0.093s)
                       Mean reward: 721.13
               Mean episode length: 247.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 143.6602
       Episode_Reward/object_height 0.0327
     Episode_Reward/reaching_object 0.7075
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 16.3750
--------------------------------------------------------------------------------
                   Total timesteps: 194052096
                    Iteration time: 0.14s
                      Time elapsed: 00:38:05
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1975/1 [0m                       

                       Computation: 750649 steps/s (collection: 0.041s, learning 0.090s)
                       Mean reward: 723.43
               Mean episode length: 245.51
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 143.8762
       Episode_Reward/object_height 0.0325
     Episode_Reward/reaching_object 0.7071
Episode_Termination/object_dropping 1.0417
       Episode_Termination/time_out 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 194150400
                    Iteration time: 0.13s
                      Time elapsed: 00:38:06
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1976/1 [0m                       

                       Computation: 569778 steps/s (collection: 0.057s, learning 0.116s)
                       Mean reward: 723.55
               Mean episode length: 246.78
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 144.6956
       Episode_Reward/object_height 0.0325
     Episode_Reward/reaching_object 0.7136
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 194248704
                    Iteration time: 0.17s
                      Time elapsed: 00:38:07
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1977/1 [0m                       

                       Computation: 568701 steps/s (collection: 0.062s, learning 0.111s)
                       Mean reward: 715.92
               Mean episode length: 247.66
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 141.8068
       Episode_Reward/object_height 0.0321
     Episode_Reward/reaching_object 0.7018
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 194347008
                    Iteration time: 0.17s
                      Time elapsed: 00:38:09
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1978/1 [0m                       

                       Computation: 593622 steps/s (collection: 0.058s, learning 0.108s)
                       Mean reward: 724.92
               Mean episode length: 248.40
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 144.3199
       Episode_Reward/object_height 0.0323
     Episode_Reward/reaching_object 0.7155
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 194445312
                    Iteration time: 0.17s
                      Time elapsed: 00:38:10
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1979/1 [0m                       

                       Computation: 689498 steps/s (collection: 0.047s, learning 0.096s)
                       Mean reward: 732.10
               Mean episode length: 247.95
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 145.4938
       Episode_Reward/object_height 0.0325
     Episode_Reward/reaching_object 0.7139
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 194543616
                    Iteration time: 0.14s
                      Time elapsed: 00:38:11
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1980/1 [0m                       

                       Computation: 774690 steps/s (collection: 0.043s, learning 0.084s)
                       Mean reward: 715.73
               Mean episode length: 248.75
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 140.7212
       Episode_Reward/object_height 0.0321
     Episode_Reward/reaching_object 0.7101
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 22.8333
--------------------------------------------------------------------------------
                   Total timesteps: 194641920
                    Iteration time: 0.13s
                      Time elapsed: 00:38:13
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1981/1 [0m                       

                       Computation: 791437 steps/s (collection: 0.042s, learning 0.082s)
                       Mean reward: 700.42
               Mean episode length: 247.21
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 139.8350
       Episode_Reward/object_height 0.0320
     Episode_Reward/reaching_object 0.7011
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 11.9583
--------------------------------------------------------------------------------
                   Total timesteps: 194740224
                    Iteration time: 0.12s
                      Time elapsed: 00:38:14
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1982/1 [0m                       

                       Computation: 806915 steps/s (collection: 0.042s, learning 0.079s)
                       Mean reward: 703.09
               Mean episode length: 248.00
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 140.2661
       Episode_Reward/object_height 0.0320
     Episode_Reward/reaching_object 0.7103
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 16.7083
--------------------------------------------------------------------------------
                   Total timesteps: 194838528
                    Iteration time: 0.12s
                      Time elapsed: 00:38:15
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1983/1 [0m                       

                       Computation: 764933 steps/s (collection: 0.045s, learning 0.083s)
                       Mean reward: 711.23
               Mean episode length: 248.26
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 141.4476
       Episode_Reward/object_height 0.0322
     Episode_Reward/reaching_object 0.7080
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.7083
--------------------------------------------------------------------------------
                   Total timesteps: 194936832
                    Iteration time: 0.13s
                      Time elapsed: 00:38:16
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1984/1 [0m                       

                       Computation: 772884 steps/s (collection: 0.045s, learning 0.083s)
                       Mean reward: 723.46
               Mean episode length: 249.23
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 144.2064
       Episode_Reward/object_height 0.0323
     Episode_Reward/reaching_object 0.7156
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 16.4583
--------------------------------------------------------------------------------
                   Total timesteps: 195035136
                    Iteration time: 0.13s
                      Time elapsed: 00:38:17
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1985/1 [0m                       

                       Computation: 659450 steps/s (collection: 0.047s, learning 0.103s)
                       Mean reward: 732.78
               Mean episode length: 247.70
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 146.3573
       Episode_Reward/object_height 0.0323
     Episode_Reward/reaching_object 0.7186
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 17.5833
--------------------------------------------------------------------------------
                   Total timesteps: 195133440
                    Iteration time: 0.15s
                      Time elapsed: 00:38:18
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1986/1 [0m                       

                       Computation: 616267 steps/s (collection: 0.044s, learning 0.116s)
                       Mean reward: 739.36
               Mean episode length: 246.66
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 147.5720
       Episode_Reward/object_height 0.0321
     Episode_Reward/reaching_object 0.7210
Episode_Termination/object_dropping 0.5417
       Episode_Termination/time_out 14.0000
--------------------------------------------------------------------------------
                   Total timesteps: 195231744
                    Iteration time: 0.16s
                      Time elapsed: 00:38:19
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1987/1 [0m                       

                       Computation: 707800 steps/s (collection: 0.045s, learning 0.094s)
                       Mean reward: 720.18
               Mean episode length: 246.61
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 143.4341
       Episode_Reward/object_height 0.0309
     Episode_Reward/reaching_object 0.7036
Episode_Termination/object_dropping 0.6250
       Episode_Termination/time_out 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 195330048
                    Iteration time: 0.14s
                      Time elapsed: 00:38:21
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1988/1 [0m                       

                       Computation: 676896 steps/s (collection: 0.053s, learning 0.092s)
                       Mean reward: 741.17
               Mean episode length: 247.28
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 147.6322
       Episode_Reward/object_height 0.0314
     Episode_Reward/reaching_object 0.7209
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.5000
--------------------------------------------------------------------------------
                   Total timesteps: 195428352
                    Iteration time: 0.15s
                      Time elapsed: 00:38:22
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1989/1 [0m                       

                       Computation: 753438 steps/s (collection: 0.043s, learning 0.088s)
                       Mean reward: 762.57
               Mean episode length: 248.46
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 151.5350
       Episode_Reward/object_height 0.0317
     Episode_Reward/reaching_object 0.7271
Episode_Termination/object_dropping 0.2917
       Episode_Termination/time_out 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 195526656
                    Iteration time: 0.13s
                      Time elapsed: 00:38:23
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1990/1 [0m                       

                       Computation: 724948 steps/s (collection: 0.042s, learning 0.094s)
                       Mean reward: 759.90
               Mean episode length: 248.79
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 150.4450
       Episode_Reward/object_height 0.0311
     Episode_Reward/reaching_object 0.7186
Episode_Termination/object_dropping 0.4583
       Episode_Termination/time_out 24.8333
--------------------------------------------------------------------------------
                   Total timesteps: 195624960
                    Iteration time: 0.14s
                      Time elapsed: 00:38:24
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1991/1 [0m                       

                       Computation: 803883 steps/s (collection: 0.043s, learning 0.080s)
                       Mean reward: 763.69
               Mean episode length: 246.97
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 152.0905
       Episode_Reward/object_height 0.0307
     Episode_Reward/reaching_object 0.7141
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 195723264
                    Iteration time: 0.12s
                      Time elapsed: 00:38:25
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1992/1 [0m                       

                       Computation: 746173 steps/s (collection: 0.044s, learning 0.088s)
                       Mean reward: 788.91
               Mean episode length: 247.69
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 157.5236
       Episode_Reward/object_height 0.0315
     Episode_Reward/reaching_object 0.7294
Episode_Termination/object_dropping 0.3333
       Episode_Termination/time_out 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 195821568
                    Iteration time: 0.13s
                      Time elapsed: 00:38:27
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1993/1 [0m                       

                       Computation: 815519 steps/s (collection: 0.040s, learning 0.081s)
                       Mean reward: 811.82
               Mean episode length: 248.48
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 161.6919
       Episode_Reward/object_height 0.0315
     Episode_Reward/reaching_object 0.7297
Episode_Termination/object_dropping 0.2500
       Episode_Termination/time_out 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 195919872
                    Iteration time: 0.12s
                      Time elapsed: 00:38:28
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1994/1 [0m                       

                       Computation: 723049 steps/s (collection: 0.043s, learning 0.093s)
                       Mean reward: 812.48
               Mean episode length: 247.49
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 161.4793
       Episode_Reward/object_height 0.0310
     Episode_Reward/reaching_object 0.7298
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 17.3333
--------------------------------------------------------------------------------
                   Total timesteps: 196018176
                    Iteration time: 0.14s
                      Time elapsed: 00:38:29
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1995/1 [0m                       

                       Computation: 805628 steps/s (collection: 0.041s, learning 0.081s)
                       Mean reward: 834.65
               Mean episode length: 247.54
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.6483
       Episode_Reward/object_height 0.0309
     Episode_Reward/reaching_object 0.7359
Episode_Termination/object_dropping 0.4167
       Episode_Termination/time_out 16.2500
--------------------------------------------------------------------------------
                   Total timesteps: 196116480
                    Iteration time: 0.12s
                      Time elapsed: 00:38:30
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1996/1 [0m                       

                       Computation: 684585 steps/s (collection: 0.051s, learning 0.092s)
                       Mean reward: 822.02
               Mean episode length: 247.68
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 163.6913
       Episode_Reward/object_height 0.0305
     Episode_Reward/reaching_object 0.7311
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 16.9167
--------------------------------------------------------------------------------
                   Total timesteps: 196214784
                    Iteration time: 0.14s
                      Time elapsed: 00:38:31
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1997/1 [0m                       

                       Computation: 697742 steps/s (collection: 0.043s, learning 0.098s)
                       Mean reward: 814.48
               Mean episode length: 247.07
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 161.8296
       Episode_Reward/object_height 0.0301
     Episode_Reward/reaching_object 0.7171
Episode_Termination/object_dropping 0.3750
       Episode_Termination/time_out 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 196313088
                    Iteration time: 0.14s
                      Time elapsed: 00:38:32
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1998/1 [0m                       

                       Computation: 785622 steps/s (collection: 0.042s, learning 0.084s)
                       Mean reward: 832.61
               Mean episode length: 246.48
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0021
      Episode_Reward/lifting_object 165.5534
       Episode_Reward/object_height 0.0304
     Episode_Reward/reaching_object 0.7291
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 196411392
                    Iteration time: 0.13s
                      Time elapsed: 00:38:34
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 1999/1 [0m                       

                       Computation: 739063 steps/s (collection: 0.043s, learning 0.090s)
                       Mean reward: 830.86
               Mean episode length: 246.84
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 165.1516
       Episode_Reward/object_height 0.0298
     Episode_Reward/reaching_object 0.7274
Episode_Termination/object_dropping 0.5000
       Episode_Termination/time_out 15.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196509696
                    Iteration time: 0.13s
                      Time elapsed: 00:38:35
                               ETA: 00:00:00

################################################################################
                      [1m Learning iteration 2000/1 [0m                       

                       Computation: 680343 steps/s (collection: 0.047s, learning 0.098s)
                       Mean reward: 840.84
               Mean episode length: 247.94
         Episode_Reward/action_rate -0.0002
           Episode_Reward/joint_vel -0.0022
      Episode_Reward/lifting_object 166.5685
       Episode_Reward/object_height 0.0302
     Episode_Reward/reaching_object 0.7299
Episode_Termination/object_dropping 0.5833
       Episode_Termination/time_out 26.4583
--------------------------------------------------------------------------------
                   Total timesteps: 196608000
                    Iteration time: 0.14s
                      Time elapsed: 00:38:36
                               ETA: 00:00:00

